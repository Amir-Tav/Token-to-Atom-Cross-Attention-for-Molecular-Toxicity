{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a660e5b",
   "metadata": {},
   "source": [
    "## phase 5 (Inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c008dcd",
   "metadata": {},
   "source": [
    "### 1:  Inference (calibrated specialist ensemble) + test export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b741c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded shared fusion model.\n",
      "✅ Loaded specialist heads for all labels.\n",
      "✅ Inference is ready: call predict_smiles(['CCO'], threshold_mode='fbeta15' or 'f1').\n"
     ]
    }
   ],
   "source": [
    "# === Cold-start Inference (checkpoint name-compatible) ===\n",
    "import os, json, math\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ---------------- Paths & basics ----------------\n",
    "BASE       = Path(\"v7\")\n",
    "PREP_DIR   = BASE / \"data\" / \"prepared\"\n",
    "DESC_DIR   = BASE / \"data\" / \"descriptors\"\n",
    "MODEL_DIR  = BASE / \"model\"\n",
    "CKPT_BEST  = MODEL_DIR / \"checkpoints\" / \"shared\" / \"best.pt\"\n",
    "ENS_DIR    = MODEL_DIR / \"ensembles\"\n",
    "CAL_DIR    = MODEL_DIR / \"calibration\"\n",
    "\n",
    "assert CKPT_BEST.exists(), f\"Missing shared checkpoint: {CKPT_BEST}\"\n",
    "assert (PREP_DIR / \"dataset_manifest.json\").exists(), \"Missing dataset manifest.\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---------------- Labels, temps, thresholds ----------------\n",
    "ds_manifest = json.loads((PREP_DIR / \"dataset_manifest.json\").read_text())\n",
    "LABEL_NAMES = ds_manifest[\"labels\"]\n",
    "DESC_IN_DIM = ds_manifest[\"n_features\"]  # 208\n",
    "\n",
    "temps      = json.loads((CAL_DIR / \"temps.json\").read_text())\n",
    "thresholds = json.loads((CAL_DIR / \"thresholds.json\").read_text())\n",
    "\n",
    "# ---------------- Text encoder (ChemBERTa) ----------------\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "class ChemBERTaEncoder(nn.Module):\n",
    "    def __init__(self, ckpt_name=\"seyonec/ChemBERTa-zinc-base-v1\", fusion_dim=256, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(ckpt_name)\n",
    "        self.backbone  = AutoModel.from_pretrained(ckpt_name)\n",
    "        self.pad_token_id = self.tokenizer.pad_token_id or self.tokenizer.eos_token_id\n",
    "        self.proj = nn.Sequential(nn.Dropout(dropout_p), nn.Linear(self.backbone.config.hidden_size, fusion_dim))\n",
    "        self.ln = nn.LayerNorm(fusion_dim)\n",
    "    def forward(self, smiles_list: List[str], max_length=256, add_special_tokens=True):\n",
    "        enc = self.tokenizer(list(smiles_list), padding=True, truncation=True,\n",
    "                             max_length=max_length, add_special_tokens=add_special_tokens,\n",
    "                             return_tensors=\"pt\")\n",
    "        input_ids, attention_mask = enc[\"input_ids\"].to(device), enc[\"attention_mask\"].to(device)\n",
    "        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state  # (B,L,H)\n",
    "        toks = self.ln(self.proj(out))  # (B,L,256)\n",
    "        return toks, attention_mask.to(dtype=torch.int32)\n",
    "\n",
    "# ---------------- Graph encoder (match checkpoint names) ----------------\n",
    "from rdkit import Chem as _Chem\n",
    "\n",
    "ATOM_LIST = [\"H\",\"C\",\"N\",\"O\",\"F\",\"P\",\"S\",\"Cl\",\"Br\",\"I\"]\n",
    "\n",
    "def _one_hot(v, choices):\n",
    "    z = [0]*len(choices)\n",
    "    if v in choices:\n",
    "        z[choices.index(v)] = 1\n",
    "    return z\n",
    "\n",
    "def _bucket_oh(v, lo, hi):\n",
    "    buckets = list(range(lo, hi+1))\n",
    "    o = [0]*(len(buckets)+1)\n",
    "    idx = v - lo\n",
    "    o[idx if 0 <= idx < len(buckets) else -1] = 1\n",
    "    return o\n",
    "\n",
    "def _atom_feat(atom):\n",
    "    hybs = [\n",
    "        _Chem.rdchem.HybridizationType.S, _Chem.rdchem.HybridizationType.SP,\n",
    "        _Chem.rdchem.HybridizationType.SP2, _Chem.rdchem.HybridizationType.SP3,\n",
    "        _Chem.rdchem.HybridizationType.SP3D, _Chem.rdchem.HybridizationType.SP3D2\n",
    "    ]\n",
    "    chir = [\n",
    "        _Chem.rdchem.ChiralType.CHI_UNSPECIFIED,\n",
    "        _Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CW,\n",
    "        _Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CCW,\n",
    "        _Chem.rdchem.ChiralType.CHI_OTHER\n",
    "    ]\n",
    "    sym = atom.GetSymbol()\n",
    "    feat = _one_hot(sym if sym in ATOM_LIST else \"other\", ATOM_LIST+[\"other\"])\n",
    "    feat += _bucket_oh(atom.GetDegree(), 0, 5)\n",
    "    feat += _bucket_oh(atom.GetFormalCharge(), -2, 2)\n",
    "    feat += (_one_hot(atom.GetHybridization(), hybs)+[0])  # +other\n",
    "    feat += [int(atom.GetIsAromatic())]\n",
    "    feat += [int(atom.IsInRing())]\n",
    "    feat += _one_hot(atom.GetChiralTag(), chir)\n",
    "    feat += _bucket_oh(atom.GetTotalNumHs(includeNeighbors=True), 0, 4)\n",
    "    feat += _bucket_oh(atom.GetTotalValence(), 0, 5)\n",
    "    feat += [atom.GetMass()/200.0]\n",
    "    return feat  # ~51 dims\n",
    "\n",
    "def _smiles_to_graph(smi, max_nodes=128):\n",
    "    mol = _Chem.MolFromSmiles(smi)\n",
    "    if mol is None or mol.GetNumAtoms() == 0:\n",
    "        return np.zeros((0,0), dtype=np.float32), np.zeros((0,0), dtype=np.float32)\n",
    "    feats = [_atom_feat(mol.GetAtomWithIdx(i)) for i in range(mol.GetNumAtoms())]\n",
    "    x = np.asarray(feats, dtype=np.float32)\n",
    "    N = mol.GetNumAtoms()\n",
    "    adj = np.zeros((N, N), dtype=np.float32)\n",
    "    for b in mol.GetBonds():\n",
    "        i, j = b.GetBeginAtomIdx(), b.GetEndAtomIdx()\n",
    "        adj[i, j] = 1.0; adj[j, i] = 1.0\n",
    "    if N > max_nodes:\n",
    "        x = x[:max_nodes]; adj = adj[:max_nodes, :max_nodes]\n",
    "    return x, adj\n",
    "\n",
    "def _collate_graphs(smiles_batch, max_nodes=128):\n",
    "    graphs = [_smiles_to_graph(s) for s in smiles_batch]\n",
    "    Nmax = max([g[0].shape[0] for g in graphs] + [1])\n",
    "    Fnode = graphs[0][0].shape[1] if graphs[0][0].size>0 else 51\n",
    "    B = len(graphs)\n",
    "    X = np.zeros((B, Nmax, Fnode), dtype=np.float32)\n",
    "    A = np.zeros((B, Nmax, Nmax), dtype=np.float32)\n",
    "    M = np.zeros((B, Nmax), dtype=np.int64)\n",
    "    for i, (x, a) in enumerate(graphs):\n",
    "        n = x.shape[0]\n",
    "        if n == 0: continue\n",
    "        X[i, :n, :] = x\n",
    "        A[i, :n, :n] = a\n",
    "        M[i, :n] = 1\n",
    "    return torch.from_numpy(X).to(device), torch.from_numpy(A).to(device), torch.from_numpy(M).to(device)\n",
    "\n",
    "class GINLayer(nn.Module):\n",
    "    def __init__(self, h=256, p=0.1):\n",
    "        super().__init__()\n",
    "        self.eps = nn.Parameter(torch.tensor(0.0))\n",
    "        self.mlp = nn.Sequential(nn.Linear(h, h), nn.GELU(), nn.LayerNorm(h), nn.Dropout(p))\n",
    "    def forward(self, x, adj, mask):\n",
    "        out = (1.0 + self.eps) * x + torch.matmul(adj, x)\n",
    "        out = self.mlp(out)\n",
    "        return out * mask.unsqueeze(-1).to(out.dtype)\n",
    "\n",
    "class GraphGINEncoder(nn.Module):\n",
    "    def __init__(self, node_in_dim=51, hidden_dim=256, n_layers=4, p=0.1):\n",
    "        super().__init__()\n",
    "        self.inp = nn.Sequential(nn.Linear(node_in_dim, hidden_dim), nn.GELU(), nn.Dropout(p))\n",
    "        self.layers = nn.ModuleList([GINLayer(hidden_dim, p) for _ in range(n_layers)])\n",
    "        # IMPORTANT: name must be 'out_ln' to match checkpoint\n",
    "        self.out_ln = nn.LayerNorm(hidden_dim)\n",
    "    def forward(self, smiles_list: List[str], max_nodes=128):\n",
    "        X, A, M = _collate_graphs(smiles_list, max_nodes=max_nodes)\n",
    "        h = self.inp(X)\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, A, M)\n",
    "        return self.out_ln(h), M.to(dtype=torch.int32)\n",
    "\n",
    "# ---------------- Fusion blocks ----------------\n",
    "def masked_mean(x: torch.Tensor, mask: torch.Tensor, dim: int) -> torch.Tensor:\n",
    "    mask = mask.to(dtype=x.dtype, device=x.device)\n",
    "    denom = mask.sum(dim=dim, keepdim=True).clamp(min=1.0)\n",
    "    return (x * mask.unsqueeze(-1)).sum(dim=dim) / denom\n",
    "\n",
    "class CrossAttentionBlock(nn.Module):\n",
    "    def __init__(self, dim=256, n_heads=4, p=0.1):\n",
    "        super().__init__()\n",
    "        self.mha = nn.MultiheadAttention(dim, n_heads, dropout=p, batch_first=False)\n",
    "        self.ln  = nn.LayerNorm(dim)\n",
    "        self.do  = nn.Dropout(p)\n",
    "    def forward(self, text_tokens, text_mask, graph_nodes, graph_mask):\n",
    "        Q = text_tokens.transpose(0,1)   # (L,B,D)\n",
    "        K = graph_nodes.transpose(0,1)   # (N,B,D)\n",
    "        V = graph_nodes.transpose(0,1)\n",
    "        kpm = (graph_mask == 0)          # (B,N) True where pad\n",
    "        attn, _ = self.mha(Q, K, V, key_padding_mask=kpm)\n",
    "        attn = attn.transpose(0,1)       # (B,L,D)\n",
    "        return self.ln(text_tokens + self.do(attn))\n",
    "\n",
    "class DescriptorMLP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim=256, hidden=256, p=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden), nn.GELU(), nn.Dropout(p),\n",
    "            nn.Linear(hidden, out_dim), nn.GELU(), nn.Dropout(p)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "# IMPORTANT: name must be 'mlp' to match checkpoint ('shared_head.mlp.*')\n",
    "class FusionClassifier(nn.Module):\n",
    "    def __init__(self, dim=256, n_labels=12, p=0.1):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim*3, dim*2), nn.GELU(), nn.Dropout(p),\n",
    "            nn.Linear(dim*2, n_labels)\n",
    "        )\n",
    "    def forward(self, fused_vec):\n",
    "        return self.mlp(fused_vec)\n",
    "\n",
    "class V7FusionModel(nn.Module):\n",
    "    def __init__(self, text_encoder, graph_encoder, desc_in_dim=208, dim=256, n_labels=12, n_heads=4, p=0.1):\n",
    "        super().__init__()\n",
    "        self.text_encoder=text_encoder\n",
    "        self.graph_encoder=graph_encoder\n",
    "        self.cross=CrossAttentionBlock(dim, n_heads, p)\n",
    "        self.desc_mlp=DescriptorMLP(desc_in_dim, out_dim=dim, hidden=256, p=p)\n",
    "        self.shared_head=FusionClassifier(dim, n_labels, p)\n",
    "    def forward(self, smiles_list, desc_feats, return_intermediates=False):\n",
    "        tt, tm = self.text_encoder(smiles_list, max_length=256)\n",
    "        gn, gm = self.graph_encoder(smiles_list, max_nodes=128)\n",
    "        tt, tm, gn, gm, desc_feats = tt.to(device), tm.to(device), gn.to(device), gm.to(device), desc_feats.to(device)\n",
    "        tta = self.cross(tt, tm, gn, gm)\n",
    "        de  = self.desc_mlp(desc_feats)\n",
    "        text_pool  = masked_mean(tta, tm, 1)\n",
    "        graph_pool = masked_mean(gn,  gm, 1)\n",
    "        fused = torch.cat([text_pool, graph_pool, de], dim=-1)  # (B,768)\n",
    "        logits = self.shared_head(fused)\n",
    "        if return_intermediates:\n",
    "            return logits, fused\n",
    "        return logits\n",
    "\n",
    "# ---------------- Build & load ----------------\n",
    "text_encoder = ChemBERTaEncoder().to(device)\n",
    "graph_encoder= GraphGINEncoder().to(device)\n",
    "v7_shared    = V7FusionModel(text_encoder, graph_encoder, desc_in_dim=DESC_IN_DIM, n_labels=len(LABEL_NAMES)).to(device)\n",
    "ckpt = torch.load(CKPT_BEST, map_location=device)\n",
    "v7_shared.load_state_dict(ckpt[\"model\"], strict=True)\n",
    "v7_shared.eval()\n",
    "print(\"✅ Loaded shared fusion model.\")\n",
    "\n",
    "# ---------------- Specialist heads (match boosted Cell 2) ----------------\n",
    "class LabelHead(nn.Module):\n",
    "    def __init__(self, in_dim=768, h1=512, h2=256, h3=128, p=0.30):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(nn.Linear(in_dim, h1), nn.GELU(), nn.LayerNorm(h1), nn.Dropout(p))\n",
    "        self.block2 = nn.Sequential(nn.Linear(h1, h2), nn.GELU(), nn.LayerNorm(h2), nn.Dropout(p))\n",
    "        self.block3 = nn.Sequential(nn.Linear(h2, h3), nn.GELU(), nn.LayerNorm(h3), nn.Dropout(p))\n",
    "        self.out    = nn.Linear(h3, 1)\n",
    "        self.short  = nn.Linear(in_dim, h3)\n",
    "    def forward(self, x):\n",
    "        z1 = self.block1(x); z2 = self.block2(z1); z3 = self.block3(z2)\n",
    "        z  = z3 + self.short(x)\n",
    "        return self.out(z).squeeze(-1)\n",
    "\n",
    "def _load_best_head(label: str) -> nn.Module:\n",
    "    # pick seed dir with highest best_ap\n",
    "    cands = []\n",
    "    for sd in sorted((ENS_DIR / label).glob(\"seed*/\")):\n",
    "        mfile = sd / \"metrics.json\"\n",
    "        if mfile.exists():\n",
    "            try:\n",
    "                ap = float(json.loads(mfile.read_text()).get(\"best_ap\", float(\"nan\")))\n",
    "                cands.append((ap, sd))\n",
    "            except Exception:\n",
    "                pass\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(f\"No trained heads for label {label}\")\n",
    "    cands.sort(key=lambda x: (-1.0 if math.isnan(x[0]) else x[0]), reverse=True)\n",
    "    best_dir = cands[0][1]\n",
    "    ck = torch.load(best_dir / \"best.pt\", map_location=device)\n",
    "    cfg = ck.get(\"config\", {\"in_dim\":768,\"h1\":512,\"h2\":256,\"h3\":128,\"dropout\":0.30})\n",
    "    head = LabelHead(in_dim=cfg[\"in_dim\"], h1=cfg[\"h1\"], h2=cfg[\"h2\"], h3=cfg[\"h3\"], p=cfg.get(\"dropout\",0.30)).to(device)\n",
    "    head.load_state_dict(ck[\"model\"], strict=True)\n",
    "    head.eval()\n",
    "    return head\n",
    "\n",
    "HEADS: Dict[str, nn.Module] = {lbl: _load_best_head(lbl) for lbl in LABEL_NAMES}\n",
    "print(\"✅ Loaded specialist heads for all labels.\")\n",
    "\n",
    "# ---------------- Descriptors for ad-hoc SMILES ----------------\n",
    "# For quick testing without the exact 208-d extractor, use standardized zero vector for descriptors.\n",
    "def prepare_desc_matrix(smiles_list: List[str]) -> torch.Tensor:\n",
    "    n = len(smiles_list)\n",
    "    Z = np.zeros((n, DESC_IN_DIM), dtype=np.float32)  # standardized zeros (mean feature)\n",
    "    return torch.tensor(Z, dtype=torch.float32, device=device)\n",
    "\n",
    "# ---------------- Fused feature builder ----------------\n",
    "@torch.no_grad()\n",
    "def fused_from_smiles(smiles_list: List[str], desc_tensor: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "    if desc_tensor is None:\n",
    "        desc_tensor = prepare_desc_matrix(smiles_list)\n",
    "    tt, tm = v7_shared.text_encoder(smiles_list, max_length=256)\n",
    "    gn, gm = v7_shared.graph_encoder(smiles_list, max_nodes=128)\n",
    "    tt, tm = tt.to(device), tm.to(device)\n",
    "    gn, gm = gn.to(device), gm.to(device)\n",
    "    de = v7_shared.desc_mlp(desc_tensor.to(device))\n",
    "    # cross-attend & pool\n",
    "    tta = v7_shared.cross(tt, tm, gn, gm)\n",
    "    text_pool  = masked_mean(tta, tm, 1)\n",
    "    graph_pool = masked_mean(gn,  gm, 1)\n",
    "    return torch.cat([text_pool, graph_pool, de], dim=-1)  # (B,768)\n",
    "\n",
    "# ---------------- Public API ----------------\n",
    "def predict_smiles(smiles_list: List[str], threshold_mode: str = \"fbeta15\"):\n",
    "    \"\"\"\n",
    "    Returns list[dict]: one per SMILES\n",
    "      label -> {logit, prob_raw, prob_cal, decision}\n",
    "    \"\"\"\n",
    "    assert threshold_mode in (\"f1\", \"fbeta15\")\n",
    "    fused = fused_from_smiles(smiles_list)  # (B,768)\n",
    "    out = []\n",
    "    for i in range(fused.size(0)):\n",
    "        row = {}\n",
    "        x = fused[i:i+1]\n",
    "        for label in LABEL_NAMES:\n",
    "            head = HEADS[label]\n",
    "            with torch.no_grad():\n",
    "                logit = head(x).item()\n",
    "            T   = max(float(temps.get(label, 1.0)), 1e-3)\n",
    "            p_r = 1.0 / (1.0 + math.e**(-logit))\n",
    "            p_c = 1.0 / (1.0 + math.e**(-logit / T))\n",
    "            th  = thresholds[label][\"th_fbeta15\"] if threshold_mode==\"fbeta15\" else thresholds[label][\"th_f1\"]\n",
    "            row[label] = {\"logit\": float(logit), \"prob_raw\": float(p_r), \"prob_cal\": float(p_c), \"decision\": bool(p_c >= float(th))}\n",
    "        out.append(row)\n",
    "    return out\n",
    "\n",
    "print(\"✅ Inference is ready: call predict_smiles(['CCO'], threshold_mode='fbeta15' or 'f1').\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a995e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12/12 label columns in the Excel.\n",
      "\n",
      "SMILES: CCOc1ccc2nc(S(N)(=O)=O)sc2c1\n",
      "  NR-AhR        prob=0.594  th=0.681  → pred=0\n",
      "  SR-ARE        prob=0.533  th=0.532  → pred=1\n",
      "  NR-ER         prob=0.529  th=0.542  → pred=0\n",
      "  SR-ATAD5      prob=0.529  th=0.567  → pred=0\n",
      "  NR-PPAR-gamma  prob=0.521  th=0.521  → pred=1\n",
      "  True positives: NR-AhR, SR-ARE\n",
      "  Pred positives (f1): NR-PPAR-gamma, SR-ARE\n",
      "\n",
      "SMILES: CCN1C(=O)NC(c2ccccc2)C1=O\n",
      "  NR-AhR        prob=0.616  th=0.681  → pred=0\n",
      "  SR-MMP        prob=0.554  th=0.600  → pred=0\n",
      "  SR-ATAD5      prob=0.537  th=0.567  → pred=0\n",
      "  NR-PPAR-gamma  prob=0.536  th=0.521  → pred=1\n",
      "  SR-p53        prob=0.534  th=0.546  → pred=0\n",
      "  True positives: —\n",
      "  Pred positives (f1): NR-PPAR-gamma\n",
      "\n",
      "SMILES: O=C(O)Cc1cc(I)c(Oc2ccc(O)c(I)c2)c(I)c1\n",
      "  NR-AhR        prob=0.670  th=0.681  → pred=0\n",
      "  SR-MMP        prob=0.641  th=0.600  → pred=1\n",
      "  NR-ER-LBD     prob=0.580  th=0.650  → pred=0\n",
      "  NR-Aromatase  prob=0.569  th=0.604  → pred=0\n",
      "  SR-p53        prob=0.560  th=0.546  → pred=1\n",
      "  True positives: NR-ER, SR-ARE, SR-HSE, SR-p53\n",
      "  Pred positives (f1): NR-PPAR-gamma, SR-ARE, SR-MMP, SR-p53\n",
      "\n",
      "SMILES: CC(O)CNCC(C)O\n",
      "  NR-AR         prob=0.516  th=0.573  → pred=0\n",
      "  NR-ER         prob=0.510  th=0.542  → pred=0\n",
      "  SR-HSE        prob=0.503  th=0.551  → pred=0\n",
      "  SR-ARE        prob=0.500  th=0.532  → pred=0\n",
      "  NR-PPAR-gamma  prob=0.494  th=0.521  → pred=0\n",
      "  True positives: —\n",
      "  Pred positives (f1): —\n",
      "\n",
      "SMILES: O=c1cc(-c2ccccc2)oc2cc(O)cc(O)c12\n",
      "  NR-AhR        prob=0.708  th=0.681  → pred=1\n",
      "  SR-MMP        prob=0.668  th=0.600  → pred=1\n",
      "  NR-ER-LBD     prob=0.617  th=0.650  → pred=0\n",
      "  NR-Aromatase  prob=0.576  th=0.604  → pred=0\n",
      "  SR-ARE        prob=0.567  th=0.532  → pred=1\n",
      "  True positives: NR-AhR, NR-ER, NR-ER-LBD, NR-PPAR-gamma, SR-ARE, SR-MMP\n",
      "  Pred positives (f1): NR-AhR, NR-ER, NR-PPAR-gamma, SR-ARE, SR-HSE, SR-MMP, SR-p53\n",
      "\n",
      "=== Summary (micro over labels with truth present) ===\n",
      "TP=8 FP=3 FN=4\n",
      "Precision=0.727 Recall=0.667 F1=0.696\n",
      "\n",
      "Saved detailed results → v7\\results\\inference\\f1.csv\n"
     ]
    }
   ],
   "source": [
    "# my_smiles = [\"CCOc1ccc2nc(S(N)(=O)=O)sc2c1\"]\n",
    "# mode = \"f1\"  # or \"f1\" fbeta15\n",
    "\n",
    "# results = predict_smiles(my_smiles, threshold_mode=mode)\n",
    "\n",
    "# from operator import itemgetter\n",
    "# for smi, rec in zip(my_smiles, results):\n",
    "#     print(\"\\nSMILES:\", smi)\n",
    "#     top = sorted([(lbl, d[\"prob_cal\"], d[\"decision\"]) for lbl, d in rec.items()],\n",
    "#                  key=itemgetter(1), reverse=True)[:5]\n",
    "#     for lbl, p, dec in top:\n",
    "#         th = thresholds[lbl][\"th_fbeta15\"] if mode==\"fbeta15\" else thresholds[lbl][\"th_f1\"]\n",
    "#         print(f\"  {lbl:12s}  prob={p:.3f}  th={th:.3f}  → pred={int(dec)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ad-hoc evaluation on Excel truth labels (simple)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from operator import itemgetter\n",
    "import math, json, os\n",
    "\n",
    "# ----------- CONFIG -----------\n",
    "EXCEL_PATH = Path(\"tox21_dualenc_v1/data/raw/Truth Lables.xlsx\")\n",
    "MODE = \"f1\"            # \"f1\" or \"fbeta15\"\n",
    "N_DISPLAY = 5          # how many rows to pretty-print (set to None to print all)\n",
    "OUT_CSV = Path(\"v7/results/inference/f1.csv\")\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----------- Checks -----------\n",
    "assert 'predict_smiles' in globals(), \"predict_smiles() not found. Run the cold-start inference cell first.\"\n",
    "assert 'LABEL_NAMES' in globals(), \"LABEL_NAMES not found. Run the cold-start inference cell first.\"\n",
    "assert 'thresholds' in globals(), \"thresholds not found. Run Phase 4 calibration cell first.\"\n",
    "assert EXCEL_PATH.exists(), f\"Cannot find: {EXCEL_PATH}\"\n",
    "\n",
    "# ----------- Load Excel -----------\n",
    "df = pd.read_excel(EXCEL_PATH)\n",
    "cols_lower = {c.lower(): c for c in df.columns}\n",
    "# find smiles col (case-insensitive)\n",
    "smiles_col = None\n",
    "for key in [\"smiles\", \"smile\", \"SMILES\", \"Smiles\"]:\n",
    "    if key.lower() in cols_lower:\n",
    "        smiles_col = cols_lower[key.lower()]\n",
    "        break\n",
    "if smiles_col is None:\n",
    "    # fallback: first column named like 'smile*'\n",
    "    cand = [c for c in df.columns if c.lower().startswith(\"smiles\")]\n",
    "    smiles_col = cand[0] if cand else None\n",
    "assert smiles_col is not None, \"Could not locate a SMILES column in the Excel file.\"\n",
    "\n",
    "# ----------- Match label columns (case/spacing/hyphen-insensitive) -----------\n",
    "def _norm(s: str) -> str:\n",
    "    return \"\".join(ch for ch in str(s).lower() if ch.isalnum())\n",
    "\n",
    "label_norm = { _norm(lbl): lbl for lbl in LABEL_NAMES }\n",
    "col_for_label = {}  # label -> column name in df (if present)\n",
    "\n",
    "for col in df.columns:\n",
    "    if col == smiles_col: \n",
    "        continue\n",
    "    n = _norm(col)\n",
    "    if n in label_norm:\n",
    "        col_for_label[label_norm[n]] = col\n",
    "\n",
    "available_labels = [lbl for lbl in LABEL_NAMES if lbl in col_for_label]\n",
    "missing_labels = [lbl for lbl in LABEL_NAMES if lbl not in col_for_label]\n",
    "print(f\"Found {len(available_labels)}/{len(LABEL_NAMES)} label columns in the Excel.\")\n",
    "if missing_labels:\n",
    "    print(\"Missing label columns (will be skipped in scoring):\", \", \".join(missing_labels))\n",
    "\n",
    "# ----------- Parse truth values -----------\n",
    "def parse_truth(v):\n",
    "    if pd.isna(v): \n",
    "        return None\n",
    "    if isinstance(v, (int, np.integer)): \n",
    "        return int(v) == 1\n",
    "    if isinstance(v, float): \n",
    "        if math.isnan(v): return None\n",
    "        return int(v) == 1\n",
    "    s = str(v).strip().lower()\n",
    "    if s in (\"1\",\"y\",\"yes\",\"true\",\"t\",\"pos\",\"positive\"):\n",
    "        return True\n",
    "    if s in (\"0\",\"n\",\"no\",\"false\",\"f\",\"neg\",\"negative\"):\n",
    "        return False\n",
    "    # anything else → None (unknown)\n",
    "    return None\n",
    "\n",
    "# ----------- Run predictions -----------\n",
    "smiles_list = df[smiles_col].astype(str).tolist()\n",
    "preds = predict_smiles(smiles_list, threshold_mode=MODE)  # list[dict[label -> details]]\n",
    "\n",
    "# ----------- Build a simple evaluation table -----------\n",
    "rows = []\n",
    "micro_tp = micro_fp = micro_fn = 0\n",
    "\n",
    "for i, (smi, rec) in enumerate(zip(smiles_list, preds)):\n",
    "    # truth set (only for labels available in Excel)\n",
    "    true_pos = set()\n",
    "    true_neg = set()\n",
    "    for lbl in available_labels:\n",
    "        val = parse_truth(df.loc[i, col_for_label[lbl]])\n",
    "        if val is True:\n",
    "            true_pos.add(lbl)\n",
    "        elif val is False:\n",
    "            true_neg.add(lbl)\n",
    "        # None → skip\n",
    "\n",
    "    # predicted positives at chosen threshold\n",
    "    pred_pos = {lbl for lbl, d in rec.items() if d[\"decision\"]}\n",
    "    # accumulate micro counts only on labels where truth is known\n",
    "    for lbl in available_labels:\n",
    "        val = parse_truth(df.loc[i, col_for_label[lbl]])\n",
    "        if val is None: \n",
    "            continue\n",
    "        if lbl in pred_pos and val is True:\n",
    "            micro_tp += 1\n",
    "        elif lbl in pred_pos and val is False:\n",
    "            micro_fp += 1\n",
    "        elif lbl not in pred_pos and val is True:\n",
    "            micro_fn += 1\n",
    "\n",
    "    # top-5 by calibrated probability (for pretty print)\n",
    "    top5 = sorted([(lbl, d[\"prob_cal\"], d[\"decision\"]) for lbl, d in rec.items()],\n",
    "                  key=itemgetter(1), reverse=True)[:5]\n",
    "\n",
    "    # save a row for CSV: include probs & preds, and truths if present\n",
    "    row = {\"smiles\": smi}\n",
    "    for lbl, det in rec.items():\n",
    "        row[f\"{lbl}_prob\"] = det[\"prob_cal\"]\n",
    "        row[f\"{lbl}_pred\"] = int(det[\"decision\"])\n",
    "        if lbl in available_labels:\n",
    "            tv = parse_truth(df.loc[i, col_for_label[lbl]])\n",
    "            row[f\"{lbl}_true\"] = (None if tv is None else int(tv))\n",
    "    rows.append(row)\n",
    "\n",
    "    # pretty print a few rows\n",
    "    if N_DISPLAY is None or i < N_DISPLAY:\n",
    "        print(\"\\nSMILES:\", smi)\n",
    "        for lbl, p, dec in top5:\n",
    "            th = thresholds[lbl][\"th_fbeta15\"] if MODE==\"fbeta15\" else thresholds[lbl][\"th_f1\"]\n",
    "            print(f\"  {lbl:12s}  prob={p:.3f}  th={float(th):.3f}  → pred={int(dec)}\")\n",
    "        if available_labels:\n",
    "            print(\"  True positives:\", \", \".join(sorted(true_pos)) if true_pos else \"—\")\n",
    "            chosen = \", \".join(sorted(pred_pos)) if pred_pos else \"—\"\n",
    "            print(f\"  Pred positives ({MODE}): {chosen}\")\n",
    "\n",
    "# ----------- Micro summary -----------\n",
    "prec = micro_tp / (micro_tp + micro_fp) if (micro_tp + micro_fp) > 0 else 0.0\n",
    "rec  = micro_tp / (micro_tp + micro_fn) if (micro_tp + micro_fn) > 0 else 0.0\n",
    "f1   = (2*prec*rec)/(prec+rec) if (prec+rec) > 0 else 0.0\n",
    "\n",
    "print(\"\\n=== Summary (micro over labels with truth present) ===\")\n",
    "print(f\"TP={micro_tp} FP={micro_fp} FN={micro_fn}\")\n",
    "print(f\"Precision={prec:.3f} Recall={rec:.3f} F1={f1:.3f}\")\n",
    "\n",
    "# ----------- Save CSV -----------\n",
    "pd.DataFrame(rows).to_csv(OUT_CSV, index=False)\n",
    "print(f\"\\nSaved detailed results → {OUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c22b9d3",
   "metadata": {},
   "source": [
    "### 2: Calibrate shared head, create blended ensemble, refit thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df9d897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating shared head temperatures on val...\n",
      "  NR-AR: T_shared=0.134\n",
      "  NR-AR-LBD: T_shared=0.132\n",
      "  NR-AhR: T_shared=0.167\n",
      "  NR-Aromatase: T_shared=0.126\n",
      "  NR-ER: T_shared=0.134\n",
      "  NR-ER-LBD: T_shared=0.110\n",
      "  NR-PPAR-gamma: T_shared=0.167\n",
      "  SR-ARE: T_shared=0.260\n",
      "  SR-ATAD5: T_shared=0.146\n",
      "  SR-HSE: T_shared=0.100\n",
      "  SR-MMP: T_shared=0.250\n",
      "  SR-p53: T_shared=0.119\n",
      "Saved → v7\\model\\calibration\\temps_shared.json\n",
      "\n",
      "Blending probs on val with alpha=0.80 (specialist weight)\n",
      "  NR-AR: AP_val=0.171 th_f1=0.653 th_fb15=0.653\n",
      "  NR-AR-LBD: AP_val=0.253 th_f1=0.621 th_fb15=0.621\n",
      "  NR-AhR: AP_val=0.524 th_f1=0.709 th_fb15=0.642\n",
      "  NR-Aromatase: AP_val=0.295 th_f1=0.564 th_fb15=0.474\n",
      "  NR-ER: AP_val=0.253 th_f1=0.547 th_fb15=0.480\n",
      "  NR-ER-LBD: AP_val=0.139 th_f1=0.589 th_fb15=0.589\n",
      "  NR-PPAR-gamma: AP_val=0.063 th_f1=0.441 th_fb15=0.427\n",
      "  SR-ARE: AP_val=0.344 th_f1=0.528 th_fb15=0.528\n",
      "  SR-ATAD5: AP_val=0.171 th_f1=0.483 th_fb15=0.483\n",
      "  SR-HSE: AP_val=0.196 th_f1=0.472 th_fb15=0.459\n",
      "  SR-MMP: AP_val=0.444 th_f1=0.589 th_fb15=0.589\n",
      "  SR-p53: AP_val=0.210 th_f1=0.513 th_fb15=0.478\n",
      "\n",
      "Saved → v7\\model\\calibration\\thresholds_blend.json\n",
      "\n",
      "✅ Blend ready: use predict_smiles_blend([...], mode='fbeta15' or 'f1').\n"
     ]
    }
   ],
   "source": [
    "# Phase 5 — Cell 2 (optional): shared+specialist blend with calibration and new thresholds\n",
    "import json, math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "BASE      = Path(\"v7\")\n",
    "FUSED_DIR = BASE / \"data\" / \"fused\"\n",
    "CAL_DIR   = BASE / \"model\" / \"calibration\"\n",
    "ENS_DIR   = BASE / \"model\" / \"ensembles\"\n",
    "CAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Expect these in memory from earlier cold-start cell:\n",
    "# v7_shared (with .shared_head), HEADS (specialists), LABEL_NAMES, temps (specialist temps)\n",
    "assert 'v7_shared' in globals() and 'HEADS' in globals() and 'LABEL_NAMES' in globals() and 'temps' in globals()\n",
    "\n",
    "# ---- load val fused + labels/mask ----\n",
    "Xva = np.load(FUSED_DIR / \"val_fused.npy\")     # (N,768)\n",
    "Yva = np.load(FUSED_DIR / \"val_Y.npy\")         # (N,12)\n",
    "Mva = np.load(FUSED_DIR / \"val_mask.npy\")      # (N,12) True where missing\n",
    "\n",
    "Xva_t = torch.tensor(Xva, dtype=torch.float32, device=device)\n",
    "\n",
    "# ---- helper: fit per-label temperature (on logits) ----\n",
    "def fit_temperature(logits: np.ndarray, y: np.ndarray, max_iter=200, lr=0.05) -> float:\n",
    "    t = torch.tensor([1.0], dtype=torch.float32, requires_grad=True, device=device)\n",
    "    x = torch.tensor(logits, dtype=torch.float32, device=device)\n",
    "    y = torch.tensor(y,      dtype=torch.float32, device=device)\n",
    "    opt = torch.optim.Adam([t], lr=lr)\n",
    "    for _ in range(max_iter):\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        z = x / (t.clamp(min=1e-3))\n",
    "        p = torch.sigmoid(z).clamp(1e-6, 1-1e-6)\n",
    "        loss = - (y*torch.log(p) + (1-y)*torch.log(1-p)).mean()\n",
    "        loss.backward(); opt.step()\n",
    "    return float(t.detach().cpu().item())\n",
    "\n",
    "def best_thresholds(y_true: np.ndarray, probs: np.ndarray):\n",
    "    prec, rec, th = precision_recall_curve(y_true, probs)\n",
    "    eps = 1e-8\n",
    "    f1 = (2*prec*rec) / np.maximum(prec+rec, eps)\n",
    "    beta = 1.5\n",
    "    fb = ((1+beta**2)*prec*rec) / np.maximum((beta**2)*prec + rec, eps)\n",
    "    th_f1 = th[np.nanargmax(f1[1:])] if th.size>0 else 0.5\n",
    "    th_fb = th[np.nanargmax(fb[1:])] if th.size>0 else 0.5\n",
    "    try:\n",
    "        ap = float(average_precision_score(y_true, probs))\n",
    "    except Exception:\n",
    "        ap = float(\"nan\")\n",
    "    return {\"th_f1\": float(th_f1), \"th_fbeta15\": float(th_fb), \"ap_val\": ap}\n",
    "\n",
    "# ---- 1) Calibrate SHARED head per label on val ----\n",
    "print(\"Calibrating shared head temperatures on val...\")\n",
    "logits_shared = v7_shared.shared_head(Xva_t).detach().cpu().numpy()  # (N,12)\n",
    "temps_shared = {}\n",
    "for j, lbl in enumerate(LABEL_NAMES):\n",
    "    valid = ~Mva[:, j]\n",
    "    if valid.sum() == 0 or np.all(Yva[valid, j] == Yva[valid, j][0]):\n",
    "        temps_shared[lbl] = 1.0\n",
    "        continue\n",
    "    T = fit_temperature(logits_shared[valid, j], Yva[valid, j])\n",
    "    temps_shared[lbl] = T\n",
    "    print(f\"  {lbl}: T_shared={T:.3f}\")\n",
    "(Path(CAL_DIR / \"temps_shared.json\")).write_text(json.dumps(temps_shared, indent=2))\n",
    "print(\"Saved →\", CAL_DIR / \"temps_shared.json\")\n",
    "\n",
    "# ---- 2) Build BLENDED probs on val (alpha specialist, (1-alpha) shared) ----\n",
    "ALPHA = 0.8  # weight on specialist; tweak if desired\n",
    "print(f\"\\nBlending probs on val with alpha={ALPHA:.2f} (specialist weight)\")\n",
    "\n",
    "# specialist logits on val\n",
    "spec_logits = np.zeros_like(logits_shared)\n",
    "with torch.no_grad():\n",
    "    for j, lbl in enumerate(LABEL_NAMES):\n",
    "        head = HEADS[lbl]\n",
    "        spec_logits[:, j] = head(Xva_t).detach().cpu().numpy()\n",
    "\n",
    "# calibrate both streams\n",
    "p_spec_val   = np.zeros_like(spec_logits)\n",
    "p_shared_val = np.zeros_like(logits_shared)\n",
    "for j, lbl in enumerate(LABEL_NAMES):\n",
    "    T_spec   = max(float(temps.get(lbl, 1.0)), 1e-3)\n",
    "    T_shared = max(float(temps_shared.get(lbl, 1.0)), 1e-3)\n",
    "    p_spec_val[:, j]   = 1. / (1. + np.exp(-spec_logits[:, j]   / T_spec))\n",
    "    p_shared_val[:, j] = 1. / (1. + np.exp(-logits_shared[:, j] / T_shared))\n",
    "\n",
    "p_blend_val = ALPHA * p_spec_val + (1-ALPHA) * p_shared_val\n",
    "p_blend_val = np.clip(p_blend_val, 0.0, 1.0)\n",
    "\n",
    "# ---- 3) Refit thresholds for BLEND on val ----\n",
    "thresholds_blend = {}\n",
    "for j, lbl in enumerate(LABEL_NAMES):\n",
    "    valid = ~Mva[:, j]\n",
    "    if valid.sum() == 0 or np.all(Yva[valid, j] == Yva[valid, j][0]):\n",
    "        thresholds_blend[lbl] = {\"th_f1\": 0.5, \"th_fbeta15\": 0.5, \"ap_val\": float(\"nan\")}\n",
    "        continue\n",
    "    thresholds_blend[lbl] = best_thresholds(Yva[valid, j], p_blend_val[valid, j])\n",
    "    print(f\"  {lbl}: AP_val={thresholds_blend[lbl]['ap_val']:.3f} th_f1={thresholds_blend[lbl]['th_f1']:.3f} th_fb15={thresholds_blend[lbl]['th_fbeta15']:.3f}\")\n",
    "\n",
    "(Path(CAL_DIR / \"thresholds_blend.json\")).write_text(json.dumps({\n",
    "    \"alpha\": ALPHA,\n",
    "    \"thresholds\": thresholds_blend\n",
    "}, indent=2))\n",
    "print(\"\\nSaved →\", CAL_DIR / \"thresholds_blend.json\")\n",
    "\n",
    "# ---- 4) Provide a convenience predictor using the BLEND (keep specialist predictor unchanged) ----\n",
    "def predict_smiles_blend(smiles_list, mode: str = \"fbeta15\", alpha: float = ALPHA):\n",
    "    \"\"\"\n",
    "    Returns list[dict]: per SMILES -> label -> {prob_spec, prob_shared, prob_blend, decision}\n",
    "    \"\"\"\n",
    "    assert mode in (\"f1\",\"fbeta15\")\n",
    "    # fused features from shared encoders (desc branch is already wired)\n",
    "    fused = fused_from_smiles(smiles_list)  # (B,768)\n",
    "    out = []\n",
    "    X = fused  # torch Tensor\n",
    "    with torch.no_grad():\n",
    "        logits_shared = v7_shared.shared_head(X).detach().cpu().numpy()\n",
    "    for i in range(X.size(0)):\n",
    "        row = {}\n",
    "        xi = X[i:i+1]\n",
    "        for j, lbl in enumerate(LABEL_NAMES):\n",
    "            # specialist\n",
    "            with torch.no_grad():\n",
    "                logit_spec = HEADS[lbl](xi).item()\n",
    "            T_spec   = max(float(temps.get(lbl, 1.0)), 1e-3)\n",
    "            p_spec   = 1. / (1. + math.e**(-logit_spec / T_spec))\n",
    "            # shared\n",
    "            T_shared = max(float(temps_shared.get(lbl, 1.0)), 1e-3)\n",
    "            logit_sh = logits_shared[i, j]\n",
    "            p_shared = 1. / (1. + math.e**(-logit_sh   / T_shared))\n",
    "            # blend\n",
    "            p_blend = alpha * p_spec + (1-alpha) * p_shared\n",
    "            # threshold (use blended thresholds we just computed)\n",
    "            th = thresholds_blend[lbl][\"th_fbeta15\"] if mode==\"fbeta15\" else thresholds_blend[lbl][\"th_f1\"]\n",
    "            row[lbl] = {\n",
    "                \"prob_spec\": float(p_spec),\n",
    "                \"prob_shared\": float(p_shared),\n",
    "                \"prob_blend\": float(p_blend),\n",
    "                \"decision\": bool(p_blend >= float(th)),\n",
    "            }\n",
    "        out.append(row)\n",
    "    return out\n",
    "\n",
    "print(\"\\n✅ Blend ready: use predict_smiles_blend([...], mode='fbeta15' or 'f1').\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618fe460",
   "metadata": {},
   "source": [
    "### 3: Evaluate on test set & export CSV (choose specialist or blend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a1b3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: v7\\results\\inference\\predictions_test_blend_fbeta15.csv\n",
      "\n",
      "Summary (test):\n",
      "{\n",
      "  \"mode\": \"blend\",\n",
      "  \"threshold_mode\": \"fbeta15\",\n",
      "  \"macro_pr_auc\": 0.3208,\n",
      "  \"micro_precision\": 0.2079,\n",
      "  \"micro_recall\": 0.5734,\n",
      "  \"micro_f1\": 0.3052\n",
      "}\n",
      "Per-label AP saved in report JSON.\n"
     ]
    }
   ],
   "source": [
    "# Phase 5 — Cell 3: Test export + quick metrics\n",
    "import json, math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "\n",
    "BASE       = Path(\"v7\")\n",
    "PREP_DIR   = BASE / \"data\" / \"prepared\"\n",
    "FUSED_DIR  = BASE / \"data\" / \"fused\"\n",
    "RESULTS_DIR= BASE / \"results\" / \"inference\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CAL_DIR    = BASE / \"model\" / \"calibration\"\n",
    "\n",
    "# Choose which predictor to use:\n",
    "USE_BLEND = True     # True → use predict_smiles_blend; False → use specialist-only predict_smiles\n",
    "MODE      = \"fbeta15\"  # \"fbeta15\" or \"f1\"\n",
    "\n",
    "# Load test blobs\n",
    "blob = np.load(PREP_DIR / \"test.npz\", allow_pickle=True)\n",
    "smiles = [str(s) for s in blob[\"smiles\"].tolist()]\n",
    "Yte    = blob[\"Y\"].astype(np.float32)\n",
    "Mte    = blob[\"y_missing_mask\"].astype(bool)\n",
    "\n",
    "# Also load fused for test to speed shared head for blend\n",
    "Xte_fused = np.load(FUSED_DIR / \"test_fused.npy\") if (FUSED_DIR / \"test_fused.npy\").exists() else None\n",
    "\n",
    "# Ensure thresholds for selected path\n",
    "if USE_BLEND:\n",
    "    data = json.loads((CAL_DIR / \"thresholds_blend.json\").read_text())\n",
    "    thresholds_blend = data[\"thresholds\"]\n",
    "else:\n",
    "    thresholds_spec = json.loads((CAL_DIR / \"thresholds.json\").read_text())\n",
    "\n",
    "rows = []\n",
    "probs_mat = np.zeros((len(smiles), len(LABEL_NAMES)), dtype=np.float32)\n",
    "\n",
    "if USE_BLEND:\n",
    "    # Compute via blend predictor\n",
    "    preds = predict_smiles_blend(smiles, mode=MODE)\n",
    "    for i, (smi, rec) in enumerate(zip(smiles, preds)):\n",
    "        row = {\"smiles\": smi}\n",
    "        for j, lbl in enumerate(LABEL_NAMES):\n",
    "            p = rec[lbl][\"prob_blend\"]\n",
    "            d = int(rec[lbl][\"decision\"])\n",
    "            row[f\"{lbl}_prob\"] = p\n",
    "            row[f\"{lbl}_pred\"] = d\n",
    "            probs_mat[i, j] = p\n",
    "        rows.append(row)\n",
    "    out_csv = RESULTS_DIR / f\"predictions_test_blend_{MODE}.csv\"\n",
    "else:\n",
    "    # Specialist-only\n",
    "    preds = predict_smiles(smiles, threshold_mode=MODE)\n",
    "    for i, (smi, rec) in enumerate(zip(smiles, preds)):\n",
    "        row = {\"smiles\": smi}\n",
    "        for j, lbl in enumerate(LABEL_NAMES):\n",
    "            p = rec[lbl][\"prob_cal\"]\n",
    "            d = int(rec[lbl][\"decision\"])\n",
    "            row[f\"{lbl}_prob\"] = p\n",
    "            row[f\"{lbl}_pred\"] = d\n",
    "            probs_mat[i, j] = p\n",
    "        rows.append(row)\n",
    "    out_csv = RESULTS_DIR / f\"predictions_test_specialist_{MODE}.csv\"\n",
    "\n",
    "pd.DataFrame(rows).to_csv(out_csv, index=False)\n",
    "print(\"✅ Saved:\", out_csv)\n",
    "\n",
    "# ---- Tiny metrics (test) ----\n",
    "per_label_ap = {}\n",
    "for j, lbl in enumerate(LABEL_NAMES):\n",
    "    valid = ~Mte[:, j]\n",
    "    if valid.sum() == 0 or np.all(Yte[valid, j] == Yte[valid, j][0]):\n",
    "        per_label_ap[lbl] = float(\"nan\"); continue\n",
    "    try:\n",
    "        per_label_ap[lbl] = float(average_precision_score(Yte[valid, j], probs_mat[valid, j]))\n",
    "    except Exception:\n",
    "        per_label_ap[lbl] = float(\"nan\")\n",
    "\n",
    "macro_pr = float(np.nanmean([v for v in per_label_ap.values()]))\n",
    "\n",
    "# micro P/R/F1 using chosen thresholds\n",
    "tp = fp = fn = 0\n",
    "for i in range(len(smiles)):\n",
    "    for j, lbl in enumerate(LABEL_NAMES):\n",
    "        if Mte[i, j]: \n",
    "            continue\n",
    "        truth = int(Yte[i, j])\n",
    "        pred  = rows[i][f\"{lbl}_pred\"]\n",
    "        tp += int(pred == 1 and truth == 1)\n",
    "        fp += int(pred == 1 and truth == 0)\n",
    "        fn += int(pred == 0 and truth == 1)\n",
    "\n",
    "prec = tp/(tp+fp) if (tp+fp)>0 else 0.0\n",
    "rec  = tp/(tp+fn) if (tp+fn)>0 else 0.0\n",
    "f1   = (2*prec*rec)/(prec+rec) if (prec+rec)>0 else 0.0\n",
    "\n",
    "report = {\n",
    "    \"mode\": (\"blend\" if USE_BLEND else \"specialist\"),\n",
    "    \"threshold_mode\": MODE,\n",
    "    \"macro_pr_auc\": macro_pr,\n",
    "    \"micro_precision\": prec,\n",
    "    \"micro_recall\": rec,\n",
    "    \"micro_f1\": f1,\n",
    "    \"per_label_ap\": per_label_ap\n",
    "}\n",
    "report_path = RESULTS_DIR / f\"test_report_{'blend' if USE_BLEND else 'specialist'}_{MODE}.json\"\n",
    "report_path.write_text(json.dumps(report, indent=2))\n",
    "print(\"\\nSummary (test):\")\n",
    "print(json.dumps({k: (round(v,4) if isinstance(v, float) else v) for k,v in report.items() if k!='per_label_ap'}, indent=2))\n",
    "print(\"Per-label AP saved in report JSON.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5502796",
   "metadata": {},
   "source": [
    "### 4: test reg after cell 2& 3 (gave very strong results!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3cd109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Blend test rig ready. Example:\n"
     ]
    }
   ],
   "source": [
    "# === V7: Single-SMILES/SMARTS Test Rig (BLENDED: specialist + shared) ===\n",
    "# Uses:\n",
    "#   v7/model/checkpoints/shared/best.pt\n",
    "#   v7/model/ensembles/<label>/seed*/best.pt\n",
    "#   v7/model/calibration/temps.json           (specialist temps)\n",
    "#   v7/model/calibration/temps_shared.json    (shared temps)\n",
    "#   v7/model/calibration/thresholds_blend.json (alpha + per-label thresholds)\n",
    "\n",
    "import os, json, math\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "BASE       = Path(\"v7\")\n",
    "PREP_DIR   = BASE / \"data\" / \"prepared\"\n",
    "DESC_DIR   = BASE / \"data\" / \"descriptors\"\n",
    "MODEL_DIR  = BASE / \"model\"\n",
    "CKPT_BEST  = MODEL_DIR / \"checkpoints\" / \"shared\" / \"best.pt\"\n",
    "ENS_DIR    = MODEL_DIR / \"ensembles\"\n",
    "CAL_DIR    = MODEL_DIR / \"calibration\"\n",
    "\n",
    "assert CKPT_BEST.exists(), f\"Missing shared checkpoint: {CKPT_BEST}\"\n",
    "assert (PREP_DIR / \"dataset_manifest.json\").exists(), \"Missing dataset manifest.\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Labels & calibration artifacts ---\n",
    "ds_manifest = json.loads((PREP_DIR / \"dataset_manifest.json\").read_text())\n",
    "LABEL_NAMES: List[str] = ds_manifest[\"labels\"]\n",
    "DESC_IN_DIM = ds_manifest[\"n_features\"]  # 208\n",
    "\n",
    "temps_spec    = json.loads((CAL_DIR / \"temps.json\").read_text())           # specialist\n",
    "temps_shared  = json.loads((CAL_DIR / \"temps_shared.json\").read_text())    # shared\n",
    "blend_payload = json.loads((CAL_DIR / \"thresholds_blend.json\").read_text())\n",
    "ALPHA         = float(blend_payload.get(\"alpha\", 0.8))\n",
    "thr_blend     = blend_payload[\"thresholds\"]  # label -> {th_f1, th_fbeta15, ap_val}\n",
    "\n",
    "# --- Text encoder (ChemBERTa) ---\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "class ChemBERTaEncoder(nn.Module):\n",
    "    def __init__(self, ckpt_name=\"seyonec/ChemBERTa-zinc-base-v1\", fusion_dim=256, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(ckpt_name)\n",
    "        self.backbone  = AutoModel.from_pretrained(ckpt_name)\n",
    "        self.proj = nn.Sequential(nn.Dropout(dropout_p), nn.Linear(self.backbone.config.hidden_size, fusion_dim))\n",
    "        self.ln = nn.LayerNorm(fusion_dim)\n",
    "    def forward(self, smiles_list: List[str], max_length=256, add_special_tokens=True):\n",
    "        enc = self.tokenizer(list(smiles_list), padding=True, truncation=True,\n",
    "                             max_length=max_length, add_special_tokens=add_special_tokens,\n",
    "                             return_tensors=\"pt\")\n",
    "        input_ids, attention_mask = enc[\"input_ids\"].to(device), enc[\"attention_mask\"].to(device)\n",
    "        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state  # (B,L,H)\n",
    "        toks = self.ln(self.proj(out))  # (B,L,256)\n",
    "        return toks, attention_mask.to(dtype=torch.int32)\n",
    "\n",
    "# --- Graph encoder (names matched to checkpoint) ---\n",
    "from rdkit import Chem\n",
    "ATOM_LIST = [\"H\",\"C\",\"N\",\"O\",\"F\",\"P\",\"S\",\"Cl\",\"Br\",\"I\"]\n",
    "\n",
    "def _one_hot(v, choices):\n",
    "    z = [0]*len(choices)\n",
    "    if v in choices: z[choices.index(v)] = 1\n",
    "    return z\n",
    "\n",
    "def _bucket_oh(v, lo, hi):\n",
    "    buckets = list(range(lo, hi+1))\n",
    "    o = [0]*(len(buckets)+1)\n",
    "    idx = v - lo\n",
    "    o[idx if 0 <= idx < len(buckets) else -1] = 1\n",
    "    return o\n",
    "\n",
    "def _atom_feat(atom):\n",
    "    hybs = [Chem.rdchem.HybridizationType.S, Chem.rdchem.HybridizationType.SP,\n",
    "            Chem.rdchem.HybridizationType.SP2, Chem.rdchem.HybridizationType.SP3,\n",
    "            Chem.rdchem.HybridizationType.SP3D, Chem.rdchem.HybridizationType.SP3D2]\n",
    "    chir = [Chem.rdchem.ChiralType.CHI_UNSPECIFIED,\n",
    "            Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CW,\n",
    "            Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CCW,\n",
    "            Chem.rdchem.ChiralType.CHI_OTHER]\n",
    "    sym = atom.GetSymbol()\n",
    "    feat = _one_hot(sym if sym in ATOM_LIST else \"other\", ATOM_LIST+[\"other\"])\n",
    "    feat += _bucket_oh(atom.GetDegree(), 0, 5)\n",
    "    feat += _bucket_oh(atom.GetFormalCharge(), -2, 2)\n",
    "    feat += (_one_hot(atom.GetHybridization(), hybs)+[0])\n",
    "    feat += [int(atom.GetIsAromatic())]\n",
    "    feat += [int(atom.IsInRing())]\n",
    "    feat += _one_hot(atom.GetChiralTag(), chir)\n",
    "    feat += _bucket_oh(atom.GetTotalNumHs(includeNeighbors=True), 0, 4)\n",
    "    feat += _bucket_oh(atom.GetTotalValence(), 0, 5)\n",
    "    feat += [atom.GetMass()/200.0]\n",
    "    return feat  # ~51 dims\n",
    "\n",
    "def _smiles_to_graph(smi, max_nodes=128):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None or mol.GetNumAtoms() == 0:\n",
    "        return np.zeros((0,0), dtype=np.float32), np.zeros((0,0), dtype=np.float32)\n",
    "    feats = [_atom_feat(mol.GetAtomWithIdx(i)) for i in range(mol.GetNumAtoms())]\n",
    "    x = np.asarray(feats, dtype=np.float32)\n",
    "    N = mol.GetNumAtoms()\n",
    "    adj = np.zeros((N, N), dtype=np.float32)\n",
    "    for b in mol.GetBonds():\n",
    "        i, j = b.GetBeginAtomIdx(), b.GetEndAtomIdx()\n",
    "        adj[i, j] = 1.0; adj[j, i] = 1.0\n",
    "    if N > max_nodes:\n",
    "        x = x[:max_nodes]; adj = adj[:max_nodes, :max_nodes]\n",
    "    return x, adj\n",
    "\n",
    "def _collate_graphs(smiles_batch, max_nodes=128):\n",
    "    graphs = [_smiles_to_graph(s) for s in smiles_batch]\n",
    "    Nmax = max([g[0].shape[0] for g in graphs] + [1])\n",
    "    Fnode = graphs[0][0].shape[1] if graphs[0][0].size>0 else 51\n",
    "    B = len(graphs)\n",
    "    X = np.zeros((B, Nmax, Fnode), dtype=np.float32)\n",
    "    A = np.zeros((B, Nmax, Nmax), dtype=np.float32)\n",
    "    M = np.zeros((B, Nmax), dtype=np.int64)\n",
    "    for i, (x, a) in enumerate(graphs):\n",
    "        n = x.shape[0]\n",
    "        if n == 0: continue\n",
    "        X[i, :n, :] = x\n",
    "        A[i, :n, :n] = a\n",
    "        M[i, :n] = 1\n",
    "    return torch.from_numpy(X).to(device), torch.from_numpy(A).to(device), torch.from_numpy(M).to(device)\n",
    "\n",
    "class GINLayer(nn.Module):\n",
    "    def __init__(self, h=256, p=0.1):\n",
    "        super().__init__()\n",
    "        self.eps = nn.Parameter(torch.tensor(0.0))\n",
    "        self.mlp = nn.Sequential(nn.Linear(h, h), nn.GELU(), nn.LayerNorm(h), nn.Dropout(p))\n",
    "    def forward(self, x, adj, mask):\n",
    "        out = (1.0 + self.eps) * x + torch.matmul(adj, x)\n",
    "        out = self.mlp(out)\n",
    "        return out * mask.unsqueeze(-1).to(out.dtype)\n",
    "\n",
    "class GraphGINEncoder(nn.Module):\n",
    "    def __init__(self, node_in_dim=51, hidden_dim=256, n_layers=4, p=0.1):\n",
    "        super().__init__()\n",
    "        self.inp = nn.Sequential(nn.Linear(node_in_dim, hidden_dim), nn.GELU(), nn.Dropout(p))\n",
    "        self.layers = nn.ModuleList([GINLayer(hidden_dim, p) for _ in range(n_layers)])\n",
    "        self.out_ln = nn.LayerNorm(hidden_dim)  # name matches checkpoint\n",
    "    def forward(self, smiles_list: List[str], max_nodes=128):\n",
    "        X, A, M = _collate_graphs(smiles_list, max_nodes=max_nodes)\n",
    "        h = self.inp(X)\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, A, M)\n",
    "        return self.out_ln(h), M.to(dtype=torch.int32)\n",
    "\n",
    "# --- Fusion & heads ---\n",
    "def masked_mean(x: torch.Tensor, mask: torch.Tensor, dim: int) -> torch.Tensor:\n",
    "    mask = mask.to(dtype=x.dtype, device=x.device)\n",
    "    denom = mask.sum(dim=dim, keepdim=True).clamp(min=1.0)\n",
    "    return (x * mask.unsqueeze(-1)).sum(dim=dim) / denom\n",
    "\n",
    "class CrossAttentionBlock(nn.Module):\n",
    "    def __init__(self, dim=256, n_heads=4, p=0.1):\n",
    "        super().__init__()\n",
    "        self.mha = nn.MultiheadAttention(dim, n_heads, dropout=p, batch_first=False)\n",
    "        self.ln  = nn.LayerNorm(dim)\n",
    "        self.do  = nn.Dropout(p)\n",
    "    def forward(self, text_tokens, text_mask, graph_nodes, graph_mask):\n",
    "        Q = text_tokens.transpose(0,1)   # (L,B,D)\n",
    "        K = graph_nodes.transpose(0,1)   # (N,B,D)\n",
    "        V = graph_nodes.transpose(0,1)\n",
    "        kpm = (graph_mask == 0)          # (B,N)\n",
    "        attn, _ = self.mha(Q, K, V, key_padding_mask=kpm)\n",
    "        attn = attn.transpose(0,1)       # (B,L,D)\n",
    "        return self.ln(text_tokens + self.do(attn))\n",
    "\n",
    "class DescriptorMLP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim=256, hidden=256, p=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden), nn.GELU(), nn.Dropout(p),\n",
    "            nn.Linear(hidden, out_dim), nn.GELU(), nn.Dropout(p)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class FusionClassifier(nn.Module):\n",
    "    # name 'mlp' matches checkpoint ('shared_head.mlp.*')\n",
    "    def __init__(self, dim=256, n_labels=12, p=0.1):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim*3, dim*2), nn.GELU(), nn.Dropout(p),\n",
    "            nn.Linear(dim*2, n_labels)\n",
    "        )\n",
    "    def forward(self, fused_vec): return self.mlp(fused_vec)\n",
    "\n",
    "class V7FusionModel(nn.Module):\n",
    "    def __init__(self, text_encoder, graph_encoder, desc_in_dim=208, dim=256, n_labels=12, n_heads=4, p=0.1):\n",
    "        super().__init__()\n",
    "        self.text_encoder=text_encoder\n",
    "        self.graph_encoder=graph_encoder\n",
    "        self.cross=CrossAttentionBlock(dim, n_heads, p)\n",
    "        self.desc_mlp=DescriptorMLP(desc_in_dim, out_dim=dim, hidden=256, p=p)\n",
    "        self.shared_head=FusionClassifier(dim, n_labels, p)\n",
    "    def forward(self, smiles_list, desc_feats):\n",
    "        tt, tm = self.text_encoder(smiles_list, max_length=256)\n",
    "        gn, gm = self.graph_encoder(smiles_list, max_nodes=128)\n",
    "        tta = self.cross(tt.to(device), tm.to(device), gn.to(device), gm.to(device))\n",
    "        de  = self.desc_mlp(desc_feats.to(device))\n",
    "        text_pool  = masked_mean(tta, tm.to(device), 1)\n",
    "        graph_pool = masked_mean(gn.to(device),  gm.to(device), 1)\n",
    "        fused = torch.cat([text_pool, graph_pool, de], dim=-1)  # (B,768)\n",
    "        logits = self.shared_head(fused)\n",
    "        return logits, fused\n",
    "\n",
    "# Build model & load checkpoint\n",
    "text_encoder = ChemBERTaEncoder().to(device)\n",
    "graph_encoder= GraphGINEncoder().to(device)\n",
    "v7_shared    = V7FusionModel(text_encoder, graph_encoder, desc_in_dim=DESC_IN_DIM, n_labels=len(LABEL_NAMES)).to(device)\n",
    "ckpt = torch.load(CKPT_BEST, map_location=device)\n",
    "v7_shared.load_state_dict(ckpt[\"model\"], strict=True)\n",
    "v7_shared.eval()\n",
    "\n",
    "# Specialist heads (same as trained)\n",
    "class LabelHead(nn.Module):\n",
    "    def __init__(self, in_dim=768, h1=512, h2=256, h3=128, p=0.30):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(nn.Linear(in_dim, h1), nn.GELU(), nn.LayerNorm(h1), nn.Dropout(p))\n",
    "        self.block2 = nn.Sequential(nn.Linear(h1, h2), nn.GELU(), nn.LayerNorm(h2), nn.Dropout(p))\n",
    "        self.block3 = nn.Sequential(nn.Linear(h2, h3), nn.GELU(), nn.LayerNorm(h3), nn.Dropout(p))\n",
    "        self.out    = nn.Linear(h3, 1)\n",
    "        self.short  = nn.Linear(in_dim, h3)\n",
    "    def forward(self, x):\n",
    "        z1 = self.block1(x); z2 = self.block2(z1); z3 = self.block3(z2)\n",
    "        z  = z3 + self.short(x)\n",
    "        return self.out(z).squeeze(-1)\n",
    "\n",
    "def _load_best_head(label: str) -> nn.Module:\n",
    "    cands = []\n",
    "    for sd in sorted((ENS_DIR / label).glob(\"seed*/\")):\n",
    "        mfile = sd / \"metrics.json\"\n",
    "        if mfile.exists():\n",
    "            try:\n",
    "                ap = float(json.loads(mfile.read_text()).get(\"best_ap\", float(\"nan\")))\n",
    "                cands.append((ap, sd))\n",
    "            except Exception:\n",
    "                pass\n",
    "    if not cands: raise FileNotFoundError(f\"No trained heads for label {label}\")\n",
    "    cands.sort(key=lambda x: (-1.0 if math.isnan(x[0]) else x[0]), reverse=True)\n",
    "    best_dir = cands[0][1]\n",
    "    ck = torch.load(best_dir / \"best.pt\", map_location=device)\n",
    "    cfg = ck.get(\"config\", {\"in_dim\":768,\"h1\":512,\"h2\":256,\"h3\":128,\"dropout\":0.30})\n",
    "    head = LabelHead(in_dim=cfg[\"in_dim\"], h1=cfg[\"h1\"], h2=cfg[\"h2\"], h3=cfg[\"h3\"], p=cfg.get(\"dropout\",0.30)).to(device)\n",
    "    head.load_state_dict(ck[\"model\"], strict=True)\n",
    "    head.eval()\n",
    "    return head\n",
    "\n",
    "HEADS: Dict[str, nn.Module] = {lbl: _load_best_head(lbl) for lbl in LABEL_NAMES}\n",
    "\n",
    "# Descriptors for ad-hoc inputs: standardized zeros (keeps it simple & robust)\n",
    "def prepare_desc_matrix(smiles_list: List[str]) -> torch.Tensor:\n",
    "    Z = np.zeros((len(smiles_list), DESC_IN_DIM), dtype=np.float32)\n",
    "    return torch.tensor(Z, dtype=torch.float32, device=device)\n",
    "\n",
    "# Normalize SMARTS→SMILES if needed\n",
    "def normalize_smiles_or_smarts(s: str) -> str:\n",
    "    if not isinstance(s, str): s = str(s)\n",
    "    mol = Chem.MolFromSmiles(s)\n",
    "    if mol: return Chem.MolToSmiles(mol)\n",
    "    q = Chem.MolFromSmarts(s)\n",
    "    if q:\n",
    "        try:\n",
    "            smi = Chem.MolToSmiles(q)\n",
    "            return smi if smi else s\n",
    "        except Exception:\n",
    "            return s\n",
    "    return s\n",
    "\n",
    "@torch.no_grad()\n",
    "def fused_from_smiles(smiles_list: List[str]) -> torch.Tensor:\n",
    "    smiles_list = [normalize_smiles_or_smarts(s) for s in smiles_list]\n",
    "    desc = prepare_desc_matrix(smiles_list)\n",
    "    logits_sh, fused = v7_shared(smiles_list, desc)  # logits not used here directly\n",
    "    return fused  # (B,768)\n",
    "\n",
    "def predict_one_blend(smi: str, mode: str = \"fbeta15\", topk: int = 5):\n",
    "    \"\"\"\n",
    "    Blended prediction for one SMILES/SMARTS using:\n",
    "      prob_blend = alpha*P_spec + (1-alpha)*P_shared\n",
    "    Thresholds taken from thresholds_blend.json for chosen mode (\"f1\" or \"fbeta15\").\n",
    "    Prints a clean summary and returns a dict[label]->details.\n",
    "    \"\"\"\n",
    "    assert mode in (\"f1\",\"fbeta15\")\n",
    "    fused = fused_from_smiles([smi])\n",
    "    x = fused[0:1]\n",
    "\n",
    "    # Shared logits and calibrated probs\n",
    "    with torch.no_grad():\n",
    "        logits_shared = v7_shared.shared_head(x).detach().cpu().numpy()[0]  # (12,)\n",
    "\n",
    "    rec = {}\n",
    "    for j, lbl in enumerate(LABEL_NAMES):\n",
    "        # Specialist prob (with its temperature)\n",
    "        with torch.no_grad():\n",
    "            logit_spec = HEADS[lbl](x).item()\n",
    "        T_spec   = max(float(temps_spec.get(lbl, 1.0)), 1e-3)\n",
    "        p_spec   = 1. / (1. + math.e**(-logit_spec / T_spec))\n",
    "\n",
    "        # Shared prob (with shared temperature)\n",
    "        T_shared = max(float(temps_shared.get(lbl, 1.0)), 1e-3)\n",
    "        p_shared = 1. / (1. + math.e**(-float(logits_shared[j]) / T_shared))\n",
    "\n",
    "        # Blend\n",
    "        p_blend = ALPHA * p_spec + (1.0 - ALPHA) * p_shared\n",
    "\n",
    "        # Threshold\n",
    "        th = thr_blend[lbl][\"th_fbeta15\"] if mode==\"fbeta15\" else thr_blend[lbl][\"th_f1\"]\n",
    "        rec[lbl] = {\n",
    "            \"prob_spec\": float(p_spec),\n",
    "            \"prob_shared\": float(p_shared),\n",
    "            \"prob_blend\": float(p_blend),\n",
    "            \"threshold\": float(th),\n",
    "            \"decision\": bool(p_blend >= float(th)),\n",
    "        }\n",
    "\n",
    "    # Pretty print\n",
    "    print(\"\\nSMILES/SMARTS:\", smi, f\"(alpha={ALPHA:.2f}, mode={mode})\")\n",
    "    top = sorted([(lbl, d[\"prob_blend\"], d[\"decision\"]) for lbl, d in rec.items()],\n",
    "                 key=lambda z: z[1], reverse=True)[:topk]\n",
    "    for lbl, p, dec in top:\n",
    "        th = rec[lbl][\"threshold\"]\n",
    "        print(f\"  {lbl:12s}  prob_blend={p:.3f}  th={th:.3f}  → pred={int(dec)}\")\n",
    "    pos = [lbl for lbl, d in rec.items() if d[\"decision\"]]\n",
    "    print(\"  Positives:\", (\", \".join(sorted(pos)) if pos else \"none\"))\n",
    "    return rec\n",
    "\n",
    "print(\"✅ Blend test rig ready. Example:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f9a913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SMILES/SMARTS: O=C(O)Cc1cc(I)c(Oc2ccc(O)c(I)c2)c(I)c1 (alpha=0.80, mode=fbeta15)\n",
      "  NR-AhR        prob_blend=0.700  th=0.642  → pred=1\n",
      "  SR-MMP        prob_blend=0.680  th=0.589  → pred=1\n",
      "  SR-ARE        prob_blend=0.588  th=0.528  → pred=1\n",
      "  NR-ER         prob_blend=0.556  th=0.480  → pred=1\n",
      "  SR-p53        prob_blend=0.551  th=0.478  → pred=1\n",
      "  NR-ER-LBD     prob_blend=0.499  th=0.589  → pred=0\n",
      "  NR-Aromatase  prob_blend=0.498  th=0.474  → pred=1\n",
      "  SR-ATAD5      prob_blend=0.479  th=0.483  → pred=0\n",
      "  NR-PPAR-gamma  prob_blend=0.478  th=0.427  → pred=1\n",
      "  SR-HSE        prob_blend=0.460  th=0.459  → pred=1\n",
      "  NR-AR         prob_blend=0.432  th=0.653  → pred=0\n",
      "  NR-AR-LBD     prob_blend=0.423  th=0.621  → pred=0\n",
      "  Positives: NR-AhR, NR-Aromatase, NR-ER, NR-PPAR-gamma, SR-ARE, SR-HSE, SR-MMP, SR-p53\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NR-AR': {'prob_spec': 0.5297900819654926,\n",
       "  'prob_shared': 0.039244673619722704,\n",
       "  'prob_blend': 0.43168100029633866,\n",
       "  'threshold': 0.653282642364502,\n",
       "  'decision': False},\n",
       " 'NR-AR-LBD': {'prob_spec': 0.527085290472785,\n",
       "  'prob_shared': 0.007392770345504927,\n",
       "  'prob_blend': 0.42314678644732895,\n",
       "  'threshold': 0.6206690669059753,\n",
       "  'decision': False},\n",
       " 'NR-AhR': {'prob_spec': 0.6696848171077073,\n",
       "  'prob_shared': 0.8209122313828833,\n",
       "  'prob_blend': 0.6999302999627425,\n",
       "  'threshold': 0.6417197585105896,\n",
       "  'decision': True},\n",
       " 'NR-Aromatase': {'prob_spec': 0.5691290816416109,\n",
       "  'prob_shared': 0.21573499976865418,\n",
       "  'prob_blend': 0.4984502652670196,\n",
       "  'threshold': 0.4737248420715332,\n",
       "  'decision': True},\n",
       " 'NR-ER': {'prob_spec': 0.5319725845509377,\n",
       "  'prob_shared': 0.6530290641575132,\n",
       "  'prob_blend': 0.5561838804722528,\n",
       "  'threshold': 0.4802268147468567,\n",
       "  'decision': True},\n",
       " 'NR-ER-LBD': {'prob_spec': 0.5796462377733185,\n",
       "  'prob_shared': 0.17392469045136985,\n",
       "  'prob_blend': 0.49850192830892875,\n",
       "  'threshold': 0.5893745422363281,\n",
       "  'decision': False},\n",
       " 'NR-PPAR-gamma': {'prob_spec': 0.5515514734433192,\n",
       "  'prob_shared': 0.1855413765345053,\n",
       "  'prob_blend': 0.4783494540615565,\n",
       "  'threshold': 0.42748475074768066,\n",
       "  'decision': True},\n",
       " 'SR-ARE': {'prob_spec': 0.5481504678492859,\n",
       "  'prob_shared': 0.7475649174003929,\n",
       "  'prob_blend': 0.5880333577595073,\n",
       "  'threshold': 0.5278913378715515,\n",
       "  'decision': True},\n",
       " 'SR-ATAD5': {'prob_spec': 0.5547528009570648,\n",
       "  'prob_shared': 0.174235174637529,\n",
       "  'prob_blend': 0.4786492756931577,\n",
       "  'threshold': 0.4825417995452881,\n",
       "  'decision': False},\n",
       " 'SR-HSE': {'prob_spec': 0.5444436734627249,\n",
       "  'prob_shared': 0.12223593661546725,\n",
       "  'prob_blend': 0.4600021260932734,\n",
       "  'threshold': 0.4591193199157715,\n",
       "  'decision': True},\n",
       " 'SR-MMP': {'prob_spec': 0.6408550104292131,\n",
       "  'prob_shared': 0.8353312082985317,\n",
       "  'prob_blend': 0.6797502500030768,\n",
       "  'threshold': 0.589274525642395,\n",
       "  'decision': True},\n",
       " 'SR-p53': {'prob_spec': 0.560059474096727,\n",
       "  'prob_shared': 0.5128437890040615,\n",
       "  'prob_blend': 0.5506163370781939,\n",
       "  'threshold': 0.477995365858078,\n",
       "  'decision': True}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_one_blend(\"O=C(O)Cc1cc(I)c(Oc2ccc(O)c(I)c2)c(I)c1\", mode=\"fbeta15\", topk=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd1431d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SMILES/SMARTS: O=C(O)Cc1cc(I)c(Oc2ccc(O)c(I)c2)c(I)c1 (alpha=0.80, mode=f1)\n",
      "  NR-AhR        prob_blend=0.700  th=0.709  → pred=0\n",
      "  SR-MMP        prob_blend=0.680  th=0.589  → pred=1\n",
      "  SR-ARE        prob_blend=0.588  th=0.528  → pred=1\n",
      "  NR-ER         prob_blend=0.556  th=0.547  → pred=1\n",
      "  SR-p53        prob_blend=0.551  th=0.513  → pred=1\n",
      "  NR-ER-LBD     prob_blend=0.499  th=0.589  → pred=0\n",
      "  NR-Aromatase  prob_blend=0.498  th=0.564  → pred=0\n",
      "  SR-ATAD5      prob_blend=0.479  th=0.483  → pred=0\n",
      "  NR-PPAR-gamma  prob_blend=0.478  th=0.441  → pred=1\n",
      "  SR-HSE        prob_blend=0.460  th=0.472  → pred=0\n",
      "  NR-AR         prob_blend=0.432  th=0.653  → pred=0\n",
      "  NR-AR-LBD     prob_blend=0.423  th=0.621  → pred=0\n",
      "  Positives: NR-ER, NR-PPAR-gamma, SR-ARE, SR-MMP, SR-p53\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NR-AR': {'prob_spec': 0.5297900819654926,\n",
       "  'prob_shared': 0.039244673619722704,\n",
       "  'prob_blend': 0.43168100029633866,\n",
       "  'threshold': 0.653282642364502,\n",
       "  'decision': False},\n",
       " 'NR-AR-LBD': {'prob_spec': 0.527085290472785,\n",
       "  'prob_shared': 0.007392770345504927,\n",
       "  'prob_blend': 0.42314678644732895,\n",
       "  'threshold': 0.6206690669059753,\n",
       "  'decision': False},\n",
       " 'NR-AhR': {'prob_spec': 0.6696848171077073,\n",
       "  'prob_shared': 0.8209122313828833,\n",
       "  'prob_blend': 0.6999302999627425,\n",
       "  'threshold': 0.7087583541870117,\n",
       "  'decision': False},\n",
       " 'NR-Aromatase': {'prob_spec': 0.5691290816416109,\n",
       "  'prob_shared': 0.21573499976865418,\n",
       "  'prob_blend': 0.4984502652670196,\n",
       "  'threshold': 0.5641032457351685,\n",
       "  'decision': False},\n",
       " 'NR-ER': {'prob_spec': 0.5319725845509377,\n",
       "  'prob_shared': 0.6530290641575132,\n",
       "  'prob_blend': 0.5561838804722528,\n",
       "  'threshold': 0.547207772731781,\n",
       "  'decision': True},\n",
       " 'NR-ER-LBD': {'prob_spec': 0.5796462377733185,\n",
       "  'prob_shared': 0.17392469045136985,\n",
       "  'prob_blend': 0.49850192830892875,\n",
       "  'threshold': 0.5893745422363281,\n",
       "  'decision': False},\n",
       " 'NR-PPAR-gamma': {'prob_spec': 0.5515514734433192,\n",
       "  'prob_shared': 0.1855413765345053,\n",
       "  'prob_blend': 0.4783494540615565,\n",
       "  'threshold': 0.4406646490097046,\n",
       "  'decision': True},\n",
       " 'SR-ARE': {'prob_spec': 0.5481504678492859,\n",
       "  'prob_shared': 0.7475649174003929,\n",
       "  'prob_blend': 0.5880333577595073,\n",
       "  'threshold': 0.5278913378715515,\n",
       "  'decision': True},\n",
       " 'SR-ATAD5': {'prob_spec': 0.5547528009570648,\n",
       "  'prob_shared': 0.174235174637529,\n",
       "  'prob_blend': 0.4786492756931577,\n",
       "  'threshold': 0.4825417995452881,\n",
       "  'decision': False},\n",
       " 'SR-HSE': {'prob_spec': 0.5444436734627249,\n",
       "  'prob_shared': 0.12223593661546725,\n",
       "  'prob_blend': 0.4600021260932734,\n",
       "  'threshold': 0.47199299931526184,\n",
       "  'decision': False},\n",
       " 'SR-MMP': {'prob_spec': 0.6408550104292131,\n",
       "  'prob_shared': 0.8353312082985317,\n",
       "  'prob_blend': 0.6797502500030768,\n",
       "  'threshold': 0.589274525642395,\n",
       "  'decision': True},\n",
       " 'SR-p53': {'prob_spec': 0.560059474096727,\n",
       "  'prob_shared': 0.5128437890040615,\n",
       "  'prob_blend': 0.5506163370781939,\n",
       "  'threshold': 0.5132721066474915,\n",
       "  'decision': True}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_one_blend(\"O=C(O)Cc1cc(I)c(Oc2ccc(O)c(I)c2)c(I)c1\", mode=\"f1\", topk=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lord",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
