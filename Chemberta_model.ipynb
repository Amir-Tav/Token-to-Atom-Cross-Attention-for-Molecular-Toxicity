{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "607aa096",
   "metadata": {},
   "source": [
    "# Phase 0: ChemBERTa on Tox21 â€” Clean Re-Training (Masked Multi-Label, Stratified K-Fold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4717d2f",
   "metadata": {},
   "source": [
    "## 1: Imports and paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "488fdf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "CSV exists: True  -> tox21_chembera_pipeline_V2\\data\\tox21.csv\n",
      "Model dir:  D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\tox21_chembera_pipeline_V2\\model\\chemberta_v1\n",
      "Outputs:    D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\tox21_chembera_pipeline_V2\\outputs\n",
      "Config:     D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\Final\\config\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers==4.42.0 torch --quiet\n",
    "# !pip install pandas numpy scikit-learn tqdm iterstrat --quiet\n",
    "\n",
    "import os, json, math, random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import (AutoConfig, AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          get_linear_schedule_with_warmup, AdamW)\n",
    "\n",
    "# ---------- Paths ----------\n",
    "DATA_CSV   = Path(\"tox21_chembera_pipeline_V2/data/tox21.csv\")\n",
    "ROOT_DIR   = Path(\"tox21_chembera_pipeline_V2\")\n",
    "MODEL_DIR  = ROOT_DIR / \"model\" / \"chemberta_v1\"\n",
    "OUTPUTS_DIR= ROOT_DIR / \"outputs\"\n",
    "FINAL_DIR  = Path(\"Final\")\n",
    "CONFIG_DIR = FINAL_DIR / \"config\"\n",
    "\n",
    "for p in [MODEL_DIR, OUTPUTS_DIR, CONFIG_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Labels (canonical Tox21 12) ----------\n",
    "LABELS = [\n",
    "    \"NR-AR\", \"NR-AR-LBD\", \"NR-AhR\", \"NR-Aromatase\", \"NR-ER\",\n",
    "    \"NR-ER-LBD\", \"NR-PPAR-gamma\", \"SR-ARE\", \"SR-ATAD5\",\n",
    "    \"SR-HSE\", \"SR-MMP\", \"SR-p53\",\n",
    "]\n",
    "\n",
    "# ---------- Reproducibility ----------\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"CSV exists: {DATA_CSV.exists()}  -> {DATA_CSV}\")\n",
    "print(f\"Model dir:  {MODEL_DIR.resolve()}\")\n",
    "print(f\"Outputs:    {OUTPUTS_DIR.resolve()}\")\n",
    "print(f\"Config:     {CONFIG_DIR.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1614a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76c94308",
   "metadata": {},
   "source": [
    "## 2: Load data, build target/mask arrays, quick sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "500047ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows (molecules): 7831, Labels: 12\n",
      "Observed counts per label: {'NR-AR': 7265, 'NR-AR-LBD': 6758, 'NR-AhR': 6549, 'NR-Aromatase': 5821, 'NR-ER': 6193, 'NR-ER-LBD': 6955, 'NR-PPAR-gamma': 6450, 'SR-ARE': 5832, 'SR-ATAD5': 7072, 'SR-HSE': 6467, 'SR-MMP': 5810, 'SR-p53': 6774}\n",
      "Positive rates per label: {'NR-AR': 0.043, 'NR-AR-LBD': 0.035, 'NR-AhR': 0.117, 'NR-Aromatase': 0.052, 'NR-ER': 0.128, 'NR-ER-LBD': 0.05, 'NR-PPAR-gamma': 0.029, 'SR-ARE': 0.162, 'SR-ATAD5': 0.037, 'SR-HSE': 0.058, 'SR-MMP': 0.158, 'SR-p53': 0.062}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>NR-AR</th>\n",
       "      <th>NR-AR-LBD</th>\n",
       "      <th>NR-AhR</th>\n",
       "      <th>NR-Aromatase</th>\n",
       "      <th>NR-ER</th>\n",
       "      <th>NR-ER-LBD</th>\n",
       "      <th>NR-PPAR-gamma</th>\n",
       "      <th>SR-ARE</th>\n",
       "      <th>SR-ATAD5</th>\n",
       "      <th>SR-HSE</th>\n",
       "      <th>SR-MMP</th>\n",
       "      <th>SR-p53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCOc1ccc2nc(S(N)(=O)=O)sc2c1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCN1C(=O)NC(c2ccccc2)C1=O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC[C@]1(O)CC[C@H]2[C@@H]3CCC4=CCCC[C@@H]4[C@H]...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCCN(CC)C(CC)C(=O)Nc1c(C)cccc1C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC(O)(P(=O)(O)O)P(=O)(O)O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  NR-AR  NR-AR-LBD  \\\n",
       "0                       CCOc1ccc2nc(S(N)(=O)=O)sc2c1    0.0        0.0   \n",
       "1                          CCN1C(=O)NC(c2ccccc2)C1=O    0.0        0.0   \n",
       "2  CC[C@]1(O)CC[C@H]2[C@@H]3CCC4=CCCC[C@@H]4[C@H]...    NaN        NaN   \n",
       "3                    CCCN(CC)C(CC)C(=O)Nc1c(C)cccc1C    0.0        0.0   \n",
       "4                          CC(O)(P(=O)(O)O)P(=O)(O)O    0.0        0.0   \n",
       "\n",
       "   NR-AhR  NR-Aromatase  NR-ER  NR-ER-LBD  NR-PPAR-gamma  SR-ARE  SR-ATAD5  \\\n",
       "0     1.0           NaN    NaN        0.0            0.0     1.0       0.0   \n",
       "1     0.0           0.0    0.0        0.0            0.0     NaN       0.0   \n",
       "2     NaN           NaN    NaN        NaN            NaN     0.0       NaN   \n",
       "3     0.0           0.0    0.0        0.0            0.0     NaN       0.0   \n",
       "4     0.0           0.0    0.0        0.0            0.0     0.0       0.0   \n",
       "\n",
       "   SR-HSE  SR-MMP  SR-p53  \n",
       "0     0.0     0.0     0.0  \n",
       "1     NaN     0.0     0.0  \n",
       "2     0.0     NaN     NaN  \n",
       "3     NaN     0.0     0.0  \n",
       "4     0.0     0.0     0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved cleaned data to: tox21_chembera_pipeline_V2\\data\\tox21_clean.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Load CSV\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "assert \"smiles\" in df.columns, \"CSV must contain a 'smiles' column\"\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "# Ensure label columns exist (create if missing -> NaN)\n",
    "for c in LABELS:\n",
    "    if c not in df.columns:\n",
    "        df[c] = np.nan\n",
    "    # Coerce to numeric (strings like \"\" -> NaN)\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# Keep only SMILES + labels (clone to avoid chained assignment warnings)\n",
    "df = df[[\"smiles\"] + LABELS].copy()\n",
    "\n",
    "# 2) Build targets (y) and mask (m)\n",
    "y = df[LABELS].to_numpy(dtype=np.float32)                  # shape [N, 12], may contain NaN\n",
    "mask = (~df[LABELS].isna()).to_numpy(dtype=np.float32)     # 1 if observed, 0 if missing\n",
    "\n",
    "N, C = y.shape\n",
    "obs_per_label = mask.sum(axis=0)                            # number of observed entries per label\n",
    "pos_per_label = np.nansum(np.where(mask == 1, y, np.nan), axis=0)  # positives among observed\n",
    "# avoid div by zero\n",
    "pos_rate = np.where(obs_per_label > 0, pos_per_label / obs_per_label, np.nan)\n",
    "\n",
    "print(f\"Rows (molecules): {N}, Labels: {C}\")\n",
    "print(\"Observed counts per label:\", dict(zip(LABELS, obs_per_label.astype(int))))\n",
    "print(\"Positive rates per label:\", {k: float(f\"{v:.3f}\") if np.isfinite(v) else None\n",
    "                                   for k, v in zip(LABELS, pos_rate)})\n",
    "\n",
    "display(df.head(5))\n",
    "\n",
    "# 3) Quick visuals (optional)\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "ax.bar(range(C), obs_per_label)\n",
    "ax.set_xticks(range(C))\n",
    "ax.set_xticklabels(LABELS, rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"# observed\")\n",
    "ax.set_title(\"Observed labels per task\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "plot_rates = np.nan_to_num(pos_rate, nan=0.0)\n",
    "ax.bar(range(C), plot_rates)\n",
    "ax.set_xticks(range(C))\n",
    "ax.set_xticklabels(LABELS, rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"positive rate (observed)\")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title(\"Positive rate per task\")\n",
    "plt.show()\n",
    "\n",
    "# Persist a cleaned copy if helpful\n",
    "CLEAN_PATH = ROOT_DIR / \"data\" / \"tox21_clean.parquet\"\n",
    "CLEAN_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_parquet(CLEAN_PATH, index=False)\n",
    "print(f\"âœ… Saved cleaned data to: {CLEAN_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e32c8c2",
   "metadata": {},
   "source": [
    "## 3: Base model, tokenizer, and stratified folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aa8f992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved run config â†’ D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\tox21_chembera_pipeline_V2\\outputs\\run_config.json\n",
      "Tokenizer loaded from: seyonec/ChemBERTa-zinc-base-v1\n",
      "âœ… Saved folds to: D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\tox21_chembera_pipeline_V2\\outputs\\folds.csv\n",
      "fold\n",
      "1    1566\n",
      "2    1567\n",
      "3    1566\n",
      "4    1566\n",
      "5    1566\n",
      "Name: count, dtype: int64\n",
      "Per-fold positive rates (observed only):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'NR-AR': 0.043,\n",
       "  'NR-AR-LBD': 0.035,\n",
       "  'NR-AhR': 0.118,\n",
       "  'NR-Aromatase': 0.052,\n",
       "  'NR-ER': 0.13,\n",
       "  'NR-ER-LBD': 0.05,\n",
       "  'NR-PPAR-gamma': 0.03,\n",
       "  'SR-ARE': 0.163,\n",
       "  'SR-ATAD5': 0.037,\n",
       "  'SR-HSE': 0.058,\n",
       "  'SR-MMP': 0.161,\n",
       "  'SR-p53': 0.064},\n",
       " 2: {'NR-AR': 0.043,\n",
       "  'NR-AR-LBD': 0.036,\n",
       "  'NR-AhR': 0.118,\n",
       "  'NR-Aromatase': 0.052,\n",
       "  'NR-ER': 0.128,\n",
       "  'NR-ER-LBD': 0.051,\n",
       "  'NR-PPAR-gamma': 0.029,\n",
       "  'SR-ARE': 0.158,\n",
       "  'SR-ATAD5': 0.038,\n",
       "  'SR-HSE': 0.056,\n",
       "  'SR-MMP': 0.155,\n",
       "  'SR-p53': 0.062},\n",
       " 3: {'NR-AR': 0.042,\n",
       "  'NR-AR-LBD': 0.035,\n",
       "  'NR-AhR': 0.116,\n",
       "  'NR-Aromatase': 0.051,\n",
       "  'NR-ER': 0.128,\n",
       "  'NR-ER-LBD': 0.05,\n",
       "  'NR-PPAR-gamma': 0.028,\n",
       "  'SR-ARE': 0.163,\n",
       "  'SR-ATAD5': 0.037,\n",
       "  'SR-HSE': 0.058,\n",
       "  'SR-MMP': 0.156,\n",
       "  'SR-p53': 0.062},\n",
       " 4: {'NR-AR': 0.042,\n",
       "  'NR-AR-LBD': 0.035,\n",
       "  'NR-AhR': 0.117,\n",
       "  'NR-Aromatase': 0.051,\n",
       "  'NR-ER': 0.127,\n",
       "  'NR-ER-LBD': 0.05,\n",
       "  'NR-PPAR-gamma': 0.029,\n",
       "  'SR-ARE': 0.162,\n",
       "  'SR-ATAD5': 0.038,\n",
       "  'SR-HSE': 0.058,\n",
       "  'SR-MMP': 0.16,\n",
       "  'SR-p53': 0.062},\n",
       " 5: {'NR-AR': 0.042,\n",
       "  'NR-AR-LBD': 0.035,\n",
       "  'NR-AhR': 0.118,\n",
       "  'NR-Aromatase': 0.052,\n",
       "  'NR-ER': 0.128,\n",
       "  'NR-ER-LBD': 0.05,\n",
       "  'NR-PPAR-gamma': 0.029,\n",
       "  'SR-ARE': 0.162,\n",
       "  'SR-ATAD5': 0.037,\n",
       "  'SR-HSE': 0.058,\n",
       "  'SR-MMP': 0.158,\n",
       "  'SR-p53': 0.062}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "\n",
    "# === Choose a base model (you can change and re-run) ===\n",
    "BASE_MODEL = \"seyonec/ChemBERTa-zinc-base-v1\"  \n",
    "\n",
    "# === Hyperparameters (tweak as you wish) ===\n",
    "MAX_LEN   = 256\n",
    "FOLDS     = 5\n",
    "SEED      = 42\n",
    "\n",
    "EPOCHS    = 100\n",
    "BATCH_SZ  = 16\n",
    "LR        = 2e-5\n",
    "L2D       = 0.95      # layer-wise lr decay factor\n",
    "PATIENCE  = 2         # early stopping patience (epochs)\n",
    "\n",
    "# Persist a tiny config snapshot for the run\n",
    "run_cfg = {\n",
    "    \"base_model\": BASE_MODEL,\n",
    "    \"max_len\": MAX_LEN,\n",
    "    \"folds\": FOLDS,\n",
    "    \"seed\": SEED,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SZ,\n",
    "    \"lr\": LR,\n",
    "    \"l2d\": L2D,\n",
    "    \"patience\": PATIENCE,\n",
    "    \"labels\": LABELS,\n",
    "}\n",
    "(OUTPUTS_DIR / \"run_config.json\").write_text(json.dumps(run_cfg, indent=2), encoding=\"utf-8\")\n",
    "print(\"Saved run config â†’\", (OUTPUTS_DIR / \"run_config.json\").resolve())\n",
    "\n",
    "# === Tokenizer & (future) model config ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True)\n",
    "print(\"Tokenizer loaded from:\", BASE_MODEL)\n",
    "\n",
    "# === Multilabel stratified folds ===\n",
    "try:\n",
    "    from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "    HAS_ITERSTRAT = True\n",
    "except Exception:\n",
    "    HAS_ITERSTRAT = False\n",
    "\n",
    "X_dummy = np.zeros((len(df), 1))\n",
    "Y_for_split = np.nan_to_num(y, nan=0.0)   # ONLY for splitting\n",
    "fold_assign = np.full(len(df), -1, dtype=int)\n",
    "\n",
    "if HAS_ITERSTRAT:\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "    for k, (tr_idx, va_idx) in enumerate(mskf.split(X_dummy, Y_for_split), 1):\n",
    "        fold_assign[va_idx] = k\n",
    "else:\n",
    "    # Fallback: stratify on \"has any positive label\"\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    proxy = (~np.isnan(y) & (y > 0.5)).sum(axis=1) > 0\n",
    "    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "    for k, (tr_idx, va_idx) in enumerate(skf.split(np.zeros(len(df)), proxy.astype(int)), 1):\n",
    "        fold_assign[va_idx] = k\n",
    "\n",
    "assert (fold_assign >= 1).all(), \"Fold assignment failed for some rows.\"\n",
    "\n",
    "# Attach and save folds\n",
    "df_folds = df.copy()\n",
    "df_folds[\"fold\"] = fold_assign\n",
    "FOLDS_CSV = OUTPUTS_DIR / \"folds.csv\"\n",
    "df_folds.to_csv(FOLDS_CSV, index=False)\n",
    "print(\"âœ… Saved folds to:\", FOLDS_CSV.resolve())\n",
    "print(df_folds[\"fold\"].value_counts().sort_index())\n",
    "\n",
    "# Quick fold sanity: positive rates per label by fold (optional preview)\n",
    "per_fold_rates = {}\n",
    "for k in range(1, FOLDS + 1):\n",
    "    d = df_folds[df_folds[\"fold\"] == k]\n",
    "    m_k = (~d[LABELS].isna()).to_numpy(dtype=np.float32)\n",
    "    y_k = d[LABELS].to_numpy(dtype=np.float32)\n",
    "    obs = m_k.sum(axis=0)\n",
    "    pos = np.nansum(np.where(m_k == 1, y_k, np.nan), axis=0)\n",
    "    rate = np.where(obs > 0, pos / obs, np.nan)\n",
    "    per_fold_rates[k] = {lab: (None if not np.isfinite(r) else float(f\"{r:.3f}\"))\n",
    "                         for lab, r in zip(LABELS, rate)}\n",
    "\n",
    "print(\"Per-fold positive rates (observed only):\")\n",
    "per_fold_rates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08448be8",
   "metadata": {},
   "source": [
    "## 4: Dataset, masked loss, and metrics utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42d72ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset, loss, and metrics helpers ready.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ---------- Dataset ----------\n",
    "class SmilesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, smiles, y, mask, tokenizer, max_len=256):\n",
    "        self.smiles = list(map(str, smiles))\n",
    "        self.y = y.astype(np.float32)\n",
    "        self.mask = mask.astype(np.float32)\n",
    "        self.tok = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        s = self.smiles[i]\n",
    "        enc = self.tok(\n",
    "            s,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        # Replace NaN with 0.0 in labels here; masking will ignore them in loss/metrics\n",
    "        item['labels'] = torch.from_numpy(np.nan_to_num(self.y[i], nan=0.0)).float()\n",
    "        item['mask']   = torch.from_numpy(self.mask[i]).float()\n",
    "        return item\n",
    "\n",
    "# ---------- Masked multi-label BCE with pos_weight ----------\n",
    "class MaskedBCELoss(nn.Module):\n",
    "    def __init__(self, pos_weight: torch.Tensor):\n",
    "        super().__init__()\n",
    "        # pos_weight: [C] on the correct device\n",
    "        self.bce = nn.BCEWithLogitsLoss(pos_weight=pos_weight, reduction='none')\n",
    "\n",
    "    def forward(self, logits, targets, mask):\n",
    "        \"\"\"\n",
    "        logits: [B, C] raw logits\n",
    "        targets: [B, C] in {0,1}\n",
    "        mask: [B, C] in {0,1} -> 0 means \"missing label\" (ignore in loss)\n",
    "        \"\"\"\n",
    "        loss = self.bce(logits, targets)  # [B, C]\n",
    "        loss = loss * mask\n",
    "        denom = mask.sum().clamp_min(1.0)\n",
    "        return loss.sum() / denom\n",
    "\n",
    "# ---------- Metrics ----------\n",
    "@torch.no_grad()\n",
    "def masked_auc(y_true: np.ndarray, y_prob: np.ndarray, mask: np.ndarray):\n",
    "    \"\"\"\n",
    "    AUROC per label using only observed entries (mask==1). Returns (macro_auc, list_per_label).\n",
    "    If a label has degenerate ground truth (all 0 or all 1), returns NaN for that label.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    aucs = []\n",
    "    for j in range(y_true.shape[1]):\n",
    "        m = mask[:, j] > 0.5\n",
    "        if m.sum() < 3 or len(np.unique(y_true[m, j])) < 2:\n",
    "            aucs.append(np.nan)\n",
    "            continue\n",
    "        try:\n",
    "            aucs.append(roc_auc_score(y_true[m, j], y_prob[m, j]))\n",
    "        except Exception:\n",
    "            aucs.append(np.nan)\n",
    "    macro = np.nanmean(aucs) if np.any(~np.isnan(aucs)) else np.nan\n",
    "    return float(macro if not np.isnan(macro) else 0.0), [None if np.isnan(x) else float(x) for x in aucs]\n",
    "\n",
    "def compute_thresholds_youden(y_true: np.ndarray, y_prob: np.ndarray, mask: np.ndarray, labels=LABELS):\n",
    "    \"\"\"\n",
    "    Per-label threshold via Youden's J (TPR - FPR). Ignores missing via mask.\n",
    "    \"\"\"\n",
    "    th = {}\n",
    "    for j, name in enumerate(labels):\n",
    "        m = mask[:, j] > 0.5\n",
    "        if m.sum() == 0:\n",
    "            th[name] = 0.5\n",
    "            continue\n",
    "        y, p = y_true[m, j], y_prob[m, j]\n",
    "        grid = np.unique(np.concatenate([[0.0, 1.0], p]))\n",
    "        best_t, best_s = 0.5, -1.0\n",
    "        for t in grid:\n",
    "            yhat = (p >= t).astype(int)\n",
    "            tp = ((y == 1) & (yhat == 1)).sum()\n",
    "            fp = ((y == 0) & (yhat == 1)).sum()\n",
    "            fn = ((y == 1) & (yhat == 0)).sum()\n",
    "            tn = ((y == 0) & (yhat == 0)).sum()\n",
    "            tpr = tp / (tp + fn + 1e-9)\n",
    "            fpr = fp / (fp + tn + 1e-9)\n",
    "            s = tpr - fpr\n",
    "            if s > best_s:\n",
    "                best_s, best_t = s, float(t)\n",
    "        th[name] = round(best_t, 4)\n",
    "    return th\n",
    "\n",
    "# ---------- Layer-wise LR decay groups ----------\n",
    "def layerwise_lr(model, base_lr, decay=0.95):\n",
    "    \"\"\"\n",
    "    Assigns smaller LR to lower layers (layer-wise LR decay).\n",
    "    Returns param groups suitable for AdamW.\n",
    "    \"\"\"\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    params = []\n",
    "    # try common encoders\n",
    "    if hasattr(model, \"roberta\"):\n",
    "        layers = list(model.roberta.encoder.layer)\n",
    "    elif hasattr(model, \"bert\"):\n",
    "        layers = list(model.bert.encoder.layer)\n",
    "    else:\n",
    "        layers = []\n",
    "\n",
    "    # classification head (if exists)\n",
    "    head, head_no_decay = [], []\n",
    "    head_module = getattr(model, \"classifier\", None)\n",
    "    if head_module is not None:\n",
    "        for n, p in head_module.named_parameters():\n",
    "            (head_no_decay if any(nd in n for nd in no_decay) else head).append(p)\n",
    "\n",
    "    # encoder layers (reversed so top layers get higher LR)\n",
    "    for i, layer in enumerate(reversed(layers)):\n",
    "        lr = base_lr * (decay ** i)\n",
    "        wd_group, no_wd_group = [], []\n",
    "        for n, p in layer.named_parameters():\n",
    "            (no_wd_group if any(nd in n for nd in no_decay) else wd_group).append(p)\n",
    "        params.append({\"params\": wd_group,      \"lr\": lr, \"weight_decay\": 0.01})\n",
    "        params.append({\"params\": no_wd_group,   \"lr\": lr, \"weight_decay\": 0.00})\n",
    "\n",
    "    if head:\n",
    "        params.append({\"params\": head,          \"lr\": base_lr, \"weight_decay\": 0.01})\n",
    "    if head_no_decay:\n",
    "        params.append({\"params\": head_no_decay, \"lr\": base_lr, \"weight_decay\": 0.00})\n",
    "\n",
    "    # fallback if we couldn't find layers\n",
    "    if not params:\n",
    "        decay_group, no_decay_group = [], []\n",
    "        for n, p in model.named_parameters():\n",
    "            (no_decay_group if any(nd in n for nd in no_decay) else decay_group).append(p)\n",
    "        params = [\n",
    "            {\"params\": decay_group,    \"lr\": base_lr, \"weight_decay\": 0.01},\n",
    "            {\"params\": no_decay_group, \"lr\": base_lr, \"weight_decay\": 0.00},\n",
    "        ]\n",
    "    return params\n",
    "\n",
    "print(\"âœ… Dataset, loss, and metrics helpers ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e555049e",
   "metadata": {},
   "source": [
    "## 5A: Training utilities (dataloaders, pos_weight, one-fold train/val with early stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "750f359b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available?  True\n",
      "GPU device count: 1\n",
      "Current device: 0\n",
      "GPU name: NVIDIA GeForce RTX 4070 Ti\n",
      "Test tensor on CUDA: cuda:0 tensor([[0.8823, 0.9150, 0.3829],\n",
      "        [0.9593, 0.3904, 0.6009],\n",
      "        [0.2566, 0.7936, 0.9408]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available? \", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU device count:\", torch.cuda.device_count())\n",
    "    print(\"Current device:\", torch.cuda.current_device())\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    x = torch.rand(3,3).to(\"cuda\")\n",
    "    print(\"Test tensor on CUDA:\", x.device, x)\n",
    "else:\n",
    "    print(\"âš ï¸ CUDA not available, training will run on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ebf196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "def make_loaders(train_idx, val_idx, tokenizer, max_len=MAX_LEN, batch_size=BATCH_SZ):\n",
    "    train_ds = SmilesDataset(df.iloc[train_idx][\"smiles\"].tolist(),\n",
    "                             y[train_idx], mask[train_idx], tokenizer, max_len=max_len)\n",
    "    val_ds   = SmilesDataset(df.iloc[val_idx][\"smiles\"].tolist(),\n",
    "                             y[val_idx],   mask[val_idx],   tokenizer, max_len=max_len)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    return train_ds, val_ds, train_loader, val_loader\n",
    "\n",
    "def compute_pos_weight_from_train(train_ds) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Estimate pos_weight = negatives/positives using only observed labels in the TRAIN split.\n",
    "    \"\"\"\n",
    "    yy = []\n",
    "    mm = []\n",
    "    for i in range(len(train_ds)):\n",
    "        item = train_ds[i]\n",
    "        yy.append(item[\"labels\"].numpy())\n",
    "        mm.append(item[\"mask\"].numpy())\n",
    "    yy = np.vstack(yy)  # [N, C]\n",
    "    mm = np.vstack(mm)  # [N, C]\n",
    "    pos = (yy * mm).sum(axis=0) + 1e-6\n",
    "    neg = ((1 - yy) * mm).sum(axis=0) + 1e-6\n",
    "    pw = torch.tensor(neg / pos, dtype=torch.float32, device=device)\n",
    "    return pw\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    all_logits, all_y, all_m = [], [], []\n",
    "    for batch in val_loader:\n",
    "        batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "        out = model(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n",
    "        all_logits.append(out.logits.detach().cpu().numpy())\n",
    "        all_y.append(batch[\"labels\"].cpu().numpy())\n",
    "        all_m.append(batch[\"mask\"].cpu().numpy())\n",
    "    logits = np.vstack(all_logits)\n",
    "    y_true = np.vstack(all_y)\n",
    "    msk    = np.vstack(all_m)\n",
    "    y_prob = 1 / (1 + np.exp(-logits))\n",
    "    macro, per_label = masked_auc(y_true, y_prob, msk)\n",
    "    return macro, per_label, y_true, y_prob, msk\n",
    "\n",
    "def train_one_fold(train_idx, val_idx):\n",
    "    \"\"\"\n",
    "    Train a fresh model on the given indices and return:\n",
    "      - best_model (loaded with best state)\n",
    "      - fold_metrics = dict(macro_auc=..., per_label_auc=[...])\n",
    "      - val_arrays = (y_true, y_prob, mask) for the validation split\n",
    "    \"\"\"\n",
    "    # Fresh model for this fold\n",
    "    cfg = AutoConfig.from_pretrained(BASE_MODEL, num_labels=len(LABELS), problem_type=\"multi_label_classification\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL, config=cfg).to(device)\n",
    "\n",
    "    # Data\n",
    "    train_ds, val_ds, train_loader, val_loader = make_loaders(train_idx, val_idx, tokenizer, max_len=MAX_LEN, batch_size=BATCH_SZ)\n",
    "\n",
    "    # Loss with pos_weight estimated from training data\n",
    "    pos_weight = compute_pos_weight_from_train(train_ds)\n",
    "    loss_fn = MaskedBCELoss(pos_weight=pos_weight)\n",
    "\n",
    "    # Optimizer & scheduler\n",
    "    optim = AdamW(layerwise_lr(model, LR, decay=L2D), betas=(0.9, 0.999), eps=1e-8)\n",
    "    total_steps = len(train_loader) * EPOCHS\n",
    "    warmup = int(0.1 * total_steps)\n",
    "    sched = get_linear_schedule_with_warmup(optim, num_warmup_steps=warmup, num_training_steps=total_steps)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "    # Early stopping on masked macro AUROC\n",
    "    best_auc = -1.0\n",
    "    best_state = None\n",
    "    patience_left = PATIENCE\n",
    "\n",
    "    for ep in range(1, EPOCHS + 1):\n",
    "        model.train()\n",
    "        ep_losses = []\n",
    "        for batch in tqdm(train_loader, desc=f\"[fold train] epoch {ep}/{EPOCHS}\"):\n",
    "            batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
    "                out = model(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n",
    "                loss = loss_fn(out.logits, batch[\"labels\"], batch[\"mask\"])\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optim)\n",
    "            scaler.update()\n",
    "            sched.step()\n",
    "            ep_losses.append(loss.item())\n",
    "\n",
    "        # Validation\n",
    "        macro, per_label, vy_true, vy_prob, vmask = validate(model, val_loader)\n",
    "        print(f\"[val] epoch={ep}  loss={np.mean(ep_losses):.4f}  macro_auc={macro:.4f}\")\n",
    "\n",
    "        if macro > best_auc:\n",
    "            best_auc = macro\n",
    "            best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
    "            patience_left = PATIENCE\n",
    "        else:\n",
    "            patience_left -= 1\n",
    "            if patience_left <= 0:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "    # Load best state\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # Final val pass with best weights\n",
    "    macro, per_label, vy_true, vy_prob, vmask = validate(model, val_loader)\n",
    "    fold_metrics = {\"macro_auc\": float(macro), \"per_label_auc\": per_label}\n",
    "\n",
    "    return model, fold_metrics, (vy_true, vy_prob, vmask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f226546e",
   "metadata": {},
   "source": [
    "### 5B: Run K-fold training, save per-fold models, OOF predictions, thresholds, and enrich config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1b87be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Fold 1/5 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\lord\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_23324\\292123357.py:71: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
      "[fold train] epoch 1/100:   0%|          | 0/392 [00:00<?, ?it/s]C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_23324\\292123357.py:84: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "[fold train] epoch 1/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [00:20<00:00, 18.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] epoch=1  loss=1.2898  macro_auc=0.6259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fold train] epoch 2/100:   0%|          | 0/392 [00:00<?, ?it/s]C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_23324\\292123357.py:84: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "[fold train] epoch 2/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [00:20<00:00, 19.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] epoch=2  loss=1.2055  macro_auc=0.7320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fold train] epoch 3/100:   0%|          | 0/392 [00:00<?, ?it/s]C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_23324\\292123357.py:84: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "[fold train] epoch 3/100:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 378/392 [00:20<00:00, 18.76it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m val_idx = np.where(folds_csv[\u001b[33m\"\u001b[39m\u001b[33mfold\u001b[39m\u001b[33m\"\u001b[39m].values == k)[\u001b[32m0\u001b[39m]\n\u001b[32m     18\u001b[39m train_idx = np.where(folds_csv[\u001b[33m\"\u001b[39m\u001b[33mfold\u001b[39m\u001b[33m\"\u001b[39m].values != k)[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m model_k, metrics_k, (vy_true, vy_prob, vmask) = \u001b[43mtrain_one_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m fold_metrics.append({\u001b[33m\"\u001b[39m\u001b[33mfold\u001b[39m\u001b[33m\"\u001b[39m: k, **metrics_k})\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Store fold model\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 88\u001b[39m, in \u001b[36mtrain_one_fold\u001b[39m\u001b[34m(train_idx, val_idx)\u001b[39m\n\u001b[32m     86\u001b[39m     loss = loss_fn(out.logits, batch[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m], batch[\u001b[33m\"\u001b[39m\u001b[33mmask\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     87\u001b[39m scaler.scale(loss).backward()\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m scaler.update()\n\u001b[32m     90\u001b[39m sched.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\lord\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:457\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    451\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    454\u001b[39m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m\n\u001b[32m    455\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\lord\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:352\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    350\u001b[39m retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v.item() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     retval = \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\lord\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:140\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    138\u001b[39m opt = opt_ref()\n\u001b[32m    139\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\lord\\Lib\\site-packages\\torch\\optim\\optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\lord\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\lord\\Lib\\site-packages\\transformers\\optimization.py:646\u001b[39m, in \u001b[36mAdamW.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    642\u001b[39m state[\u001b[33m\"\u001b[39m\u001b[33mstep\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m    644\u001b[39m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[32m    645\u001b[39m \u001b[38;5;66;03m# In-place operations to update the averages at the same time\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m646\u001b[39m \u001b[43mexp_avg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m.add_(grad, alpha=(\u001b[32m1.0\u001b[39m - beta1))\n\u001b[32m    647\u001b[39m exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=\u001b[32m1.0\u001b[39m - beta2)\n\u001b[32m    648\u001b[39m denom = exp_avg_sq.sqrt().add_(group[\u001b[33m\"\u001b[39m\u001b[33meps\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "# Load folds\n",
    "folds_csv = pd.read_csv(OUTPUTS_DIR / \"folds.csv\")\n",
    "assert \"fold\" in folds_csv.columns and \"smiles\" in folds_csv.columns\n",
    "\n",
    "# Containers for OOF logits (weâ€™ll reconstruct logits from val probs)\n",
    "oof_prob = np.zeros((len(folds_csv), len(LABELS)), dtype=np.float32)\n",
    "oof_mask = mask.copy()  # same order as original df\n",
    "\n",
    "fold_metrics = []\n",
    "for k in range(1, FOLDS + 1):\n",
    "    print(f\"\\n========== Fold {k}/{FOLDS} ==========\")\n",
    "    val_idx = np.where(folds_csv[\"fold\"].values == k)[0]\n",
    "    train_idx = np.where(folds_csv[\"fold\"].values != k)[0]\n",
    "\n",
    "    model_k, metrics_k, (vy_true, vy_prob, vmask) = train_one_fold(train_idx, val_idx)\n",
    "    fold_metrics.append({\"fold\": k, **metrics_k})\n",
    "\n",
    "    # Store fold model\n",
    "    fold_dir = MODEL_DIR / f\"fold_{k}\"\n",
    "    fold_dir.mkdir(parents=True, exist_ok=True)\n",
    "    model_k.save_pretrained(fold_dir)\n",
    "    tokenizer.save_pretrained(fold_dir)\n",
    "\n",
    "    # Insert OOF probs at validation indices\n",
    "    assert vy_prob.shape[0] == len(val_idx)\n",
    "    oof_prob[val_idx] = vy_prob.astype(np.float32)\n",
    "\n",
    "# Aggregate OOF metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "macro_oof, per_label_oof = masked_auc(np.nan_to_num(y, nan=-1), oof_prob, oof_mask)\n",
    "print(f\"\\nOOF macro AUROC: {macro_oof:.4f}\")\n",
    "print(\"OOF per-label AUROC:\", dict(zip(LABELS, per_label_oof)))\n",
    "\n",
    "# Save OOF arrays & a compatibility copy for the app\n",
    "np.save(OUTPUTS_DIR / \"oof_prob.npy\", oof_prob.astype(np.float32))\n",
    "np.save(OUTPUTS_DIR / \"oof_mask.npy\", oof_mask.astype(np.float32))\n",
    "np.save(OUTPUTS_DIR / \"val_y.npy\", np.nan_to_num(y, nan=-1).astype(np.float32))\n",
    "np.save(OUTPUTS_DIR / \"val_prob.npy\", oof_prob.astype(np.float32))\n",
    "\n",
    "# Compute & save thresholds\n",
    "thresholds = compute_thresholds_youden(np.nan_to_num(y, nan=-1), oof_prob, oof_mask, labels=LABELS)\n",
    "(CONFIG_DIR / \"thresholds.json\").write_text(json.dumps(thresholds, indent=2), encoding=\"utf-8\")\n",
    "print(\"âœ… thresholds.json saved â†’\", (CONFIG_DIR / \"thresholds.json\").resolve())\n",
    "\n",
    "# Save tcav layers (we'll use last 3)\n",
    "(CONFIG_DIR / \"tcav_layers.json\").write_text(json.dumps({\"layers\": [-1, -2, -3]}, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# Save metrics summary\n",
    "metrics = {\"oof_macro_auc\": float(macro_oof), \"oof_per_label_auc\": per_label_oof, \"folds\": fold_metrics}\n",
    "(OUTPUTS_DIR / \"metrics.json\").write_text(json.dumps(metrics, indent=2), encoding=\"utf-8\")\n",
    "print(\"âœ… metrics.json saved â†’\", (OUTPUTS_DIR / \"metrics.json\").resolve())\n",
    "\n",
    "# Refit on all data briefly (optional but useful)\n",
    "print(\"\\nRefitting on all data for final model (short pass)...\")\n",
    "cfg = AutoConfig.from_pretrained(BASE_MODEL, num_labels=len(LABELS), problem_type=\"multi_label_classification\")\n",
    "model_full = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL, config=cfg).to(device)\n",
    "\n",
    "# Quick single-epoch-ish pass to adapt head on full data\n",
    "full_ds = SmilesDataset(df[\"smiles\"].tolist(), y, mask, tokenizer, max_len=MAX_LEN)\n",
    "full_loader = DataLoader(full_ds, batch_size=BATCH_SZ, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "# pos_weight on all observed data\n",
    "yy = np.nan_to_num(y, nan=0.0)\n",
    "pos = (yy * mask).sum(axis=0) + 1e-6\n",
    "neg = ((1 - yy) * mask).sum(axis=0) + 1e-6\n",
    "pos_weight_full = torch.tensor(neg / pos, dtype=torch.float32, device=device)\n",
    "loss_fn_full = MaskedBCELoss(pos_weight=pos_weight_full)\n",
    "\n",
    "optim = AdamW(layerwise_lr(model_full, LR, decay=L2D))\n",
    "steps = len(full_loader)  # one pass\n",
    "sched = get_linear_schedule_with_warmup(optim, int(0.1 * steps), steps)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "model_full.train()\n",
    "for step, batch in enumerate(tqdm(full_loader, desc=\"Refit(full)\")):\n",
    "    batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "    optim.zero_grad(set_to_none=True)\n",
    "    with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
    "        out = model_full(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n",
    "        loss = loss_fn_full(out.logits, batch[\"labels\"], batch[\"mask\"])\n",
    "    scaler.scale(loss).backward(); scaler.step(optim); scaler.update(); sched.step()\n",
    "\n",
    "# Save final model\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "model_full.save_pretrained(MODEL_DIR)\n",
    "tokenizer.save_pretrained(MODEL_DIR)\n",
    "\n",
    "# Enrich final config with id2label / label2id\n",
    "cfg_path = MODEL_DIR / \"config.json\"\n",
    "cfg_json = json.loads(cfg_path.read_text(encoding=\"utf-8\"))\n",
    "id2label = {i: LABELS[i] for i in range(len(LABELS))}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "cfg_json[\"id2label\"] = {str(k): v for k, v in id2label.items()}\n",
    "cfg_json[\"label2id\"] = label2id\n",
    "cfg_path.write_text(json.dumps(cfg_json, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\nâœ… Done.\")\n",
    "print(f\"- Fold models â†’ {MODEL_DIR}\")\n",
    "print(f\"- Final model â†’ {MODEL_DIR}\")\n",
    "print(f\"- OOF arrays  â†’ {OUTPUTS_DIR}\")\n",
    "print(f\"- thresholds  â†’ {CONFIG_DIR / 'thresholds.json'}\")\n",
    "print(f\"- tcav layers â†’ {CONFIG_DIR / 'tcav_layers.json'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b2517",
   "metadata": {},
   "source": [
    "## Calibration + Thresholds "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46676789",
   "metadata": {},
   "source": [
    "### Calibration saved in implementation/models/metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e10c0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - temperature.npy\n",
      " - calibration_methods.json\n",
      " - platt_params.json\n",
      " - isotonic_params.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_8596\\335931111.py:56: RuntimeWarning: divide by zero encountered in log\n",
      "  return float(-(y*np.log(p) + (1-y)*np.log(1-p)).mean())\n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_8596\\335931111.py:56: RuntimeWarning: invalid value encountered in multiply\n",
      "  return float(-(y*np.log(p) + (1-y)*np.log(1-p)).mean())\n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_8596\\335931111.py:56: RuntimeWarning: divide by zero encountered in log\n",
      "  return float(-(y*np.log(p) + (1-y)*np.log(1-p)).mean())\n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_8596\\335931111.py:56: RuntimeWarning: invalid value encountered in multiply\n",
      "  return float(-(y*np.log(p) + (1-y)*np.log(1-p)).mean())\n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_8596\\335931111.py:56: RuntimeWarning: divide by zero encountered in log\n",
      "  return float(-(y*np.log(p) + (1-y)*np.log(1-p)).mean())\n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_8596\\335931111.py:56: RuntimeWarning: invalid value encountered in multiply\n",
      "  return float(-(y*np.log(p) + (1-y)*np.log(1-p)).mean())\n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_8596\\335931111.py:56: RuntimeWarning: divide by zero encountered in log\n",
      "  return float(-(y*np.log(p) + (1-y)*np.log(1-p)).mean())\n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_8596\\335931111.py:56: RuntimeWarning: invalid value encountered in multiply\n",
      "  return float(-(y*np.log(p) + (1-y)*np.log(1-p)).mean())\n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_8596\\335931111.py:56: RuntimeWarning: divide by zero encountered in log\n",
      "  return float(-(y*np.log(p) + (1-y)*np.log(1-p)).mean())\n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_8596\\335931111.py:56: RuntimeWarning: invalid value encountered in multiply\n",
      "  return float(-(y*np.log(p) + (1-y)*np.log(1-p)).mean())\n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_8596\\335931111.py:56: RuntimeWarning: divide by zero encountered in log\n",
      "  return float(-(y*np.log(p) + (1-y)*np.log(1-p)).mean())\n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_8596\\335931111.py:56: RuntimeWarning: invalid value encountered in multiply\n",
      "  return float(-(y*np.log(p) + (1-y)*np.log(1-p)).mean())\n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_8596\\335931111.py:56: RuntimeWarning: divide by zero encountered in log\n",
      "  return float(-(y*np.log(p) + (1-y)*np.log(1-p)).mean())\n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_8596\\335931111.py:56: RuntimeWarning: invalid value encountered in multiply\n",
      "  return float(-(y*np.log(p) + (1-y)*np.log(1-p)).mean())\n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_8596\\335931111.py:56: RuntimeWarning: divide by zero encountered in log\n",
      "  return float(-(y*np.log(p) + (1-y)*np.log(1-p)).mean())\n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_8596\\335931111.py:56: RuntimeWarning: invalid value encountered in multiply\n",
      "  return float(-(y*np.log(p) + (1-y)*np.log(1-p)).mean())\n"
     ]
    }
   ],
   "source": [
    "# === CELL 1: CALIBRATION (save to implementation/models/metadata) ===\n",
    "import json, numpy as np\n",
    "from pathlib import Path\n",
    "from transformers import AutoConfig\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import torch\n",
    "\n",
    "# ---- paths (edit VAL_DIR if needed) ----\n",
    "META_DIR = Path(\"implementation/models/metadata\")\n",
    "VAL_DIR  = Path(\"tox21_chembera_pipeline_V2/outputs\")  # <-- change if your arrays live elsewhere\n",
    "CFG_PATH = \"implementation/models/chemberta_v1/config.json\"\n",
    "\n",
    "META_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- load validation arrays ----\n",
    "val_prob = np.load(VAL_DIR / \"val_prob.npy\")  # shape [N, L], raw model probs (sigmoid)\n",
    "val_y    = np.load(VAL_DIR / \"val_y.npy\")     # shape [N, L], {0,1}\n",
    "\n",
    "# ---- label order from model config ----\n",
    "cfg = AutoConfig.from_pretrained(CFG_PATH)\n",
    "id2label = cfg.id2label\n",
    "label_names = [id2label[i] for i in range(len(id2label))]\n",
    "\n",
    "# ---- logits from probs (for temperature / Platt) ----\n",
    "eps = 1e-6\n",
    "val_prob_clip = val_prob.clip(eps, 1 - eps)\n",
    "val_logit = np.log(val_prob_clip / (1 - val_prob_clip))\n",
    "\n",
    "# ---- A) global temperature scaling (minimize BCE on logits/T) ----\n",
    "X = torch.tensor(val_logit, dtype=torch.float32)\n",
    "Y = torch.tensor(val_y,    dtype=torch.float32)\n",
    "\n",
    "T = torch.nn.Parameter(torch.tensor(1.0, dtype=torch.float32))\n",
    "opt = torch.optim.LBFGS([T], lr=0.1, max_iter=100)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "\n",
    "def closure():\n",
    "    opt.zero_grad()\n",
    "    logits_T = X / torch.clamp(T, min=0.05, max=10.0)\n",
    "    loss = loss_fn(logits_T, Y)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "for _ in range(25):\n",
    "    opt.step(closure)\n",
    "\n",
    "T_final = float(T.detach().clamp(0.05, 10.0))\n",
    "np.save(META_DIR / \"temperature.npy\", np.array([T_final], dtype=np.float32))\n",
    "\n",
    "cal_prob_temp = torch.sigmoid(X / T_final).numpy()\n",
    "\n",
    "# ---- B) per-label Platt (logistic) & Isotonic; pick best by NLL ----\n",
    "def nll(p, y, eps=1e-8):\n",
    "    p = np.clip(p, eps, 1 - eps)\n",
    "    return float(-(y*np.log(p) + (1-y)*np.log(1-p)).mean())\n",
    "\n",
    "platt_params = {}\n",
    "iso_params   = {}\n",
    "method_per_label = {}\n",
    "final_probs  = np.zeros_like(val_prob)\n",
    "\n",
    "for j, lbl in enumerate(label_names):\n",
    "    yj = val_y[:, j].astype(float)\n",
    "    lj = val_logit[:, j].reshape(-1, 1)\n",
    "    pj = val_prob[:, j]\n",
    "\n",
    "    # Platt on logits\n",
    "    lr = LogisticRegression(solver=\"lbfgs\", max_iter=2000)\n",
    "    lr.fit(lj, yj)\n",
    "    A = float(lr.coef_[0][0]); B = float(lr.intercept_[0])\n",
    "    platt_params[lbl] = {\"A\": A, \"B\": B}\n",
    "    prob_platt = 1.0 / (1.0 + np.exp(-(A*val_logit[:, j] + B)))\n",
    "\n",
    "    # Isotonic on probs\n",
    "    ir = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "    ir.fit(pj, yj)\n",
    "    prob_iso = ir.transform(pj)\n",
    "    iso_params[lbl] = {\n",
    "        \"X\": ir.X_thresholds_.astype(float).tolist(),\n",
    "        \"Y\": ir.y_thresholds_.astype(float).tolist()\n",
    "    }\n",
    "\n",
    "    # candidates & NLLs\n",
    "    cands = {\n",
    "        \"none\":  pj,\n",
    "        \"temp\":  cal_prob_temp[:, j],\n",
    "        \"platt\": prob_platt,\n",
    "        \"iso\":   prob_iso,\n",
    "    }\n",
    "    scores = {k: nll(v, yj) for k, v in cands.items()}\n",
    "    best = min(scores, key=scores.get)\n",
    "    method_per_label[lbl] = {\"method\": best, \"scores\": scores}\n",
    "    final_probs[:, j] = cands[best]\n",
    "\n",
    "# ---- save calibration artifacts ----\n",
    "with open(META_DIR / \"calibration_methods.json\", \"w\") as f:\n",
    "    json.dump(method_per_label, f, indent=2)\n",
    "with open(META_DIR / \"platt_params.json\", \"w\") as f:\n",
    "    json.dump(platt_params, f, indent=2)\n",
    "with open(META_DIR / \"isotonic_params.json\", \"w\") as f:\n",
    "    json.dump(iso_params, f, indent=2)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" - temperature.npy\")\n",
    "print(\" - calibration_methods.json\")\n",
    "print(\" - platt_params.json\")\n",
    "print(\" - isotonic_params.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480dc651",
   "metadata": {},
   "source": [
    "### Compute robust per-label thresholds (bootstrapped) & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f15ba2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved thresholds.json and calibration artifacts under: D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\implementation\\models\\metadata\n",
      "Example thresholds: [('NR-AR', 0.62), ('NR-AR-LBD', 0.4599999999999999), ('NR-AhR', 0.36999999999999994), ('NR-Aromatase', 0.05), ('NR-ER', 0.5399999999999999)]\n"
     ]
    }
   ],
   "source": [
    "# === CELL 2: ROBUST THRESHOLDS (save to implementation/models/metadata) ===\n",
    "import json, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "META_DIR = Path(\"implementation/models/metadata\")\n",
    "VAL_DIR  = Path(\"tox21_chembera_pipeline_V2/outputs\")  # <-- keep in sync with Cell 1\n",
    "CFG_PATH = \"implementation/models/chemberta_v1/config.json\"\n",
    "\n",
    "# ---- reload arrays and calibration artifacts for a clean, reproducible step ----\n",
    "val_prob = np.load(VAL_DIR / \"val_prob.npy\")  # [N, L] raw probs\n",
    "val_y    = np.load(VAL_DIR / \"val_y.npy\")     # [N, L]\n",
    "\n",
    "from transformers import AutoConfig\n",
    "cfg = AutoConfig.from_pretrained(CFG_PATH)\n",
    "id2label = cfg.id2label\n",
    "label_names = [id2label[i] for i in range(len(id2label))]\n",
    "\n",
    "with open(META_DIR / \"calibration_methods.json\") as f:\n",
    "    CAL_METHOD = json.load(f)\n",
    "with open(META_DIR / \"platt_params.json\") as f:\n",
    "    PLATT = json.load(f)\n",
    "with open(META_DIR / \"isotonic_params.json\") as f:\n",
    "    ISO = json.load(f)\n",
    "temp_path = META_DIR / \"temperature.npy\"\n",
    "TEMP = float(np.load(temp_path)[0]) if temp_path.exists() else 1.0\n",
    "\n",
    "# ---- helper: apply saved calibration per label ----\n",
    "def apply_iso_scalar(p, X, Y):\n",
    "    return float(np.interp(p, np.asarray(X, float), np.asarray(Y, float)))\n",
    "\n",
    "def calibrate_probs(val_prob: np.ndarray) -> np.ndarray:\n",
    "    eps = 1e-6\n",
    "    logits = np.log(np.clip(val_prob, eps, 1 - eps) / np.clip(1 - val_prob, eps, 1 - eps))\n",
    "    out = np.zeros_like(val_prob, dtype=float)\n",
    "    for j, lbl in enumerate(label_names):\n",
    "        method = CAL_METHOD[lbl][\"method\"]\n",
    "        if method == \"temp\":\n",
    "            out[:, j] = 1.0 / (1.0 + np.exp(-(logits[:, j] / TEMP)))\n",
    "        elif method == \"platt\":\n",
    "            A = PLATT[lbl][\"A\"]; B = PLATT[lbl][\"B\"]\n",
    "            out[:, j] = 1.0 / (1.0 + np.exp(-(A*logits[:, j] + B)))\n",
    "        elif method == \"iso\":\n",
    "            X = ISO[lbl][\"X\"]; Y = ISO[lbl][\"Y\"]\n",
    "            out[:, j] = np.array([apply_iso_scalar(p, X, Y) for p in val_prob[:, j]])\n",
    "        else:  # \"none\"\n",
    "            out[:, j] = val_prob[:, j]\n",
    "    return out\n",
    "\n",
    "cal_prob = calibrate_probs(val_prob)\n",
    "\n",
    "# ---- robust thresholding via bootstrap (choose metric) ----\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def youden_score(y_true, y_hat):\n",
    "    tp = ((y_hat==1)&(y_true==1)).sum(); fn = ((y_hat==0)&(y_true==1)).sum()\n",
    "    fp = ((y_hat==1)&(y_true==0)).sum(); tn = ((y_hat==0)&(y_true==0)).sum()\n",
    "    tpr = tp/(tp+fn+1e-8); fpr = fp/(fp+tn+1e-8)\n",
    "    return tpr - fpr\n",
    "\n",
    "def best_threshold(p, y, metric=\"youden\", beta=1.0):\n",
    "    grid = np.linspace(0.05, 0.95, 181)\n",
    "    best_t, best_s = 0.5, -1.0\n",
    "    for t in grid:\n",
    "        yh = (p >= t).astype(int)\n",
    "        if metric == \"youden\":\n",
    "            s = youden_score(y, yh)\n",
    "        elif metric == \"f1\":\n",
    "            s = f1_score(y, yh) if yh.sum() or y.sum() else 0.0\n",
    "        else:  # f-beta\n",
    "            from sklearn.metrics import fbeta_score\n",
    "            s = fbeta_score(y, yh, beta=beta) if yh.sum() or y.sum() else 0.0\n",
    "        if s > best_s:\n",
    "            best_s, best_t = s, t\n",
    "    return best_t\n",
    "\n",
    "def boot_thresholds(probs: np.ndarray, y: np.ndarray, B=200, metric=\"youden\", beta=1.0):\n",
    "    N, L = probs.shape\n",
    "    rng = np.random.default_rng(123)\n",
    "    out = {}\n",
    "    for j, lbl in enumerate(label_names):\n",
    "        ts = []\n",
    "        for _ in range(B):\n",
    "            idx = rng.choice(N, size=N, replace=True)\n",
    "            ts.append(best_threshold(probs[idx, j], y[idx, j], metric=metric, beta=beta))\n",
    "        out[lbl] = float(np.median(ts))\n",
    "    return out\n",
    "\n",
    "# choose your objective: \"youden\" (balanced) or \"f1\" (positive-focused)\n",
    "thresholds = boot_thresholds(cal_prob, val_y, B=200, metric=\"youden\")\n",
    "\n",
    "# ---- save thresholds ----\n",
    "with open(META_DIR / \"thresholds.json\", \"w\") as f:\n",
    "    json.dump({k: round(v, 3) for k, v in thresholds.items()}, f, indent=2)\n",
    "\n",
    "print(\"Saved thresholds.json and calibration artifacts under:\", META_DIR.resolve())\n",
    "print(\"Example thresholds:\", list(thresholds.items())[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb480cd6",
   "metadata": {},
   "source": [
    "## 6: Post-training evaluation & plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977b8cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>thr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>balanced_acc</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>n_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SR-MMP</td>\n",
       "      <td>0.876089</td>\n",
       "      <td>0.590214</td>\n",
       "      <td>0.4741</td>\n",
       "      <td>0.403621</td>\n",
       "      <td>0.825708</td>\n",
       "      <td>0.542203</td>\n",
       "      <td>0.798381</td>\n",
       "      <td>758</td>\n",
       "      <td>1120</td>\n",
       "      <td>160</td>\n",
       "      <td>3772</td>\n",
       "      <td>5810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>0.862693</td>\n",
       "      <td>0.490267</td>\n",
       "      <td>0.3642</td>\n",
       "      <td>0.278385</td>\n",
       "      <td>0.861979</td>\n",
       "      <td>0.420852</td>\n",
       "      <td>0.782572</td>\n",
       "      <td>662</td>\n",
       "      <td>1716</td>\n",
       "      <td>106</td>\n",
       "      <td>4065</td>\n",
       "      <td>6549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>0.862111</td>\n",
       "      <td>0.539174</td>\n",
       "      <td>0.4680</td>\n",
       "      <td>0.248485</td>\n",
       "      <td>0.691983</td>\n",
       "      <td>0.365663</td>\n",
       "      <td>0.807961</td>\n",
       "      <td>164</td>\n",
       "      <td>496</td>\n",
       "      <td>73</td>\n",
       "      <td>6025</td>\n",
       "      <td>6758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>0.853894</td>\n",
       "      <td>0.293585</td>\n",
       "      <td>0.3820</td>\n",
       "      <td>0.141573</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.242308</td>\n",
       "      <td>0.781619</td>\n",
       "      <td>252</td>\n",
       "      <td>1528</td>\n",
       "      <td>48</td>\n",
       "      <td>3993</td>\n",
       "      <td>5821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SR-p53</td>\n",
       "      <td>0.840981</td>\n",
       "      <td>0.290373</td>\n",
       "      <td>0.3352</td>\n",
       "      <td>0.167335</td>\n",
       "      <td>0.789598</td>\n",
       "      <td>0.276147</td>\n",
       "      <td>0.763954</td>\n",
       "      <td>334</td>\n",
       "      <td>1662</td>\n",
       "      <td>89</td>\n",
       "      <td>4689</td>\n",
       "      <td>6774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SR-ATAD5</td>\n",
       "      <td>0.830246</td>\n",
       "      <td>0.284805</td>\n",
       "      <td>0.2870</td>\n",
       "      <td>0.110814</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.194184</td>\n",
       "      <td>0.770057</td>\n",
       "      <td>207</td>\n",
       "      <td>1661</td>\n",
       "      <td>57</td>\n",
       "      <td>5147</td>\n",
       "      <td>7072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>0.823367</td>\n",
       "      <td>0.209895</td>\n",
       "      <td>0.3499</td>\n",
       "      <td>0.093793</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.166259</td>\n",
       "      <td>0.760706</td>\n",
       "      <td>136</td>\n",
       "      <td>1314</td>\n",
       "      <td>50</td>\n",
       "      <td>4950</td>\n",
       "      <td>6450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>0.794642</td>\n",
       "      <td>0.408290</td>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.316040</td>\n",
       "      <td>0.776008</td>\n",
       "      <td>0.449155</td>\n",
       "      <td>0.726246</td>\n",
       "      <td>731</td>\n",
       "      <td>1582</td>\n",
       "      <td>211</td>\n",
       "      <td>3308</td>\n",
       "      <td>5832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NR-ER-LBD</td>\n",
       "      <td>0.794518</td>\n",
       "      <td>0.369676</td>\n",
       "      <td>0.4247</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.250923</td>\n",
       "      <td>0.740908</td>\n",
       "      <td>238</td>\n",
       "      <td>1309</td>\n",
       "      <td>112</td>\n",
       "      <td>5296</td>\n",
       "      <td>6955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-AR</td>\n",
       "      <td>0.794139</td>\n",
       "      <td>0.508918</td>\n",
       "      <td>0.6344</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.553398</td>\n",
       "      <td>0.397674</td>\n",
       "      <td>0.749384</td>\n",
       "      <td>171</td>\n",
       "      <td>380</td>\n",
       "      <td>138</td>\n",
       "      <td>6576</td>\n",
       "      <td>7265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>0.785774</td>\n",
       "      <td>0.249943</td>\n",
       "      <td>0.3185</td>\n",
       "      <td>0.125331</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.215315</td>\n",
       "      <td>0.719128</td>\n",
       "      <td>284</td>\n",
       "      <td>1982</td>\n",
       "      <td>88</td>\n",
       "      <td>4113</td>\n",
       "      <td>6467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>0.722230</td>\n",
       "      <td>0.406897</td>\n",
       "      <td>0.5293</td>\n",
       "      <td>0.293548</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.388391</td>\n",
       "      <td>0.685496</td>\n",
       "      <td>455</td>\n",
       "      <td>1095</td>\n",
       "      <td>338</td>\n",
       "      <td>4305</td>\n",
       "      <td>6193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label       AUC     AUPRC     thr  precision    recall        F1  \\\n",
       "10         SR-MMP  0.876089  0.590214  0.4741   0.403621  0.825708  0.542203   \n",
       "2          NR-AhR  0.862693  0.490267  0.3642   0.278385  0.861979  0.420852   \n",
       "1       NR-AR-LBD  0.862111  0.539174  0.4680   0.248485  0.691983  0.365663   \n",
       "3    NR-Aromatase  0.853894  0.293585  0.3820   0.141573  0.840000  0.242308   \n",
       "11         SR-p53  0.840981  0.290373  0.3352   0.167335  0.789598  0.276147   \n",
       "8        SR-ATAD5  0.830246  0.284805  0.2870   0.110814  0.784091  0.194184   \n",
       "6   NR-PPAR-gamma  0.823367  0.209895  0.3499   0.093793  0.731183  0.166259   \n",
       "7          SR-ARE  0.794642  0.408290  0.3860   0.316040  0.776008  0.449155   \n",
       "5       NR-ER-LBD  0.794518  0.369676  0.4247   0.153846  0.680000  0.250923   \n",
       "0           NR-AR  0.794139  0.508918  0.6344   0.310345  0.553398  0.397674   \n",
       "9          SR-HSE  0.785774  0.249943  0.3185   0.125331  0.763441  0.215315   \n",
       "4           NR-ER  0.722230  0.406897  0.5293   0.293548  0.573770  0.388391   \n",
       "\n",
       "    balanced_acc   tp    fp   fn    tn  n_obs  \n",
       "10      0.798381  758  1120  160  3772   5810  \n",
       "2       0.782572  662  1716  106  4065   6549  \n",
       "1       0.807961  164   496   73  6025   6758  \n",
       "3       0.781619  252  1528   48  3993   5821  \n",
       "11      0.763954  334  1662   89  4689   6774  \n",
       "8       0.770057  207  1661   57  5147   7072  \n",
       "6       0.760706  136  1314   50  4950   6450  \n",
       "7       0.726246  731  1582  211  3308   5832  \n",
       "5       0.740908  238  1309  112  5296   6955  \n",
       "0       0.749384  171   380  138  6576   7265  \n",
       "9       0.719128  284  1982   88  4113   6467  \n",
       "4       0.685496  455  1095  338  4305   6193  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved figures â†’ D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\tox21_chembera_pipeline_V2\\outputs\\figs\n",
      "âœ… Saved summary â†’ D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\tox21_chembera_pipeline_V2\\outputs\\summary.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "\n",
    "FIG_DIR = OUTPUTS_DIR / \"figs\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "oof_prob_path = OUTPUTS_DIR / \"oof_prob.npy\"\n",
    "oof_mask_path = OUTPUTS_DIR / \"oof_mask.npy\"\n",
    "th_path       = CONFIG_DIR / \"thresholds.json\"\n",
    "\n",
    "if not oof_prob_path.exists() or not oof_mask_path.exists():\n",
    "    print(\"âš ï¸ OOF arrays not found yet. Run this cell after training (Cell 5B) completes.\")\n",
    "else:\n",
    "    # Load arrays\n",
    "    oof_prob = np.load(oof_prob_path)        # [N, C]\n",
    "    oof_mask = np.load(oof_mask_path)        # [N, C]\n",
    "    y_true   = df[LABELS].to_numpy(dtype=np.float32)  # [N, C] with NaNs\n",
    "    y_true   = np.nan_to_num(y_true, nan=-1) # use -1 as \"missing\" sentinel (ignored via mask)\n",
    "\n",
    "    # Load thresholds (Youden)\n",
    "    if th_path.exists():\n",
    "        thresholds = json.loads(th_path.read_text(encoding=\"utf-8\"))\n",
    "    else:\n",
    "        thresholds = {lab: 0.5 for lab in LABELS}\n",
    "\n",
    "    # Containers\n",
    "    per_label_auc  = []\n",
    "    per_label_aupr = []\n",
    "    rows = []\n",
    "\n",
    "    # --- Per-label curves & metrics ---\n",
    "    for j, lab in enumerate(LABELS):\n",
    "        m = oof_mask[:, j] > 0.5\n",
    "        y = y_true[m, j]\n",
    "        p = oof_prob[m, j]\n",
    "        if m.sum() < 3 or len(np.unique(y)) < 2:\n",
    "            print(f\"Skipping {lab}: insufficient positives/negatives.\")\n",
    "            per_label_auc.append(np.nan)\n",
    "            per_label_aupr.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # ROC\n",
    "        fpr, tpr, _ = roc_curve(y, p)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        per_label_auc.append(roc_auc)\n",
    "\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.plot(fpr, tpr, lw=2, label=f\"AUC = {roc_auc:.3f}\")\n",
    "        plt.plot([0,1],[0,1], \"--\", lw=1)\n",
    "        plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC â€” {lab}\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FIG_DIR / f\"roc_{lab}.png\", dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "        # PR\n",
    "        precision, recall, _ = precision_recall_curve(y, p)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        per_label_aupr.append(pr_auc)\n",
    "\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.plot(recall, precision, lw=2, label=f\"AUPRC = {pr_auc:.3f}\")\n",
    "        plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"PR â€” {lab}\")\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FIG_DIR / f\"pr_{lab}.png\", dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "        # Thresholded metrics at Youden threshold\n",
    "        thr = float(thresholds.get(lab, 0.5))\n",
    "        yhat = (p >= thr).astype(int)\n",
    "\n",
    "        tp = int(((y == 1) & (yhat == 1)).sum())\n",
    "        fp = int(((y == 0) & (yhat == 1)).sum())\n",
    "        fn = int(((y == 1) & (yhat == 0)).sum())\n",
    "        tn = int(((y == 0) & (yhat == 0)).sum())\n",
    "        prec = tp / (tp + fp + 1e-9)\n",
    "        rec  = tp / (tp + fn + 1e-9)\n",
    "        f1   = 2 * prec * rec / (prec + rec + 1e-9)\n",
    "        tpr  = rec\n",
    "        tnr  = tn / (tn + fp + 1e-9)\n",
    "        bal_acc = 0.5 * (tpr + tnr)\n",
    "\n",
    "        rows.append({\n",
    "            \"label\": lab, \"AUC\": roc_auc, \"AUPRC\": pr_auc, \"thr\": thr,\n",
    "            \"precision\": prec, \"recall\": rec, \"F1\": f1, \"balanced_acc\": bal_acc,\n",
    "            \"tp\": tp, \"fp\": fp, \"fn\": fn, \"tn\": tn, \"n_obs\": int(m.sum())\n",
    "        })\n",
    "\n",
    "    # --- Bars: AUC & AUPRC ---\n",
    "    idx = np.arange(len(LABELS))\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.bar(idx, [0 if np.isnan(x) else x for x in per_label_auc])\n",
    "    plt.xticks(idx, LABELS, rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"AUC\"); plt.ylim(0, 1); plt.title(\"Per-label ROC AUC (OOF)\")\n",
    "    plt.tight_layout(); plt.savefig(FIG_DIR / \"auc_bars.png\", dpi=200); plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.bar(idx, [0 if np.isnan(x) else x for x in per_label_aupr])\n",
    "    plt.xticks(idx, LABELS, rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"AUPRC\"); plt.ylim(0, 1); plt.title(\"Per-label PR AUC (OOF)\")\n",
    "    plt.tight_layout(); plt.savefig(FIG_DIR / \"auprc_bars.png\", dpi=200); plt.close()\n",
    "\n",
    "    # --- Summary CSV ---\n",
    "    summary_df = pd.DataFrame(rows)\n",
    "    summary_df.to_csv(OUTPUTS_DIR / \"summary.csv\", index=False)\n",
    "    display(summary_df.sort_values(\"AUC\", ascending=False).head(12))\n",
    "\n",
    "    print(\"âœ… Saved figures â†’\", FIG_DIR.resolve())\n",
    "    print(\"âœ… Saved summary â†’\", (OUTPUTS_DIR / \"summary.csv\").resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b908746",
   "metadata": {},
   "source": [
    "## 7: Load final model, verify id2label/label2id, quick inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e3f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\tox21_chembera_pipeline_V2\\model\\chemberta_v1\n",
      "Has id2label/label2id? True\n",
      "Labels (model): ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53']\n",
      "Thresholds loaded: 12 labels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>prob_NR-AR</th>\n",
       "      <th>prob_NR-AR-LBD</th>\n",
       "      <th>prob_NR-AhR</th>\n",
       "      <th>prob_NR-Aromatase</th>\n",
       "      <th>prob_NR-ER</th>\n",
       "      <th>prob_NR-ER-LBD</th>\n",
       "      <th>prob_NR-PPAR-gamma</th>\n",
       "      <th>prob_SR-ARE</th>\n",
       "      <th>prob_SR-ATAD5</th>\n",
       "      <th>prob_SR-HSE</th>\n",
       "      <th>prob_SR-MMP</th>\n",
       "      <th>prob_SR-p53</th>\n",
       "      <th>active_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCOc1ccc2nc(S(N)(=O)=O)sc2c1</td>\n",
       "      <td>0.348548</td>\n",
       "      <td>0.349381</td>\n",
       "      <td>0.674655</td>\n",
       "      <td>0.458120</td>\n",
       "      <td>0.553033</td>\n",
       "      <td>0.395183</td>\n",
       "      <td>0.567299</td>\n",
       "      <td>0.594629</td>\n",
       "      <td>0.545322</td>\n",
       "      <td>0.474459</td>\n",
       "      <td>0.469864</td>\n",
       "      <td>0.533133</td>\n",
       "      <td>NR-AhR, NR-Aromatase, NR-ER, NR-PPAR-gamma, SR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCN1C(=O)NC(c2ccccc2)C1=O</td>\n",
       "      <td>0.295447</td>\n",
       "      <td>0.272559</td>\n",
       "      <td>0.268464</td>\n",
       "      <td>0.207889</td>\n",
       "      <td>0.383303</td>\n",
       "      <td>0.258151</td>\n",
       "      <td>0.557607</td>\n",
       "      <td>0.356508</td>\n",
       "      <td>0.465704</td>\n",
       "      <td>0.293275</td>\n",
       "      <td>0.199272</td>\n",
       "      <td>0.274022</td>\n",
       "      <td>NR-PPAR-gamma, SR-ATAD5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC[C@]1(O)CC[C@H]2[C@@H]3CCC4=CCCC[C@@H]4[C@H]...</td>\n",
       "      <td>0.909052</td>\n",
       "      <td>0.916249</td>\n",
       "      <td>0.363034</td>\n",
       "      <td>0.668026</td>\n",
       "      <td>0.663242</td>\n",
       "      <td>0.760119</td>\n",
       "      <td>0.488878</td>\n",
       "      <td>0.572209</td>\n",
       "      <td>0.396183</td>\n",
       "      <td>0.507996</td>\n",
       "      <td>0.582347</td>\n",
       "      <td>0.673476</td>\n",
       "      <td>NR-AR, NR-AR-LBD, NR-Aromatase, NR-ER, NR-ER-L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCCN(CC)C(CC)C(=O)Nc1c(C)cccc1C</td>\n",
       "      <td>0.273525</td>\n",
       "      <td>0.160495</td>\n",
       "      <td>0.229333</td>\n",
       "      <td>0.393187</td>\n",
       "      <td>0.360224</td>\n",
       "      <td>0.332453</td>\n",
       "      <td>0.342863</td>\n",
       "      <td>0.297181</td>\n",
       "      <td>0.222546</td>\n",
       "      <td>0.281365</td>\n",
       "      <td>0.345788</td>\n",
       "      <td>0.189560</td>\n",
       "      <td>NR-Aromatase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC(O)(P(=O)(O)O)P(=O)(O)O</td>\n",
       "      <td>0.252302</td>\n",
       "      <td>0.237628</td>\n",
       "      <td>0.175839</td>\n",
       "      <td>0.186748</td>\n",
       "      <td>0.277199</td>\n",
       "      <td>0.195887</td>\n",
       "      <td>0.360137</td>\n",
       "      <td>0.229450</td>\n",
       "      <td>0.235798</td>\n",
       "      <td>0.256584</td>\n",
       "      <td>0.182748</td>\n",
       "      <td>0.234374</td>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  prob_NR-AR  \\\n",
       "0                       CCOc1ccc2nc(S(N)(=O)=O)sc2c1    0.348548   \n",
       "1                          CCN1C(=O)NC(c2ccccc2)C1=O    0.295447   \n",
       "2  CC[C@]1(O)CC[C@H]2[C@@H]3CCC4=CCCC[C@@H]4[C@H]...    0.909052   \n",
       "3                    CCCN(CC)C(CC)C(=O)Nc1c(C)cccc1C    0.273525   \n",
       "4                          CC(O)(P(=O)(O)O)P(=O)(O)O    0.252302   \n",
       "\n",
       "   prob_NR-AR-LBD  prob_NR-AhR  prob_NR-Aromatase  prob_NR-ER  prob_NR-ER-LBD  \\\n",
       "0        0.349381     0.674655           0.458120    0.553033        0.395183   \n",
       "1        0.272559     0.268464           0.207889    0.383303        0.258151   \n",
       "2        0.916249     0.363034           0.668026    0.663242        0.760119   \n",
       "3        0.160495     0.229333           0.393187    0.360224        0.332453   \n",
       "4        0.237628     0.175839           0.186748    0.277199        0.195887   \n",
       "\n",
       "   prob_NR-PPAR-gamma  prob_SR-ARE  prob_SR-ATAD5  prob_SR-HSE  prob_SR-MMP  \\\n",
       "0            0.567299     0.594629       0.545322     0.474459     0.469864   \n",
       "1            0.557607     0.356508       0.465704     0.293275     0.199272   \n",
       "2            0.488878     0.572209       0.396183     0.507996     0.582347   \n",
       "3            0.342863     0.297181       0.222546     0.281365     0.345788   \n",
       "4            0.360137     0.229450       0.235798     0.256584     0.182748   \n",
       "\n",
       "   prob_SR-p53                                      active_labels  \n",
       "0     0.533133  NR-AhR, NR-Aromatase, NR-ER, NR-PPAR-gamma, SR...  \n",
       "1     0.274022                            NR-PPAR-gamma, SR-ATAD5  \n",
       "2     0.673476  NR-AR, NR-AR-LBD, NR-Aromatase, NR-ER, NR-ER-L...  \n",
       "3     0.189560                                       NR-Aromatase  \n",
       "4     0.234374                                      NR-PPAR-gamma  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved sample predictions â†’ D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\tox21_chembera_pipeline_V2\\outputs\\pred_samples.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Paths\n",
    "FINAL_MODEL_DIR = MODEL_DIR            # tox21_chembera_pipeline_V2/model/chemberta_v1\n",
    "THRESH_PATH     = CONFIG_DIR / \"thresholds.json\"\n",
    "\n",
    "# 1) Load model & tokenizer\n",
    "print(\"Loading model from:\", FINAL_MODEL_DIR.resolve())\n",
    "tokenizer = AutoTokenizer.from_pretrained(FINAL_MODEL_DIR, use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(FINAL_MODEL_DIR)\n",
    "model.eval().to(device)\n",
    "\n",
    "# 2) Verify config enrichment\n",
    "cfg_path = FINAL_MODEL_DIR / \"config.json\"\n",
    "cfg = json.loads(cfg_path.read_text(encoding=\"utf-8\"))\n",
    "has_maps = (\"id2label\" in cfg) and (\"label2id\" in cfg)\n",
    "print(\"Has id2label/label2id?\", has_maps)\n",
    "\n",
    "# Resolve labels from config if present; else fall back to notebook LABELS\n",
    "if has_maps:\n",
    "    # id2label keys may be strings; sort by numeric id\n",
    "    id2label = {int(k): v for k, v in cfg[\"id2label\"].items()}\n",
    "    LABELS_MODEL = [id2label[i] for i in sorted(id2label.keys())]\n",
    "else:\n",
    "    LABELS_MODEL = LABELS\n",
    "\n",
    "print(\"Labels (model):\", LABELS_MODEL)\n",
    "\n",
    "# 3) Load thresholds (Youden) â€” fallback to 0.5 if not found\n",
    "if THRESH_PATH.exists():\n",
    "    thresholds = json.loads(THRESH_PATH.read_text(encoding=\"utf-8\"))\n",
    "else:\n",
    "    thresholds = {lab: 0.5 for lab in LABELS_MODEL}\n",
    "print(\"Thresholds loaded:\", len(thresholds), \"labels\")\n",
    "\n",
    "# 4) Inference helper\n",
    "@torch.inference_mode()\n",
    "def predict_smiles_batch(smiles_list, batch_size=16):\n",
    "    rows = []\n",
    "    for i in range(0, len(smiles_list), batch_size):\n",
    "        chunk = smiles_list[i:i+batch_size]\n",
    "        enc = tokenizer(\n",
    "            list(map(str, chunk)),\n",
    "            padding=True, truncation=True, max_length=MAX_LEN,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        enc = {k: v.to(device) for k, v in enc.items()}\n",
    "        logits = model(**enc).logits\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()  # [B, C]\n",
    "        for s, p in zip(chunk, probs):\n",
    "            prob_map = {lab: float(p[j]) for j, lab in enumerate(LABELS_MODEL)}\n",
    "            active = [lab for lab in LABELS_MODEL if prob_map[lab] >= thresholds.get(lab, 0.5)]\n",
    "            rows.append({\n",
    "                \"smiles\": s,\n",
    "                **{f\"prob_{lab}\": prob_map[lab] for lab in LABELS_MODEL},\n",
    "                \"active_labels\": \", \".join(active)\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# 5) Demo set â€” take a few molecules from the dataset (you can edit this list)\n",
    "SAMPLE_SMILES = df[\"smiles\"].head(5).tolist()\n",
    "pred_df = predict_smiles_batch(SAMPLE_SMILES, batch_size=8)\n",
    "display(pred_df)\n",
    "\n",
    "# 6) Save to outputs\n",
    "pred_path = OUTPUTS_DIR / \"pred_samples.csv\"\n",
    "pred_df.to_csv(pred_path, index=False)\n",
    "print(\"âœ… Saved sample predictions â†’\", pred_path.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6713ce",
   "metadata": {},
   "source": [
    "# ChemBERTa_V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f3c006",
   "metadata": {},
   "source": [
    "## 0: Setup, paths, config, seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d45989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ChemBERTa v2 â€” Setup ===\n",
      "Python         : 3.11.9  |  PyTorch: 2.6.0+cu124\n",
      "Transformers   : 4.43.3\n",
      "OS/Platform    : Windows 10\n",
      "Device         : cuda  |  GPU: NVIDIA GeForce RTX 4070 Ti  |  VRAM: 12.0GB\n",
      "Data CSV       : implementation\\data\\tox21.csv  |  Exists: True\n",
      "Base model (v1): implementation\\models\\chemberta_v1     |  Exists: True\n",
      "v2 output root : D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\implementation\\models\\chemberta_v2\n",
      "Labels (n=12): ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER'] ...\n",
      "\n",
      "Saved:\n",
      "- labels.json         â†’ implementation\\models\\chemberta_v2\\metadata\\labels.json\n",
      "- run_cfg_default.jsonâ†’ implementation\\models\\chemberta_v2\\metadata\\run_cfg_default.json\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 0: Setup / Paths / Seeding / Env Check ====\n",
    "\n",
    "import os, json, sys, math, random, time, platform\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "# ---------- Paths ----------\n",
    "ROOT = Path(\"implementation\")\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "V1_DIR = ROOT / \"models\" / \"chemberta_v1\"         # source checkpoint\n",
    "V2_DIR = ROOT / \"models\" / \"chemberta_v2\"         # NEW outputs/checkpoints\n",
    "V2_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CKPT_DIR      = V2_DIR / \"checkpoints\"            # trainer checkpoints\n",
    "OUT_DIR       = V2_DIR / \"outputs\"                # numpy dumps (val_prob, val_y, test_prob, etc.)\n",
    "META_DIR      = V2_DIR / \"metadata\"               # id2label/label2id & run config for v2\n",
    "METRICS_DIR   = V2_DIR / \"metrics\"                # CSV metrics per epoch/eval\n",
    "for d in [CKPT_DIR, OUT_DIR, META_DIR, METRICS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Data (assumes tox21.csv with columns: mol_id, smiles, 12 labels)\n",
    "TOX21_CSV = DATA_DIR / \"tox21.csv\"\n",
    "\n",
    "# ---------- Reproducibility ----------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "set_seed(SEED)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---------- Load v1 config & tokenizer to inherit labels ----------\n",
    "assert V1_DIR.exists(), f\"Base model not found: {V1_DIR}\"\n",
    "base_config = AutoConfig.from_pretrained(str(V1_DIR))\n",
    "tokenizer = AutoTokenizer.from_pretrained(str(V1_DIR))\n",
    "\n",
    "# Sanity: id2label/label2id\n",
    "id2label = dict(sorted({int(k): v for k, v in base_config.id2label.items()}.items(), key=lambda kv: kv[0]))\n",
    "label2id = {v: int(k) for k, v in id2label.items()}\n",
    "label_names = [id2label[i] for i in range(len(id2label))]\n",
    "\n",
    "# ---------- Minimal run config (editable defaults) ----------\n",
    "@dataclass\n",
    "class RunCfg:\n",
    "    model_name_or_path: str = str(V1_DIR)  # start from v1 weights\n",
    "    output_dir: str = str(V2_DIR)\n",
    "    max_length: int = 256\n",
    "    train_batch_size: int = 32\n",
    "    eval_batch_size: int = 64\n",
    "    gradient_accumulation_steps: int = 1\n",
    "    num_train_epochs: int = 5\n",
    "    learning_rate: float = 2e-5\n",
    "    weight_decay: float = 0.01\n",
    "    warmup_ratio: float = 0.06\n",
    "    lr_schedule: str = \"cosine\"  # cosine | linear | cosine_restarts\n",
    "    fp16: bool = torch.cuda.is_available()\n",
    "    bfloat16: bool = False\n",
    "    gradient_checkpointing: bool = True\n",
    "    max_grad_norm: float = 1.0\n",
    "    llrd_enable: bool = False     # Layer-wise LR decay (we can turn on later)\n",
    "    llrd_decay: float = 0.9\n",
    "    label_smoothing: float = 0.0  # can tune later\n",
    "    use_random_smiles: bool = False  # on-the-fly SMILES augmentation\n",
    "    random_smiles_per_epoch: int = 1 # how many alternates to sample per epoch (if enabled)\n",
    "    save_total_limit: int = 3\n",
    "    eval_steps: Optional[int] = None  # set after we know dataset size\n",
    "    logging_steps: int = 50\n",
    "    early_stopping_patience: int = 3  # epochs without improvement\n",
    "    metric_primary: str = \"roc_auc_macro\"  # choose what to monitor for early stopping\n",
    "\n",
    "run_cfg = RunCfg()\n",
    "\n",
    "# Save the v2 label schema immediately for reproducibility\n",
    "with open(META_DIR / \"labels.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"id2label\": {str(k): v for k, v in id2label.items()},\n",
    "            \"label2id\": {k: int(v) for k, v in label2id.items()},\n",
    "            \"n_labels\": len(label_names),\n",
    "        },\n",
    "        f, indent=2\n",
    "    )\n",
    "\n",
    "# ---------- Environment summary ----------\n",
    "def human_bytes(n):\n",
    "    units = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]\n",
    "    i = 0\n",
    "    while n >= 1024 and i < len(units)-1:\n",
    "        n /= 1024; i += 1\n",
    "    return f\"{n:.1f}{units[i]}\"\n",
    "\n",
    "gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"\n",
    "gpu_mem_total = torch.cuda.get_device_properties(0).total_memory if torch.cuda.is_available() else 0\n",
    "\n",
    "print(\"=== ChemBERTa v2 â€” Setup ===\")\n",
    "print(f\"Python         : {sys.version.split()[0]}  |  PyTorch: {torch.__version__}\")\n",
    "try:\n",
    "    import transformers\n",
    "    print(f\"Transformers   : {transformers.__version__}\")\n",
    "except Exception:\n",
    "    pass\n",
    "print(f\"OS/Platform    : {platform.system()} {platform.release()}\")\n",
    "print(f\"Device         : {DEVICE}  |  GPU: {gpu_name}  |  VRAM: {human_bytes(gpu_mem_total) if gpu_mem_total else 'N/A'}\")\n",
    "print(f\"Data CSV       : {TOX21_CSV}  |  Exists: {TOX21_CSV.exists()}\")\n",
    "print(f\"Base model (v1): {V1_DIR}     |  Exists: {V1_DIR.exists()}\")\n",
    "print(f\"v2 output root : {V2_DIR.resolve()}\")\n",
    "print(f\"Labels (n={len(label_names)}): {label_names[:5]}{' ...' if len(label_names)>5 else ''}\")\n",
    "\n",
    "# Save a minimal run-config snapshot for traceability (human-readable)\n",
    "with open(META_DIR / \"run_cfg_default.json\", \"w\") as f:\n",
    "    json.dump(asdict(run_cfg), f, indent=2)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(f\"- labels.json         â†’ {META_DIR / 'labels.json'}\")\n",
    "print(f\"- run_cfg_default.jsonâ†’ {META_DIR / 'run_cfg_default.json'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2696b57",
   "metadata": {},
   "source": [
    "## 1: Data load, cleaning, label stats, and splits (80/10/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46e560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:33:03] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size after cleaning/dedup: 7831\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-AR</td>\n",
       "      <td>7265</td>\n",
       "      <td>309</td>\n",
       "      <td>6956</td>\n",
       "      <td>0.042533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>6758</td>\n",
       "      <td>237</td>\n",
       "      <td>6521</td>\n",
       "      <td>0.035070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>6549</td>\n",
       "      <td>768</td>\n",
       "      <td>5781</td>\n",
       "      <td>0.117270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>5821</td>\n",
       "      <td>300</td>\n",
       "      <td>5521</td>\n",
       "      <td>0.051538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>6193</td>\n",
       "      <td>793</td>\n",
       "      <td>5400</td>\n",
       "      <td>0.128048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NR-ER-LBD</td>\n",
       "      <td>6955</td>\n",
       "      <td>350</td>\n",
       "      <td>6605</td>\n",
       "      <td>0.050324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>6450</td>\n",
       "      <td>186</td>\n",
       "      <td>6264</td>\n",
       "      <td>0.028837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>5832</td>\n",
       "      <td>942</td>\n",
       "      <td>4890</td>\n",
       "      <td>0.161523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SR-ATAD5</td>\n",
       "      <td>7072</td>\n",
       "      <td>264</td>\n",
       "      <td>6808</td>\n",
       "      <td>0.037330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>6467</td>\n",
       "      <td>372</td>\n",
       "      <td>6095</td>\n",
       "      <td>0.057523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SR-MMP</td>\n",
       "      <td>5810</td>\n",
       "      <td>918</td>\n",
       "      <td>4892</td>\n",
       "      <td>0.158003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SR-p53</td>\n",
       "      <td>6774</td>\n",
       "      <td>423</td>\n",
       "      <td>6351</td>\n",
       "      <td>0.062445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label     n  pos   neg  pos_rate\n",
       "0           NR-AR  7265  309  6956  0.042533\n",
       "1       NR-AR-LBD  6758  237  6521  0.035070\n",
       "2          NR-AhR  6549  768  5781  0.117270\n",
       "3    NR-Aromatase  5821  300  5521  0.051538\n",
       "4           NR-ER  6193  793  5400  0.128048\n",
       "5       NR-ER-LBD  6955  350  6605  0.050324\n",
       "6   NR-PPAR-gamma  6450  186  6264  0.028837\n",
       "7          SR-ARE  5832  942  4890  0.161523\n",
       "8        SR-ATAD5  7072  264  6808  0.037330\n",
       "9          SR-HSE  6467  372  6095  0.057523\n",
       "10         SR-MMP  5810  918  4892  0.158003\n",
       "11         SR-p53  6774  423  6351  0.062445"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using MultilabelStratifiedKFold (iterative stratification).\n",
      "Split sizes â†’ train=6264  val=784  test=783  (N=7831)\n",
      "\n",
      "Label prevalence (overall):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_484b2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_484b2_level0_col0\" class=\"col_heading level0 col0\" >label</th>\n",
       "      <th id=\"T_484b2_level0_col1\" class=\"col_heading level0 col1\" >n</th>\n",
       "      <th id=\"T_484b2_level0_col2\" class=\"col_heading level0 col2\" >pos</th>\n",
       "      <th id=\"T_484b2_level0_col3\" class=\"col_heading level0 col3\" >neg</th>\n",
       "      <th id=\"T_484b2_level0_col4\" class=\"col_heading level0 col4\" >pos_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_484b2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_484b2_row0_col0\" class=\"data row0 col0\" >NR-AR</td>\n",
       "      <td id=\"T_484b2_row0_col1\" class=\"data row0 col1\" >7265</td>\n",
       "      <td id=\"T_484b2_row0_col2\" class=\"data row0 col2\" >309</td>\n",
       "      <td id=\"T_484b2_row0_col3\" class=\"data row0 col3\" >6956</td>\n",
       "      <td id=\"T_484b2_row0_col4\" class=\"data row0 col4\" >0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_484b2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_484b2_row1_col0\" class=\"data row1 col0\" >NR-AR-LBD</td>\n",
       "      <td id=\"T_484b2_row1_col1\" class=\"data row1 col1\" >6758</td>\n",
       "      <td id=\"T_484b2_row1_col2\" class=\"data row1 col2\" >237</td>\n",
       "      <td id=\"T_484b2_row1_col3\" class=\"data row1 col3\" >6521</td>\n",
       "      <td id=\"T_484b2_row1_col4\" class=\"data row1 col4\" >0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_484b2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_484b2_row2_col0\" class=\"data row2 col0\" >NR-AhR</td>\n",
       "      <td id=\"T_484b2_row2_col1\" class=\"data row2 col1\" >6549</td>\n",
       "      <td id=\"T_484b2_row2_col2\" class=\"data row2 col2\" >768</td>\n",
       "      <td id=\"T_484b2_row2_col3\" class=\"data row2 col3\" >5781</td>\n",
       "      <td id=\"T_484b2_row2_col4\" class=\"data row2 col4\" >0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_484b2_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_484b2_row3_col0\" class=\"data row3 col0\" >NR-Aromatase</td>\n",
       "      <td id=\"T_484b2_row3_col1\" class=\"data row3 col1\" >5821</td>\n",
       "      <td id=\"T_484b2_row3_col2\" class=\"data row3 col2\" >300</td>\n",
       "      <td id=\"T_484b2_row3_col3\" class=\"data row3 col3\" >5521</td>\n",
       "      <td id=\"T_484b2_row3_col4\" class=\"data row3 col4\" >0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_484b2_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_484b2_row4_col0\" class=\"data row4 col0\" >NR-ER</td>\n",
       "      <td id=\"T_484b2_row4_col1\" class=\"data row4 col1\" >6193</td>\n",
       "      <td id=\"T_484b2_row4_col2\" class=\"data row4 col2\" >793</td>\n",
       "      <td id=\"T_484b2_row4_col3\" class=\"data row4 col3\" >5400</td>\n",
       "      <td id=\"T_484b2_row4_col4\" class=\"data row4 col4\" >0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_484b2_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_484b2_row5_col0\" class=\"data row5 col0\" >NR-ER-LBD</td>\n",
       "      <td id=\"T_484b2_row5_col1\" class=\"data row5 col1\" >6955</td>\n",
       "      <td id=\"T_484b2_row5_col2\" class=\"data row5 col2\" >350</td>\n",
       "      <td id=\"T_484b2_row5_col3\" class=\"data row5 col3\" >6605</td>\n",
       "      <td id=\"T_484b2_row5_col4\" class=\"data row5 col4\" >0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_484b2_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_484b2_row6_col0\" class=\"data row6 col0\" >NR-PPAR-gamma</td>\n",
       "      <td id=\"T_484b2_row6_col1\" class=\"data row6 col1\" >6450</td>\n",
       "      <td id=\"T_484b2_row6_col2\" class=\"data row6 col2\" >186</td>\n",
       "      <td id=\"T_484b2_row6_col3\" class=\"data row6 col3\" >6264</td>\n",
       "      <td id=\"T_484b2_row6_col4\" class=\"data row6 col4\" >0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_484b2_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_484b2_row7_col0\" class=\"data row7 col0\" >SR-ARE</td>\n",
       "      <td id=\"T_484b2_row7_col1\" class=\"data row7 col1\" >5832</td>\n",
       "      <td id=\"T_484b2_row7_col2\" class=\"data row7 col2\" >942</td>\n",
       "      <td id=\"T_484b2_row7_col3\" class=\"data row7 col3\" >4890</td>\n",
       "      <td id=\"T_484b2_row7_col4\" class=\"data row7 col4\" >0.162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_484b2_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_484b2_row8_col0\" class=\"data row8 col0\" >SR-ATAD5</td>\n",
       "      <td id=\"T_484b2_row8_col1\" class=\"data row8 col1\" >7072</td>\n",
       "      <td id=\"T_484b2_row8_col2\" class=\"data row8 col2\" >264</td>\n",
       "      <td id=\"T_484b2_row8_col3\" class=\"data row8 col3\" >6808</td>\n",
       "      <td id=\"T_484b2_row8_col4\" class=\"data row8 col4\" >0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_484b2_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_484b2_row9_col0\" class=\"data row9 col0\" >SR-HSE</td>\n",
       "      <td id=\"T_484b2_row9_col1\" class=\"data row9 col1\" >6467</td>\n",
       "      <td id=\"T_484b2_row9_col2\" class=\"data row9 col2\" >372</td>\n",
       "      <td id=\"T_484b2_row9_col3\" class=\"data row9 col3\" >6095</td>\n",
       "      <td id=\"T_484b2_row9_col4\" class=\"data row9 col4\" >0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_484b2_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_484b2_row10_col0\" class=\"data row10 col0\" >SR-MMP</td>\n",
       "      <td id=\"T_484b2_row10_col1\" class=\"data row10 col1\" >5810</td>\n",
       "      <td id=\"T_484b2_row10_col2\" class=\"data row10 col2\" >918</td>\n",
       "      <td id=\"T_484b2_row10_col3\" class=\"data row10 col3\" >4892</td>\n",
       "      <td id=\"T_484b2_row10_col4\" class=\"data row10 col4\" >0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_484b2_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_484b2_row11_col0\" class=\"data row11 col0\" >SR-p53</td>\n",
       "      <td id=\"T_484b2_row11_col1\" class=\"data row11 col1\" >6774</td>\n",
       "      <td id=\"T_484b2_row11_col2\" class=\"data row11 col2\" >423</td>\n",
       "      <td id=\"T_484b2_row11_col3\" class=\"data row11 col3\" >6351</td>\n",
       "      <td id=\"T_484b2_row11_col4\" class=\"data row11 col4\" >0.062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x127691c3c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label prevalence (train):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_93a82\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_93a82_level0_col0\" class=\"col_heading level0 col0\" >label</th>\n",
       "      <th id=\"T_93a82_level0_col1\" class=\"col_heading level0 col1\" >n</th>\n",
       "      <th id=\"T_93a82_level0_col2\" class=\"col_heading level0 col2\" >pos</th>\n",
       "      <th id=\"T_93a82_level0_col3\" class=\"col_heading level0 col3\" >neg</th>\n",
       "      <th id=\"T_93a82_level0_col4\" class=\"col_heading level0 col4\" >pos_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_93a82_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_93a82_row0_col0\" class=\"data row0 col0\" >NR-AR</td>\n",
       "      <td id=\"T_93a82_row0_col1\" class=\"data row0 col1\" >5809</td>\n",
       "      <td id=\"T_93a82_row0_col2\" class=\"data row0 col2\" >248</td>\n",
       "      <td id=\"T_93a82_row0_col3\" class=\"data row0 col3\" >5561</td>\n",
       "      <td id=\"T_93a82_row0_col4\" class=\"data row0 col4\" >0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a82_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_93a82_row1_col0\" class=\"data row1 col0\" >NR-AR-LBD</td>\n",
       "      <td id=\"T_93a82_row1_col1\" class=\"data row1 col1\" >5410</td>\n",
       "      <td id=\"T_93a82_row1_col2\" class=\"data row1 col2\" >189</td>\n",
       "      <td id=\"T_93a82_row1_col3\" class=\"data row1 col3\" >5221</td>\n",
       "      <td id=\"T_93a82_row1_col4\" class=\"data row1 col4\" >0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a82_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_93a82_row2_col0\" class=\"data row2 col0\" >NR-AhR</td>\n",
       "      <td id=\"T_93a82_row2_col1\" class=\"data row2 col1\" >5237</td>\n",
       "      <td id=\"T_93a82_row2_col2\" class=\"data row2 col2\" >614</td>\n",
       "      <td id=\"T_93a82_row2_col3\" class=\"data row2 col3\" >4623</td>\n",
       "      <td id=\"T_93a82_row2_col4\" class=\"data row2 col4\" >0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a82_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_93a82_row3_col0\" class=\"data row3 col0\" >NR-Aromatase</td>\n",
       "      <td id=\"T_93a82_row3_col1\" class=\"data row3 col1\" >4662</td>\n",
       "      <td id=\"T_93a82_row3_col2\" class=\"data row3 col2\" >240</td>\n",
       "      <td id=\"T_93a82_row3_col3\" class=\"data row3 col3\" >4422</td>\n",
       "      <td id=\"T_93a82_row3_col4\" class=\"data row3 col4\" >0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a82_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_93a82_row4_col0\" class=\"data row4 col0\" >NR-ER</td>\n",
       "      <td id=\"T_93a82_row4_col1\" class=\"data row4 col1\" >4946</td>\n",
       "      <td id=\"T_93a82_row4_col2\" class=\"data row4 col2\" >634</td>\n",
       "      <td id=\"T_93a82_row4_col3\" class=\"data row4 col3\" >4312</td>\n",
       "      <td id=\"T_93a82_row4_col4\" class=\"data row4 col4\" >0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a82_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_93a82_row5_col0\" class=\"data row5 col0\" >NR-ER-LBD</td>\n",
       "      <td id=\"T_93a82_row5_col1\" class=\"data row5 col1\" >5561</td>\n",
       "      <td id=\"T_93a82_row5_col2\" class=\"data row5 col2\" >280</td>\n",
       "      <td id=\"T_93a82_row5_col3\" class=\"data row5 col3\" >5281</td>\n",
       "      <td id=\"T_93a82_row5_col4\" class=\"data row5 col4\" >0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a82_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_93a82_row6_col0\" class=\"data row6 col0\" >NR-PPAR-gamma</td>\n",
       "      <td id=\"T_93a82_row6_col1\" class=\"data row6 col1\" >5144</td>\n",
       "      <td id=\"T_93a82_row6_col2\" class=\"data row6 col2\" >149</td>\n",
       "      <td id=\"T_93a82_row6_col3\" class=\"data row6 col3\" >4995</td>\n",
       "      <td id=\"T_93a82_row6_col4\" class=\"data row6 col4\" >0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a82_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_93a82_row7_col0\" class=\"data row7 col0\" >SR-ARE</td>\n",
       "      <td id=\"T_93a82_row7_col1\" class=\"data row7 col1\" >4688</td>\n",
       "      <td id=\"T_93a82_row7_col2\" class=\"data row7 col2\" >754</td>\n",
       "      <td id=\"T_93a82_row7_col3\" class=\"data row7 col3\" >3934</td>\n",
       "      <td id=\"T_93a82_row7_col4\" class=\"data row7 col4\" >0.161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a82_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_93a82_row8_col0\" class=\"data row8 col0\" >SR-ATAD5</td>\n",
       "      <td id=\"T_93a82_row8_col1\" class=\"data row8 col1\" >5656</td>\n",
       "      <td id=\"T_93a82_row8_col2\" class=\"data row8 col2\" >210</td>\n",
       "      <td id=\"T_93a82_row8_col3\" class=\"data row8 col3\" >5446</td>\n",
       "      <td id=\"T_93a82_row8_col4\" class=\"data row8 col4\" >0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a82_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_93a82_row9_col0\" class=\"data row9 col0\" >SR-HSE</td>\n",
       "      <td id=\"T_93a82_row9_col1\" class=\"data row9 col1\" >5181</td>\n",
       "      <td id=\"T_93a82_row9_col2\" class=\"data row9 col2\" >297</td>\n",
       "      <td id=\"T_93a82_row9_col3\" class=\"data row9 col3\" >4884</td>\n",
       "      <td id=\"T_93a82_row9_col4\" class=\"data row9 col4\" >0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a82_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_93a82_row10_col0\" class=\"data row10 col0\" >SR-MMP</td>\n",
       "      <td id=\"T_93a82_row10_col1\" class=\"data row10 col1\" >4658</td>\n",
       "      <td id=\"T_93a82_row10_col2\" class=\"data row10 col2\" >735</td>\n",
       "      <td id=\"T_93a82_row10_col3\" class=\"data row10 col3\" >3923</td>\n",
       "      <td id=\"T_93a82_row10_col4\" class=\"data row10 col4\" >0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93a82_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_93a82_row11_col0\" class=\"data row11 col0\" >SR-p53</td>\n",
       "      <td id=\"T_93a82_row11_col1\" class=\"data row11 col1\" >5414</td>\n",
       "      <td id=\"T_93a82_row11_col2\" class=\"data row11 col2\" >339</td>\n",
       "      <td id=\"T_93a82_row11_col3\" class=\"data row11 col3\" >5075</td>\n",
       "      <td id=\"T_93a82_row11_col4\" class=\"data row11 col4\" >0.063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x12781f4a350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label prevalence (val):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_54ff9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_54ff9_level0_col0\" class=\"col_heading level0 col0\" >label</th>\n",
       "      <th id=\"T_54ff9_level0_col1\" class=\"col_heading level0 col1\" >n</th>\n",
       "      <th id=\"T_54ff9_level0_col2\" class=\"col_heading level0 col2\" >pos</th>\n",
       "      <th id=\"T_54ff9_level0_col3\" class=\"col_heading level0 col3\" >neg</th>\n",
       "      <th id=\"T_54ff9_level0_col4\" class=\"col_heading level0 col4\" >pos_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_54ff9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_54ff9_row0_col0\" class=\"data row0 col0\" >NR-AR</td>\n",
       "      <td id=\"T_54ff9_row0_col1\" class=\"data row0 col1\" >735</td>\n",
       "      <td id=\"T_54ff9_row0_col2\" class=\"data row0 col2\" >31</td>\n",
       "      <td id=\"T_54ff9_row0_col3\" class=\"data row0 col3\" >704</td>\n",
       "      <td id=\"T_54ff9_row0_col4\" class=\"data row0 col4\" >0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54ff9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_54ff9_row1_col0\" class=\"data row1 col0\" >NR-AR-LBD</td>\n",
       "      <td id=\"T_54ff9_row1_col1\" class=\"data row1 col1\" >674</td>\n",
       "      <td id=\"T_54ff9_row1_col2\" class=\"data row1 col2\" >24</td>\n",
       "      <td id=\"T_54ff9_row1_col3\" class=\"data row1 col3\" >650</td>\n",
       "      <td id=\"T_54ff9_row1_col4\" class=\"data row1 col4\" >0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54ff9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_54ff9_row2_col0\" class=\"data row2 col0\" >NR-AhR</td>\n",
       "      <td id=\"T_54ff9_row2_col1\" class=\"data row2 col1\" >652</td>\n",
       "      <td id=\"T_54ff9_row2_col2\" class=\"data row2 col2\" >77</td>\n",
       "      <td id=\"T_54ff9_row2_col3\" class=\"data row2 col3\" >575</td>\n",
       "      <td id=\"T_54ff9_row2_col4\" class=\"data row2 col4\" >0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54ff9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_54ff9_row3_col0\" class=\"data row3 col0\" >NR-Aromatase</td>\n",
       "      <td id=\"T_54ff9_row3_col1\" class=\"data row3 col1\" >577</td>\n",
       "      <td id=\"T_54ff9_row3_col2\" class=\"data row3 col2\" >30</td>\n",
       "      <td id=\"T_54ff9_row3_col3\" class=\"data row3 col3\" >547</td>\n",
       "      <td id=\"T_54ff9_row3_col4\" class=\"data row3 col4\" >0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54ff9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_54ff9_row4_col0\" class=\"data row4 col0\" >NR-ER</td>\n",
       "      <td id=\"T_54ff9_row4_col1\" class=\"data row4 col1\" >611</td>\n",
       "      <td id=\"T_54ff9_row4_col2\" class=\"data row4 col2\" >79</td>\n",
       "      <td id=\"T_54ff9_row4_col3\" class=\"data row4 col3\" >532</td>\n",
       "      <td id=\"T_54ff9_row4_col4\" class=\"data row4 col4\" >0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54ff9_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_54ff9_row5_col0\" class=\"data row5 col0\" >NR-ER-LBD</td>\n",
       "      <td id=\"T_54ff9_row5_col1\" class=\"data row5 col1\" >691</td>\n",
       "      <td id=\"T_54ff9_row5_col2\" class=\"data row5 col2\" >35</td>\n",
       "      <td id=\"T_54ff9_row5_col3\" class=\"data row5 col3\" >656</td>\n",
       "      <td id=\"T_54ff9_row5_col4\" class=\"data row5 col4\" >0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54ff9_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_54ff9_row6_col0\" class=\"data row6 col0\" >NR-PPAR-gamma</td>\n",
       "      <td id=\"T_54ff9_row6_col1\" class=\"data row6 col1\" >643</td>\n",
       "      <td id=\"T_54ff9_row6_col2\" class=\"data row6 col2\" >19</td>\n",
       "      <td id=\"T_54ff9_row6_col3\" class=\"data row6 col3\" >624</td>\n",
       "      <td id=\"T_54ff9_row6_col4\" class=\"data row6 col4\" >0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54ff9_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_54ff9_row7_col0\" class=\"data row7 col0\" >SR-ARE</td>\n",
       "      <td id=\"T_54ff9_row7_col1\" class=\"data row7 col1\" >571</td>\n",
       "      <td id=\"T_54ff9_row7_col2\" class=\"data row7 col2\" >94</td>\n",
       "      <td id=\"T_54ff9_row7_col3\" class=\"data row7 col3\" >477</td>\n",
       "      <td id=\"T_54ff9_row7_col4\" class=\"data row7 col4\" >0.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54ff9_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_54ff9_row8_col0\" class=\"data row8 col0\" >SR-ATAD5</td>\n",
       "      <td id=\"T_54ff9_row8_col1\" class=\"data row8 col1\" >705</td>\n",
       "      <td id=\"T_54ff9_row8_col2\" class=\"data row8 col2\" >27</td>\n",
       "      <td id=\"T_54ff9_row8_col3\" class=\"data row8 col3\" >678</td>\n",
       "      <td id=\"T_54ff9_row8_col4\" class=\"data row8 col4\" >0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54ff9_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_54ff9_row9_col0\" class=\"data row9 col0\" >SR-HSE</td>\n",
       "      <td id=\"T_54ff9_row9_col1\" class=\"data row9 col1\" >631</td>\n",
       "      <td id=\"T_54ff9_row9_col2\" class=\"data row9 col2\" >38</td>\n",
       "      <td id=\"T_54ff9_row9_col3\" class=\"data row9 col3\" >593</td>\n",
       "      <td id=\"T_54ff9_row9_col4\" class=\"data row9 col4\" >0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54ff9_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_54ff9_row10_col0\" class=\"data row10 col0\" >SR-MMP</td>\n",
       "      <td id=\"T_54ff9_row10_col1\" class=\"data row10 col1\" >560</td>\n",
       "      <td id=\"T_54ff9_row10_col2\" class=\"data row10 col2\" >91</td>\n",
       "      <td id=\"T_54ff9_row10_col3\" class=\"data row10 col3\" >469</td>\n",
       "      <td id=\"T_54ff9_row10_col4\" class=\"data row10 col4\" >0.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54ff9_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_54ff9_row11_col0\" class=\"data row11 col0\" >SR-p53</td>\n",
       "      <td id=\"T_54ff9_row11_col1\" class=\"data row11 col1\" >669</td>\n",
       "      <td id=\"T_54ff9_row11_col2\" class=\"data row11 col2\" >42</td>\n",
       "      <td id=\"T_54ff9_row11_col3\" class=\"data row11 col3\" >627</td>\n",
       "      <td id=\"T_54ff9_row11_col4\" class=\"data row11 col4\" >0.063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x127694ef450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label prevalence (test):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_5f6fd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5f6fd_level0_col0\" class=\"col_heading level0 col0\" >label</th>\n",
       "      <th id=\"T_5f6fd_level0_col1\" class=\"col_heading level0 col1\" >n</th>\n",
       "      <th id=\"T_5f6fd_level0_col2\" class=\"col_heading level0 col2\" >pos</th>\n",
       "      <th id=\"T_5f6fd_level0_col3\" class=\"col_heading level0 col3\" >neg</th>\n",
       "      <th id=\"T_5f6fd_level0_col4\" class=\"col_heading level0 col4\" >pos_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5f6fd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5f6fd_row0_col0\" class=\"data row0 col0\" >NR-AR</td>\n",
       "      <td id=\"T_5f6fd_row0_col1\" class=\"data row0 col1\" >721</td>\n",
       "      <td id=\"T_5f6fd_row0_col2\" class=\"data row0 col2\" >30</td>\n",
       "      <td id=\"T_5f6fd_row0_col3\" class=\"data row0 col3\" >691</td>\n",
       "      <td id=\"T_5f6fd_row0_col4\" class=\"data row0 col4\" >0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f6fd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5f6fd_row1_col0\" class=\"data row1 col0\" >NR-AR-LBD</td>\n",
       "      <td id=\"T_5f6fd_row1_col1\" class=\"data row1 col1\" >674</td>\n",
       "      <td id=\"T_5f6fd_row1_col2\" class=\"data row1 col2\" >24</td>\n",
       "      <td id=\"T_5f6fd_row1_col3\" class=\"data row1 col3\" >650</td>\n",
       "      <td id=\"T_5f6fd_row1_col4\" class=\"data row1 col4\" >0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f6fd_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5f6fd_row2_col0\" class=\"data row2 col0\" >NR-AhR</td>\n",
       "      <td id=\"T_5f6fd_row2_col1\" class=\"data row2 col1\" >660</td>\n",
       "      <td id=\"T_5f6fd_row2_col2\" class=\"data row2 col2\" >77</td>\n",
       "      <td id=\"T_5f6fd_row2_col3\" class=\"data row2 col3\" >583</td>\n",
       "      <td id=\"T_5f6fd_row2_col4\" class=\"data row2 col4\" >0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f6fd_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5f6fd_row3_col0\" class=\"data row3 col0\" >NR-Aromatase</td>\n",
       "      <td id=\"T_5f6fd_row3_col1\" class=\"data row3 col1\" >582</td>\n",
       "      <td id=\"T_5f6fd_row3_col2\" class=\"data row3 col2\" >30</td>\n",
       "      <td id=\"T_5f6fd_row3_col3\" class=\"data row3 col3\" >552</td>\n",
       "      <td id=\"T_5f6fd_row3_col4\" class=\"data row3 col4\" >0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f6fd_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_5f6fd_row4_col0\" class=\"data row4 col0\" >NR-ER</td>\n",
       "      <td id=\"T_5f6fd_row4_col1\" class=\"data row4 col1\" >636</td>\n",
       "      <td id=\"T_5f6fd_row4_col2\" class=\"data row4 col2\" >80</td>\n",
       "      <td id=\"T_5f6fd_row4_col3\" class=\"data row4 col3\" >556</td>\n",
       "      <td id=\"T_5f6fd_row4_col4\" class=\"data row4 col4\" >0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f6fd_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_5f6fd_row5_col0\" class=\"data row5 col0\" >NR-ER-LBD</td>\n",
       "      <td id=\"T_5f6fd_row5_col1\" class=\"data row5 col1\" >703</td>\n",
       "      <td id=\"T_5f6fd_row5_col2\" class=\"data row5 col2\" >35</td>\n",
       "      <td id=\"T_5f6fd_row5_col3\" class=\"data row5 col3\" >668</td>\n",
       "      <td id=\"T_5f6fd_row5_col4\" class=\"data row5 col4\" >0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f6fd_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_5f6fd_row6_col0\" class=\"data row6 col0\" >NR-PPAR-gamma</td>\n",
       "      <td id=\"T_5f6fd_row6_col1\" class=\"data row6 col1\" >663</td>\n",
       "      <td id=\"T_5f6fd_row6_col2\" class=\"data row6 col2\" >18</td>\n",
       "      <td id=\"T_5f6fd_row6_col3\" class=\"data row6 col3\" >645</td>\n",
       "      <td id=\"T_5f6fd_row6_col4\" class=\"data row6 col4\" >0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f6fd_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_5f6fd_row7_col0\" class=\"data row7 col0\" >SR-ARE</td>\n",
       "      <td id=\"T_5f6fd_row7_col1\" class=\"data row7 col1\" >573</td>\n",
       "      <td id=\"T_5f6fd_row7_col2\" class=\"data row7 col2\" >94</td>\n",
       "      <td id=\"T_5f6fd_row7_col3\" class=\"data row7 col3\" >479</td>\n",
       "      <td id=\"T_5f6fd_row7_col4\" class=\"data row7 col4\" >0.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f6fd_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_5f6fd_row8_col0\" class=\"data row8 col0\" >SR-ATAD5</td>\n",
       "      <td id=\"T_5f6fd_row8_col1\" class=\"data row8 col1\" >711</td>\n",
       "      <td id=\"T_5f6fd_row8_col2\" class=\"data row8 col2\" >27</td>\n",
       "      <td id=\"T_5f6fd_row8_col3\" class=\"data row8 col3\" >684</td>\n",
       "      <td id=\"T_5f6fd_row8_col4\" class=\"data row8 col4\" >0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f6fd_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_5f6fd_row9_col0\" class=\"data row9 col0\" >SR-HSE</td>\n",
       "      <td id=\"T_5f6fd_row9_col1\" class=\"data row9 col1\" >655</td>\n",
       "      <td id=\"T_5f6fd_row9_col2\" class=\"data row9 col2\" >37</td>\n",
       "      <td id=\"T_5f6fd_row9_col3\" class=\"data row9 col3\" >618</td>\n",
       "      <td id=\"T_5f6fd_row9_col4\" class=\"data row9 col4\" >0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f6fd_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_5f6fd_row10_col0\" class=\"data row10 col0\" >SR-MMP</td>\n",
       "      <td id=\"T_5f6fd_row10_col1\" class=\"data row10 col1\" >592</td>\n",
       "      <td id=\"T_5f6fd_row10_col2\" class=\"data row10 col2\" >92</td>\n",
       "      <td id=\"T_5f6fd_row10_col3\" class=\"data row10 col3\" >500</td>\n",
       "      <td id=\"T_5f6fd_row10_col4\" class=\"data row10 col4\" >0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5f6fd_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_5f6fd_row11_col0\" class=\"data row11 col0\" >SR-p53</td>\n",
       "      <td id=\"T_5f6fd_row11_col1\" class=\"data row11 col1\" >691</td>\n",
       "      <td id=\"T_5f6fd_row11_col2\" class=\"data row11 col2\" >42</td>\n",
       "      <td id=\"T_5f6fd_row11_col3\" class=\"data row11 col3\" >649</td>\n",
       "      <td id=\"T_5f6fd_row11_col4\" class=\"data row11 col4\" >0.061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x127694ef450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved:\n",
      "- train.csv â†’ implementation\\models\\chemberta_v2\\metadata\\train.csv\n",
      "- val.csv   â†’ implementation\\models\\chemberta_v2\\metadata\\val.csv\n",
      "- test.csv  â†’ implementation\\models\\chemberta_v2\\metadata\\test.csv\n",
      "- label_stats.json â†’ implementation\\models\\chemberta_v2\\metadata\\label_stats.json\n",
      "- splits.json      â†’ implementation\\models\\chemberta_v2\\metadata\\splits.json\n",
      "- run_cfg_current.json â†’ implementation\\models\\chemberta_v2\\metadata\\run_cfg_current.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, math, warnings, gc\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from rdkit.Chem.rdmolops import RemoveHs\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------- 1) Load Tox21 ----------\n",
    "df = pd.read_csv(TOX21_CSV)\n",
    "expected_cols = {\"mol_id\",\"smiles\", *set(label_names)}\n",
    "missing_cols = expected_cols - set(df.columns)\n",
    "assert not missing_cols, f\"tox21.csv missing columns: {missing_cols}\"\n",
    "\n",
    "# Keep only what we need, in a consistent order\n",
    "df = df[[\"mol_id\",\"smiles\"] + label_names].copy()\n",
    "\n",
    "# Coerce labels to {0,1,NaN}\n",
    "for c in label_names:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")  # converts non-numeric to NaN\n",
    "    # If dataset uses -1 for missing, turn into NaN\n",
    "    df.loc[df[c] < 0, c] = np.nan\n",
    "    # Clip to [0,1] if noisy values\n",
    "    df.loc[df[c] > 1, c] = 1\n",
    "    df.loc[df[c] < 0, c] = np.nan\n",
    "\n",
    "# Canonicalize SMILES (fast, deterministic)\n",
    "def canon_smiles(s):\n",
    "    try:\n",
    "        m = Chem.MolFromSmiles(s)\n",
    "        if m is None: \n",
    "            return None\n",
    "        return Chem.MolToSmiles(m, canonical=True)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "df[\"smiles_canon\"] = df[\"smiles\"].astype(str).map(canon_smiles)\n",
    "n_bad = int(df[\"smiles_canon\"].isna().sum())\n",
    "if n_bad:\n",
    "    print(f\"[WARN] Dropping {n_bad} rows with invalid SMILES.\")\n",
    "df = df.dropna(subset=[\"smiles_canon\"]).reset_index(drop=True)\n",
    "\n",
    "# Deduplicate by canonical SMILES (keep the most \"positive\" label row)\n",
    "# Merge duplicates by OR across labels (1 wins over 0; NaN treated as 0 in merge but we remember coverage)\n",
    "def merge_rows(g):\n",
    "    out = g.iloc[0][[\"mol_id\",\"smiles\",\"smiles_canon\"]].copy()\n",
    "    for c in label_names:\n",
    "        vals = g[c].dropna().values\n",
    "        if len(vals) == 0:\n",
    "            out[c] = np.nan\n",
    "        else:\n",
    "            out[c] = 1.0 if (vals == 1).any() else 0.0\n",
    "    return out\n",
    "\n",
    "dup_groups = df.groupby(\"smiles_canon\", sort=False)\n",
    "df_merged = dup_groups.apply(merge_rows).reset_index(drop=True)\n",
    "n_dups = len(df) - len(df_merged)\n",
    "if n_dups:\n",
    "    print(f\"[INFO] Deduplicated {n_dups} duplicate molecules by canonical SMILES.\")\n",
    "\n",
    "df = df_merged.copy()\n",
    "N = len(df)\n",
    "print(f\"Dataset size after cleaning/dedup: {N}\")\n",
    "\n",
    "# ---------- 2) Label stats ----------\n",
    "def compute_label_stats(frame: pd.DataFrame) -> pd.DataFrame:\n",
    "    stats = []\n",
    "    for c in label_names:\n",
    "        col = frame[c]\n",
    "        n_obs = int(col.notna().sum())\n",
    "        n_pos = int((col == 1).sum())\n",
    "        n_neg = int((col == 0).sum())\n",
    "        pos_rate = n_pos / n_obs if n_obs > 0 else np.nan\n",
    "        stats.append(dict(label=c, n=n_obs, pos=n_pos, neg=n_neg, pos_rate=pos_rate))\n",
    "    return pd.DataFrame(stats).sort_values(\"label\").reset_index(drop=True)\n",
    "\n",
    "overall_stats = compute_label_stats(df)\n",
    "display(overall_stats)\n",
    "\n",
    "# ---------- 3) Multi-label splits ----------\n",
    "# Preference: Iterative Stratification (sechidis). Fallback: RDKit scaffold split.\n",
    "\n",
    "def multilabel_matrix(frame: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Return Y with NaN -> 0 for stratification only.\"\"\"\n",
    "    Y = np.stack([frame[c].fillna(0).astype(int).values for c in label_names], axis=1)\n",
    "    return Y\n",
    "\n",
    "train_idx = val_idx = test_idx = None\n",
    "\n",
    "# Try iterative stratification if available\n",
    "try:\n",
    "    from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "    print(\"[INFO] Using MultilabelStratifiedKFold (iterative stratification).\")\n",
    "    Y = multilabel_matrix(df)\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "\n",
    "    folds = list(mskf.split(np.zeros((N, 1)), Y))\n",
    "    # Take fold 0 as TEST (10%), fold 1 as VAL (10%), rest TRAIN (80%)\n",
    "    test_idx = folds[0][1]\n",
    "    val_idx  = folds[1][1]\n",
    "    train_mask = np.ones(N, dtype=bool)\n",
    "    train_mask[test_idx] = False\n",
    "    train_mask[val_idx]  = False\n",
    "    train_idx = np.where(train_mask)[0]\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[WARN] Iterative stratification not available ({e}). Falling back to scaffold split.\")\n",
    "\n",
    "    def murcko_scaffold(smiles: str) -> str:\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is None:\n",
    "                return \"\"\n",
    "            core = MurckoScaffold.GetScaffoldForMol(mol)\n",
    "            return Chem.MolToSmiles(core, canonical=True) if core else \"\"\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "    df[\"scaffold\"] = df[\"smiles_canon\"].map(murcko_scaffold)\n",
    "    scaff2idxs = defaultdict(list)\n",
    "    for i, sc in enumerate(df[\"scaffold\"].values):\n",
    "        scaff2idxs[sc].append(i)\n",
    "\n",
    "    # greedy bin-packing scaffolds into splits by target sizes (80/10/10)\n",
    "    target_train = int(round(0.80 * N))\n",
    "    target_val   = int(round(0.10 * N))\n",
    "    target_test  = N - target_train - target_val\n",
    "\n",
    "    # sort scaffolds by size (descending) so big scaffolds get placed first\n",
    "    buckets = sorted(scaff2idxs.items(), key=lambda kv: len(kv[1]), reverse=True)\n",
    "\n",
    "    train, val, test = [], [], []\n",
    "    ntr = nvl = nts = 0\n",
    "    for sc, idxs in buckets:\n",
    "        # choose the split with most remaining room\n",
    "        rem = [\n",
    "            (target_train - ntr, \"tr\"),\n",
    "            (target_val   - nvl, \"va\"),\n",
    "            (target_test  - nts, \"te\"),\n",
    "        ]\n",
    "        rem.sort(reverse=True)  # biggest remaining first\n",
    "        put = rem[0][1]\n",
    "        if put == \"tr\":\n",
    "            train.extend(idxs); ntr += len(idxs)\n",
    "        elif put == \"va\":\n",
    "            val.extend(idxs); nvl += len(idxs)\n",
    "        else:\n",
    "            test.extend(idxs); nts += len(idxs)\n",
    "\n",
    "    train_idx = np.array(sorted(train))\n",
    "    val_idx   = np.array(sorted(val))\n",
    "    test_idx  = np.array(sorted(test))\n",
    "\n",
    "# Build splits\n",
    "def take(frame, idx):\n",
    "    return frame.iloc[idx].reset_index(drop=True)\n",
    "\n",
    "df_train = take(df, train_idx)\n",
    "df_val   = take(df, val_idx)\n",
    "df_test  = take(df, test_idx)\n",
    "\n",
    "print(f\"Split sizes â†’ train={len(df_train)}  val={len(df_val)}  test={len(df_test)}  (N={N})\")\n",
    "\n",
    "# ---------- 4) Split stats ----------\n",
    "train_stats = compute_label_stats(df_train)\n",
    "val_stats   = compute_label_stats(df_val)\n",
    "test_stats  = compute_label_stats(df_test)\n",
    "\n",
    "print(\"\\nLabel prevalence (overall):\")\n",
    "display(overall_stats.style.format({\"pos_rate\":\"{:.3f}\"}))\n",
    "\n",
    "print(\"\\nLabel prevalence (train):\")\n",
    "display(train_stats.style.format({\"pos_rate\":\"{:.3f}\"}))\n",
    "\n",
    "print(\"\\nLabel prevalence (val):\")\n",
    "display(val_stats.style.format({\"pos_rate\":\"{:.3f}\"}))\n",
    "\n",
    "print(\"\\nLabel prevalence (test):\")\n",
    "display(test_stats.style.format({\"pos_rate\":\"{:.3f}\"}))\n",
    "\n",
    "# ---------- 5) Save splits & stats ----------\n",
    "SPLIT_DIR = META_DIR  # keep with v2 metadata\n",
    "train_path = SPLIT_DIR / \"train.csv\"\n",
    "val_path   = SPLIT_DIR / \"val.csv\"\n",
    "test_path  = SPLIT_DIR / \"test.csv\"\n",
    "df_train.to_csv(train_path, index=False)\n",
    "df_val.to_csv(val_path, index=False)\n",
    "df_test.to_csv(test_path, index=False)\n",
    "\n",
    "stats_payload = {\n",
    "    \"overall\": overall_stats.to_dict(orient=\"records\"),\n",
    "    \"train\":   train_stats.to_dict(orient=\"records\"),\n",
    "    \"val\":     val_stats.to_dict(orient=\"records\"),\n",
    "    \"test\":    test_stats.to_dict(orient=\"records\"),\n",
    "    \"sizes\":   {\"train\": len(df_train), \"val\": len(df_val), \"test\": len(df_test), \"N\": N},\n",
    "}\n",
    "with open(SPLIT_DIR / \"label_stats.json\", \"w\") as f:\n",
    "    json.dump(stats_payload, f, indent=2)\n",
    "\n",
    "# Save an index file for easy loading\n",
    "splits_index = {\n",
    "    \"train_csv\": str(train_path),\n",
    "    \"val_csv\":   str(val_path),\n",
    "    \"test_csv\":  str(test_path),\n",
    "    \"generated_by\": \"Cell 1\",\n",
    "}\n",
    "with open(SPLIT_DIR / \"splits.json\", \"w\") as f:\n",
    "    json.dump(splits_index, f, indent=2)\n",
    "\n",
    "# Update eval_steps in run_cfg based on dataset size\n",
    "steps_per_epoch = math.ceil(len(df_train) / (run_cfg.train_batch_size * max(1, run_cfg.gradient_accumulation_steps)))\n",
    "run_cfg.eval_steps = max(50, steps_per_epoch // 4)\n",
    "with open(META_DIR / \"run_cfg_current.json\", \"w\") as f:\n",
    "    json.dump(asdict(run_cfg), f, indent=2)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(f\"- train.csv â†’ {train_path}\")\n",
    "print(f\"- val.csv   â†’ {val_path}\")\n",
    "print(f\"- test.csv  â†’ {test_path}\")\n",
    "print(f\"- label_stats.json â†’ {SPLIT_DIR / 'label_stats.json'}\")\n",
    "print(f\"- splits.json      â†’ {SPLIT_DIR / 'splits.json'}\")\n",
    "print(f\"- run_cfg_current.json â†’ {META_DIR / 'run_cfg_current.json'}\")\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22505443",
   "metadata": {},
   "source": [
    "## 2: Dataset, augmentation, collator, and label weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aad69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved pos_weight.json\n",
      "Datasets â†’ train=6264, val=784, test=783\n",
      "Random SMILES augmentation enabled: False\n",
      "input_ids    (4, 37)  dtype=torch.int64\n",
      "attention_mask (4, 37)  dtype=torch.int64\n",
      "labels       (4, 12)  dtype=torch.float32\n",
      "label_mask   (4, 12)  dtype=torch.float32\n",
      "label_mask sums (per-sample): [11.0, 8.0, 10.0, 12.0]\n",
      "labels example (first row): [0.0, 0.0, 0.0, 0.0, 0.0, 0.0] ...\n"
     ]
    }
   ],
   "source": [
    "import json, math\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict, Any, List\n",
    "\n",
    "from rdkit import Chem\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# ---------- Load splits ----------\n",
    "with open(META_DIR / \"splits.json\") as f:\n",
    "    sp = json.load(f)\n",
    "train_csv = Path(sp[\"train_csv\"])\n",
    "val_csv   = Path(sp[\"val_csv\"])\n",
    "test_csv  = Path(sp[\"test_csv\"])\n",
    "\n",
    "df_train = pd.read_csv(train_csv)\n",
    "df_val   = pd.read_csv(val_csv)\n",
    "df_test  = pd.read_csv(test_csv)\n",
    "\n",
    "# Safety: ensure columns exist in splits (in case of external edits)\n",
    "for frame in (df_train, df_val, df_test):\n",
    "    assert \"smiles_canon\" in frame.columns and all(c in frame.columns for c in label_names), \\\n",
    "        \"Split CSV missing required columns.\"\n",
    "\n",
    "# ---------- Optional: label prevalence â†’ pos_weight for BCE ----------\n",
    "# pos_weight_j = (N_neg / N_pos) computed over TRAIN (where labels observed)\n",
    "pos_weight = []\n",
    "for c in label_names:\n",
    "    col = df_train[c]\n",
    "    n_obs = int(col.notna().sum())\n",
    "    n_pos = int((col == 1).sum())\n",
    "    n_neg = int((col == 0).sum())\n",
    "    # Avoid div by zero: if no positives, set small prior; if all positive, set 1.0\n",
    "    if n_pos == 0:\n",
    "        w = 1.0\n",
    "    else:\n",
    "        w = max(1.0, n_neg / max(1, n_pos))\n",
    "    pos_weight.append(float(w))\n",
    "\n",
    "pos_weight = torch.tensor(pos_weight, dtype=torch.float32)\n",
    "with open(META_DIR / \"pos_weight.json\", \"w\") as f:\n",
    "    json.dump({lbl: float(w) for lbl, w in zip(label_names, pos_weight.tolist())}, f, indent=2)\n",
    "print(\"[INFO] Saved pos_weight.json\")\n",
    "\n",
    "# ---------- SMILES augmentation ----------\n",
    "def randomize_smiles(smiles: str) -> Optional[str]:\n",
    "    \"\"\"RDKit random SMILES; returns None if parsing fails.\"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        # RDKit: canonical=False and doRandom=True to shuffle traversal\n",
    "        return Chem.MolToSmiles(mol, canonical=False, doRandom=True)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def maybe_augment(smiles: str, enable: bool) -> str:\n",
    "    if not enable or not run_cfg.use_random_smiles:\n",
    "        return smiles\n",
    "    alt = randomize_smiles(smiles)\n",
    "    return alt or smiles\n",
    "\n",
    "# ---------- Dataset ----------\n",
    "class Tox21Dataset(Dataset):\n",
    "    def __init__(self, frame: pd.DataFrame, tokenizer, max_length: int = 256, train: bool = False):\n",
    "        self.df = frame.reset_index(drop=True)\n",
    "        self.tok = tokenizer\n",
    "        self.max_length = int(max_length)\n",
    "        self.train_mode = bool(train)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # Use canonical SMILES produced in Cell 1 (stable input),\n",
    "        # but allow augmentation in train mode (random SMILES preserves chemistry)\n",
    "        base = str(row[\"smiles_canon\"])\n",
    "        smi  = maybe_augment(base, enable=self.train_mode)\n",
    "\n",
    "        enc = self.tok(\n",
    "            smi,\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=None,\n",
    "        )\n",
    "\n",
    "        # labels and mask (NaN -> unlabeled)\n",
    "        y = np.array([row[c] for c in label_names], dtype=np.float32)\n",
    "        m = ~np.isnan(y)  # True where we have a label\n",
    "        # Replace NaN with 0.0 (won't contribute to loss thanks to mask)\n",
    "        y[np.isnan(y)] = 0.0\n",
    "\n",
    "        item = {\n",
    "            \"input_ids\": enc[\"input_ids\"],\n",
    "            \"attention_mask\": enc[\"attention_mask\"],\n",
    "            \"labels\": y,                  # float32\n",
    "            \"label_mask\": m.astype(np.float32),  # 1.0 where labeled, else 0.0\n",
    "        }\n",
    "        return item\n",
    "\n",
    "# ---------- Collator ----------\n",
    "@dataclass\n",
    "class Collator:\n",
    "    tokenizer: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:\n",
    "        # token fields\n",
    "        batch = {\n",
    "            \"input_ids\":       [f[\"input_ids\"]       for f in features],\n",
    "            \"attention_mask\":  [f[\"attention_mask\"]  for f in features],\n",
    "        }\n",
    "        batch = self.tokenizer.pad(\n",
    "            batch,\n",
    "            padding=True,\n",
    "            max_length=None,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        # labels\n",
    "        labels = torch.tensor([f[\"labels\"] for f in features], dtype=torch.float32)\n",
    "        label_mask = torch.tensor([f[\"label_mask\"] for f in features], dtype=torch.float32)\n",
    "        batch[\"labels\"] = labels\n",
    "        batch[\"label_mask\"] = label_mask\n",
    "        return batch\n",
    "\n",
    "collator = Collator(tokenizer=tokenizer)\n",
    "\n",
    "# ---------- Instantiate datasets ----------\n",
    "train_ds = Tox21Dataset(df_train, tokenizer, max_length=run_cfg.max_length, train=True)\n",
    "val_ds   = Tox21Dataset(df_val,   tokenizer, max_length=run_cfg.max_length, train=False)\n",
    "test_ds  = Tox21Dataset(df_test,  tokenizer, max_length=run_cfg.max_length, train=False)\n",
    "\n",
    "print(f\"Datasets â†’ train={len(train_ds)}, val={len(val_ds)}, test={len(test_ds)}\")\n",
    "print(f\"Random SMILES augmentation enabled: {bool(run_cfg.use_random_smiles)}\")\n",
    "\n",
    "# ---------- Debug peek ----------\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dbg_loader = DataLoader(train_ds, batch_size=4, shuffle=True, collate_fn=collator)\n",
    "batch = next(iter(dbg_loader))\n",
    "for k, v in batch.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        print(f\"{k:12s} {tuple(v.shape)}  dtype={v.dtype}\")\n",
    "    else:\n",
    "        print(f\"{k:12s} (non-tensor)\")\n",
    "\n",
    "print(\"label_mask sums (per-sample):\", batch[\"label_mask\"].sum(dim=1).tolist())\n",
    "print(\"labels example (first row):\", batch[\"labels\"][0].tolist()[:6], \"...\")\n",
    "\n",
    "# Keep pos_weight tensor around for loss (Cell 3/4)\n",
    "POS_WEIGHT = pos_weight.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42047e72",
   "metadata": {},
   "source": [
    "## 3: Metrics (masked multi-label AUROC/PR-AUC) + custom Trainer that carries label masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624f235e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics + MultiLabelTrainer ready.\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# ---------- masked metric helpers ----------\n",
    "\n",
    "def _valid_col(y_true_col: np.ndarray) -> bool:\n",
    "    \"\"\"Must have at least one positive and one negative to be valid.\"\"\"\n",
    "    # y_true is expected {0,1}; but after masking we may have empty or single-class\n",
    "    if y_true_col.size < 2:\n",
    "        return False\n",
    "    pos = (y_true_col == 1).sum()\n",
    "    neg = (y_true_col == 0).sum()\n",
    "    return pos > 0 and neg > 0\n",
    "\n",
    "def _masked_arrays(\n",
    "    y_true: np.ndarray, y_score: np.ndarray, mask: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Apply mask (1=observed) and return masked arrays with shape [N, L].\"\"\"\n",
    "    m = (mask.astype(bool))\n",
    "    # Keep only rows where at least one label is observed\n",
    "    row_has = m.any(axis=1)\n",
    "    return y_true[row_has], y_score[row_has], m[row_has]\n",
    "\n",
    "def multilabel_metrics_masked(\n",
    "    logits: np.ndarray, labels: np.ndarray, mask: np.ndarray\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Compute ROC-AUC micro/macro and PR-AUC micro/macro under a label mask.\n",
    "    - logits: [N, L] raw logits\n",
    "    - labels: [N, L] in {0,1} (unlabeled were set to 0 in dataset)\n",
    "    - mask:   [N, L] in {0,1} indicating which label entries are *observed*\n",
    "    \"\"\"\n",
    "    # sigmoid\n",
    "    probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "    y, p, m = _masked_arrays(labels.astype(int), probs.astype(float), mask.astype(int))\n",
    "\n",
    "    # Micro: flatten arrays only at observed positions\n",
    "    y_flat = y[m == 1]\n",
    "    p_flat = p[m == 1]\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    # ROC-AUC micro\n",
    "    try:\n",
    "        metrics[\"roc_auc_micro\"] = float(roc_auc_score(y_flat, p_flat))\n",
    "    except Exception:\n",
    "        metrics[\"roc_auc_micro\"] = float(\"nan\")\n",
    "\n",
    "    # PR-AUC micro\n",
    "    try:\n",
    "        metrics[\"pr_auc_micro\"] = float(average_precision_score(y_flat, p_flat))\n",
    "    except Exception:\n",
    "        metrics[\"pr_auc_micro\"] = float(\"nan\")\n",
    "\n",
    "    # Macro: average over labels that are valid\n",
    "    aucs = []\n",
    "    aps  = []\n",
    "    valid_cols = 0\n",
    "    for j in range(y.shape[1]):\n",
    "        col_mask = m[:, j] == 1\n",
    "        yj = y[col_mask, j]\n",
    "        pj = p[col_mask, j]\n",
    "        if not _valid_col(yj):\n",
    "            continue\n",
    "        valid_cols += 1\n",
    "        try:\n",
    "            aucs.append(roc_auc_score(yj, pj))\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            aps.append(average_precision_score(yj, pj))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    metrics[\"roc_auc_macro\"] = float(np.mean(aucs)) if len(aucs) else float(\"nan\")\n",
    "    metrics[\"pr_auc_macro\"]  = float(np.mean(aps))  if len(aps)  else float(\"nan\")\n",
    "    metrics[\"macro_valid_labels\"] = int(valid_cols)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# ---------- custom Trainer (handles label_mask + pos_weight) ----------\n",
    "\n",
    "class MultiLabelTrainer(Trainer):\n",
    "    \"\"\"\n",
    "    - Uses BCEWithLogitsLoss with pos_weight and label_mask (missing labels excluded).\n",
    "    - Collects label_mask during evaluation so compute_metrics can use it.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, pos_weight: Optional[torch.Tensor] = None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.pos_weight = pos_weight  # [L]\n",
    "        self._eval_label_masks = []\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")           # [B,L], float\n",
    "        label_mask = inputs.pop(\"label_mask\")   # [B,L], float (1 where observed)\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits                 # [B,L]\n",
    "\n",
    "        # BCE-with-logits per entry\n",
    "        loss_fct = torch.nn.BCEWithLogitsLoss(reduction=\"none\", pos_weight=self.pos_weight.to(logits.device) if self.pos_weight is not None else None)\n",
    "        loss = loss_fct(logits, labels)\n",
    "\n",
    "        # mask out unlabeled entries and average\n",
    "        loss = (loss * label_mask).sum() / (label_mask.sum() + 1e-8)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def evaluate(self, *args, **kwargs):\n",
    "        # clear masks for this eval pass\n",
    "        self._eval_label_masks = []\n",
    "        return super().evaluate(*args, **kwargs)\n",
    "\n",
    "    def predict(self, *args, **kwargs):\n",
    "        self._eval_label_masks = []\n",
    "        return super().predict(*args, **kwargs)\n",
    "\n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "        # Keep a copy of label_mask for metrics\n",
    "        if \"label_mask\" in inputs:\n",
    "            # store on CPU to save VRAM; will be concatenated later in compute_metrics\n",
    "            self._eval_label_masks.append(inputs[\"label_mask\"].detach().cpu())\n",
    "        return super().prediction_step(model, inputs, prediction_loss_only, ignore_keys)\n",
    "\n",
    "# ---------- compute_metrics wrapper that sees trainer._eval_label_masks ----------\n",
    "\n",
    "def make_compute_metrics(trainer_ref: MultiLabelTrainer):\n",
    "    def _cmp(eval_pred):\n",
    "        logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "        # HF sometimes passes tuple; ensure we pick first array\n",
    "        if isinstance(logits, tuple):\n",
    "            logits = logits[0]\n",
    "        # concatenate stored masks\n",
    "        if len(trainer_ref._eval_label_masks) == 0:\n",
    "            # Fallback: assume everything observed (not ideal, but prevents crash)\n",
    "            mask = np.ones_like(labels, dtype=np.float32)\n",
    "        else:\n",
    "            mask = torch.cat(trainer_ref._eval_label_masks, dim=0).numpy().astype(np.float32)\n",
    "            # align shapes just in case\n",
    "            if mask.shape != labels.shape:\n",
    "                min_n = min(mask.shape[0], labels.shape[0])\n",
    "                mask = mask[:min_n]\n",
    "                logits = logits[:min_n]\n",
    "                labels = labels[:min_n]\n",
    "\n",
    "        return multilabel_metrics_masked(logits, labels, mask)\n",
    "    return _cmp\n",
    "\n",
    "print(\"Metrics + MultiLabelTrainer ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7cd196",
   "metadata": {},
   "source": [
    "## 4: Model init, LLRD optimizer, Trainer, Train/Eval, and save outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcd5f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke batch shapes: {'input_ids': (8, 76), 'attention_mask': (8, 76), 'labels': (8, 12), 'label_mask': (8, 12)}\n",
      "Time to first batch: 0.014s (single-process)\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 3.1: Unblock Windows/Jupyter dataloader hangs ====\n",
    "import os, time\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # avoid nested parallel deadlocks\n",
    "\n",
    "import torch\n",
    "torch.set_num_threads(2)  # be nice on CPU\n",
    "\n",
    "# quick smoke test: pull one batch via our collator (single-process)\n",
    "from torch.utils.data import DataLoader\n",
    "_smoke = DataLoader(train_ds, batch_size=8, shuffle=True, collate_fn=collator, num_workers=0, pin_memory=True)\n",
    "t0 = time.time()\n",
    "b = next(iter(_smoke))\n",
    "t1 = time.time()\n",
    "print(\"Smoke batch shapes:\", {k: tuple(v.shape) for k,v in b.items()})\n",
    "print(f\"Time to first batch: {t1-t0:.3f}s (single-process)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7321ee6",
   "metadata": {},
   "source": [
    "### training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e4faf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Preflight] got first train batch in 0.01s\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378e7deefcfc4448bac158bc4d67ebfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/980 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9881, 'grad_norm': 3.3376524448394775, 'learning_rate': 3.3898305084745763e-06, 'epoch': 0.05}\n",
      "{'loss': 1.0272, 'grad_norm': 2.782851457595825, 'learning_rate': 6.779661016949153e-06, 'epoch': 0.1}\n",
      "{'loss': 0.9733, 'grad_norm': 3.429290771484375, 'learning_rate': 1.016949152542373e-05, 'epoch': 0.15}\n",
      "{'loss': 1.1214, 'grad_norm': 3.992232084274292, 'learning_rate': 1.3559322033898305e-05, 'epoch': 0.2}\n",
      "{'loss': 1.0209, 'grad_norm': 5.8991923332214355, 'learning_rate': 1.694915254237288e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1604b8dfb58d4be2be1b434614d36b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0101964473724365, 'eval_roc_auc_micro': 0.7999134834863814, 'eval_pr_auc_micro': 0.306829951991755, 'eval_roc_auc_macro': 0.8009903154335389, 'eval_pr_auc_macro': 0.32900205398477206, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4609, 'eval_samples_per_second': 1700.894, 'eval_steps_per_second': 28.204, 'epoch': 0.26}\n",
      "{'loss': 0.9491, 'grad_norm': 2.6206154823303223, 'learning_rate': 1.9999941823167997e-05, 'epoch': 0.31}\n",
      "{'loss': 0.9516, 'grad_norm': 2.625777244567871, 'learning_rate': 1.9992961422349808e-05, 'epoch': 0.36}\n",
      "{'loss': 0.9703, 'grad_norm': 3.129124402999878, 'learning_rate': 1.9974354960845326e-05, 'epoch': 0.41}\n",
      "{'loss': 1.007, 'grad_norm': 7.759378433227539, 'learning_rate': 1.9944144085876186e-05, 'epoch': 0.46}\n",
      "{'loss': 1.0597, 'grad_norm': 5.367362022399902, 'learning_rate': 1.990236394552821e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a9728a7622499b9d9617f8952e6bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.003836750984192, 'eval_roc_auc_micro': 0.8003711467665947, 'eval_pr_auc_micro': 0.3040584187243391, 'eval_roc_auc_macro': 0.8015197453622358, 'eval_pr_auc_macro': 0.35121153982501246, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4573, 'eval_samples_per_second': 1714.266, 'eval_steps_per_second': 28.425, 'epoch': 0.51}\n",
      "{'loss': 0.9537, 'grad_norm': 2.804459810256958, 'learning_rate': 1.9849063147859282e-05, 'epoch': 0.56}\n",
      "{'loss': 0.9419, 'grad_norm': 4.468618869781494, 'learning_rate': 1.9784303704347487e-05, 'epoch': 0.61}\n",
      "{'loss': 1.0025, 'grad_norm': 4.212106227874756, 'learning_rate': 1.9708160957745442e-05, 'epoch': 0.66}\n",
      "{'loss': 1.0237, 'grad_norm': 4.474313735961914, 'learning_rate': 1.9620723494424627e-05, 'epoch': 0.71}\n",
      "{'loss': 1.0615, 'grad_norm': 8.29330062866211, 'learning_rate': 1.9522093041311814e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6083c566fa794b7ebea83d9819df5b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9945693016052246, 'eval_roc_auc_micro': 0.8162609722143928, 'eval_pr_auc_micro': 0.33055815159951246, 'eval_roc_auc_macro': 0.8118986786356892, 'eval_pr_auc_macro': 0.35128312053266475, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4521, 'eval_samples_per_second': 1733.958, 'eval_steps_per_second': 28.752, 'epoch': 0.77}\n",
      "{'loss': 0.9928, 'grad_norm': 2.7739157676696777, 'learning_rate': 1.9412384347537415e-05, 'epoch': 0.82}\n",
      "{'loss': 1.0584, 'grad_norm': 3.9269633293151855, 'learning_rate': 1.929172505093347e-05, 'epoch': 0.87}\n",
      "{'loss': 0.9299, 'grad_norm': 3.075220823287964, 'learning_rate': 1.916025552953661e-05, 'epoch': 0.92}\n",
      "{'loss': 1.0945, 'grad_norm': 9.146592140197754, 'learning_rate': 1.9018128738268774e-05, 'epoch': 0.97}\n",
      "{'loss': 0.9519, 'grad_norm': 2.596013307571411, 'learning_rate': 1.8865510030985588e-05, 'epoch': 1.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afaef2fa2f7402181cff62e348f85f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9788133502006531, 'eval_roc_auc_micro': 0.817213322683187, 'eval_pr_auc_micro': 0.35885522797323877, 'eval_roc_auc_macro': 0.8141343322508764, 'eval_pr_auc_macro': 0.3871577167051176, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.448, 'eval_samples_per_second': 1749.902, 'eval_steps_per_second': 29.016, 'epoch': 1.02}\n",
      "{'loss': 0.8268, 'grad_norm': 3.406885862350464, 'learning_rate': 1.8702576968099607e-05, 'epoch': 1.07}\n",
      "{'loss': 1.0097, 'grad_norm': 2.1330080032348633, 'learning_rate': 1.8529519110002076e-05, 'epoch': 1.12}\n",
      "{'loss': 0.8333, 'grad_norm': 3.3248536586761475, 'learning_rate': 1.8346537796523643e-05, 'epoch': 1.17}\n",
      "{'loss': 0.8212, 'grad_norm': 5.322171688079834, 'learning_rate': 1.815384591269059e-05, 'epoch': 1.22}\n",
      "{'loss': 0.9497, 'grad_norm': 3.878390073776245, 'learning_rate': 1.7951667641049052e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c8f07ea2bb4ecdb6e05d43042f2676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9692842364311218, 'eval_roc_auc_micro': 0.824823646764206, 'eval_pr_auc_micro': 0.35394600567839274, 'eval_roc_auc_macro': 0.8175866295068362, 'eval_pr_auc_macro': 0.3812263909710007, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4562, 'eval_samples_per_second': 1718.728, 'eval_steps_per_second': 28.499, 'epoch': 1.28}\n",
      "{'loss': 0.9865, 'grad_norm': 3.9243357181549072, 'learning_rate': 1.7740238200845485e-05, 'epoch': 1.33}\n",
      "{'loss': 1.0111, 'grad_norm': 13.467887878417969, 'learning_rate': 1.75198035743667e-05, 'epoch': 1.38}\n",
      "{'loss': 0.8959, 'grad_norm': 3.017143964767456, 'learning_rate': 1.7290620220757926e-05, 'epoch': 1.43}\n",
      "{'loss': 0.9256, 'grad_norm': 6.010690689086914, 'learning_rate': 1.705295477765188e-05, 'epoch': 1.48}\n",
      "{'loss': 0.8617, 'grad_norm': 3.312304735183716, 'learning_rate': 1.6807083750955847e-05, 'epoch': 1.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6470f1a3014417ba608c85c428060c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9949485659599304, 'eval_roc_auc_micro': 0.8172234743999978, 'eval_pr_auc_micro': 0.3250506672998002, 'eval_roc_auc_macro': 0.814162602625847, 'eval_pr_auc_macro': 0.355927760190146, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4564, 'eval_samples_per_second': 1717.708, 'eval_steps_per_second': 28.482, 'epoch': 1.53}\n",
      "{'loss': 0.8815, 'grad_norm': 2.7966396808624268, 'learning_rate': 1.6553293193157824e-05, 'epoch': 1.58}\n",
      "{'loss': 0.8526, 'grad_norm': 3.0048654079437256, 'learning_rate': 1.6291878370525925e-05, 'epoch': 1.63}\n",
      "{'loss': 0.8857, 'grad_norm': 3.51379656791687, 'learning_rate': 1.602314341958823e-05, 'epoch': 1.68}\n",
      "{'loss': 0.8218, 'grad_norm': 4.400569438934326, 'learning_rate': 1.5747400993292756e-05, 'epoch': 1.73}\n",
      "{'loss': 0.9512, 'grad_norm': 8.03151798248291, 'learning_rate': 1.546497189725922e-05, 'epoch': 1.79}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad76353d2e43402b9590b6d6757afd3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9800438284873962, 'eval_roc_auc_micro': 0.8180586621136018, 'eval_pr_auc_micro': 0.35494318426454824, 'eval_roc_auc_macro': 0.8137886282624779, 'eval_pr_auc_macro': 0.37709848817295594, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4456, 'eval_samples_per_second': 1759.373, 'eval_steps_per_second': 29.173, 'epoch': 1.79}\n",
      "{'loss': 0.9957, 'grad_norm': 2.940859794616699, 'learning_rate': 1.517618471654577e-05, 'epoch': 1.84}\n",
      "{'loss': 0.9427, 'grad_norm': 5.640134334564209, 'learning_rate': 1.4881375433364937e-05, 'epoch': 1.89}\n",
      "{'loss': 0.7922, 'grad_norm': 4.718266010284424, 'learning_rate': 1.4580887036193539e-05, 'epoch': 1.94}\n",
      "{'loss': 0.9344, 'grad_norm': 9.819231986999512, 'learning_rate': 1.4275069120731325e-05, 'epoch': 1.99}\n",
      "{'loss': 0.7846, 'grad_norm': 8.249105453491211, 'learning_rate': 1.396427748317262e-05, 'epoch': 2.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30b0f510d40425ebeb058ed3f74ae94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9585692882537842, 'eval_roc_auc_micro': 0.8284640524124779, 'eval_pr_auc_micro': 0.3761272263078259, 'eval_roc_auc_macro': 0.8232040325946682, 'eval_pr_auc_macro': 0.39590236543558693, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4456, 'eval_samples_per_second': 1759.34, 'eval_steps_per_second': 29.173, 'epoch': 2.04}\n",
      "{'loss': 0.8384, 'grad_norm': 4.394472599029541, 'learning_rate': 1.3648873706264159e-05, 'epoch': 2.09}\n",
      "{'loss': 0.8089, 'grad_norm': 3.8336474895477295, 'learning_rate': 1.3329224738630677e-05, 'epoch': 2.14}\n",
      "{'loss': 0.8148, 'grad_norm': 5.054844379425049, 'learning_rate': 1.3005702467857744e-05, 'epoch': 2.19}\n",
      "{'loss': 0.7423, 'grad_norm': 3.22786808013916, 'learning_rate': 1.2678683287828451e-05, 'epoch': 2.24}\n",
      "{'loss': 0.8498, 'grad_norm': 4.396328926086426, 'learning_rate': 1.2348547660817388e-05, 'epoch': 2.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf7e9d11a5ad499e9746ee8242df3634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9451444745063782, 'eval_roc_auc_micro': 0.8320731668865806, 'eval_pr_auc_micro': 0.37962834936090306, 'eval_roc_auc_macro': 0.8272261466261295, 'eval_pr_auc_macro': 0.40565221517074584, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4538, 'eval_samples_per_second': 1727.63, 'eval_steps_per_second': 28.647, 'epoch': 2.3}\n",
      "{'loss': 0.8361, 'grad_norm': 4.984880447387695, 'learning_rate': 1.2015679674851329e-05, 'epoch': 2.35}\n",
      "{'loss': 0.8132, 'grad_norm': 4.7031941413879395, 'learning_rate': 1.1680466596851635e-05, 'epoch': 2.4}\n",
      "{'loss': 0.7054, 'grad_norm': 2.895181179046631, 'learning_rate': 1.134329842207827e-05, 'epoch': 2.45}\n",
      "{'loss': 0.9182, 'grad_norm': 8.917871475219727, 'learning_rate': 1.1004567420399563e-05, 'epoch': 2.5}\n",
      "{'loss': 0.9064, 'grad_norm': 4.033668518066406, 'learning_rate': 1.066466767991567e-05, 'epoch': 2.55}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a08eb336934a4ababab92c2eb0415b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9576736688613892, 'eval_roc_auc_micro': 0.8286244495380849, 'eval_pr_auc_micro': 0.36524469042347063, 'eval_roc_auc_macro': 0.8224721545735477, 'eval_pr_auc_macro': 0.3947339394794764, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4492, 'eval_samples_per_second': 1745.281, 'eval_steps_per_second': 28.94, 'epoch': 2.55}\n",
      "{'loss': 0.8542, 'grad_norm': 4.458804607391357, 'learning_rate': 1.0323994648466637e-05, 'epoch': 2.6}\n",
      "{'loss': 0.8363, 'grad_norm': 3.9726240634918213, 'learning_rate': 9.982944673558508e-06, 'epoch': 2.65}\n",
      "{'loss': 0.7648, 'grad_norm': 5.391849994659424, 'learning_rate': 9.64191454124277e-06, 'epoch': 2.7}\n",
      "{'loss': 0.8074, 'grad_norm': 3.345750331878662, 'learning_rate': 9.301301014485527e-06, 'epoch': 2.76}\n",
      "{'loss': 0.8724, 'grad_norm': 4.87542200088501, 'learning_rate': 8.961500371563585e-06, 'epoch': 2.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08e632e1c3a47ac8fbcea0fe129e691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9496233463287354, 'eval_roc_auc_micro': 0.8321177150085848, 'eval_pr_auc_micro': 0.3784703921741511, 'eval_roc_auc_macro': 0.8259832062529274, 'eval_pr_auc_macro': 0.4124036743634906, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4459, 'eval_samples_per_second': 1758.239, 'eval_steps_per_second': 29.154, 'epoch': 2.81}\n",
      "{'loss': 0.7691, 'grad_norm': 4.277701377868652, 'learning_rate': 8.622907945024418e-06, 'epoch': 2.86}\n",
      "{'loss': 0.8088, 'grad_norm': 9.605561256408691, 'learning_rate': 8.2859176617464e-06, 'epoch': 2.91}\n",
      "{'loss': 0.893, 'grad_norm': 6.579733848571777, 'learning_rate': 7.95092158463446e-06, 'epoch': 2.96}\n",
      "{'loss': 0.7435, 'grad_norm': 4.31878662109375, 'learning_rate': 7.618309456484309e-06, 'epoch': 3.01}\n",
      "{'loss': 0.7904, 'grad_norm': 2.9980530738830566, 'learning_rate': 7.288468246545946e-06, 'epoch': 3.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d6373c6b4b4a5bbaa21adef51c0bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9702308773994446, 'eval_roc_auc_micro': 0.8347019838126696, 'eval_pr_auc_micro': 0.3970395334193286, 'eval_roc_auc_macro': 0.8271611785997615, 'eval_pr_auc_macro': 0.4237971439347931, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4655, 'eval_samples_per_second': 1684.049, 'eval_steps_per_second': 27.924, 'epoch': 3.06}\n",
      "{'train_runtime': 40.0624, 'train_samples_per_second': 781.78, 'train_steps_per_second': 24.462, 'train_loss': 0.9069427569707235, 'epoch': 3.06}\n",
      "Training finished.\n",
      "TrainOutput(global_step=600, training_loss=0.9069427569707235, metrics={'train_runtime': 40.0624, 'train_samples_per_second': 781.78, 'train_steps_per_second': 24.462, 'total_flos': 526949918585856.0, 'train_loss': 0.9069427569707235, 'epoch': 3.061224489795918})\n",
      "\n",
      "Evaluating on validation set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d95e62766ec47adb72e2f55ce4d0092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL METRICS]\n",
      "eval_loss           : 0.945144\n",
      "eval_roc_auc_micro  : 0.832073\n",
      "eval_pr_auc_micro   : 0.379628\n",
      "eval_roc_auc_macro  : 0.827226\n",
      "eval_pr_auc_macro   : 0.405652\n",
      "eval_macro_valid_labels: 12.000000\n",
      "eval_runtime        : 0.473500\n",
      "eval_samples_per_second: 1655.654000\n",
      "eval_steps_per_second: 27.453000\n",
      "epoch               : 3.061224\n",
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1307365a33a4acb974b110843f31211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_roc_auc_macro so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST METRICS]\n",
      "test_loss           : 1.007828\n",
      "test_roc_auc_micro  : 0.821974\n",
      "test_pr_auc_micro   : 0.385951\n",
      "test_roc_auc_macro  : 0.799102\n",
      "test_pr_auc_macro   : 0.389610\n",
      "test_macro_valid_labels: 12.000000\n",
      "test_runtime        : 0.376000\n",
      "test_samples_per_second: 2082.640000\n",
      "test_steps_per_second: 34.578000\n",
      "epoch               : 3.061224\n",
      "\n",
      "Saving v2 final model + tokenizer...\n",
      "\n",
      "Dumping VAL and TEST outputs for calibration/thresholding...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f41a37ddee43d5a75eeab0d3790f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] val_logits/prob/y/mask â†’ implementation\\models\\chemberta_v2\\outputs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab50eb69c81404081ae7d26f5e27858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] test_logits/prob/y/mask â†’ implementation\\models\\chemberta_v2\\outputs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, math, json, gc, time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "from transformers import AdamW as HFAdamW\n",
    "\n",
    "\n",
    "# ----- Build model from v1 checkpoint (inherit labels) -----\n",
    "config_v2 = AutoConfig.from_pretrained(\n",
    "    str(V1_DIR),\n",
    "    num_labels=len(label_names),\n",
    "    id2label={i: lbl for i, lbl in id2label.items()},\n",
    "    label2id={lbl: i for lbl, i in label2id.items()},\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(str(V1_DIR), config=config_v2)\n",
    "model.to(DEVICE)\n",
    "# gradient checkpointing reduces memory\n",
    "if run_cfg.gradient_checkpointing:\n",
    "    model.gradient_checkpointing_enable()\n",
    "# disable cache for decoder-less models if present\n",
    "if hasattr(model.config, \"use_cache\"):\n",
    "    model.config.use_cache = False\n",
    "\n",
    "# ----- Extend Trainer to support label smoothing + LLRD optimizer -----\n",
    "from transformers import AdamW as HFAdamW\n",
    "\n",
    "class V2Trainer(MultiLabelTrainer):\n",
    "    def __init__(self, *args, label_smoothing: float = 0.0, llrd_enable: bool = False, llrd_decay: float = 0.9, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.label_smoothing = float(label_smoothing)\n",
    "        self.llrd_enable = bool(llrd_enable)\n",
    "        self.llrd_decay = float(llrd_decay)\n",
    "        self._optimizer_created = False\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")           # [B,L]\n",
    "        label_mask = inputs.pop(\"label_mask\")   # [B,L]\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits                 # [B,L]\n",
    "\n",
    "        # optional label smoothing: y' = y*(1-Îµ) + 0.5*Îµ\n",
    "        y = labels\n",
    "        if self.label_smoothing > 0.0:\n",
    "            eps = self.label_smoothing\n",
    "            y = y * (1.0 - eps) + 0.5 * eps\n",
    "\n",
    "        loss_fct = nn.BCEWithLogitsLoss(\n",
    "            reduction=\"none\",\n",
    "            pos_weight=self.pos_weight.to(logits.device) if self.pos_weight is not None else None\n",
    "        )\n",
    "        loss = loss_fct(logits, y)\n",
    "        loss = (loss * label_mask).sum() / (label_mask.sum() + 1e-8)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def create_optimizer(self):\n",
    "        if self._optimizer_created:\n",
    "            return\n",
    "        wd = self.args.weight_decay\n",
    "        base_lr = self.args.learning_rate\n",
    "\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\", \"layer_norm.weight\"]\n",
    "        params = list(self.model.named_parameters())\n",
    "\n",
    "        if not self.llrd_enable:\n",
    "            # default AdamW groups\n",
    "            decay, nodecay = [], []\n",
    "            for n, p in params:\n",
    "                if any(nd in n for nd in no_decay):\n",
    "                    nodecay.append(p)\n",
    "                else:\n",
    "                    decay.append(p)\n",
    "            param_groups = [\n",
    "                {\"params\": decay, \"weight_decay\": wd, \"lr\": base_lr},\n",
    "                {\"params\": nodecay, \"weight_decay\": 0.0, \"lr\": base_lr},\n",
    "            ]\n",
    "        else:\n",
    "            # Layer-wise LR decay: lower lr for lower layers\n",
    "            layers = []\n",
    "            # Try to detect encoder layers (works for Roberta/BERT)\n",
    "            L = 0\n",
    "            if hasattr(self.model, \"roberta\") and hasattr(self.model.roberta, \"encoder\"):\n",
    "                L = len(self.model.roberta.encoder.layer)\n",
    "            elif hasattr(self.model, \"bert\") and hasattr(self.model.bert, \"encoder\"):\n",
    "                L = len(self.model.bert.encoder.layer)\n",
    "            else:\n",
    "                L = 12  # fallback guess\n",
    "\n",
    "            def layer_id(name: str) -> int:\n",
    "                # return -1 for embeddings, 0..L-1 for encoder layers, L for head\n",
    "                if re.search(r\"(embeddings)\", name):\n",
    "                    return -1\n",
    "                m = re.search(r\"encoder\\.layer\\.(\\d+)\\.\", name)\n",
    "                if m:\n",
    "                    return int(m.group(1))\n",
    "                return L  # head/classifier\n",
    "\n",
    "            # build groups\n",
    "            groups = {}\n",
    "            for n, p in params:\n",
    "                if not p.requires_grad:\n",
    "                    continue\n",
    "                lid = layer_id(n)\n",
    "                if lid not in groups:\n",
    "                    groups[lid] = {\"decay\": [], \"nodecay\": []}\n",
    "                if any(nd in n for nd in no_decay):\n",
    "                    groups[lid][\"nodecay\"].append(p)\n",
    "                else:\n",
    "                    groups[lid][\"decay\"].append(p)\n",
    "\n",
    "            param_groups = []\n",
    "            for lid in sorted(groups.keys()):\n",
    "                # deeper layers (higher lid) use higher lr; embeddings lowest\n",
    "                # base for head (lid==L) = base_lr; for layer k use base_lr * (llrd_decay ** (L - 1 - k))\n",
    "                if lid == L:\n",
    "                    lr = base_lr\n",
    "                elif lid == -1:\n",
    "                    lr = base_lr * (self.llrd_decay ** (L + 1))\n",
    "                else:\n",
    "                    lr = base_lr * (self.llrd_decay ** (L - 1 - lid))\n",
    "                if groups[lid][\"decay\"]:\n",
    "                    param_groups.append({\"params\": groups[lid][\"decay\"], \"weight_decay\": wd, \"lr\": lr})\n",
    "                if groups[lid][\"nodecay\"]:\n",
    "                    param_groups.append({\"params\": groups[lid][\"nodecay\"], \"weight_decay\": 0.0, \"lr\": lr})\n",
    "\n",
    "        self.optimizer = HFAdamW(param_groups, lr=base_lr, betas=(0.9, 0.999), eps=1e-8)\n",
    "        self._optimizer_created = True\n",
    "\n",
    "# ----- TrainingArguments -----\n",
    "greater_is_better = True  # for AUC metrics\n",
    "args = TrainingArguments(\n",
    "    output_dir=str(CKPT_DIR),\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=run_cfg.train_batch_size,\n",
    "    per_device_eval_batch_size=run_cfg.eval_batch_size,\n",
    "    gradient_accumulation_steps=run_cfg.gradient_accumulation_steps,\n",
    "    learning_rate=run_cfg.learning_rate,\n",
    "    weight_decay=run_cfg.weight_decay,\n",
    "    warmup_ratio=run_cfg.warmup_ratio,\n",
    "    num_train_epochs=run_cfg.num_train_epochs,\n",
    "    lr_scheduler_type=run_cfg.lr_schedule,\n",
    "    logging_steps=10,                    # CHANGED: more frequent logs\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=run_cfg.eval_steps,\n",
    "    save_steps=run_cfg.eval_steps,\n",
    "    save_total_limit=run_cfg.save_total_limit,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=run_cfg.metric_primary,\n",
    "    greater_is_better=greater_is_better,\n",
    "    fp16=run_cfg.fp16,\n",
    "    bf16=run_cfg.bfloat16,\n",
    "    gradient_checkpointing=run_cfg.gradient_checkpointing,\n",
    "    max_grad_norm=run_cfg.max_grad_norm,\n",
    "    report_to=[],\n",
    "    dataloader_num_workers=0,            # CHANGED: avoid Windows spawn/pickling hang\n",
    "    dataloader_pin_memory=True,          # CHANGED: faster hostâ†’GPU copies\n",
    "    disable_tqdm=False,                  # ensure progress bar shows\n",
    "    remove_unused_columns=False,         # keep extra fields (label_mask)\n",
    ")\n",
    "\n",
    "trainer = V2Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    "    pos_weight=POS_WEIGHT,\n",
    "    label_smoothing=run_cfg.label_smoothing,\n",
    "    llrd_enable=run_cfg.llrd_enable,\n",
    "    llrd_decay=run_cfg.llrd_decay,\n",
    ")\n",
    "trainer.compute_metrics = make_compute_metrics(trainer)\n",
    "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=run_cfg.early_stopping_patience))\n",
    "\n",
    "# quick preflight: get one batch from trainer's dataloader to ensure no stall\n",
    "dl = trainer.get_train_dataloader()\n",
    "t0 = time.time()\n",
    "_ = next(iter(dl))\n",
    "print(f\"[Preflight] got first train batch in {time.time()-t0:.2f}s\")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "train_out = trainer.train()\n",
    "print(\"Training finished.\")\n",
    "print(train_out)\n",
    "\n",
    "# ----- Evaluate on VAL & TEST -----\n",
    "print(\"\\nEvaluating on validation set...\")\n",
    "val_metrics = trainer.evaluate(eval_dataset=val_ds)\n",
    "print(\"[VAL METRICS]\")\n",
    "for k, v in val_metrics.items():\n",
    "    if isinstance(v, (float, int)):\n",
    "        print(f\"{k:20s}: {v:.6f}\")\n",
    "    else:\n",
    "        print(f\"{k:20s}: {v}\")\n",
    "\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_metrics = trainer.evaluate(eval_dataset=test_ds, metric_key_prefix=\"test\")\n",
    "print(\"[TEST METRICS]\")\n",
    "for k, v in test_metrics.items():\n",
    "    if isinstance(v, (float, int)):\n",
    "        print(f\"{k:20s}: {v:.6f}\")\n",
    "    else:\n",
    "        print(f\"{k:20s}: {v}\")\n",
    "\n",
    "# ----- Save best model as v2 final -----\n",
    "print(\"\\nSaving v2 final model + tokenizer...\")\n",
    "trainer.save_model(str(V2_DIR))  # config + weights\n",
    "tokenizer.save_pretrained(str(V2_DIR))\n",
    "# snapshot training/eval metrics\n",
    "with open(METRICS_DIR / \"val_metrics.json\", \"w\") as f:\n",
    "    json.dump({k: float(v) if isinstance(v, (int, float, np.floating)) else v for k, v in val_metrics.items()}, f, indent=2)\n",
    "with open(METRICS_DIR / \"test_metrics.json\", \"w\") as f:\n",
    "    json.dump({k: float(v) if isinstance(v, (int, float, np.floating)) else v for k, v in test_metrics.items()}, f, indent=2)\n",
    "\n",
    "# ----- Dump raw outputs for calibration/thresholding notebooks -----\n",
    "def dump_outputs(ds, prefix: str):\n",
    "    preds = trainer.predict(ds)\n",
    "    logits = preds.predictions\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "    labels = preds.label_ids\n",
    "    # mask from trainer buffer (aligned by prediction_step)\n",
    "    if len(trainer._eval_label_masks) == 0:\n",
    "        mask = np.ones_like(labels, dtype=np.float32)\n",
    "    else:\n",
    "        mask = torch.cat(trainer._eval_label_masks, dim=0).numpy().astype(np.float32)\n",
    "        if mask.shape != labels.shape:\n",
    "            min_n = min(mask.shape[0], labels.shape[0])\n",
    "            mask = mask[:min_n]; labels = labels[:min_n]; logits = logits[:min_n]\n",
    "\n",
    "    probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "    np.save(OUT_DIR / f\"{prefix}_logits.npy\", logits.astype(np.float32))\n",
    "    np.save(OUT_DIR / f\"{prefix}_prob.npy\",    probs.astype(np.float32))\n",
    "    np.save(OUT_DIR / f\"{prefix}_y.npy\",       labels.astype(np.float32))\n",
    "    np.save(OUT_DIR / f\"{prefix}_mask.npy\",    mask.astype(np.float32))\n",
    "    print(f\"[SAVED] {prefix}_logits/prob/y/mask â†’ {OUT_DIR}\")\n",
    "\n",
    "print(\"\\nDumping VAL and TEST outputs for calibration/thresholding...\")\n",
    "dump_outputs(val_ds, \"val\")\n",
    "dump_outputs(test_ds, \"test\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761bd579",
   "metadata": {},
   "source": [
    "## 5: Post-training summary & per-label metrics (val + test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6fe4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ChemBERTa v2 Summary ===\n",
      "VAL  â†’ AUROC micro=nan  macro=nan | PR-AUC micro=nan  macro=nan\n",
      "TEST â†’ AUROC micro=0.8220  macro=0.7991 | PR-AUC micro=0.3860  macro=0.3896\n",
      "Saved per-label CSVs â†’ implementation\\models\\chemberta_v2\\metrics\\per_label_val.csv  and  implementation\\models\\chemberta_v2\\metrics\\per_label_test.csv\n",
      "\n",
      "Top 3 labels (VAL) by AUROC:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n</th>\n",
       "      <th>auroc</th>\n",
       "      <th>ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>674</td>\n",
       "      <td>0.910962</td>\n",
       "      <td>0.639487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>643</td>\n",
       "      <td>0.877657</td>\n",
       "      <td>0.299927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>577</td>\n",
       "      <td>0.868708</td>\n",
       "      <td>0.375160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label    n     auroc        ap\n",
       "1      NR-AR-LBD  674  0.910962  0.639487\n",
       "6  NR-PPAR-gamma  643  0.877657  0.299927\n",
       "3   NR-Aromatase  577  0.868708  0.375160"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom 3 labels (VAL) by AUROC:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n</th>\n",
       "      <th>auroc</th>\n",
       "      <th>ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>611</td>\n",
       "      <td>0.716689</td>\n",
       "      <td>0.399331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SR-p53</td>\n",
       "      <td>669</td>\n",
       "      <td>0.797277</td>\n",
       "      <td>0.212568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>571</td>\n",
       "      <td>0.802857</td>\n",
       "      <td>0.411013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label    n     auroc        ap\n",
       "4    NR-ER  611  0.716689  0.399331\n",
       "11  SR-p53  669  0.797277  0.212568\n",
       "7   SR-ARE  571  0.802857  0.411013"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 3 labels (TEST) by AUROC:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n</th>\n",
       "      <th>auroc</th>\n",
       "      <th>ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>660</td>\n",
       "      <td>0.880288</td>\n",
       "      <td>0.612642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SR-MMP</td>\n",
       "      <td>592</td>\n",
       "      <td>0.877435</td>\n",
       "      <td>0.561264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>582</td>\n",
       "      <td>0.862138</td>\n",
       "      <td>0.282484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label    n     auroc        ap\n",
       "2         NR-AhR  660  0.880288  0.612642\n",
       "10        SR-MMP  592  0.877435  0.561264\n",
       "3   NR-Aromatase  582  0.862138  0.282484"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom 3 labels (TEST) by AUROC:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n</th>\n",
       "      <th>auroc</th>\n",
       "      <th>ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>636</td>\n",
       "      <td>0.710297</td>\n",
       "      <td>0.424557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>655</td>\n",
       "      <td>0.740860</td>\n",
       "      <td>0.264388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-AR</td>\n",
       "      <td>721</td>\n",
       "      <td>0.750531</td>\n",
       "      <td>0.486580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label    n     auroc        ap\n",
       "4   NR-ER  636  0.710297  0.424557\n",
       "9  SR-HSE  655  0.740860  0.264388\n",
       "0   NR-AR  721  0.750531  0.486580"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==== Cell 5: Summarize v2 results & per-label metrics (val + test) ====\n",
    "import numpy as np, pandas as pd, json\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "OUT_DIR  = Path(str(V2_DIR)) / \"outputs\"\n",
    "META_DIR = Path(str(V2_DIR)) / \"metadata\"\n",
    "METRICS_DIR = Path(str(V2_DIR)) / \"metrics\"\n",
    "\n",
    "def load_split(prefix):\n",
    "    logits = np.load(OUT_DIR / f\"{prefix}_logits.npy\")\n",
    "    probs  = 1/(1+np.exp(-logits))\n",
    "    y      = np.load(OUT_DIR / f\"{prefix}_y.npy\")\n",
    "    mask   = np.load(OUT_DIR / f\"{prefix}_mask.npy\")\n",
    "    return probs, y, mask\n",
    "\n",
    "def per_label_table(probs, y, mask, labels):\n",
    "    rows = []\n",
    "    for j, name in enumerate(labels):\n",
    "        m = mask[:, j] == 1\n",
    "        yj = y[m, j].astype(int)\n",
    "        pj = probs[m, j].astype(float)\n",
    "        if len(yj) < 2 or (yj.max()==yj.min()):\n",
    "            rows.append(dict(label=name, n=len(yj), auroc=np.nan, ap=np.nan))\n",
    "            continue\n",
    "        try:\n",
    "            auc = roc_auc_score(yj, pj)\n",
    "        except Exception:\n",
    "            auc = np.nan\n",
    "        try:\n",
    "            ap = average_precision_score(yj, pj)\n",
    "        except Exception:\n",
    "            ap = np.nan\n",
    "        rows.append(dict(label=name, n=len(yj), auroc=float(auc), ap=float(ap)))\n",
    "    return pd.DataFrame(rows).sort_values(\"label\").reset_index(drop=True)\n",
    "\n",
    "def head_tail(df, k=3):\n",
    "    top = df.sort_values(\"auroc\", ascending=False).head(k)\n",
    "    bot = df.sort_values(\"auroc\", ascending=True).head(k)\n",
    "    return top, bot\n",
    "\n",
    "# load\n",
    "p_val, y_val, m_val = load_split(\"val\")\n",
    "p_test, y_test, m_test = load_split(\"test\")\n",
    "\n",
    "val_tbl  = per_label_table(p_val,  y_val,  m_val,  label_names)\n",
    "test_tbl = per_label_table(p_test, y_test, m_test, label_names)\n",
    "\n",
    "# Save CSVs for traceability\n",
    "METRICS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "val_tbl.to_csv(METRICS_DIR / \"per_label_val.csv\", index=False)\n",
    "test_tbl.to_csv(METRICS_DIR / \"per_label_test.csv\", index=False)\n",
    "\n",
    "# quick summary\n",
    "with open(METRICS_DIR / \"val_metrics.json\") as f:\n",
    "    val_json = json.load(f)\n",
    "with open(METRICS_DIR / \"test_metrics.json\") as f:\n",
    "    test_json = json.load(f)\n",
    "\n",
    "def fmt(x): \n",
    "    return \"nan\" if x!=x else f\"{x:.4f}\"\n",
    "\n",
    "print(\"=== ChemBERTa v2 Summary ===\")\n",
    "print(f\"VAL  â†’ AUROC micro={fmt(val_json.get('roc_auc_micro', float('nan')))}  macro={fmt(val_json.get('roc_auc_macro', float('nan')))}\"\n",
    "      f\" | PR-AUC micro={fmt(val_json.get('pr_auc_micro', float('nan')))}  macro={fmt(val_json.get('pr_auc_macro', float('nan')))}\")\n",
    "print(f\"TEST â†’ AUROC micro={fmt(test_json.get('test_roc_auc_micro', float('nan')))}  macro={fmt(test_json.get('test_roc_auc_macro', float('nan')))}\"\n",
    "      f\" | PR-AUC micro={fmt(test_json.get('test_pr_auc_micro', float('nan')))}  macro={fmt(test_json.get('test_pr_auc_macro', float('nan')))}\")\n",
    "print(f\"Saved per-label CSVs â†’ {METRICS_DIR/'per_label_val.csv'}  and  {METRICS_DIR/'per_label_test.csv'}\")\n",
    "\n",
    "# show top/bottom labels by AUROC\n",
    "k = 3\n",
    "val_top, val_bot = head_tail(val_tbl, k=k)\n",
    "test_top, test_bot = head_tail(test_tbl, k=k)\n",
    "\n",
    "print(f\"\\nTop {k} labels (VAL) by AUROC:\")\n",
    "display(val_top)\n",
    "print(f\"Bottom {k} labels (VAL) by AUROC:\")\n",
    "display(val_bot)\n",
    "\n",
    "print(f\"\\nTop {k} labels (TEST) by AUROC:\")\n",
    "display(test_top)\n",
    "print(f\"Bottom {k} labels (TEST) by AUROC:\")\n",
    "display(test_bot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf42d24",
   "metadata": {},
   "source": [
    "## 6: Diagnose & propose label-wise focal Î³/Î±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c67757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 5 (VAL):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n</th>\n",
       "      <th>auroc</th>\n",
       "      <th>ap</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos_rate</th>\n",
       "      <th>difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>611</td>\n",
       "      <td>0.716689</td>\n",
       "      <td>0.399331</td>\n",
       "      <td>4946</td>\n",
       "      <td>634</td>\n",
       "      <td>4312</td>\n",
       "      <td>0.128184</td>\n",
       "      <td>0.159814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SR-p53</td>\n",
       "      <td>669</td>\n",
       "      <td>0.797277</td>\n",
       "      <td>0.212568</td>\n",
       "      <td>5414</td>\n",
       "      <td>339</td>\n",
       "      <td>5075</td>\n",
       "      <td>0.062615</td>\n",
       "      <td>0.107708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>571</td>\n",
       "      <td>0.802857</td>\n",
       "      <td>0.411013</td>\n",
       "      <td>4688</td>\n",
       "      <td>754</td>\n",
       "      <td>3934</td>\n",
       "      <td>0.160836</td>\n",
       "      <td>0.114425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>631</td>\n",
       "      <td>0.805827</td>\n",
       "      <td>0.281024</td>\n",
       "      <td>5181</td>\n",
       "      <td>297</td>\n",
       "      <td>4884</td>\n",
       "      <td>0.057325</td>\n",
       "      <td>0.102652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>652</td>\n",
       "      <td>0.812614</td>\n",
       "      <td>0.451127</td>\n",
       "      <td>5237</td>\n",
       "      <td>614</td>\n",
       "      <td>4623</td>\n",
       "      <td>0.117243</td>\n",
       "      <td>0.104678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label    n     auroc        ap  n_obs  pos   neg  pos_rate  difficulty\n",
       "4    NR-ER  611  0.716689  0.399331   4946  634  4312  0.128184    0.159814\n",
       "11  SR-p53  669  0.797277  0.212568   5414  339  5075  0.062615    0.107708\n",
       "7   SR-ARE  571  0.802857  0.411013   4688  754  3934  0.160836    0.114425\n",
       "9   SR-HSE  631  0.805827  0.281024   5181  297  4884  0.057325    0.102652\n",
       "2   NR-AhR  652  0.812614  0.451127   5237  614  4623  0.117243    0.104678"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 5 (TEST):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n</th>\n",
       "      <th>auroc</th>\n",
       "      <th>ap</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos_rate</th>\n",
       "      <th>difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>636</td>\n",
       "      <td>0.710297</td>\n",
       "      <td>0.424557</td>\n",
       "      <td>4946</td>\n",
       "      <td>634</td>\n",
       "      <td>4312</td>\n",
       "      <td>0.128184</td>\n",
       "      <td>0.163419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>655</td>\n",
       "      <td>0.740860</td>\n",
       "      <td>0.264388</td>\n",
       "      <td>5181</td>\n",
       "      <td>297</td>\n",
       "      <td>4884</td>\n",
       "      <td>0.057325</td>\n",
       "      <td>0.136998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-AR</td>\n",
       "      <td>721</td>\n",
       "      <td>0.750531</td>\n",
       "      <td>0.486580</td>\n",
       "      <td>5809</td>\n",
       "      <td>248</td>\n",
       "      <td>5561</td>\n",
       "      <td>0.042692</td>\n",
       "      <td>0.130060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NR-ER-LBD</td>\n",
       "      <td>703</td>\n",
       "      <td>0.760650</td>\n",
       "      <td>0.381504</td>\n",
       "      <td>5561</td>\n",
       "      <td>280</td>\n",
       "      <td>5281</td>\n",
       "      <td>0.050351</td>\n",
       "      <td>0.125701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>573</td>\n",
       "      <td>0.767001</td>\n",
       "      <td>0.396166</td>\n",
       "      <td>4688</td>\n",
       "      <td>754</td>\n",
       "      <td>3934</td>\n",
       "      <td>0.160836</td>\n",
       "      <td>0.135237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label    n     auroc        ap  n_obs  pos   neg  pos_rate  difficulty\n",
       "4      NR-ER  636  0.710297  0.424557   4946  634  4312  0.128184    0.163419\n",
       "9     SR-HSE  655  0.740860  0.264388   5181  297  4884  0.057325    0.136998\n",
       "0      NR-AR  721  0.750531  0.486580   5809  248  5561  0.042692    0.130060\n",
       "5  NR-ER-LBD  703  0.760650  0.381504   5561  280  5281  0.050351    0.125701\n",
       "7     SR-ARE  573  0.767001  0.396166   4688  754  3934  0.160836    0.135237"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>gamma</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>1.614394</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>1.595898</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>1.594666</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-AR</td>\n",
       "      <td>1.591042</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NR-ER-LBD</td>\n",
       "      <td>1.587990</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SR-p53</td>\n",
       "      <td>1.576462</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>1.573955</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>1.569205</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SR-ATAD5</td>\n",
       "      <td>1.557374</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>1.550736</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SR-MMP</td>\n",
       "      <td>1.549667</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>1.546812</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label     gamma  alpha\n",
       "4           NR-ER  1.614394   0.75\n",
       "9          SR-HSE  1.595898   0.75\n",
       "7          SR-ARE  1.594666   0.75\n",
       "0           NR-AR  1.591042   0.75\n",
       "5       NR-ER-LBD  1.587990   0.75\n",
       "11         SR-p53  1.576462   0.75\n",
       "1       NR-AR-LBD  1.573955   0.75\n",
       "6   NR-PPAR-gamma  1.569205   0.75\n",
       "8        SR-ATAD5  1.557374   0.75\n",
       "3    NR-Aromatase  1.550736   0.75\n",
       "10         SR-MMP  1.549667   0.75\n",
       "2          NR-AhR  1.546812   0.75"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved focal suggestions â†’ implementation\\models\\chemberta_v2\\metadata\\focal_suggest.json\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 6: Diagnose underperformers & propose focal-loss gamma/alpha ====\n",
    "import json, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "METRICS_DIR = V2_DIR / \"metrics\"\n",
    "with open(META_DIR / \"label_stats.json\") as f:\n",
    "    stats = json.load(f)\n",
    "\n",
    "prev = pd.DataFrame(stats[\"train\"])  # use TRAIN prevalence to set alphas\n",
    "prev = prev[[\"label\",\"n\",\"pos\",\"neg\",\"pos_rate\"]].rename(columns={\"n\":\"n_obs\"})\n",
    "val_tbl  = pd.read_csv(METRICS_DIR / \"per_label_val.csv\")\n",
    "test_tbl = pd.read_csv(METRICS_DIR / \"per_label_test.csv\")\n",
    "\n",
    "def merge_all(tbl):\n",
    "    df = tbl.merge(prev, on=\"label\", how=\"left\")\n",
    "    # difficulty: (1 - AUROC) scaled by prevalence (to focus on common labels too)\n",
    "    df[\"difficulty\"] = (1.0 - df[\"auroc\"]).clip(0,1) * (0.5 + 0.5*df[\"pos_rate\"].fillna(0))\n",
    "    return df.sort_values(\"auroc\")\n",
    "\n",
    "val_m = merge_all(val_tbl)\n",
    "test_m = merge_all(test_tbl)\n",
    "\n",
    "print(\"Worst 5 (VAL):\")\n",
    "display(val_m.head(5))\n",
    "print(\"Worst 5 (TEST):\")\n",
    "display(test_m.head(5))\n",
    "\n",
    "# propose gamma: base 1.5; add up to +0.7 based on difficulty; clip 1.5..2.2\n",
    "def propose_gamma(d):\n",
    "    return float(np.clip(1.5 + 0.7*d, 1.5, 2.2))\n",
    "\n",
    "# propose alpha (class-balancing): inverse prevalence, clipped 0.25..0.75\n",
    "def propose_alpha(pos_rate):\n",
    "    if pd.isna(pos_rate) or pos_rate <= 0:\n",
    "        return 0.5\n",
    "    inv = 1.0 - float(pos_rate)\n",
    "    return float(np.clip(inv, 0.25, 0.75))\n",
    "\n",
    "# combine (take TEST when available else VAL)\n",
    "labels = val_tbl[\"label\"].tolist()\n",
    "suggest = []\n",
    "for lab in labels:\n",
    "    row = test_m[test_m[\"label\"]==lab]\n",
    "    if row.empty:\n",
    "        row = val_m[val_m[\"label\"]==lab]\n",
    "    d = float(row[\"difficulty\"].values[0]) if not row.empty else 0.0\n",
    "    pr = float(prev.loc[prev[\"label\"]==lab, \"pos_rate\"].values[0])\n",
    "    suggest.append({\"label\": lab, \"gamma\": propose_gamma(d), \"alpha\": propose_alpha(pr)})\n",
    "\n",
    "gamma_df = pd.DataFrame(suggest).sort_values(\"gamma\", ascending=False)\n",
    "display(gamma_df)\n",
    "\n",
    "# Save suggested hyperparams for next cell\n",
    "with open(META_DIR / \"focal_suggest.json\", \"w\") as f:\n",
    "    json.dump({r[\"label\"]: {\"gamma\": r[\"gamma\"], \"alpha\": r[\"alpha\"]} for r in suggest}, f, indent=2)\n",
    "\n",
    "print(\"Saved focal suggestions â†’\", META_DIR / \"focal_suggest.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868161ad",
   "metadata": {},
   "source": [
    "## 7: retraining v2b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804ec46b",
   "metadata": {},
   "source": [
    "### Add Focal BCE (label-wise Î±, Î³) to Trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7aef94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focal BCE integrated.\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 7: Focal BCE (label-wise) integration ====\n",
    "import json, torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Load suggestions (you can edit the JSON manually if you want to tweak)\n",
    "with open(META_DIR / \"focal_suggest.json\") as f:\n",
    "    FOCAL_MAP = json.load(f)  # {label: {\"gamma\":..., \"alpha\":...}}\n",
    "\n",
    "# create per-label tensors aligned to label_names\n",
    "gamma_vec = torch.tensor([FOCAL_MAP.get(l, {}).get(\"gamma\", 1.5) for l in label_names], dtype=torch.float32)\n",
    "alpha_vec = torch.tensor([FOCAL_MAP.get(l, {}).get(\"alpha\", 0.5)  for l in label_names], dtype=torch.float32)\n",
    "\n",
    "class BCEWithLogitsFocalMasked(nn.Module):\n",
    "    \"\"\"\n",
    "    Mask-aware focal BCE with per-label alpha & gamma and optional pos_weight.\n",
    "    - logits: [B,L], labels: [B,L] in {0,1}, mask: [B,L] in {0,1}\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha: torch.Tensor, gamma: torch.Tensor, pos_weight: torch.Tensor=None, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"alpha\", alpha.view(1,-1))        # [1,L]\n",
    "        self.register_buffer(\"gamma\", gamma.view(1,-1))        # [1,L]\n",
    "        self.register_buffer(\"pos_weight\", pos_weight.view(1,-1) if pos_weight is not None else None)  # [1,L]\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, logits: torch.Tensor, targets: torch.Tensor, mask: torch.Tensor):\n",
    "        # base BCE with logits\n",
    "        # sigmoid for focal factor (but keep logits to avoid stability issues)\n",
    "        prob = torch.sigmoid(logits)\n",
    "        # standard BCE for each entry\n",
    "        if self.pos_weight is not None:\n",
    "            # manual BCE with pos_weight\n",
    "            # BCE = -(w*y*log(p) + (1-y)*log(1-p))\n",
    "            w = self.pos_weight\n",
    "            bce = -( w * targets * torch.log(prob.clamp_min(self.eps)) + (1-targets) * torch.log((1-prob).clamp_min(self.eps)) )\n",
    "        else:\n",
    "            # use PyTorch BCE (stable) and then detach logits? We'll compute explicitly to inject focal factor\n",
    "            bce = -( targets * torch.log(prob.clamp_min(self.eps)) + (1-targets) * torch.log((1-prob).clamp_min(self.eps)) )\n",
    "\n",
    "        # focal factor per entry\n",
    "        pt = prob*targets + (1-prob)*(1-targets)  # pt = p if y=1 else 1-p\n",
    "        focal = (self.alpha * (1-pt).pow(self.gamma))\n",
    "\n",
    "        loss = focal * bce\n",
    "        # apply mask\n",
    "        loss = (loss * mask).sum() / (mask.sum() + 1e-8)\n",
    "        return loss\n",
    "\n",
    "# Rebuild Trainer to use focal loss when enabled\n",
    "class V2TrainerFocal(V2Trainer):\n",
    "    def __init__(self, *args, use_focal: bool = False, focal_alpha=None, focal_gamma=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.use_focal = bool(use_focal)\n",
    "        if self.use_focal:\n",
    "            pw = self.pos_weight if self.pos_weight is not None else None\n",
    "            self.focal_loss = BCEWithLogitsFocalMasked(\n",
    "                alpha=focal_alpha.to(DEVICE),\n",
    "                gamma=focal_gamma.to(DEVICE),\n",
    "                pos_weight=pw.to(DEVICE) if pw is not None else None\n",
    "            )\n",
    "        else:\n",
    "            self.focal_loss = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        label_mask = inputs.pop(\"label_mask\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        y = labels\n",
    "        if self.label_smoothing > 0.0:\n",
    "            eps = self.label_smoothing\n",
    "            y = y * (1.0 - eps) + 0.5 * eps\n",
    "\n",
    "        if self.use_focal and self.focal_loss is not None:\n",
    "            loss = self.focal_loss(logits, y, label_mask)\n",
    "        else:\n",
    "            # fallback to BCE-with-logits (masked), as defined before\n",
    "            loss_fct = nn.BCEWithLogitsLoss(\n",
    "                reduction=\"none\",\n",
    "                pos_weight=self.pos_weight.to(logits.device) if self.pos_weight is not None else None\n",
    "            )\n",
    "            loss = loss_fct(logits, y)\n",
    "            loss = (loss * label_mask).sum() / (label_mask.sum() + 1e-8)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "print(\"Focal BCE integrated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35727059",
   "metadata": {},
   "source": [
    "### Turn on stronger recipe & retrain v2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94045135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting v2b training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f1cc72cd7145d2bd40a39082761466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1568 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3819, 'grad_norm': 7.174509048461914, 'learning_rate': 5.034704210526316e-07, 'epoch': 0.05}\n",
      "{'loss': 0.4437, 'grad_norm': 4.967910289764404, 'learning_rate': 1.0069408421052633e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:39:29] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3825, 'grad_norm': 7.506126880645752, 'learning_rate': 1.5104112631578948e-06, 'epoch': 0.15}\n",
      "{'loss': 0.4365, 'grad_norm': 5.017623424530029, 'learning_rate': 2.0138816842105266e-06, 'epoch': 0.2}\n",
      "{'loss': 0.3775, 'grad_norm': 7.6391801834106445, 'learning_rate': 2.5173521052631584e-06, 'epoch': 0.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73bbcdb6d62a4372af2c1ff62ac8e999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35538166761398315, 'eval_roc_auc_micro': 0.8300588274074379, 'eval_pr_auc_micro': 0.3761299839182934, 'eval_roc_auc_macro': 0.8264836181627483, 'eval_pr_auc_macro': 0.40825771010644635, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4654, 'eval_samples_per_second': 1684.396, 'eval_steps_per_second': 27.93, 'epoch': 0.26}\n",
      "{'loss': 0.3215, 'grad_norm': 2.0361268520355225, 'learning_rate': 3.0208225263157897e-06, 'epoch': 0.31}\n",
      "{'loss': 0.3076, 'grad_norm': 1.5911823511123657, 'learning_rate': 3.5242929473684214e-06, 'epoch': 0.36}\n",
      "{'loss': 0.3265, 'grad_norm': 3.3216421604156494, 'learning_rate': 4.027763368421053e-06, 'epoch': 0.41}\n",
      "{'loss': 0.3158, 'grad_norm': 6.545434951782227, 'learning_rate': 4.531233789473685e-06, 'epoch': 0.46}\n",
      "{'loss': 0.3794, 'grad_norm': 7.265249252319336, 'learning_rate': 4.782833022291087e-06, 'epoch': 0.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3f45d9e71e40f7a3d8828dfd9b25d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3479882776737213, 'eval_roc_auc_micro': 0.8214793129509155, 'eval_pr_auc_micro': 0.3574008243411208, 'eval_roc_auc_macro': 0.8187634893517992, 'eval_pr_auc_macro': 0.39916426132097976, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4648, 'eval_samples_per_second': 1686.641, 'eval_steps_per_second': 27.967, 'epoch': 0.51}\n",
      "{'loss': 0.3351, 'grad_norm': 1.7890448570251465, 'learning_rate': 4.781745293396896e-06, 'epoch': 0.56}\n",
      "{'loss': 0.3292, 'grad_norm': 3.9480104446411133, 'learning_rate': 4.779570330372927e-06, 'epoch': 0.61}\n",
      "{'loss': 0.3083, 'grad_norm': 4.498034477233887, 'learning_rate': 4.7763091225229575e-06, 'epoch': 0.66}\n",
      "{'loss': 0.3185, 'grad_norm': 1.700005054473877, 'learning_rate': 4.771963153240132e-06, 'epoch': 0.71}\n",
      "{'loss': 0.3208, 'grad_norm': 2.860858201980591, 'learning_rate': 4.766534399332231e-06, 'epoch': 0.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d25cd351894c14adf0c4189350bd52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33998942375183105, 'eval_roc_auc_micro': 0.825020351206406, 'eval_pr_auc_micro': 0.36301993404946, 'eval_roc_auc_macro': 0.822154004671658, 'eval_pr_auc_macro': 0.4070990941352457, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4574, 'eval_samples_per_second': 1714.123, 'eval_steps_per_second': 28.423, 'epoch': 0.77}\n",
      "{'loss': 0.3478, 'grad_norm': 2.1134307384490967, 'learning_rate': 4.7600253301224966e-06, 'epoch': 0.82}\n",
      "{'loss': 0.3099, 'grad_norm': 2.530061960220337, 'learning_rate': 4.752438906326435e-06, 'epoch': 0.87}\n",
      "{'loss': 0.2982, 'grad_norm': 1.7413438558578491, 'learning_rate': 4.743778578705111e-06, 'epoch': 0.92}\n",
      "{'loss': 0.3629, 'grad_norm': 3.0324933528900146, 'learning_rate': 4.734048286495524e-06, 'epoch': 0.97}\n",
      "{'loss': 0.2853, 'grad_norm': 1.7321866750717163, 'learning_rate': 4.72325245561882e-06, 'epoch': 1.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2742cb13183e4274800a8679b8726fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3299958407878876, 'eval_roc_auc_micro': 0.8258272335449031, 'eval_pr_auc_micro': 0.37081370724371787, 'eval_roc_auc_macro': 0.8218725444936966, 'eval_pr_auc_macro': 0.4133084599119852, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4542, 'eval_samples_per_second': 1726.207, 'eval_steps_per_second': 28.623, 'epoch': 1.02}\n",
      "{'train_runtime': 14.9109, 'train_samples_per_second': 3360.769, 'train_steps_per_second': 105.158, 'train_loss': 0.3444568824768066, 'epoch': 1.02}\n",
      "v2b finished.\n",
      "\n",
      "Evaluating v2b on validation set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c43630a0ed64fae9cebbc71c2d8ef7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35538166761398315, 'eval_roc_auc_micro': 0.8300588274074379, 'eval_pr_auc_micro': 0.3761299839182934, 'eval_roc_auc_macro': 0.8264836181627483, 'eval_pr_auc_macro': 0.40825771010644635, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.458, 'eval_samples_per_second': 1711.848, 'eval_steps_per_second': 28.385, 'epoch': 1.0204081632653061}\n",
      "\n",
      "Evaluating v2b on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2d7541ccf040b786d49785b6b492d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_roc_auc_macro so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.39235612750053406, 'test_roc_auc_micro': 0.8224582761573015, 'test_pr_auc_micro': 0.3759112503014855, 'test_roc_auc_macro': 0.801406090910667, 'test_pr_auc_macro': 0.38599566669581353, 'test_macro_valid_labels': 12, 'test_runtime': 0.3567, 'test_samples_per_second': 2195.061, 'test_steps_per_second': 36.444, 'epoch': 1.0204081632653061}\n",
      "\n",
      "Dumping v2b outputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8729ad3ae0ad46d99ab71aa14b5d98c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] val_*_v2b.npy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba574d636ab4f8aba048f3bd09e6988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] test_*_v2b.npy\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 8: Stronger training recipe & retrain v2b ====\n",
    "\n",
    "# Update run_cfg knobs (you can tweak)\n",
    "run_cfg.llrd_enable = True\n",
    "run_cfg.llrd_decay  = 0.90\n",
    "run_cfg.label_smoothing = 0.05\n",
    "run_cfg.learning_rate = 1e-5\n",
    "run_cfg.num_train_epochs = 8\n",
    "run_cfg.use_random_smiles = True   # turn on augmentation\n",
    "run_cfg.random_smiles_per_epoch = 1\n",
    "\n",
    "with open(META_DIR / \"run_cfg_current.json\", \"w\") as f:\n",
    "    json.dump(asdict(run_cfg), f, indent=2)\n",
    "\n",
    "from transformers import TrainingArguments, EarlyStoppingCallback\n",
    "args2 = TrainingArguments(\n",
    "    output_dir=str(CKPT_DIR / \"v2b\"),\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=run_cfg.train_batch_size,\n",
    "    per_device_eval_batch_size=run_cfg.eval_batch_size,\n",
    "    gradient_accumulation_steps=run_cfg.gradient_accumulation_steps,\n",
    "    learning_rate=run_cfg.learning_rate,\n",
    "    weight_decay=run_cfg.weight_decay,\n",
    "    warmup_ratio=run_cfg.warmup_ratio,\n",
    "    num_train_epochs=run_cfg.num_train_epochs,\n",
    "    lr_scheduler_type=run_cfg.lr_schedule,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=run_cfg.eval_steps,\n",
    "    save_steps=run_cfg.eval_steps,\n",
    "    save_total_limit=run_cfg.save_total_limit,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=run_cfg.metric_primary,\n",
    "    greater_is_better=True,\n",
    "    fp16=run_cfg.fp16,\n",
    "    bf16=run_cfg.bfloat16,\n",
    "    gradient_checkpointing=run_cfg.gradient_checkpointing,\n",
    "    max_grad_norm=run_cfg.max_grad_norm,\n",
    "    report_to=[],\n",
    "    dataloader_num_workers=0,\n",
    "    dataloader_pin_memory=True,\n",
    "    disable_tqdm=False,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer2 = V2TrainerFocal(\n",
    "    model=model,  # continue from the end of previous training (already in memory)\n",
    "    args=args2,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    "    pos_weight=POS_WEIGHT,\n",
    "    label_smoothing=run_cfg.label_smoothing,\n",
    "    llrd_enable=run_cfg.llrd_enable,\n",
    "    llrd_decay=run_cfg.llrd_decay,\n",
    "    use_focal=True,\n",
    "    focal_alpha=alpha_vec,\n",
    "    focal_gamma=gamma_vec,\n",
    ")\n",
    "\n",
    "trainer2.compute_metrics = make_compute_metrics(trainer2)\n",
    "trainer2.add_callback(EarlyStoppingCallback(early_stopping_patience=run_cfg.early_stopping_patience))\n",
    "\n",
    "print(\"Starting v2b training...\")\n",
    "train_out2 = trainer2.train()\n",
    "print(\"v2b finished.\")\n",
    "\n",
    "print(\"\\nEvaluating v2b on validation set...\")\n",
    "val_metrics2 = trainer2.evaluate(eval_dataset=val_ds)\n",
    "print(val_metrics2)\n",
    "\n",
    "print(\"\\nEvaluating v2b on test set...\")\n",
    "test_metrics2 = trainer2.evaluate(eval_dataset=test_ds, metric_key_prefix=\"test\")\n",
    "print(test_metrics2)\n",
    "\n",
    "# dump new outputs for calibration\n",
    "def dump_outputs2(tr, ds, prefix):\n",
    "    preds = tr.predict(ds)\n",
    "    logits = preds.predictions if not isinstance(preds.predictions, tuple) else preds.predictions[0]\n",
    "    labels = preds.label_ids\n",
    "    mask   = torch.cat(tr._eval_label_masks, dim=0).numpy().astype(np.float32) if len(tr._eval_label_masks) else np.ones_like(labels, dtype=np.float32)\n",
    "    probs = 1/(1+np.exp(-logits))\n",
    "    np.save(OUT_DIR / f\"{prefix}_logits_v2b.npy\", logits.astype(np.float32))\n",
    "    np.save(OUT_DIR / f\"{prefix}_prob_v2b.npy\",    probs.astype(np.float32))\n",
    "    np.save(OUT_DIR / f\"{prefix}_y_v2b.npy\",       labels.astype(np.float32))\n",
    "    np.save(OUT_DIR / f\"{prefix}_mask_v2b.npy\",    mask.astype(np.float32))\n",
    "    print(f\"[SAVED] {prefix}_*_v2b.npy\")\n",
    "\n",
    "print(\"\\nDumping v2b outputs...\")\n",
    "dump_outputs2(trainer2, val_ds, \"val\")\n",
    "dump_outputs2(trainer2, test_ds, \"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b12cb38",
   "metadata": {},
   "source": [
    "### Results evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b1531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ChemBERTa v2b Summary ===\n",
      "VAL  â†’ AUROC micro=0.8301  macro=0.8265 | PR-AUC micro=0.3761  macro=0.4083  (valid labels=12)\n",
      "TEST â†’ AUROC micro=0.8225  macro=0.8014 | PR-AUC micro=0.3759  macro=0.3860 (valid labels=12)\n",
      "\n",
      "Î” vs v2 baseline:\n",
      "VAL  â†’ Î”AUROC micro=+nan  macro=+nan | Î”PR micro=+nan  macro=+nan\n",
      "TEST â†’ Î”AUROC micro=+0.0005  macro=+0.0023 | Î”PR micro=-0.0100  macro=-0.0036\n",
      "\n",
      "Saved per-label CSVs â†’ implementation\\models\\chemberta_v2\\metrics\\per_label_val_v2b.csv and implementation\\models\\chemberta_v2\\metrics\\per_label_test_v2b.csv\n",
      "\n",
      "Top 3 labels (VAL) by AUROC:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n</th>\n",
       "      <th>auroc</th>\n",
       "      <th>ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>674</td>\n",
       "      <td>0.909263</td>\n",
       "      <td>0.622871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>643</td>\n",
       "      <td>0.877362</td>\n",
       "      <td>0.333659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>577</td>\n",
       "      <td>0.871664</td>\n",
       "      <td>0.377744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label    n     auroc        ap\n",
       "1      NR-AR-LBD  674  0.909263  0.622871\n",
       "6  NR-PPAR-gamma  643  0.877362  0.333659\n",
       "3   NR-Aromatase  577  0.871664  0.377744"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom 3 labels (VAL) by AUROC:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n</th>\n",
       "      <th>auroc</th>\n",
       "      <th>ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>611</td>\n",
       "      <td>0.716998</td>\n",
       "      <td>0.393186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SR-p53</td>\n",
       "      <td>669</td>\n",
       "      <td>0.794638</td>\n",
       "      <td>0.212525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>571</td>\n",
       "      <td>0.800616</td>\n",
       "      <td>0.410317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label    n     auroc        ap\n",
       "4    NR-ER  611  0.716998  0.393186\n",
       "11  SR-p53  669  0.794638  0.212525\n",
       "7   SR-ARE  571  0.800616  0.410317"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 3 labels (TEST) by AUROC:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n</th>\n",
       "      <th>auroc</th>\n",
       "      <th>ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>660</td>\n",
       "      <td>0.881246</td>\n",
       "      <td>0.618427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SR-MMP</td>\n",
       "      <td>592</td>\n",
       "      <td>0.878043</td>\n",
       "      <td>0.562263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>582</td>\n",
       "      <td>0.864191</td>\n",
       "      <td>0.293996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label    n     auroc        ap\n",
       "2         NR-AhR  660  0.881246  0.618427\n",
       "10        SR-MMP  592  0.878043  0.562263\n",
       "3   NR-Aromatase  582  0.864191  0.293996"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom 3 labels (TEST) by AUROC:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n</th>\n",
       "      <th>auroc</th>\n",
       "      <th>ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>636</td>\n",
       "      <td>0.708285</td>\n",
       "      <td>0.417266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>655</td>\n",
       "      <td>0.743549</td>\n",
       "      <td>0.255873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NR-ER-LBD</td>\n",
       "      <td>703</td>\n",
       "      <td>0.756416</td>\n",
       "      <td>0.366228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label    n     auroc        ap\n",
       "4      NR-ER  636  0.708285  0.417266\n",
       "9     SR-HSE  655  0.743549  0.255873\n",
       "5  NR-ER-LBD  703  0.756416  0.366228"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==== Cell 9: v2b summary (val/test) + per-label + delta vs v2 baseline ====\n",
    "import numpy as np, pandas as pd, json\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "OUT_DIR   = Path(\"implementation/models/chemberta_v2/outputs\")\n",
    "META_DIR  = Path(\"implementation/models/chemberta_v2/metadata\")\n",
    "METRICS_DIR = Path(\"implementation/models/chemberta_v2/metrics\")\n",
    "\n",
    "# --- helpers ---\n",
    "def load_split(prefix, suffix=\"\"):\n",
    "    logits = np.load(OUT_DIR / f\"{prefix}_logits{suffix}.npy\")\n",
    "    probs  = 1/(1+np.exp(-logits))\n",
    "    y      = np.load(OUT_DIR / f\"{prefix}_y{suffix}.npy\")\n",
    "    mask   = np.load(OUT_DIR / f\"{prefix}_mask{suffix}.npy\")\n",
    "    return probs, y.astype(int), mask.astype(int)\n",
    "\n",
    "def masked_micro(y, p, m):\n",
    "    y_flat = y[m == 1]\n",
    "    p_flat = p[m == 1]\n",
    "    auc = roc_auc_score(y_flat, p_flat)\n",
    "    ap  = average_precision_score(y_flat, p_flat)\n",
    "    return auc, ap\n",
    "\n",
    "def masked_macro(y, p, m):\n",
    "    aucs, aps = [], []\n",
    "    L = y.shape[1]\n",
    "    valid = 0\n",
    "    for j in range(L):\n",
    "        idx = (m[:, j] == 1)\n",
    "        yj, pj = y[idx, j], p[idx, j]\n",
    "        if len(yj) < 2 or (yj.max()==yj.min()):  # needs both classes\n",
    "            continue\n",
    "        aucs.append(roc_auc_score(yj, pj))\n",
    "        aps.append(average_precision_score(yj, pj))\n",
    "        valid += 1\n",
    "    return (np.mean(aucs) if aucs else np.nan,\n",
    "            np.mean(aps)  if aps  else np.nan,\n",
    "            valid)\n",
    "\n",
    "def per_label_table(y, p, m, labels):\n",
    "    rows = []\n",
    "    for j, name in enumerate(labels):\n",
    "        idx = (m[:, j] == 1)\n",
    "        yj, pj = y[idx, j], p[idx, j]\n",
    "        if len(yj) < 2 or (yj.max()==yj.min()):\n",
    "            rows.append(dict(label=name, n=len(yj), auroc=np.nan, ap=np.nan))\n",
    "            continue\n",
    "        rows.append(dict(label=name,\n",
    "                         n=int(len(yj)),\n",
    "                         auroc=float(roc_auc_score(yj, pj)),\n",
    "                         ap=float(average_precision_score(yj, pj))))\n",
    "    return pd.DataFrame(rows).sort_values(\"label\").reset_index(drop=True)\n",
    "\n",
    "def head_tail(df, k=3):\n",
    "    top = df.sort_values(\"auroc\", ascending=False).head(k)\n",
    "    bot = df.sort_values(\"auroc\", ascending=True).head(k)\n",
    "    return top, bot\n",
    "\n",
    "# --- labels\n",
    "with open(META_DIR / \"labels.json\") as f:\n",
    "    lbl = json.load(f)\n",
    "label_names = [lbl[\"id2label\"][str(i)] for i in range(lbl[\"n_labels\"])]\n",
    "\n",
    "# --- Load v2b\n",
    "p_val,  y_val,  m_val  = load_split(\"val\",  \"_v2b\")\n",
    "p_test, y_test, m_test = load_split(\"test\", \"_v2b\")\n",
    "\n",
    "# --- Summary metrics (v2b)\n",
    "val_micro = masked_micro(y_val, p_val, m_val)\n",
    "val_macro = masked_macro(y_val, p_val, m_val)\n",
    "test_micro = masked_micro(y_test, p_test, m_test)\n",
    "test_macro = masked_macro(y_test, p_test, m_test)\n",
    "\n",
    "print(\"=== ChemBERTa v2b Summary ===\")\n",
    "print(f\"VAL  â†’ AUROC micro={val_micro[0]:.4f}  macro={val_macro[0]:.4f} | PR-AUC micro={val_micro[1]:.4f}  macro={val_macro[1]:.4f}  (valid labels={val_macro[2]})\")\n",
    "print(f\"TEST â†’ AUROC micro={test_micro[0]:.4f}  macro={test_macro[0]:.4f} | PR-AUC micro={test_micro[1]:.4f}  macro={test_macro[1]:.4f} (valid labels={test_macro[2]})\")\n",
    "\n",
    "# --- Delta vs v2 baseline (if baseline metrics JSONs exist)\n",
    "val_base_path  = METRICS_DIR / \"val_metrics.json\"\n",
    "test_base_path = METRICS_DIR / \"test_metrics.json\"\n",
    "if val_base_path.exists() and test_base_path.exists():\n",
    "    with open(val_base_path) as f:  val_json = json.load(f)\n",
    "    with open(test_base_path) as f: test_json = json.load(f)\n",
    "    def fmt(x): return np.nan if x is None else float(x)\n",
    "    base_val = (fmt(val_json.get(\"roc_auc_micro\")), fmt(val_json.get(\"roc_auc_macro\")),\n",
    "                fmt(val_json.get(\"pr_auc_micro\")),  fmt(val_json.get(\"pr_auc_macro\")))\n",
    "    base_test = (fmt(test_json.get(\"test_roc_auc_micro\")), fmt(test_json.get(\"test_roc_auc_macro\")),\n",
    "                 fmt(test_json.get(\"test_pr_auc_micro\")),  fmt(test_json.get(\"test_pr_auc_macro\")))\n",
    "    print(\"\\nÎ” vs v2 baseline:\")\n",
    "    print(f\"VAL  â†’ Î”AUROC micro={val_micro[0]-base_val[0]:+.4f}  macro={val_macro[0]-base_val[1]:+.4f} | Î”PR micro={val_micro[1]-base_val[2]:+.4f}  macro={val_macro[1]-base_val[3]:+.4f}\")\n",
    "    print(f\"TEST â†’ Î”AUROC micro={test_micro[0]-base_test[0]:+.4f}  macro={test_macro[0]-base_test[1]:+.4f} | Î”PR micro={test_micro[1]-base_test[2]:+.4f}  macro={test_macro[1]-base_test[3]:+.4f}\")\n",
    "else:\n",
    "    print(\"\\n(v2 baseline metrics not found â€” skipping deltas)\")\n",
    "\n",
    "# --- Per-label tables + top/bottom\n",
    "val_tbl  = per_label_table(y_val,  p_val,  m_val,  label_names)\n",
    "test_tbl = per_label_table(y_test, p_test, m_test, label_names)\n",
    "\n",
    "# persist CSVs for traceability\n",
    "val_tbl.to_csv(METRICS_DIR / \"per_label_val_v2b.csv\", index=False)\n",
    "test_tbl.to_csv(METRICS_DIR / \"per_label_test_v2b.csv\", index=False)\n",
    "\n",
    "print(f\"\\nSaved per-label CSVs â†’ {METRICS_DIR/'per_label_val_v2b.csv'} and {METRICS_DIR/'per_label_test_v2b.csv'}\")\n",
    "\n",
    "k = 3\n",
    "val_top,  val_bot  = head_tail(val_tbl,  k=k)\n",
    "test_top, test_bot = head_tail(test_tbl, k=k)\n",
    "\n",
    "print(f\"\\nTop {k} labels (VAL) by AUROC:\")\n",
    "display(val_top)\n",
    "print(f\"Bottom {k} labels (VAL) by AUROC:\")\n",
    "display(val_bot)\n",
    "\n",
    "print(f\"\\nTop {k} labels (TEST) by AUROC:\")\n",
    "display(test_top)  \n",
    "print(f\"Bottom {k} labels (TEST) by AUROC:\")\n",
    "display(test_bot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15160b7f",
   "metadata": {},
   "source": [
    "## 8: Targeted Tune v2c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0fe71e",
   "metadata": {},
   "source": [
    "### Targeted knobs (turn off LS; bump hard-label emphasis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc9194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2c knobs set: {'model_name_or_path': 'implementation\\\\models\\\\chemberta_v1', 'output_dir': 'implementation\\\\models\\\\chemberta_v2', 'max_length': 256, 'train_batch_size': 32, 'eval_batch_size': 64, 'gradient_accumulation_steps': 1, 'num_train_epochs': 10, 'learning_rate': 1e-05, 'weight_decay': 0.01, 'warmup_ratio': 0.06, 'lr_schedule': 'cosine', 'fp16': True, 'bfloat16': False, 'gradient_checkpointing': True, 'max_grad_norm': 1.0, 'llrd_enable': True, 'llrd_decay': 0.85, 'label_smoothing': 0.0, 'use_random_smiles': True, 'random_smiles_per_epoch': 1, 'save_total_limit': 3, 'eval_steps': 50, 'logging_steps': 50, 'early_stopping_patience': 3, 'metric_primary': 'roc_auc_macro'}\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import asdict\n",
    "import json\n",
    "\n",
    "# Turn OFF label smoothing (often hurts PR-AUC on imbalanced multilabel)\n",
    "run_cfg.label_smoothing = 0.0\n",
    "\n",
    "# Keep LLRD; slightly stronger decay to emphasize top layers\n",
    "run_cfg.llrd_enable = True\n",
    "run_cfg.llrd_decay  = 0.85\n",
    "\n",
    "# Keep LR conservative; a touch more epochs for ASL to settle\n",
    "run_cfg.learning_rate = 1e-5\n",
    "run_cfg.num_train_epochs = 10\n",
    "\n",
    "# Optional: keep random SMILES on; it helped generalization\n",
    "run_cfg.use_random_smiles = True\n",
    "run_cfg.random_smiles_per_epoch = 1\n",
    "\n",
    "with open(META_DIR / \"run_cfg_current.json\", \"w\") as f:\n",
    "    json.dump(asdict(run_cfg), f, indent=2)\n",
    "\n",
    "print(\"v2c knobs set:\", asdict(run_cfg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5061cbf9",
   "metadata": {},
   "source": [
    "### ASL loss + WeightedRandomSampler (focus on rare positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2100a03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASL + WeightedRandomSampler ready.\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# --- Per-label emphasis for sampling (tuneable) ---\n",
    "# Heavier weights for labels that underperform\n",
    "HARD_LABEL_WEIGHTS = {\n",
    "    \"NR-ER\": 4.0,\n",
    "    \"SR-HSE\": 3.0,\n",
    "    \"NR-ER-LBD\": 2.0,\n",
    "}\n",
    "base_weight = 1.0\n",
    "\n",
    "# Build per-sample weights from TRAIN split\n",
    "w = np.full(len(train_ds), base_weight, dtype=np.float32)\n",
    "df_tr = train_ds.df\n",
    "for lbl, mult in HARD_LABEL_WEIGHTS.items():\n",
    "    if lbl in df_tr.columns:\n",
    "        w += (df_tr[lbl].fillna(0).values.astype(np.float32) > 0) * float(mult)\n",
    "\n",
    "# Normalize (optional)\n",
    "w = w / w.mean()\n",
    "SAMPLE_WEIGHTS = torch.tensor(w, dtype=torch.float32)\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=SAMPLE_WEIGHTS,\n",
    "    num_samples=len(train_ds),  # 1 epoch ~= full dataset size\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "# --- ASL (Asymmetric Focal Loss) ---\n",
    "class ASLWithMask(nn.Module):\n",
    "    \"\"\"\n",
    "    Asymmetric Loss for Multi-Label Classification, mask-aware.\n",
    "    - Separate focusing for positives (gamma_pos) and negatives (gamma_neg)\n",
    "    - Optional probability clip for negatives (to reduce easy-negative dominance)\n",
    "    - Optional class alpha (positive prior) vector\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma_pos=2.0, gamma_neg=1.0, clip=0.05, alpha=None, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.gamma_pos = float(gamma_pos)\n",
    "        self.gamma_neg = float(gamma_neg)\n",
    "        self.clip = float(clip) if clip is not None else 0.0\n",
    "        self.register_buffer(\"alpha\", alpha.view(1, -1) if alpha is not None else None)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, logits: torch.Tensor, targets: torch.Tensor, mask: torch.Tensor):\n",
    "        # probabilities\n",
    "        p = torch.sigmoid(logits)\n",
    "\n",
    "        # optional clip on negatives\n",
    "        if self.clip > 0:\n",
    "            p_neg = (p - self.clip).clamp_min(0.0)\n",
    "        else:\n",
    "            p_neg = p\n",
    "\n",
    "        # positive/negative losses (log-prob form for stability)\n",
    "        pos_loss = -torch.log(p.clamp_min(self.eps)) * (1 - p).pow(self.gamma_pos) * targets\n",
    "        neg_loss = -torch.log((1 - p_neg).clamp_min(self.eps)) * (p_neg).pow(self.gamma_neg) * (1 - targets)\n",
    "\n",
    "        # optional alpha to balance positives per label (applies to pos term)\n",
    "        if self.alpha is not None:\n",
    "            pos_loss = pos_loss * self.alpha\n",
    "\n",
    "        loss = pos_loss + neg_loss\n",
    "\n",
    "        # apply label mask and average\n",
    "        loss = (loss * mask).sum() / (mask.sum() + 1e-8)\n",
    "        return loss\n",
    "\n",
    "# Build alpha from TRAIN prevalence (inverse prevalence; clipped)\n",
    "alpha_vec_asl = []\n",
    "for c in label_names:\n",
    "    col = df_tr[c]\n",
    "    pos_rate = (col == 1).sum() / max(1, col.notna().sum())\n",
    "    if pos_rate == 0 or np.isnan(pos_rate):\n",
    "        a = 0.5\n",
    "    else:\n",
    "        a = float(np.clip(1.0 - pos_rate, 0.25, 0.75))\n",
    "    alpha_vec_asl.append(a)\n",
    "alpha_vec_asl = torch.tensor(alpha_vec_asl, dtype=torch.float32)\n",
    "\n",
    "# Trainer subclass using ASL + sampler\n",
    "class V2TrainerASL(V2Trainer):\n",
    "    def __init__(self, *args, gamma_pos=2.0, gamma_neg=1.0, clip=0.05, alpha_vec=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.asl = ASLWithMask(gamma_pos=gamma_pos, gamma_neg=gamma_neg, clip=clip, alpha=alpha_vec.to(DEVICE))\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        label_mask = inputs.pop(\"label_mask\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # No label smoothing for ASL (we turned it off in Cell 10)\n",
    "        loss = self.asl(logits, labels, label_mask)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    # use weighted sampler\n",
    "    def get_train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.args.train_batch_size,\n",
    "            sampler=sampler,\n",
    "            collate_fn=self.data_collator,\n",
    "            num_workers=0,              # Windows-safe\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "print(\"ASL + WeightedRandomSampler ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1786dd2a",
   "metadata": {},
   "source": [
    "### Train v2c with ASL + sampler (and LLRD), then dump outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df27d922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting v2c (ASL + sampler)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a176537b0fdb446fb71484a1d478adc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2003, 'grad_norm': 2.632017135620117, 'learning_rate': 2.7167549854343213e-07, 'epoch': 0.05}\n",
      "{'loss': 0.1929, 'grad_norm': 2.4239554405212402, 'learning_rate': 5.433509970868643e-07, 'epoch': 0.1}\n",
      "{'loss': 0.1566, 'grad_norm': 2.040797233581543, 'learning_rate': 8.150264956302964e-07, 'epoch': 0.15}\n",
      "{'loss': 0.1407, 'grad_norm': 1.101197600364685, 'learning_rate': 1.0867019941737285e-06, 'epoch': 0.2}\n",
      "{'loss': 0.1084, 'grad_norm': 0.8160191178321838, 'learning_rate': 1.3583774927171606e-06, 'epoch': 0.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0a3a67d6b24aa78243cf3197149e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08435676246881485, 'eval_roc_auc_micro': 0.8178243366032212, 'eval_pr_auc_micro': 0.3678725740952498, 'eval_roc_auc_macro': 0.813634473185412, 'eval_pr_auc_macro': 0.3918986075404396, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4653, 'eval_samples_per_second': 1684.936, 'eval_steps_per_second': 27.939, 'epoch': 0.26}\n",
      "{'loss': 0.1065, 'grad_norm': 0.49265676736831665, 'learning_rate': 1.6300529912605928e-06, 'epoch': 0.31}\n",
      "{'loss': 0.1205, 'grad_norm': 0.8886138200759888, 'learning_rate': 1.901728489804025e-06, 'epoch': 0.36}\n",
      "{'loss': 0.1095, 'grad_norm': 0.7977358102798462, 'learning_rate': 2.173403988347457e-06, 'epoch': 0.41}\n",
      "{'loss': 0.1021, 'grad_norm': 0.5369810461997986, 'learning_rate': 2.4450794868908894e-06, 'epoch': 0.46}\n",
      "{'loss': 0.1032, 'grad_norm': 0.476547509431839, 'learning_rate': 2.7167549854343213e-06, 'epoch': 0.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed4ca4dfb234a5b882c49dd99a81c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0753212571144104, 'eval_roc_auc_micro': 0.8200462488331497, 'eval_pr_auc_micro': 0.37619552636691805, 'eval_roc_auc_macro': 0.8058518647637732, 'eval_pr_auc_macro': 0.38307802228722493, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4447, 'eval_samples_per_second': 1763.097, 'eval_steps_per_second': 29.235, 'epoch': 0.51}\n",
      "{'loss': 0.0939, 'grad_norm': 0.5245117545127869, 'learning_rate': 2.9884304839777536e-06, 'epoch': 0.56}\n",
      "{'loss': 0.1038, 'grad_norm': 0.4236505627632141, 'learning_rate': 3.2057615577327945e-06, 'epoch': 0.61}\n",
      "{'loss': 0.0983, 'grad_norm': 0.6693574786186218, 'learning_rate': 3.20543519133556e-06, 'epoch': 0.66}\n",
      "{'loss': 0.094, 'grad_norm': 0.6144261360168457, 'learning_rate': 3.204642679448129e-06, 'epoch': 0.71}\n",
      "{'loss': 0.0901, 'grad_norm': 0.5966107249259949, 'learning_rate': 3.2033842525942908e-06, 'epoch': 0.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d2292a9b1e46ba8038ddd20b6de768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07021787017583847, 'eval_roc_auc_micro': 0.8240836463246963, 'eval_pr_auc_micro': 0.38408333070245176, 'eval_roc_auc_macro': 0.8079159924355119, 'eval_pr_auc_macro': 0.39109941093631256, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4466, 'eval_samples_per_second': 1755.649, 'eval_steps_per_second': 29.112, 'epoch': 0.77}\n",
      "{'loss': 0.1021, 'grad_norm': 0.41833361983299255, 'learning_rate': 3.2016602768219672e-06, 'epoch': 0.82}\n",
      "{'loss': 0.0948, 'grad_norm': 0.44745972752571106, 'learning_rate': 3.199471253596731e-06, 'epoch': 0.87}\n",
      "{'loss': 0.0927, 'grad_norm': 0.605241060256958, 'learning_rate': 3.196817819655949e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0888, 'grad_norm': 0.5265015363693237, 'learning_rate': 3.193700746823561e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:57:38] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0926, 'grad_norm': 0.3700205981731415, 'learning_rate': 3.1901209417855813e-06, 'epoch': 1.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2023b236bb54c4b8bc912db79f4439e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06987837702035904, 'eval_roc_auc_micro': 0.8229851111338297, 'eval_pr_auc_micro': 0.3781497482435438, 'eval_roc_auc_macro': 0.8074453555034783, 'eval_pr_auc_macro': 0.39054338870804917, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4447, 'eval_samples_per_second': 1763.176, 'eval_steps_per_second': 29.236, 'epoch': 1.02}\n",
      "{'train_runtime': 14.6723, 'train_samples_per_second': 4269.266, 'train_steps_per_second': 133.585, 'train_loss': 0.11458823561668396, 'epoch': 1.02}\n",
      "v2c finished.\n",
      "\n",
      "Evaluating v2c on validation set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63159beb30764fab832c591c608dd8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08435676246881485, 'eval_roc_auc_micro': 0.8178243366032212, 'eval_pr_auc_micro': 0.3678725740952498, 'eval_roc_auc_macro': 0.813634473185412, 'eval_pr_auc_macro': 0.3918986075404396, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.45, 'eval_samples_per_second': 1742.404, 'eval_steps_per_second': 28.892, 'epoch': 1.0204081632653061}\n",
      "\n",
      "Evaluating v2c on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9762a73fb47349fc9557567261aa9fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_roc_auc_macro so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.07924722880125046, 'test_roc_auc_micro': 0.8181962867832471, 'test_pr_auc_micro': 0.39025000670892873, 'test_roc_auc_macro': 0.792021447056149, 'test_pr_auc_macro': 0.3845921562980783, 'test_macro_valid_labels': 12, 'test_runtime': 0.3647, 'test_samples_per_second': 2147.232, 'test_steps_per_second': 35.65, 'epoch': 1.0204081632653061}\n",
      "\n",
      "Dumping v2c outputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebdcbefd6f247a2bcc67c2cfccc09c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] val_*_v2c.npy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a8113b5f5341849c8aced3b1a04ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] test_*_v2c.npy\n"
     ]
    }
   ],
   "source": [
    "import json, numpy as np, torch\n",
    "from transformers import TrainingArguments, EarlyStoppingCallback\n",
    "\n",
    "args3 = TrainingArguments(\n",
    "    output_dir=str(CKPT_DIR / \"v2c\"),\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=run_cfg.train_batch_size,\n",
    "    per_device_eval_batch_size=run_cfg.eval_batch_size,\n",
    "    gradient_accumulation_steps=run_cfg.gradient_accumulation_steps,\n",
    "    learning_rate=run_cfg.learning_rate,\n",
    "    weight_decay=run_cfg.weight_decay,\n",
    "    warmup_ratio=run_cfg.warmup_ratio,\n",
    "    num_train_epochs=run_cfg.num_train_epochs,\n",
    "    lr_scheduler_type=run_cfg.lr_schedule,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=run_cfg.eval_steps,\n",
    "    save_steps=run_cfg.eval_steps,\n",
    "    save_total_limit=run_cfg.save_total_limit,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=run_cfg.metric_primary,\n",
    "    greater_is_better=True,\n",
    "    fp16=run_cfg.fp16,\n",
    "    bf16=run_cfg.bfloat16,\n",
    "    gradient_checkpointing=run_cfg.gradient_checkpointing,\n",
    "    max_grad_norm=run_cfg.max_grad_norm,\n",
    "    report_to=[],\n",
    "    dataloader_num_workers=0,\n",
    "    dataloader_pin_memory=True,\n",
    "    disable_tqdm=False,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer3 = V2TrainerASL(\n",
    "    model=model,  # continue from v2b weights in memory\n",
    "    args=args3,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    "    pos_weight=None,                 # not used in ASL\n",
    "    label_smoothing=0.0,            # off\n",
    "    llrd_enable=run_cfg.llrd_enable,\n",
    "    llrd_decay=run_cfg.llrd_decay,\n",
    "    gamma_pos=2.0,                  # you can bump to 2.2 if NR-ER still lags\n",
    "    gamma_neg=1.0,\n",
    "    clip=0.05,\n",
    "    alpha_vec=alpha_vec_asl,\n",
    ")\n",
    "\n",
    "trainer3.compute_metrics = make_compute_metrics(trainer3)\n",
    "trainer3.add_callback(EarlyStoppingCallback(early_stopping_patience=run_cfg.early_stopping_patience))\n",
    "\n",
    "print(\"Starting v2c (ASL + sampler)...\")\n",
    "train_out3 = trainer3.train()\n",
    "print(\"v2c finished.\")\n",
    "\n",
    "print(\"\\nEvaluating v2c on validation set...\")\n",
    "val_metrics3 = trainer3.evaluate(eval_dataset=val_ds)\n",
    "print(val_metrics3)\n",
    "\n",
    "print(\"\\nEvaluating v2c on test set...\")\n",
    "test_metrics3 = trainer3.evaluate(eval_dataset=test_ds, metric_key_prefix=\"test\")\n",
    "print(test_metrics3)\n",
    "\n",
    "# Dump outputs for v2c (suffix _v2c)\n",
    "def dump_outputs3(tr, ds, prefix):\n",
    "    preds = tr.predict(ds)\n",
    "    logits = preds.predictions if not isinstance(preds.predictions, tuple) else preds.predictions[0]\n",
    "    labels = preds.label_ids\n",
    "    mask   = torch.cat(tr._eval_label_masks, dim=0).numpy().astype(np.float32) if len(tr._eval_label_masks) else np.ones_like(labels, dtype=np.float32)\n",
    "    probs = 1/(1+np.exp(-logits))\n",
    "    np.save(OUT_DIR / f\"{prefix}_logits_v2c.npy\", logits.astype(np.float32))\n",
    "    np.save(OUT_DIR / f\"{prefix}_prob_v2c.npy\",    probs.astype(np.float32))\n",
    "    np.save(OUT_DIR / f\"{prefix}_y_v2c.npy\",       labels.astype(np.float32))\n",
    "    np.save(OUT_DIR / f\"{prefix}_mask_v2c.npy\",    mask.astype(np.float32))\n",
    "    print(f\"[SAVED] {prefix}_*_v2c.npy\")\n",
    "\n",
    "print(\"\\nDumping v2c outputs...\")\n",
    "dump_outputs3(trainer3, val_ds, \"val\")\n",
    "dump_outputs3(trainer3, test_ds, \"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ec6f9f",
   "metadata": {},
   "source": [
    "### Quick v2c summary & deltas vs v2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e54b094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ChemBERTa v2c (ASL+sampler) Summary ===\n",
      "VAL  â†’ AUROC micro=0.8178  macro=0.8136 | PR-AUC micro=0.3679  macro=0.3919 (valid=12)\n",
      "TEST â†’ AUROC micro=0.8182  macro=0.7920 | PR-AUC micro=0.3903  macro=0.3846 (valid=12)\n",
      "\n",
      "Î” vs v2b:\n",
      "VAL  â†’ Î”AUROC micro=-0.0122  macro=-0.0128 | Î”PR micro=-0.0083  macro=-0.0164\n",
      "TEST â†’ Î”AUROC micro=-0.0043  macro=-0.0094 | Î”PR micro=+0.0143  macro=-0.0014\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, json\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "OUT_DIR   = Path(\"implementation/models/chemberta_v2/outputs\")\n",
    "META_DIR  = Path(\"implementation/models/chemberta_v2/metadata\")\n",
    "METRICS_DIR = Path(\"implementation/models/chemberta_v2/metrics\")\n",
    "\n",
    "def load_split(prefix, suffix):\n",
    "    logits = np.load(OUT_DIR / f\"{prefix}_logits{suffix}.npy\")\n",
    "    probs  = 1/(1+np.exp(-logits))\n",
    "    y      = np.load(OUT_DIR / f\"{prefix}_y{suffix}.npy\").astype(int)\n",
    "    mask   = np.load(OUT_DIR / f\"{prefix}_mask{suffix}.npy\").astype(int)\n",
    "    return probs, y, mask\n",
    "\n",
    "def masked_micro(y, p, m):\n",
    "    y_flat = y[m==1]; p_flat = p[m==1]\n",
    "    return (roc_auc_score(y_flat, p_flat), average_precision_score(y_flat, p_flat))\n",
    "\n",
    "def masked_macro(y, p, m):\n",
    "    aucs, aps = [], []\n",
    "    L = y.shape[1]\n",
    "    valid = 0\n",
    "    for j in range(L):\n",
    "        idx = m[:,j]==1\n",
    "        yj, pj = y[idx,j], p[idx,j]\n",
    "        if len(yj)<2 or (yj.max()==yj.min()): continue\n",
    "        aucs.append(roc_auc_score(yj,pj)); aps.append(average_precision_score(yj,pj))\n",
    "        valid += 1\n",
    "    return (np.mean(aucs), np.mean(aps), valid)\n",
    "\n",
    "# labels\n",
    "with open(META_DIR / \"labels.json\") as f:\n",
    "    lbl = json.load(f)\n",
    "label_names = [lbl[\"id2label\"][str(i)] for i in range(lbl[\"n_labels\"])]\n",
    "\n",
    "# v2c\n",
    "pv_val, yv_val, mv_val = load_split(\"val\",  \"_v2c\")\n",
    "pv_te,  yv_te,  mv_te  = load_split(\"test\", \"_v2c\")\n",
    "val_micro = masked_micro(yv_val, pv_val, mv_val)\n",
    "val_macro = masked_macro(yv_val, pv_val, mv_val)\n",
    "test_micro = masked_micro(yv_te,  pv_te,  mv_te)\n",
    "test_macro = masked_macro(yv_te,  pv_te,  mv_te)\n",
    "\n",
    "print(\"=== ChemBERTa v2c (ASL+sampler) Summary ===\")\n",
    "print(f\"VAL  â†’ AUROC micro={val_micro[0]:.4f}  macro={val_macro[0]:.4f} | PR-AUC micro={val_micro[1]:.4f}  macro={val_macro[1]:.4f} (valid={val_macro[2]})\")\n",
    "print(f\"TEST â†’ AUROC micro={test_micro[0]:.4f}  macro={test_macro[0]:.4f} | PR-AUC micro={test_micro[1]:.4f}  macro={test_macro[1]:.4f} (valid={test_macro[2]})\")\n",
    "\n",
    "# deltas vs v2b if present\n",
    "try:\n",
    "    pb_val, yb_val, mb_val = load_split(\"val\",  \"_v2b\")\n",
    "    pb_te,  yb_te,  mb_te  = load_split(\"test\", \"_v2b\")\n",
    "    vb_micro = masked_micro(yb_val, pb_val, mb_val)\n",
    "    vb_macro = masked_macro(yb_val, pb_val, mb_val)\n",
    "    tb_micro = masked_micro(yb_te,  pb_te,  mb_te)\n",
    "    tb_macro = masked_macro(yb_te,  pb_te,  mb_te)\n",
    "    print(\"\\nÎ” vs v2b:\")\n",
    "    print(f\"VAL  â†’ Î”AUROC micro={val_micro[0]-vb_micro[0]:+.4f}  macro={val_macro[0]-vb_macro[0]:+.4f} | Î”PR micro={val_micro[1]-vb_micro[1]:+.4f}  macro={val_macro[1]-vb_macro[1]:+.4f}\")\n",
    "    print(f\"TEST â†’ Î”AUROC micro={test_micro[0]-tb_micro[0]:+.4f}  macro={test_macro[0]-tb_macro[0]:+.4f} | Î”PR micro={test_micro[1]-tb_micro[1]:+.4f}  macro={test_macro[1]-tb_macro[1]:+.4f}\")\n",
    "except Exception as e:\n",
    "    print(\"\\n(v2b outputs not found for delta; skipping)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8165e305",
   "metadata": {},
   "source": [
    "## 9: Further improvements v2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb4e79",
   "metadata": {},
   "source": [
    "### Randomized HPO (fast trials on VAL PR-AUC macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b625bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 1] cfg={'loss': 'asl', 'learning_rate': 5e-06, 'weight_decay': 0.0, 'warmup_ratio': 0.1, 'batch_size': 32, 'max_length': 128, 'label_smoothing': 0.0, 'llrd_enable': False, 'llrd_decay': 0.95, 'augment': False, 'gamma_pos': 2.0, 'gamma_neg': 1.0, 'clip': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffff3565ef954eb1bce7f69c2e9a465c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2068, 'grad_norm': 1.2781728506088257, 'learning_rate': 8.474576271186441e-07, 'epoch': 0.05}\n",
      "{'loss': 0.2036, 'grad_norm': 1.2967710494995117, 'learning_rate': 1.6949152542372882e-06, 'epoch': 0.1}\n",
      "{'loss': 0.1692, 'grad_norm': 1.0536091327667236, 'learning_rate': 2.5423728813559323e-06, 'epoch': 0.15}\n",
      "{'loss': 0.1411, 'grad_norm': 0.6651315689086914, 'learning_rate': 3.3898305084745763e-06, 'epoch': 0.2}\n",
      "{'loss': 0.1205, 'grad_norm': 0.49128037691116333, 'learning_rate': 4.23728813559322e-06, 'epoch': 0.26}\n",
      "{'loss': 0.1067, 'grad_norm': 0.3164961040019989, 'learning_rate': 4.999955914361218e-06, 'epoch': 0.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78489ec430f44f9396dc158988a78f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07534877210855484, 'eval_roc_auc_micro': 0.7885882282125048, 'eval_pr_auc_micro': 0.2798177621583246, 'eval_roc_auc_macro': 0.7756032992222285, 'eval_pr_auc_macro': 0.29903620443892726, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3574, 'eval_samples_per_second': 2193.922, 'eval_steps_per_second': 36.379, 'epoch': 0.33}\n",
      "{'loss': 0.1181, 'grad_norm': 0.3952575922012329, 'learning_rate': 4.9946675187988104e-06, 'epoch': 0.36}\n",
      "{'loss': 0.1052, 'grad_norm': 0.3876678943634033, 'learning_rate': 4.980583362063697e-06, 'epoch': 0.41}\n",
      "{'loss': 0.1037, 'grad_norm': 0.33647778630256653, 'learning_rate': 4.957753102428184e-06, 'epoch': 0.46}\n",
      "{'loss': 0.1046, 'grad_norm': 0.4038802981376648, 'learning_rate': 4.926257235393077e-06, 'epoch': 0.51}\n",
      "{'loss': 0.0973, 'grad_norm': 0.32396626472473145, 'learning_rate': 4.8862068098746246e-06, 'epoch': 0.56}\n",
      "{'loss': 0.1075, 'grad_norm': 0.39712944626808167, 'learning_rate': 4.837743036665477e-06, 'epoch': 0.61}\n",
      "{'loss': 0.1018, 'grad_norm': 0.4229896664619446, 'learning_rate': 4.781036790550134e-06, 'epoch': 0.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b274770a7e8d47cfb7aa799b0b30c0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07464053481817245, 'eval_roc_auc_micro': 0.8112880641607613, 'eval_pr_auc_micro': 0.33246122719959004, 'eval_roc_auc_macro': 0.7940254732913248, 'eval_pr_auc_macro': 0.34659060050209445, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3453, 'eval_samples_per_second': 2270.783, 'eval_steps_per_second': 37.653, 'epoch': 0.66}\n",
      "{'loss': 0.1006, 'grad_norm': 0.37589171528816223, 'learning_rate': 4.716288007830357e-06, 'epoch': 0.71}\n",
      "{'loss': 0.0971, 'grad_norm': 0.4139067232608795, 'learning_rate': 4.6437249813847495e-06, 'epoch': 0.77}\n",
      "{'loss': 0.1024, 'grad_norm': 0.35268038511276245, 'learning_rate': 4.563603555748015e-06, 'epoch': 0.82}\n",
      "{'loss': 0.1004, 'grad_norm': 0.390546053647995, 'learning_rate': 4.476206225047889e-06, 'epoch': 0.87}\n",
      "{'loss': 0.101, 'grad_norm': 0.45121634006500244, 'learning_rate': 4.38184113698028e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0911, 'grad_norm': 0.3511559069156647, 'learning_rate': 4.280841006334403e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9fbbbe731e74bec94bcb5226b9275b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07161368429660797, 'eval_roc_auc_micro': 0.8205789153857987, 'eval_pr_auc_micro': 0.3551567273505325, 'eval_roc_auc_macro': 0.8022049038218076, 'eval_pr_auc_macro': 0.37527232221186413, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.351, 'eval_samples_per_second': 2233.81, 'eval_steps_per_second': 37.04, 'epoch': 0.99}\n",
      "{'loss': 0.092, 'grad_norm': 0.29313233494758606, 'learning_rate': 4.173561941898656e-06, 'epoch': 1.02}\n",
      "{'loss': 0.098, 'grad_norm': 0.36861470341682434, 'learning_rate': 4.0603821908833386e-06, 'epoch': 1.07}\n",
      "{'loss': 0.0893, 'grad_norm': 0.5592856407165527, 'learning_rate': 3.941700805287168e-06, 'epoch': 1.12}\n",
      "{'loss': 0.0952, 'grad_norm': 0.4476100504398346, 'learning_rate': 3.817936234909763e-06, 'epoch': 1.17}\n",
      "{'loss': 0.0972, 'grad_norm': 0.4539039731025696, 'learning_rate': 3.6895248519708552e-06, 'epoch': 1.22}\n",
      "{'loss': 0.0918, 'grad_norm': 0.26031556725502014, 'learning_rate': 3.5569194125382122e-06, 'epoch': 1.28}\n",
      "{'loss': 0.0961, 'grad_norm': 0.3514987826347351, 'learning_rate': 3.4205874601889465e-06, 'epoch': 1.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d122d5faddc144b8b517922e4f4628e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07054416835308075, 'eval_roc_auc_micro': 0.8240574907249137, 'eval_pr_auc_micro': 0.370362819755599, 'eval_roc_auc_macro': 0.807796297359063, 'eval_pr_auc_macro': 0.38762627308284264, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.34, 'eval_samples_per_second': 2305.723, 'eval_steps_per_second': 38.233, 'epoch': 1.33}\n",
      "{'loss': 0.0918, 'grad_norm': 0.3583292067050934, 'learning_rate': 3.2810096775326807e-06, 'epoch': 1.38}\n",
      "{'loss': 0.0889, 'grad_norm': 0.34692177176475525, 'learning_rate': 3.1386781914087644e-06, 'epoch': 1.43}\n",
      "{'loss': 0.0934, 'grad_norm': 0.3012702465057373, 'learning_rate': 2.9940948377331545e-06, 'epoch': 1.48}\n",
      "{'loss': 0.0929, 'grad_norm': 0.3520547151565552, 'learning_rate': 2.847769392112779e-06, 'epoch': 1.53}\n",
      "{'loss': 0.0923, 'grad_norm': 0.5159593224525452, 'learning_rate': 2.700217772465946e-06, 'epoch': 1.58}\n",
      "{'loss': 0.0868, 'grad_norm': 0.3591775894165039, 'learning_rate': 2.551960219986031e-06, 'epoch': 1.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08af13bd17f44c0b1f394fcfaf35224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0684095174074173, 'eval_roc_auc_micro': 0.827274390634241, 'eval_pr_auc_micro': 0.37393662499863045, 'eval_roc_auc_macro': 0.8095748699919506, 'eval_pr_auc_macro': 0.3931741120743659, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3527, 'eval_samples_per_second': 2222.577, 'eval_steps_per_second': 36.854, 'epoch': 1.66}\n",
      "{'loss': 0.0863, 'grad_norm': 0.2854832410812378, 'learning_rate': 2.4035194648620625e-06, 'epoch': 1.68}\n",
      "{'loss': 0.0923, 'grad_norm': 0.44905757904052734, 'learning_rate': 2.2554188832235363e-06, 'epoch': 1.73}\n",
      "{'loss': 0.0898, 'grad_norm': 0.3568965792655945, 'learning_rate': 2.1081806518077575e-06, 'epoch': 1.79}\n",
      "{'loss': 0.088, 'grad_norm': 0.4772495627403259, 'learning_rate': 1.9623239068560373e-06, 'epoch': 1.84}\n",
      "{'loss': 0.0915, 'grad_norm': 0.45554426312446594, 'learning_rate': 1.818362913730133e-06, 'epoch': 1.89}\n",
      "{'loss': 0.0895, 'grad_norm': 0.5670253038406372, 'learning_rate': 1.6768052537025697e-06, 'epoch': 1.94}\n",
      "{'loss': 0.0951, 'grad_norm': 0.4885518252849579, 'learning_rate': 1.5381500343138877e-06, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573df2d46d14410884903c3889836370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06880511343479156, 'eval_roc_auc_micro': 0.8290223968370594, 'eval_pr_auc_micro': 0.37923405145427447, 'eval_roc_auc_macro': 0.8125332375078992, 'eval_pr_auc_macro': 0.39728824657731304, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3486, 'eval_samples_per_second': 2248.678, 'eval_steps_per_second': 37.287, 'epoch': 1.99}\n",
      "{'loss': 0.0978, 'grad_norm': 0.3371701240539551, 'learning_rate': 1.4028861296067802e-06, 'epoch': 2.04}\n",
      "{'loss': 0.0913, 'grad_norm': 0.2902781069278717, 'learning_rate': 1.2714904564417623e-06, 'epoch': 2.09}\n",
      "{'loss': 0.0883, 'grad_norm': 0.3741152286529541, 'learning_rate': 1.1444262929717627e-06, 'epoch': 2.14}\n",
      "{'loss': 0.0936, 'grad_norm': 0.5421854853630066, 'learning_rate': 1.0221416452044237e-06, 'epoch': 2.19}\n",
      "{'loss': 0.0819, 'grad_norm': 0.3089121878147125, 'learning_rate': 9.050676674113071e-07, 'epoch': 2.24}\n",
      "{'loss': 0.0992, 'grad_norm': 0.35272493958473206, 'learning_rate': 7.936171419533653e-07, 'epoch': 2.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97329b02fa848b0a8aa79bcfc257916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06877640634775162, 'eval_roc_auc_micro': 0.8314369528224639, 'eval_pr_auc_micro': 0.3838198950214917, 'eval_roc_auc_macro': 0.8147758372724865, 'eval_pr_auc_macro': 0.398820489012998, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3477, 'eval_samples_per_second': 2254.891, 'eval_steps_per_second': 37.39, 'epoch': 2.32}\n",
      "{'loss': 0.088, 'grad_norm': 0.43915873765945435, 'learning_rate': 6.881830238825699e-07, 'epoch': 2.35}\n",
      "{'loss': 0.089, 'grad_norm': 0.48133981227874756, 'learning_rate': 5.891370554511519e-07, 'epoch': 2.4}\n",
      "{'loss': 0.0889, 'grad_norm': 0.3496638536453247, 'learning_rate': 4.968284554134653e-07, 'epoch': 2.45}\n",
      "{'loss': 0.085, 'grad_norm': 0.3341969847679138, 'learning_rate': 4.115826877417631e-07, 'epoch': 2.5}\n",
      "{'loss': 0.0873, 'grad_norm': 0.35611292719841003, 'learning_rate': 3.3370031409717755e-07, 'epoch': 2.55}\n",
      "{'loss': 0.0914, 'grad_norm': 0.43154242634773254, 'learning_rate': 2.634559341018947e-07, 'epoch': 2.6}\n",
      "{'loss': 0.0872, 'grad_norm': 0.403942346572876, 'learning_rate': 2.0109721714893283e-07, 'epoch': 2.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60bc95f93c5d4d47adf5a863ee91bd1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06838088482618332, 'eval_roc_auc_micro': 0.8310225239126675, 'eval_pr_auc_micro': 0.38316150437072427, 'eval_roc_auc_macro': 0.814825774227366, 'eval_pr_auc_macro': 0.39984044057920687, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3542, 'eval_samples_per_second': 2213.48, 'eval_steps_per_second': 36.703, 'epoch': 2.65}\n",
      "{'loss': 0.0997, 'grad_norm': 0.6122041940689087, 'learning_rate': 1.468440291631984e-07, 'epoch': 2.7}\n",
      "{'loss': 0.0848, 'grad_norm': 0.2933502793312073, 'learning_rate': 1.0088765739270479e-07, 'epoch': 2.76}\n",
      "{'loss': 0.0899, 'grad_norm': 0.5001567006111145, 'learning_rate': 6.339013596320692e-08, 'epoch': 2.81}\n",
      "{'loss': 0.0891, 'grad_norm': 0.46312215924263, 'learning_rate': 3.448367457422497e-08, 'epoch': 2.86}\n",
      "{'loss': 0.0924, 'grad_norm': 0.39496850967407227, 'learning_rate': 1.4270192350775703e-08, 'epoch': 2.91}\n",
      "{'loss': 0.088, 'grad_norm': 0.4660615622997284, 'learning_rate': 2.820958494373083e-09, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22080b9281244905877f2bc9c4a88f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06848151236772537, 'eval_roc_auc_micro': 0.8312925595798287, 'eval_pr_auc_micro': 0.3840257925548896, 'eval_roc_auc_macro': 0.8150552904477685, 'eval_pr_auc_macro': 0.40023350945124253, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.345, 'eval_samples_per_second': 2272.366, 'eval_steps_per_second': 37.68, 'epoch': 2.98}\n",
      "{'train_runtime': 31.7289, 'train_samples_per_second': 592.267, 'train_steps_per_second': 18.532, 'train_loss': 0.10037784663592877, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9990afa8c2427faa4765dfbd697b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 1] VAL pr_auc_macro=nan | dur=0.5 min\n",
      "\n",
      "[Trial 2] cfg={'loss': 'asl', 'learning_rate': 5e-06, 'weight_decay': 0.0, 'warmup_ratio': 0.1, 'batch_size': 32, 'max_length': 128, 'label_smoothing': 0.0, 'llrd_enable': False, 'llrd_decay': 0.95, 'augment': False, 'gamma_pos': 2.0, 'gamma_neg': 1.0, 'clip': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ebfbe2fe2d46d0a3f319613467d9df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2068, 'grad_norm': 1.2781728506088257, 'learning_rate': 8.474576271186441e-07, 'epoch': 0.05}\n",
      "{'loss': 0.2036, 'grad_norm': 1.2967710494995117, 'learning_rate': 1.6949152542372882e-06, 'epoch': 0.1}\n",
      "{'loss': 0.1692, 'grad_norm': 1.0536091327667236, 'learning_rate': 2.5423728813559323e-06, 'epoch': 0.15}\n",
      "{'loss': 0.1411, 'grad_norm': 0.6651315689086914, 'learning_rate': 3.3898305084745763e-06, 'epoch': 0.2}\n",
      "{'loss': 0.1205, 'grad_norm': 0.49128037691116333, 'learning_rate': 4.23728813559322e-06, 'epoch': 0.26}\n",
      "{'loss': 0.1067, 'grad_norm': 0.3164961040019989, 'learning_rate': 4.999955914361218e-06, 'epoch': 0.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc69ad2e3926482990e61988975fb706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07534877210855484, 'eval_roc_auc_micro': 0.7885882282125048, 'eval_pr_auc_micro': 0.2798177621583246, 'eval_roc_auc_macro': 0.7756032992222285, 'eval_pr_auc_macro': 0.29903620443892726, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.336, 'eval_samples_per_second': 2333.107, 'eval_steps_per_second': 38.687, 'epoch': 0.33}\n",
      "{'loss': 0.1181, 'grad_norm': 0.3952575922012329, 'learning_rate': 4.9946675187988104e-06, 'epoch': 0.36}\n",
      "{'loss': 0.1052, 'grad_norm': 0.3876678943634033, 'learning_rate': 4.980583362063697e-06, 'epoch': 0.41}\n",
      "{'loss': 0.1037, 'grad_norm': 0.33647778630256653, 'learning_rate': 4.957753102428184e-06, 'epoch': 0.46}\n",
      "{'loss': 0.1046, 'grad_norm': 0.4038802981376648, 'learning_rate': 4.926257235393077e-06, 'epoch': 0.51}\n",
      "{'loss': 0.0973, 'grad_norm': 0.32396626472473145, 'learning_rate': 4.8862068098746246e-06, 'epoch': 0.56}\n",
      "{'loss': 0.1075, 'grad_norm': 0.39712944626808167, 'learning_rate': 4.837743036665477e-06, 'epoch': 0.61}\n",
      "{'loss': 0.1018, 'grad_norm': 0.4229896664619446, 'learning_rate': 4.781036790550134e-06, 'epoch': 0.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c238cdf2bc9e4f0896ab6c39c9fad33a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07464053481817245, 'eval_roc_auc_micro': 0.8112880641607613, 'eval_pr_auc_micro': 0.33246122719959004, 'eval_roc_auc_macro': 0.7940254732913248, 'eval_pr_auc_macro': 0.34659060050209445, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.331, 'eval_samples_per_second': 2368.371, 'eval_steps_per_second': 39.271, 'epoch': 0.66}\n",
      "{'loss': 0.1006, 'grad_norm': 0.37589171528816223, 'learning_rate': 4.716288007830357e-06, 'epoch': 0.71}\n",
      "{'loss': 0.0971, 'grad_norm': 0.4139067232608795, 'learning_rate': 4.6437249813847495e-06, 'epoch': 0.77}\n",
      "{'loss': 0.1024, 'grad_norm': 0.35268038511276245, 'learning_rate': 4.563603555748015e-06, 'epoch': 0.82}\n",
      "{'loss': 0.1004, 'grad_norm': 0.390546053647995, 'learning_rate': 4.476206225047889e-06, 'epoch': 0.87}\n",
      "{'loss': 0.101, 'grad_norm': 0.45121634006500244, 'learning_rate': 4.38184113698028e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0911, 'grad_norm': 0.3511559069156647, 'learning_rate': 4.280841006334403e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2a929f1804446298196902a2fa651f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07161368429660797, 'eval_roc_auc_micro': 0.8205789153857987, 'eval_pr_auc_micro': 0.3551567273505325, 'eval_roc_auc_macro': 0.8022049038218076, 'eval_pr_auc_macro': 0.37527232221186413, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3426, 'eval_samples_per_second': 2288.508, 'eval_steps_per_second': 37.947, 'epoch': 0.99}\n",
      "{'loss': 0.092, 'grad_norm': 0.29313233494758606, 'learning_rate': 4.173561941898656e-06, 'epoch': 1.02}\n",
      "{'loss': 0.098, 'grad_norm': 0.36861470341682434, 'learning_rate': 4.0603821908833386e-06, 'epoch': 1.07}\n",
      "{'loss': 0.0893, 'grad_norm': 0.5592856407165527, 'learning_rate': 3.941700805287168e-06, 'epoch': 1.12}\n",
      "{'loss': 0.0952, 'grad_norm': 0.4476100504398346, 'learning_rate': 3.817936234909763e-06, 'epoch': 1.17}\n",
      "{'loss': 0.0972, 'grad_norm': 0.4539039731025696, 'learning_rate': 3.6895248519708552e-06, 'epoch': 1.22}\n",
      "{'loss': 0.0918, 'grad_norm': 0.26031556725502014, 'learning_rate': 3.5569194125382122e-06, 'epoch': 1.28}\n",
      "{'loss': 0.0961, 'grad_norm': 0.3514987826347351, 'learning_rate': 3.4205874601889465e-06, 'epoch': 1.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa34ff1741646ee995df40407f4c2a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07054416835308075, 'eval_roc_auc_micro': 0.8240574907249137, 'eval_pr_auc_micro': 0.370362819755599, 'eval_roc_auc_macro': 0.807796297359063, 'eval_pr_auc_macro': 0.38762627308284264, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3459, 'eval_samples_per_second': 2266.341, 'eval_steps_per_second': 37.58, 'epoch': 1.33}\n",
      "{'loss': 0.0918, 'grad_norm': 0.3583292067050934, 'learning_rate': 3.2810096775326807e-06, 'epoch': 1.38}\n",
      "{'loss': 0.0889, 'grad_norm': 0.34692177176475525, 'learning_rate': 3.1386781914087644e-06, 'epoch': 1.43}\n",
      "{'loss': 0.0934, 'grad_norm': 0.3012702465057373, 'learning_rate': 2.9940948377331545e-06, 'epoch': 1.48}\n",
      "{'loss': 0.0929, 'grad_norm': 0.3520547151565552, 'learning_rate': 2.847769392112779e-06, 'epoch': 1.53}\n",
      "{'loss': 0.0923, 'grad_norm': 0.5159593224525452, 'learning_rate': 2.700217772465946e-06, 'epoch': 1.58}\n",
      "{'loss': 0.0868, 'grad_norm': 0.3591775894165039, 'learning_rate': 2.551960219986031e-06, 'epoch': 1.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a183274a2d465f9dc11acc0dcf6ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0684095174074173, 'eval_roc_auc_micro': 0.827274390634241, 'eval_pr_auc_micro': 0.37393662499863045, 'eval_roc_auc_macro': 0.8095748699919506, 'eval_pr_auc_macro': 0.3931741120743659, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.347, 'eval_samples_per_second': 2259.398, 'eval_steps_per_second': 37.465, 'epoch': 1.66}\n",
      "{'loss': 0.0863, 'grad_norm': 0.2854832410812378, 'learning_rate': 2.4035194648620625e-06, 'epoch': 1.68}\n",
      "{'loss': 0.0923, 'grad_norm': 0.44905757904052734, 'learning_rate': 2.2554188832235363e-06, 'epoch': 1.73}\n",
      "{'loss': 0.0898, 'grad_norm': 0.3568965792655945, 'learning_rate': 2.1081806518077575e-06, 'epoch': 1.79}\n",
      "{'loss': 0.088, 'grad_norm': 0.4772495627403259, 'learning_rate': 1.9623239068560373e-06, 'epoch': 1.84}\n",
      "{'loss': 0.0915, 'grad_norm': 0.45554426312446594, 'learning_rate': 1.818362913730133e-06, 'epoch': 1.89}\n",
      "{'loss': 0.0895, 'grad_norm': 0.5670253038406372, 'learning_rate': 1.6768052537025697e-06, 'epoch': 1.94}\n",
      "{'loss': 0.0951, 'grad_norm': 0.4885518252849579, 'learning_rate': 1.5381500343138877e-06, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9ccd3104b64f218f76c8051067cbc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06880511343479156, 'eval_roc_auc_micro': 0.8290223968370594, 'eval_pr_auc_micro': 0.37923405145427447, 'eval_roc_auc_macro': 0.8125332375078992, 'eval_pr_auc_macro': 0.39728824657731304, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3441, 'eval_samples_per_second': 2278.542, 'eval_steps_per_second': 37.782, 'epoch': 1.99}\n",
      "{'loss': 0.0978, 'grad_norm': 0.3371701240539551, 'learning_rate': 1.4028861296067802e-06, 'epoch': 2.04}\n",
      "{'loss': 0.0913, 'grad_norm': 0.2902781069278717, 'learning_rate': 1.2714904564417623e-06, 'epoch': 2.09}\n",
      "{'loss': 0.0883, 'grad_norm': 0.3741152286529541, 'learning_rate': 1.1444262929717627e-06, 'epoch': 2.14}\n",
      "{'loss': 0.0936, 'grad_norm': 0.5421854853630066, 'learning_rate': 1.0221416452044237e-06, 'epoch': 2.19}\n",
      "{'loss': 0.0819, 'grad_norm': 0.3089121878147125, 'learning_rate': 9.050676674113071e-07, 'epoch': 2.24}\n",
      "{'loss': 0.0992, 'grad_norm': 0.35272493958473206, 'learning_rate': 7.936171419533653e-07, 'epoch': 2.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c201cc9589492096497dc0b8a5a569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06877640634775162, 'eval_roc_auc_micro': 0.8314369528224639, 'eval_pr_auc_micro': 0.3838198950214917, 'eval_roc_auc_macro': 0.8147758372724865, 'eval_pr_auc_macro': 0.398820489012998, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3472, 'eval_samples_per_second': 2258.158, 'eval_steps_per_second': 37.444, 'epoch': 2.32}\n",
      "{'loss': 0.088, 'grad_norm': 0.43915873765945435, 'learning_rate': 6.881830238825699e-07, 'epoch': 2.35}\n",
      "{'loss': 0.089, 'grad_norm': 0.48133981227874756, 'learning_rate': 5.891370554511519e-07, 'epoch': 2.4}\n",
      "{'loss': 0.0889, 'grad_norm': 0.3496638536453247, 'learning_rate': 4.968284554134653e-07, 'epoch': 2.45}\n",
      "{'loss': 0.085, 'grad_norm': 0.3341969847679138, 'learning_rate': 4.115826877417631e-07, 'epoch': 2.5}\n",
      "{'loss': 0.0873, 'grad_norm': 0.35611292719841003, 'learning_rate': 3.3370031409717755e-07, 'epoch': 2.55}\n",
      "{'loss': 0.0914, 'grad_norm': 0.43154242634773254, 'learning_rate': 2.634559341018947e-07, 'epoch': 2.6}\n",
      "{'loss': 0.0872, 'grad_norm': 0.403942346572876, 'learning_rate': 2.0109721714893283e-07, 'epoch': 2.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9288d396251649a3a6b19735b7812f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06838088482618332, 'eval_roc_auc_micro': 0.8310225239126675, 'eval_pr_auc_micro': 0.38316150437072427, 'eval_roc_auc_macro': 0.814825774227366, 'eval_pr_auc_macro': 0.39984044057920687, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3418, 'eval_samples_per_second': 2293.933, 'eval_steps_per_second': 38.037, 'epoch': 2.65}\n",
      "{'loss': 0.0997, 'grad_norm': 0.6122041940689087, 'learning_rate': 1.468440291631984e-07, 'epoch': 2.7}\n",
      "{'loss': 0.0848, 'grad_norm': 0.2933502793312073, 'learning_rate': 1.0088765739270479e-07, 'epoch': 2.76}\n",
      "{'loss': 0.0899, 'grad_norm': 0.5001567006111145, 'learning_rate': 6.339013596320692e-08, 'epoch': 2.81}\n",
      "{'loss': 0.0891, 'grad_norm': 0.46312215924263, 'learning_rate': 3.448367457422497e-08, 'epoch': 2.86}\n",
      "{'loss': 0.0924, 'grad_norm': 0.39496850967407227, 'learning_rate': 1.4270192350775703e-08, 'epoch': 2.91}\n",
      "{'loss': 0.088, 'grad_norm': 0.4660615622997284, 'learning_rate': 2.820958494373083e-09, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4fefad5611d4e43b72e1b51d502189c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06848151236772537, 'eval_roc_auc_micro': 0.8312925595798287, 'eval_pr_auc_micro': 0.3840257925548896, 'eval_roc_auc_macro': 0.8150552904477685, 'eval_pr_auc_macro': 0.40023350945124253, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3435, 'eval_samples_per_second': 2282.619, 'eval_steps_per_second': 37.85, 'epoch': 2.98}\n",
      "{'train_runtime': 31.3287, 'train_samples_per_second': 599.834, 'train_steps_per_second': 18.769, 'train_loss': 0.10037784663592877, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fcdc3981bf04cf5b23b07a39136ad18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 2] VAL pr_auc_macro=nan | dur=0.5 min\n",
      "\n",
      "[Trial 3] cfg={'loss': 'asl', 'learning_rate': 5e-06, 'weight_decay': 0.0, 'warmup_ratio': 0.1, 'batch_size': 32, 'max_length': 128, 'label_smoothing': 0.0, 'llrd_enable': False, 'llrd_decay': 0.95, 'augment': False, 'gamma_pos': 2.0, 'gamma_neg': 1.0, 'clip': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ecd472afb64f2593ff4b4c980176bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2068, 'grad_norm': 1.2781728506088257, 'learning_rate': 8.474576271186441e-07, 'epoch': 0.05}\n",
      "{'loss': 0.2036, 'grad_norm': 1.2967710494995117, 'learning_rate': 1.6949152542372882e-06, 'epoch': 0.1}\n",
      "{'loss': 0.1692, 'grad_norm': 1.0536091327667236, 'learning_rate': 2.5423728813559323e-06, 'epoch': 0.15}\n",
      "{'loss': 0.1411, 'grad_norm': 0.6651315689086914, 'learning_rate': 3.3898305084745763e-06, 'epoch': 0.2}\n",
      "{'loss': 0.1205, 'grad_norm': 0.49128037691116333, 'learning_rate': 4.23728813559322e-06, 'epoch': 0.26}\n",
      "{'loss': 0.1067, 'grad_norm': 0.3164961040019989, 'learning_rate': 4.999955914361218e-06, 'epoch': 0.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dec0657d96e41d8819e1fea980c7cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07534877210855484, 'eval_roc_auc_micro': 0.7885882282125048, 'eval_pr_auc_micro': 0.2798177621583246, 'eval_roc_auc_macro': 0.7756032992222285, 'eval_pr_auc_macro': 0.29903620443892726, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3461, 'eval_samples_per_second': 2265.545, 'eval_steps_per_second': 37.566, 'epoch': 0.33}\n",
      "{'loss': 0.1181, 'grad_norm': 0.3952575922012329, 'learning_rate': 4.9946675187988104e-06, 'epoch': 0.36}\n",
      "{'loss': 0.1052, 'grad_norm': 0.3876678943634033, 'learning_rate': 4.980583362063697e-06, 'epoch': 0.41}\n",
      "{'loss': 0.1037, 'grad_norm': 0.33647778630256653, 'learning_rate': 4.957753102428184e-06, 'epoch': 0.46}\n",
      "{'loss': 0.1046, 'grad_norm': 0.4038802981376648, 'learning_rate': 4.926257235393077e-06, 'epoch': 0.51}\n",
      "{'loss': 0.0973, 'grad_norm': 0.32396626472473145, 'learning_rate': 4.8862068098746246e-06, 'epoch': 0.56}\n",
      "{'loss': 0.1075, 'grad_norm': 0.39712944626808167, 'learning_rate': 4.837743036665477e-06, 'epoch': 0.61}\n",
      "{'loss': 0.1018, 'grad_norm': 0.4229896664619446, 'learning_rate': 4.781036790550134e-06, 'epoch': 0.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10332c7c7b974433ad25799f9cce9c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07464053481817245, 'eval_roc_auc_micro': 0.8112880641607613, 'eval_pr_auc_micro': 0.33246122719959004, 'eval_roc_auc_macro': 0.7940254732913248, 'eval_pr_auc_macro': 0.34659060050209445, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.349, 'eval_samples_per_second': 2246.736, 'eval_steps_per_second': 37.255, 'epoch': 0.66}\n",
      "{'loss': 0.1006, 'grad_norm': 0.37589171528816223, 'learning_rate': 4.716288007830357e-06, 'epoch': 0.71}\n",
      "{'loss': 0.0971, 'grad_norm': 0.4139067232608795, 'learning_rate': 4.6437249813847495e-06, 'epoch': 0.77}\n",
      "{'loss': 0.1024, 'grad_norm': 0.35268038511276245, 'learning_rate': 4.563603555748015e-06, 'epoch': 0.82}\n",
      "{'loss': 0.1004, 'grad_norm': 0.390546053647995, 'learning_rate': 4.476206225047889e-06, 'epoch': 0.87}\n",
      "{'loss': 0.101, 'grad_norm': 0.45121634006500244, 'learning_rate': 4.38184113698028e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0911, 'grad_norm': 0.3511559069156647, 'learning_rate': 4.280841006334403e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25228b2bcf6b4e06ab52b4fdc5582e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07161368429660797, 'eval_roc_auc_micro': 0.8205789153857987, 'eval_pr_auc_micro': 0.3551567273505325, 'eval_roc_auc_macro': 0.8022049038218076, 'eval_pr_auc_macro': 0.37527232221186413, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.345, 'eval_samples_per_second': 2272.456, 'eval_steps_per_second': 37.681, 'epoch': 0.99}\n",
      "{'loss': 0.092, 'grad_norm': 0.29313233494758606, 'learning_rate': 4.173561941898656e-06, 'epoch': 1.02}\n",
      "{'loss': 0.098, 'grad_norm': 0.36861470341682434, 'learning_rate': 4.0603821908833386e-06, 'epoch': 1.07}\n",
      "{'loss': 0.0893, 'grad_norm': 0.5592856407165527, 'learning_rate': 3.941700805287168e-06, 'epoch': 1.12}\n",
      "{'loss': 0.0952, 'grad_norm': 0.4476100504398346, 'learning_rate': 3.817936234909763e-06, 'epoch': 1.17}\n",
      "{'loss': 0.0972, 'grad_norm': 0.4539039731025696, 'learning_rate': 3.6895248519708552e-06, 'epoch': 1.22}\n",
      "{'loss': 0.0918, 'grad_norm': 0.26031556725502014, 'learning_rate': 3.5569194125382122e-06, 'epoch': 1.28}\n",
      "{'loss': 0.0961, 'grad_norm': 0.3514987826347351, 'learning_rate': 3.4205874601889465e-06, 'epoch': 1.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7ae6fec09d4cfd8e958f2320856237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07054416835308075, 'eval_roc_auc_micro': 0.8240574907249137, 'eval_pr_auc_micro': 0.370362819755599, 'eval_roc_auc_macro': 0.807796297359063, 'eval_pr_auc_macro': 0.38762627308284264, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.349, 'eval_samples_per_second': 2246.497, 'eval_steps_per_second': 37.251, 'epoch': 1.33}\n",
      "{'loss': 0.0918, 'grad_norm': 0.3583292067050934, 'learning_rate': 3.2810096775326807e-06, 'epoch': 1.38}\n",
      "{'loss': 0.0889, 'grad_norm': 0.34692177176475525, 'learning_rate': 3.1386781914087644e-06, 'epoch': 1.43}\n",
      "{'loss': 0.0934, 'grad_norm': 0.3012702465057373, 'learning_rate': 2.9940948377331545e-06, 'epoch': 1.48}\n",
      "{'loss': 0.0929, 'grad_norm': 0.3520547151565552, 'learning_rate': 2.847769392112779e-06, 'epoch': 1.53}\n",
      "{'loss': 0.0923, 'grad_norm': 0.5159593224525452, 'learning_rate': 2.700217772465946e-06, 'epoch': 1.58}\n",
      "{'loss': 0.0868, 'grad_norm': 0.3591775894165039, 'learning_rate': 2.551960219986031e-06, 'epoch': 1.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb3e92366e54a6b918f498071d8cbb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0684095174074173, 'eval_roc_auc_micro': 0.827274390634241, 'eval_pr_auc_micro': 0.37393662499863045, 'eval_roc_auc_macro': 0.8095748699919506, 'eval_pr_auc_macro': 0.3931741120743659, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3379, 'eval_samples_per_second': 2319.893, 'eval_steps_per_second': 38.468, 'epoch': 1.66}\n",
      "{'loss': 0.0863, 'grad_norm': 0.2854832410812378, 'learning_rate': 2.4035194648620625e-06, 'epoch': 1.68}\n",
      "{'loss': 0.0923, 'grad_norm': 0.44905757904052734, 'learning_rate': 2.2554188832235363e-06, 'epoch': 1.73}\n",
      "{'loss': 0.0898, 'grad_norm': 0.3568965792655945, 'learning_rate': 2.1081806518077575e-06, 'epoch': 1.79}\n",
      "{'loss': 0.088, 'grad_norm': 0.4772495627403259, 'learning_rate': 1.9623239068560373e-06, 'epoch': 1.84}\n",
      "{'loss': 0.0915, 'grad_norm': 0.45554426312446594, 'learning_rate': 1.818362913730133e-06, 'epoch': 1.89}\n",
      "{'loss': 0.0895, 'grad_norm': 0.5670253038406372, 'learning_rate': 1.6768052537025697e-06, 'epoch': 1.94}\n",
      "{'loss': 0.0951, 'grad_norm': 0.4885518252849579, 'learning_rate': 1.5381500343138877e-06, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c00a12893f40069de1a56b7ae68022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06880511343479156, 'eval_roc_auc_micro': 0.8290223968370594, 'eval_pr_auc_micro': 0.37923405145427447, 'eval_roc_auc_macro': 0.8125332375078992, 'eval_pr_auc_macro': 0.39728824657731304, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3364, 'eval_samples_per_second': 2330.438, 'eval_steps_per_second': 38.642, 'epoch': 1.99}\n",
      "{'loss': 0.0978, 'grad_norm': 0.3371701240539551, 'learning_rate': 1.4028861296067802e-06, 'epoch': 2.04}\n",
      "{'loss': 0.0913, 'grad_norm': 0.2902781069278717, 'learning_rate': 1.2714904564417623e-06, 'epoch': 2.09}\n",
      "{'loss': 0.0883, 'grad_norm': 0.3741152286529541, 'learning_rate': 1.1444262929717627e-06, 'epoch': 2.14}\n",
      "{'loss': 0.0936, 'grad_norm': 0.5421854853630066, 'learning_rate': 1.0221416452044237e-06, 'epoch': 2.19}\n",
      "{'loss': 0.0819, 'grad_norm': 0.3089121878147125, 'learning_rate': 9.050676674113071e-07, 'epoch': 2.24}\n",
      "{'loss': 0.0992, 'grad_norm': 0.35272493958473206, 'learning_rate': 7.936171419533653e-07, 'epoch': 2.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d728d9720c4da5aaac837dd5cd68e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06877640634775162, 'eval_roc_auc_micro': 0.8314369528224639, 'eval_pr_auc_micro': 0.3838198950214917, 'eval_roc_auc_macro': 0.8147758372724865, 'eval_pr_auc_macro': 0.398820489012998, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3439, 'eval_samples_per_second': 2279.45, 'eval_steps_per_second': 37.797, 'epoch': 2.32}\n",
      "{'loss': 0.088, 'grad_norm': 0.43915873765945435, 'learning_rate': 6.881830238825699e-07, 'epoch': 2.35}\n",
      "{'loss': 0.089, 'grad_norm': 0.48133981227874756, 'learning_rate': 5.891370554511519e-07, 'epoch': 2.4}\n",
      "{'loss': 0.0889, 'grad_norm': 0.3496638536453247, 'learning_rate': 4.968284554134653e-07, 'epoch': 2.45}\n",
      "{'loss': 0.085, 'grad_norm': 0.3341969847679138, 'learning_rate': 4.115826877417631e-07, 'epoch': 2.5}\n",
      "{'loss': 0.0873, 'grad_norm': 0.35611292719841003, 'learning_rate': 3.3370031409717755e-07, 'epoch': 2.55}\n",
      "{'loss': 0.0914, 'grad_norm': 0.43154242634773254, 'learning_rate': 2.634559341018947e-07, 'epoch': 2.6}\n",
      "{'loss': 0.0872, 'grad_norm': 0.403942346572876, 'learning_rate': 2.0109721714893283e-07, 'epoch': 2.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b643ff35c74242998070e30532cadac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06838088482618332, 'eval_roc_auc_micro': 0.8310225239126675, 'eval_pr_auc_micro': 0.38316150437072427, 'eval_roc_auc_macro': 0.814825774227366, 'eval_pr_auc_macro': 0.39984044057920687, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3425, 'eval_samples_per_second': 2288.806, 'eval_steps_per_second': 37.952, 'epoch': 2.65}\n",
      "{'loss': 0.0997, 'grad_norm': 0.6122041940689087, 'learning_rate': 1.468440291631984e-07, 'epoch': 2.7}\n",
      "{'loss': 0.0848, 'grad_norm': 0.2933502793312073, 'learning_rate': 1.0088765739270479e-07, 'epoch': 2.76}\n",
      "{'loss': 0.0899, 'grad_norm': 0.5001567006111145, 'learning_rate': 6.339013596320692e-08, 'epoch': 2.81}\n",
      "{'loss': 0.0891, 'grad_norm': 0.46312215924263, 'learning_rate': 3.448367457422497e-08, 'epoch': 2.86}\n",
      "{'loss': 0.0924, 'grad_norm': 0.39496850967407227, 'learning_rate': 1.4270192350775703e-08, 'epoch': 2.91}\n",
      "{'loss': 0.088, 'grad_norm': 0.4660615622997284, 'learning_rate': 2.820958494373083e-09, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742da8579bd94c3bb37cf5fc51b4c0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06848151236772537, 'eval_roc_auc_micro': 0.8312925595798287, 'eval_pr_auc_micro': 0.3840257925548896, 'eval_roc_auc_macro': 0.8150552904477685, 'eval_pr_auc_macro': 0.40023350945124253, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3382, 'eval_samples_per_second': 2318.385, 'eval_steps_per_second': 38.443, 'epoch': 2.98}\n",
      "{'train_runtime': 31.236, 'train_samples_per_second': 601.613, 'train_steps_per_second': 18.824, 'train_loss': 0.10037784663592877, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9c2583184546188704d276b1b8299f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 3] VAL pr_auc_macro=nan | dur=0.5 min\n",
      "\n",
      "[Trial 4] cfg={'loss': 'asl', 'learning_rate': 5e-06, 'weight_decay': 0.0, 'warmup_ratio': 0.1, 'batch_size': 32, 'max_length': 128, 'label_smoothing': 0.0, 'llrd_enable': False, 'llrd_decay': 0.95, 'augment': False, 'gamma_pos': 2.0, 'gamma_neg': 1.0, 'clip': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b5499993a44ae6aad4a4474b62cbf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2068, 'grad_norm': 1.2781728506088257, 'learning_rate': 8.474576271186441e-07, 'epoch': 0.05}\n",
      "{'loss': 0.2036, 'grad_norm': 1.2967710494995117, 'learning_rate': 1.6949152542372882e-06, 'epoch': 0.1}\n",
      "{'loss': 0.1692, 'grad_norm': 1.0536091327667236, 'learning_rate': 2.5423728813559323e-06, 'epoch': 0.15}\n",
      "{'loss': 0.1411, 'grad_norm': 0.6651315689086914, 'learning_rate': 3.3898305084745763e-06, 'epoch': 0.2}\n",
      "{'loss': 0.1205, 'grad_norm': 0.49128037691116333, 'learning_rate': 4.23728813559322e-06, 'epoch': 0.26}\n",
      "{'loss': 0.1067, 'grad_norm': 0.3164961040019989, 'learning_rate': 4.999955914361218e-06, 'epoch': 0.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d202926e8f4a368497382739828c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07534877210855484, 'eval_roc_auc_micro': 0.7885882282125048, 'eval_pr_auc_micro': 0.2798177621583246, 'eval_roc_auc_macro': 0.7756032992222285, 'eval_pr_auc_macro': 0.29903620443892726, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.338, 'eval_samples_per_second': 2319.408, 'eval_steps_per_second': 38.46, 'epoch': 0.33}\n",
      "{'loss': 0.1181, 'grad_norm': 0.3952575922012329, 'learning_rate': 4.9946675187988104e-06, 'epoch': 0.36}\n",
      "{'loss': 0.1052, 'grad_norm': 0.3876678943634033, 'learning_rate': 4.980583362063697e-06, 'epoch': 0.41}\n",
      "{'loss': 0.1037, 'grad_norm': 0.33647778630256653, 'learning_rate': 4.957753102428184e-06, 'epoch': 0.46}\n",
      "{'loss': 0.1046, 'grad_norm': 0.4038802981376648, 'learning_rate': 4.926257235393077e-06, 'epoch': 0.51}\n",
      "{'loss': 0.0973, 'grad_norm': 0.32396626472473145, 'learning_rate': 4.8862068098746246e-06, 'epoch': 0.56}\n",
      "{'loss': 0.1075, 'grad_norm': 0.39712944626808167, 'learning_rate': 4.837743036665477e-06, 'epoch': 0.61}\n",
      "{'loss': 0.1018, 'grad_norm': 0.4229896664619446, 'learning_rate': 4.781036790550134e-06, 'epoch': 0.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465418feeede46c084e0c1ca537b79f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07464053481817245, 'eval_roc_auc_micro': 0.8112880641607613, 'eval_pr_auc_micro': 0.33246122719959004, 'eval_roc_auc_macro': 0.7940254732913248, 'eval_pr_auc_macro': 0.34659060050209445, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3481, 'eval_samples_per_second': 2252.529, 'eval_steps_per_second': 37.351, 'epoch': 0.66}\n",
      "{'loss': 0.1006, 'grad_norm': 0.37589171528816223, 'learning_rate': 4.716288007830357e-06, 'epoch': 0.71}\n",
      "{'loss': 0.0971, 'grad_norm': 0.4139067232608795, 'learning_rate': 4.6437249813847495e-06, 'epoch': 0.77}\n",
      "{'loss': 0.1024, 'grad_norm': 0.35268038511276245, 'learning_rate': 4.563603555748015e-06, 'epoch': 0.82}\n",
      "{'loss': 0.1004, 'grad_norm': 0.390546053647995, 'learning_rate': 4.476206225047889e-06, 'epoch': 0.87}\n",
      "{'loss': 0.101, 'grad_norm': 0.45121634006500244, 'learning_rate': 4.38184113698028e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0911, 'grad_norm': 0.3511559069156647, 'learning_rate': 4.280841006334403e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96fd48321e74c56b1b3980a18c8b5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07161368429660797, 'eval_roc_auc_micro': 0.8205789153857987, 'eval_pr_auc_micro': 0.3551567273505325, 'eval_roc_auc_macro': 0.8022049038218076, 'eval_pr_auc_macro': 0.37527232221186413, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3411, 'eval_samples_per_second': 2298.691, 'eval_steps_per_second': 38.116, 'epoch': 0.99}\n",
      "{'loss': 0.092, 'grad_norm': 0.29313233494758606, 'learning_rate': 4.173561941898656e-06, 'epoch': 1.02}\n",
      "{'loss': 0.098, 'grad_norm': 0.36861470341682434, 'learning_rate': 4.0603821908833386e-06, 'epoch': 1.07}\n",
      "{'loss': 0.0893, 'grad_norm': 0.5592856407165527, 'learning_rate': 3.941700805287168e-06, 'epoch': 1.12}\n",
      "{'loss': 0.0952, 'grad_norm': 0.4476100504398346, 'learning_rate': 3.817936234909763e-06, 'epoch': 1.17}\n",
      "{'loss': 0.0972, 'grad_norm': 0.4539039731025696, 'learning_rate': 3.6895248519708552e-06, 'epoch': 1.22}\n",
      "{'loss': 0.0918, 'grad_norm': 0.26031556725502014, 'learning_rate': 3.5569194125382122e-06, 'epoch': 1.28}\n",
      "{'loss': 0.0961, 'grad_norm': 0.3514987826347351, 'learning_rate': 3.4205874601889465e-06, 'epoch': 1.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f245ed938a7347f480771b31c3f41e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07054416835308075, 'eval_roc_auc_micro': 0.8240574907249137, 'eval_pr_auc_micro': 0.370362819755599, 'eval_roc_auc_macro': 0.807796297359063, 'eval_pr_auc_macro': 0.38762627308284264, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3386, 'eval_samples_per_second': 2315.205, 'eval_steps_per_second': 38.39, 'epoch': 1.33}\n",
      "{'loss': 0.0918, 'grad_norm': 0.3583292067050934, 'learning_rate': 3.2810096775326807e-06, 'epoch': 1.38}\n",
      "{'loss': 0.0889, 'grad_norm': 0.34692177176475525, 'learning_rate': 3.1386781914087644e-06, 'epoch': 1.43}\n",
      "{'loss': 0.0934, 'grad_norm': 0.3012702465057373, 'learning_rate': 2.9940948377331545e-06, 'epoch': 1.48}\n",
      "{'loss': 0.0929, 'grad_norm': 0.3520547151565552, 'learning_rate': 2.847769392112779e-06, 'epoch': 1.53}\n",
      "{'loss': 0.0923, 'grad_norm': 0.5159593224525452, 'learning_rate': 2.700217772465946e-06, 'epoch': 1.58}\n",
      "{'loss': 0.0868, 'grad_norm': 0.3591775894165039, 'learning_rate': 2.551960219986031e-06, 'epoch': 1.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48b43cdab51444db22d9b4e93d3626a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0684095174074173, 'eval_roc_auc_micro': 0.827274390634241, 'eval_pr_auc_micro': 0.37393662499863045, 'eval_roc_auc_macro': 0.8095748699919506, 'eval_pr_auc_macro': 0.3931741120743659, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3379, 'eval_samples_per_second': 2319.88, 'eval_steps_per_second': 38.467, 'epoch': 1.66}\n",
      "{'loss': 0.0863, 'grad_norm': 0.2854832410812378, 'learning_rate': 2.4035194648620625e-06, 'epoch': 1.68}\n",
      "{'loss': 0.0923, 'grad_norm': 0.44905757904052734, 'learning_rate': 2.2554188832235363e-06, 'epoch': 1.73}\n",
      "{'loss': 0.0898, 'grad_norm': 0.3568965792655945, 'learning_rate': 2.1081806518077575e-06, 'epoch': 1.79}\n",
      "{'loss': 0.088, 'grad_norm': 0.4772495627403259, 'learning_rate': 1.9623239068560373e-06, 'epoch': 1.84}\n",
      "{'loss': 0.0915, 'grad_norm': 0.45554426312446594, 'learning_rate': 1.818362913730133e-06, 'epoch': 1.89}\n",
      "{'loss': 0.0895, 'grad_norm': 0.5670253038406372, 'learning_rate': 1.6768052537025697e-06, 'epoch': 1.94}\n",
      "{'loss': 0.0951, 'grad_norm': 0.4885518252849579, 'learning_rate': 1.5381500343138877e-06, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215f83ecf94f45a6bb5b53a5c02b328e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06880511343479156, 'eval_roc_auc_micro': 0.8290223968370594, 'eval_pr_auc_micro': 0.37923405145427447, 'eval_roc_auc_macro': 0.8125332375078992, 'eval_pr_auc_macro': 0.39728824657731304, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3352, 'eval_samples_per_second': 2338.649, 'eval_steps_per_second': 38.779, 'epoch': 1.99}\n",
      "{'loss': 0.0978, 'grad_norm': 0.3371701240539551, 'learning_rate': 1.4028861296067802e-06, 'epoch': 2.04}\n",
      "{'loss': 0.0913, 'grad_norm': 0.2902781069278717, 'learning_rate': 1.2714904564417623e-06, 'epoch': 2.09}\n",
      "{'loss': 0.0883, 'grad_norm': 0.3741152286529541, 'learning_rate': 1.1444262929717627e-06, 'epoch': 2.14}\n",
      "{'loss': 0.0936, 'grad_norm': 0.5421854853630066, 'learning_rate': 1.0221416452044237e-06, 'epoch': 2.19}\n",
      "{'loss': 0.0819, 'grad_norm': 0.3089121878147125, 'learning_rate': 9.050676674113071e-07, 'epoch': 2.24}\n",
      "{'loss': 0.0992, 'grad_norm': 0.35272493958473206, 'learning_rate': 7.936171419533653e-07, 'epoch': 2.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e43af717d74c54831229e5cd73bc4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06877640634775162, 'eval_roc_auc_micro': 0.8314369528224639, 'eval_pr_auc_micro': 0.3838198950214917, 'eval_roc_auc_macro': 0.8147758372724865, 'eval_pr_auc_macro': 0.398820489012998, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.339, 'eval_samples_per_second': 2312.584, 'eval_steps_per_second': 38.346, 'epoch': 2.32}\n",
      "{'loss': 0.088, 'grad_norm': 0.43915873765945435, 'learning_rate': 6.881830238825699e-07, 'epoch': 2.35}\n",
      "{'loss': 0.089, 'grad_norm': 0.48133981227874756, 'learning_rate': 5.891370554511519e-07, 'epoch': 2.4}\n",
      "{'loss': 0.0889, 'grad_norm': 0.3496638536453247, 'learning_rate': 4.968284554134653e-07, 'epoch': 2.45}\n",
      "{'loss': 0.085, 'grad_norm': 0.3341969847679138, 'learning_rate': 4.115826877417631e-07, 'epoch': 2.5}\n",
      "{'loss': 0.0873, 'grad_norm': 0.35611292719841003, 'learning_rate': 3.3370031409717755e-07, 'epoch': 2.55}\n",
      "{'loss': 0.0914, 'grad_norm': 0.43154242634773254, 'learning_rate': 2.634559341018947e-07, 'epoch': 2.6}\n",
      "{'loss': 0.0872, 'grad_norm': 0.403942346572876, 'learning_rate': 2.0109721714893283e-07, 'epoch': 2.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abbe243c89174653aa6cd44adcc04b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06838088482618332, 'eval_roc_auc_micro': 0.8310225239126675, 'eval_pr_auc_micro': 0.38316150437072427, 'eval_roc_auc_macro': 0.814825774227366, 'eval_pr_auc_macro': 0.39984044057920687, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.337, 'eval_samples_per_second': 2326.404, 'eval_steps_per_second': 38.576, 'epoch': 2.65}\n",
      "{'loss': 0.0997, 'grad_norm': 0.6122041940689087, 'learning_rate': 1.468440291631984e-07, 'epoch': 2.7}\n",
      "{'loss': 0.0848, 'grad_norm': 0.2933502793312073, 'learning_rate': 1.0088765739270479e-07, 'epoch': 2.76}\n",
      "{'loss': 0.0899, 'grad_norm': 0.5001567006111145, 'learning_rate': 6.339013596320692e-08, 'epoch': 2.81}\n",
      "{'loss': 0.0891, 'grad_norm': 0.46312215924263, 'learning_rate': 3.448367457422497e-08, 'epoch': 2.86}\n",
      "{'loss': 0.0924, 'grad_norm': 0.39496850967407227, 'learning_rate': 1.4270192350775703e-08, 'epoch': 2.91}\n",
      "{'loss': 0.088, 'grad_norm': 0.4660615622997284, 'learning_rate': 2.820958494373083e-09, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9bf5f172b4c4261bd59c4b95b22fcc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06848151236772537, 'eval_roc_auc_micro': 0.8312925595798287, 'eval_pr_auc_micro': 0.3840257925548896, 'eval_roc_auc_macro': 0.8150552904477685, 'eval_pr_auc_macro': 0.40023350945124253, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3382, 'eval_samples_per_second': 2317.921, 'eval_steps_per_second': 38.435, 'epoch': 2.98}\n",
      "{'train_runtime': 30.8152, 'train_samples_per_second': 609.829, 'train_steps_per_second': 19.081, 'train_loss': 0.10037784663592877, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763905927e84457eb5b69b24585d803d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 4] VAL pr_auc_macro=nan | dur=0.5 min\n",
      "\n",
      "[Trial 5] cfg={'loss': 'asl', 'learning_rate': 5e-06, 'weight_decay': 0.0, 'warmup_ratio': 0.1, 'batch_size': 32, 'max_length': 128, 'label_smoothing': 0.0, 'llrd_enable': False, 'llrd_decay': 0.95, 'augment': False, 'gamma_pos': 2.0, 'gamma_neg': 1.0, 'clip': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806b13c471894ca993d06a4f76eae763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2068, 'grad_norm': 1.2781728506088257, 'learning_rate': 8.474576271186441e-07, 'epoch': 0.05}\n",
      "{'loss': 0.2036, 'grad_norm': 1.2967710494995117, 'learning_rate': 1.6949152542372882e-06, 'epoch': 0.1}\n",
      "{'loss': 0.1692, 'grad_norm': 1.0536091327667236, 'learning_rate': 2.5423728813559323e-06, 'epoch': 0.15}\n",
      "{'loss': 0.1411, 'grad_norm': 0.6651315689086914, 'learning_rate': 3.3898305084745763e-06, 'epoch': 0.2}\n",
      "{'loss': 0.1205, 'grad_norm': 0.49128037691116333, 'learning_rate': 4.23728813559322e-06, 'epoch': 0.26}\n",
      "{'loss': 0.1067, 'grad_norm': 0.3164961040019989, 'learning_rate': 4.999955914361218e-06, 'epoch': 0.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c790b44cf96a4cd6b254ce5d8264e0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07534877210855484, 'eval_roc_auc_micro': 0.7885882282125048, 'eval_pr_auc_micro': 0.2798177621583246, 'eval_roc_auc_macro': 0.7756032992222285, 'eval_pr_auc_macro': 0.29903620443892726, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3378, 'eval_samples_per_second': 2321.052, 'eval_steps_per_second': 38.487, 'epoch': 0.33}\n",
      "{'loss': 0.1181, 'grad_norm': 0.3952575922012329, 'learning_rate': 4.9946675187988104e-06, 'epoch': 0.36}\n",
      "{'loss': 0.1052, 'grad_norm': 0.3876678943634033, 'learning_rate': 4.980583362063697e-06, 'epoch': 0.41}\n",
      "{'loss': 0.1037, 'grad_norm': 0.33647778630256653, 'learning_rate': 4.957753102428184e-06, 'epoch': 0.46}\n",
      "{'loss': 0.1046, 'grad_norm': 0.4038802981376648, 'learning_rate': 4.926257235393077e-06, 'epoch': 0.51}\n",
      "{'loss': 0.0973, 'grad_norm': 0.32396626472473145, 'learning_rate': 4.8862068098746246e-06, 'epoch': 0.56}\n",
      "{'loss': 0.1075, 'grad_norm': 0.39712944626808167, 'learning_rate': 4.837743036665477e-06, 'epoch': 0.61}\n",
      "{'loss': 0.1018, 'grad_norm': 0.4229896664619446, 'learning_rate': 4.781036790550134e-06, 'epoch': 0.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f30d0ea0ed4b60a63713e6b3702990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07464053481817245, 'eval_roc_auc_micro': 0.8112880641607613, 'eval_pr_auc_micro': 0.33246122719959004, 'eval_roc_auc_macro': 0.7940254732913248, 'eval_pr_auc_macro': 0.34659060050209445, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.34, 'eval_samples_per_second': 2305.716, 'eval_steps_per_second': 38.233, 'epoch': 0.66}\n",
      "{'loss': 0.1006, 'grad_norm': 0.37589171528816223, 'learning_rate': 4.716288007830357e-06, 'epoch': 0.71}\n",
      "{'loss': 0.0971, 'grad_norm': 0.4139067232608795, 'learning_rate': 4.6437249813847495e-06, 'epoch': 0.77}\n",
      "{'loss': 0.1024, 'grad_norm': 0.35268038511276245, 'learning_rate': 4.563603555748015e-06, 'epoch': 0.82}\n",
      "{'loss': 0.1004, 'grad_norm': 0.390546053647995, 'learning_rate': 4.476206225047889e-06, 'epoch': 0.87}\n",
      "{'loss': 0.101, 'grad_norm': 0.45121634006500244, 'learning_rate': 4.38184113698028e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0911, 'grad_norm': 0.3511559069156647, 'learning_rate': 4.280841006334403e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b42f1fa98b42b1915a843e7bac53d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07161368429660797, 'eval_roc_auc_micro': 0.8205789153857987, 'eval_pr_auc_micro': 0.3551567273505325, 'eval_roc_auc_macro': 0.8022049038218076, 'eval_pr_auc_macro': 0.37527232221186413, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3402, 'eval_samples_per_second': 2304.404, 'eval_steps_per_second': 38.211, 'epoch': 0.99}\n",
      "{'loss': 0.092, 'grad_norm': 0.29313233494758606, 'learning_rate': 4.173561941898656e-06, 'epoch': 1.02}\n",
      "{'loss': 0.098, 'grad_norm': 0.36861470341682434, 'learning_rate': 4.0603821908833386e-06, 'epoch': 1.07}\n",
      "{'loss': 0.0893, 'grad_norm': 0.5592856407165527, 'learning_rate': 3.941700805287168e-06, 'epoch': 1.12}\n",
      "{'loss': 0.0952, 'grad_norm': 0.4476100504398346, 'learning_rate': 3.817936234909763e-06, 'epoch': 1.17}\n",
      "{'loss': 0.0972, 'grad_norm': 0.4539039731025696, 'learning_rate': 3.6895248519708552e-06, 'epoch': 1.22}\n",
      "{'loss': 0.0918, 'grad_norm': 0.26031556725502014, 'learning_rate': 3.5569194125382122e-06, 'epoch': 1.28}\n",
      "{'loss': 0.0961, 'grad_norm': 0.3514987826347351, 'learning_rate': 3.4205874601889465e-06, 'epoch': 1.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0cd73b610d4d5dac7f6bb6b41301ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07054416835308075, 'eval_roc_auc_micro': 0.8240574907249137, 'eval_pr_auc_micro': 0.370362819755599, 'eval_roc_auc_macro': 0.807796297359063, 'eval_pr_auc_macro': 0.38762627308284264, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3413, 'eval_samples_per_second': 2296.921, 'eval_steps_per_second': 38.087, 'epoch': 1.33}\n",
      "{'loss': 0.0918, 'grad_norm': 0.3583292067050934, 'learning_rate': 3.2810096775326807e-06, 'epoch': 1.38}\n",
      "{'loss': 0.0889, 'grad_norm': 0.34692177176475525, 'learning_rate': 3.1386781914087644e-06, 'epoch': 1.43}\n",
      "{'loss': 0.0934, 'grad_norm': 0.3012702465057373, 'learning_rate': 2.9940948377331545e-06, 'epoch': 1.48}\n",
      "{'loss': 0.0929, 'grad_norm': 0.3520547151565552, 'learning_rate': 2.847769392112779e-06, 'epoch': 1.53}\n",
      "{'loss': 0.0923, 'grad_norm': 0.5159593224525452, 'learning_rate': 2.700217772465946e-06, 'epoch': 1.58}\n",
      "{'loss': 0.0868, 'grad_norm': 0.3591775894165039, 'learning_rate': 2.551960219986031e-06, 'epoch': 1.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a676f4cc4c4d7b999aecdae8ccb184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0684095174074173, 'eval_roc_auc_micro': 0.827274390634241, 'eval_pr_auc_micro': 0.37393662499863045, 'eval_roc_auc_macro': 0.8095748699919506, 'eval_pr_auc_macro': 0.3931741120743659, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.341, 'eval_samples_per_second': 2299.116, 'eval_steps_per_second': 38.123, 'epoch': 1.66}\n",
      "{'loss': 0.0863, 'grad_norm': 0.2854832410812378, 'learning_rate': 2.4035194648620625e-06, 'epoch': 1.68}\n",
      "{'loss': 0.0923, 'grad_norm': 0.44905757904052734, 'learning_rate': 2.2554188832235363e-06, 'epoch': 1.73}\n",
      "{'loss': 0.0898, 'grad_norm': 0.3568965792655945, 'learning_rate': 2.1081806518077575e-06, 'epoch': 1.79}\n",
      "{'loss': 0.088, 'grad_norm': 0.4772495627403259, 'learning_rate': 1.9623239068560373e-06, 'epoch': 1.84}\n",
      "{'loss': 0.0915, 'grad_norm': 0.45554426312446594, 'learning_rate': 1.818362913730133e-06, 'epoch': 1.89}\n",
      "{'loss': 0.0895, 'grad_norm': 0.5670253038406372, 'learning_rate': 1.6768052537025697e-06, 'epoch': 1.94}\n",
      "{'loss': 0.0951, 'grad_norm': 0.4885518252849579, 'learning_rate': 1.5381500343138877e-06, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f626d6a0b54b4984c0cefd84b7893d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06880511343479156, 'eval_roc_auc_micro': 0.8290223968370594, 'eval_pr_auc_micro': 0.37923405145427447, 'eval_roc_auc_macro': 0.8125332375078992, 'eval_pr_auc_macro': 0.39728824657731304, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.34, 'eval_samples_per_second': 2305.875, 'eval_steps_per_second': 38.235, 'epoch': 1.99}\n",
      "{'loss': 0.0978, 'grad_norm': 0.3371701240539551, 'learning_rate': 1.4028861296067802e-06, 'epoch': 2.04}\n",
      "{'loss': 0.0913, 'grad_norm': 0.2902781069278717, 'learning_rate': 1.2714904564417623e-06, 'epoch': 2.09}\n",
      "{'loss': 0.0883, 'grad_norm': 0.3741152286529541, 'learning_rate': 1.1444262929717627e-06, 'epoch': 2.14}\n",
      "{'loss': 0.0936, 'grad_norm': 0.5421854853630066, 'learning_rate': 1.0221416452044237e-06, 'epoch': 2.19}\n",
      "{'loss': 0.0819, 'grad_norm': 0.3089121878147125, 'learning_rate': 9.050676674113071e-07, 'epoch': 2.24}\n",
      "{'loss': 0.0992, 'grad_norm': 0.35272493958473206, 'learning_rate': 7.936171419533653e-07, 'epoch': 2.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc886805e5b41379e491b592d3cb9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06877640634775162, 'eval_roc_auc_micro': 0.8314369528224639, 'eval_pr_auc_micro': 0.3838198950214917, 'eval_roc_auc_macro': 0.8147758372724865, 'eval_pr_auc_macro': 0.398820489012998, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3396, 'eval_samples_per_second': 2308.408, 'eval_steps_per_second': 38.277, 'epoch': 2.32}\n",
      "{'loss': 0.088, 'grad_norm': 0.43915873765945435, 'learning_rate': 6.881830238825699e-07, 'epoch': 2.35}\n",
      "{'loss': 0.089, 'grad_norm': 0.48133981227874756, 'learning_rate': 5.891370554511519e-07, 'epoch': 2.4}\n",
      "{'loss': 0.0889, 'grad_norm': 0.3496638536453247, 'learning_rate': 4.968284554134653e-07, 'epoch': 2.45}\n",
      "{'loss': 0.085, 'grad_norm': 0.3341969847679138, 'learning_rate': 4.115826877417631e-07, 'epoch': 2.5}\n",
      "{'loss': 0.0873, 'grad_norm': 0.35611292719841003, 'learning_rate': 3.3370031409717755e-07, 'epoch': 2.55}\n",
      "{'loss': 0.0914, 'grad_norm': 0.43154242634773254, 'learning_rate': 2.634559341018947e-07, 'epoch': 2.6}\n",
      "{'loss': 0.0872, 'grad_norm': 0.403942346572876, 'learning_rate': 2.0109721714893283e-07, 'epoch': 2.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c357bc8650343b196854e12c7941294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06838088482618332, 'eval_roc_auc_micro': 0.8310225239126675, 'eval_pr_auc_micro': 0.38316150437072427, 'eval_roc_auc_macro': 0.814825774227366, 'eval_pr_auc_macro': 0.39984044057920687, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3388, 'eval_samples_per_second': 2313.811, 'eval_steps_per_second': 38.367, 'epoch': 2.65}\n",
      "{'loss': 0.0997, 'grad_norm': 0.6122041940689087, 'learning_rate': 1.468440291631984e-07, 'epoch': 2.7}\n",
      "{'loss': 0.0848, 'grad_norm': 0.2933502793312073, 'learning_rate': 1.0088765739270479e-07, 'epoch': 2.76}\n",
      "{'loss': 0.0899, 'grad_norm': 0.5001567006111145, 'learning_rate': 6.339013596320692e-08, 'epoch': 2.81}\n",
      "{'loss': 0.0891, 'grad_norm': 0.46312215924263, 'learning_rate': 3.448367457422497e-08, 'epoch': 2.86}\n",
      "{'loss': 0.0924, 'grad_norm': 0.39496850967407227, 'learning_rate': 1.4270192350775703e-08, 'epoch': 2.91}\n",
      "{'loss': 0.088, 'grad_norm': 0.4660615622997284, 'learning_rate': 2.820958494373083e-09, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d78623bb134535a8f72158494be5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06848151236772537, 'eval_roc_auc_micro': 0.8312925595798287, 'eval_pr_auc_micro': 0.3840257925548896, 'eval_roc_auc_macro': 0.8150552904477685, 'eval_pr_auc_macro': 0.40023350945124253, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.346, 'eval_samples_per_second': 2266.095, 'eval_steps_per_second': 37.576, 'epoch': 2.98}\n",
      "{'train_runtime': 31.0509, 'train_samples_per_second': 605.2, 'train_steps_per_second': 18.937, 'train_loss': 0.10037784663592877, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db49eeecbe5347db86e8e8a400cda7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 5] VAL pr_auc_macro=nan | dur=0.5 min\n",
      "\n",
      "[Trial 6] cfg={'loss': 'asl', 'learning_rate': 5e-06, 'weight_decay': 0.0, 'warmup_ratio': 0.1, 'batch_size': 32, 'max_length': 128, 'label_smoothing': 0.0, 'llrd_enable': False, 'llrd_decay': 0.95, 'augment': False, 'gamma_pos': 2.0, 'gamma_neg': 1.0, 'clip': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c2c11be0524b1cab8c8e6bfae8e4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2068, 'grad_norm': 1.2781728506088257, 'learning_rate': 8.474576271186441e-07, 'epoch': 0.05}\n",
      "{'loss': 0.2036, 'grad_norm': 1.2967710494995117, 'learning_rate': 1.6949152542372882e-06, 'epoch': 0.1}\n",
      "{'loss': 0.1692, 'grad_norm': 1.0536091327667236, 'learning_rate': 2.5423728813559323e-06, 'epoch': 0.15}\n",
      "{'loss': 0.1411, 'grad_norm': 0.6651315689086914, 'learning_rate': 3.3898305084745763e-06, 'epoch': 0.2}\n",
      "{'loss': 0.1205, 'grad_norm': 0.49128037691116333, 'learning_rate': 4.23728813559322e-06, 'epoch': 0.26}\n",
      "{'loss': 0.1067, 'grad_norm': 0.3164961040019989, 'learning_rate': 4.999955914361218e-06, 'epoch': 0.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9013015aa3414cd899e7f935aea5b8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07534877210855484, 'eval_roc_auc_micro': 0.7885882282125048, 'eval_pr_auc_micro': 0.2798177621583246, 'eval_roc_auc_macro': 0.7756032992222285, 'eval_pr_auc_macro': 0.29903620443892726, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.349, 'eval_samples_per_second': 2246.42, 'eval_steps_per_second': 37.249, 'epoch': 0.33}\n",
      "{'loss': 0.1181, 'grad_norm': 0.3952575922012329, 'learning_rate': 4.9946675187988104e-06, 'epoch': 0.36}\n",
      "{'loss': 0.1052, 'grad_norm': 0.3876678943634033, 'learning_rate': 4.980583362063697e-06, 'epoch': 0.41}\n",
      "{'loss': 0.1037, 'grad_norm': 0.33647778630256653, 'learning_rate': 4.957753102428184e-06, 'epoch': 0.46}\n",
      "{'loss': 0.1046, 'grad_norm': 0.4038802981376648, 'learning_rate': 4.926257235393077e-06, 'epoch': 0.51}\n",
      "{'loss': 0.0973, 'grad_norm': 0.32396626472473145, 'learning_rate': 4.8862068098746246e-06, 'epoch': 0.56}\n",
      "{'loss': 0.1075, 'grad_norm': 0.39712944626808167, 'learning_rate': 4.837743036665477e-06, 'epoch': 0.61}\n",
      "{'loss': 0.1018, 'grad_norm': 0.4229896664619446, 'learning_rate': 4.781036790550134e-06, 'epoch': 0.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f912b17410104655a4a67ddeb942723e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07464053481817245, 'eval_roc_auc_micro': 0.8112880641607613, 'eval_pr_auc_micro': 0.33246122719959004, 'eval_roc_auc_macro': 0.7940254732913248, 'eval_pr_auc_macro': 0.34659060050209445, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3399, 'eval_samples_per_second': 2306.253, 'eval_steps_per_second': 38.241, 'epoch': 0.66}\n",
      "{'loss': 0.1006, 'grad_norm': 0.37589171528816223, 'learning_rate': 4.716288007830357e-06, 'epoch': 0.71}\n",
      "{'loss': 0.0971, 'grad_norm': 0.4139067232608795, 'learning_rate': 4.6437249813847495e-06, 'epoch': 0.77}\n",
      "{'loss': 0.1024, 'grad_norm': 0.35268038511276245, 'learning_rate': 4.563603555748015e-06, 'epoch': 0.82}\n",
      "{'loss': 0.1004, 'grad_norm': 0.390546053647995, 'learning_rate': 4.476206225047889e-06, 'epoch': 0.87}\n",
      "{'loss': 0.101, 'grad_norm': 0.45121634006500244, 'learning_rate': 4.38184113698028e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0911, 'grad_norm': 0.3511559069156647, 'learning_rate': 4.280841006334403e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4646095d7a14b69939d2237720a6da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07161368429660797, 'eval_roc_auc_micro': 0.8205789153857987, 'eval_pr_auc_micro': 0.3551567273505325, 'eval_roc_auc_macro': 0.8022049038218076, 'eval_pr_auc_macro': 0.37527232221186413, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3429, 'eval_samples_per_second': 2286.484, 'eval_steps_per_second': 37.914, 'epoch': 0.99}\n",
      "{'loss': 0.092, 'grad_norm': 0.29313233494758606, 'learning_rate': 4.173561941898656e-06, 'epoch': 1.02}\n",
      "{'loss': 0.098, 'grad_norm': 0.36861470341682434, 'learning_rate': 4.0603821908833386e-06, 'epoch': 1.07}\n",
      "{'loss': 0.0893, 'grad_norm': 0.5592856407165527, 'learning_rate': 3.941700805287168e-06, 'epoch': 1.12}\n",
      "{'loss': 0.0952, 'grad_norm': 0.4476100504398346, 'learning_rate': 3.817936234909763e-06, 'epoch': 1.17}\n",
      "{'loss': 0.0972, 'grad_norm': 0.4539039731025696, 'learning_rate': 3.6895248519708552e-06, 'epoch': 1.22}\n",
      "{'loss': 0.0918, 'grad_norm': 0.26031556725502014, 'learning_rate': 3.5569194125382122e-06, 'epoch': 1.28}\n",
      "{'loss': 0.0961, 'grad_norm': 0.3514987826347351, 'learning_rate': 3.4205874601889465e-06, 'epoch': 1.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c788b355cd4a3d84daca44c4c94405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07054416835308075, 'eval_roc_auc_micro': 0.8240574907249137, 'eval_pr_auc_micro': 0.370362819755599, 'eval_roc_auc_macro': 0.807796297359063, 'eval_pr_auc_macro': 0.38762627308284264, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3392, 'eval_samples_per_second': 2311.566, 'eval_steps_per_second': 38.33, 'epoch': 1.33}\n",
      "{'loss': 0.0918, 'grad_norm': 0.3583292067050934, 'learning_rate': 3.2810096775326807e-06, 'epoch': 1.38}\n",
      "{'loss': 0.0889, 'grad_norm': 0.34692177176475525, 'learning_rate': 3.1386781914087644e-06, 'epoch': 1.43}\n",
      "{'loss': 0.0934, 'grad_norm': 0.3012702465057373, 'learning_rate': 2.9940948377331545e-06, 'epoch': 1.48}\n",
      "{'loss': 0.0929, 'grad_norm': 0.3520547151565552, 'learning_rate': 2.847769392112779e-06, 'epoch': 1.53}\n",
      "{'loss': 0.0923, 'grad_norm': 0.5159593224525452, 'learning_rate': 2.700217772465946e-06, 'epoch': 1.58}\n",
      "{'loss': 0.0868, 'grad_norm': 0.3591775894165039, 'learning_rate': 2.551960219986031e-06, 'epoch': 1.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effcd72cce0340ed8c16552398998017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0684095174074173, 'eval_roc_auc_micro': 0.827274390634241, 'eval_pr_auc_micro': 0.37393662499863045, 'eval_roc_auc_macro': 0.8095748699919506, 'eval_pr_auc_macro': 0.3931741120743659, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3367, 'eval_samples_per_second': 2328.786, 'eval_steps_per_second': 38.615, 'epoch': 1.66}\n",
      "{'loss': 0.0863, 'grad_norm': 0.2854832410812378, 'learning_rate': 2.4035194648620625e-06, 'epoch': 1.68}\n",
      "{'loss': 0.0923, 'grad_norm': 0.44905757904052734, 'learning_rate': 2.2554188832235363e-06, 'epoch': 1.73}\n",
      "{'loss': 0.0898, 'grad_norm': 0.3568965792655945, 'learning_rate': 2.1081806518077575e-06, 'epoch': 1.79}\n",
      "{'loss': 0.088, 'grad_norm': 0.4772495627403259, 'learning_rate': 1.9623239068560373e-06, 'epoch': 1.84}\n",
      "{'loss': 0.0915, 'grad_norm': 0.45554426312446594, 'learning_rate': 1.818362913730133e-06, 'epoch': 1.89}\n",
      "{'loss': 0.0895, 'grad_norm': 0.5670253038406372, 'learning_rate': 1.6768052537025697e-06, 'epoch': 1.94}\n",
      "{'loss': 0.0951, 'grad_norm': 0.4885518252849579, 'learning_rate': 1.5381500343138877e-06, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d205d40d62c444afab0de955948f6c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06880511343479156, 'eval_roc_auc_micro': 0.8290223968370594, 'eval_pr_auc_micro': 0.37923405145427447, 'eval_roc_auc_macro': 0.8125332375078992, 'eval_pr_auc_macro': 0.39728824657731304, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3403, 'eval_samples_per_second': 2304.081, 'eval_steps_per_second': 38.205, 'epoch': 1.99}\n",
      "{'loss': 0.0978, 'grad_norm': 0.3371701240539551, 'learning_rate': 1.4028861296067802e-06, 'epoch': 2.04}\n",
      "{'loss': 0.0913, 'grad_norm': 0.2902781069278717, 'learning_rate': 1.2714904564417623e-06, 'epoch': 2.09}\n",
      "{'loss': 0.0883, 'grad_norm': 0.3741152286529541, 'learning_rate': 1.1444262929717627e-06, 'epoch': 2.14}\n",
      "{'loss': 0.0936, 'grad_norm': 0.5421854853630066, 'learning_rate': 1.0221416452044237e-06, 'epoch': 2.19}\n",
      "{'loss': 0.0819, 'grad_norm': 0.3089121878147125, 'learning_rate': 9.050676674113071e-07, 'epoch': 2.24}\n",
      "{'loss': 0.0992, 'grad_norm': 0.35272493958473206, 'learning_rate': 7.936171419533653e-07, 'epoch': 2.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5c0006a82a4a1ea1797492df039b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06877640634775162, 'eval_roc_auc_micro': 0.8314369528224639, 'eval_pr_auc_micro': 0.3838198950214917, 'eval_roc_auc_macro': 0.8147758372724865, 'eval_pr_auc_macro': 0.398820489012998, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3394, 'eval_samples_per_second': 2309.747, 'eval_steps_per_second': 38.299, 'epoch': 2.32}\n",
      "{'loss': 0.088, 'grad_norm': 0.43915873765945435, 'learning_rate': 6.881830238825699e-07, 'epoch': 2.35}\n",
      "{'loss': 0.089, 'grad_norm': 0.48133981227874756, 'learning_rate': 5.891370554511519e-07, 'epoch': 2.4}\n",
      "{'loss': 0.0889, 'grad_norm': 0.3496638536453247, 'learning_rate': 4.968284554134653e-07, 'epoch': 2.45}\n",
      "{'loss': 0.085, 'grad_norm': 0.3341969847679138, 'learning_rate': 4.115826877417631e-07, 'epoch': 2.5}\n",
      "{'loss': 0.0873, 'grad_norm': 0.35611292719841003, 'learning_rate': 3.3370031409717755e-07, 'epoch': 2.55}\n",
      "{'loss': 0.0914, 'grad_norm': 0.43154242634773254, 'learning_rate': 2.634559341018947e-07, 'epoch': 2.6}\n",
      "{'loss': 0.0872, 'grad_norm': 0.403942346572876, 'learning_rate': 2.0109721714893283e-07, 'epoch': 2.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284a849245a34e929689c64501aabff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06838088482618332, 'eval_roc_auc_micro': 0.8310225239126675, 'eval_pr_auc_micro': 0.38316150437072427, 'eval_roc_auc_macro': 0.814825774227366, 'eval_pr_auc_macro': 0.39984044057920687, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3347, 'eval_samples_per_second': 2342.232, 'eval_steps_per_second': 38.838, 'epoch': 2.65}\n",
      "{'loss': 0.0997, 'grad_norm': 0.6122041940689087, 'learning_rate': 1.468440291631984e-07, 'epoch': 2.7}\n",
      "{'loss': 0.0848, 'grad_norm': 0.2933502793312073, 'learning_rate': 1.0088765739270479e-07, 'epoch': 2.76}\n",
      "{'loss': 0.0899, 'grad_norm': 0.5001567006111145, 'learning_rate': 6.339013596320692e-08, 'epoch': 2.81}\n",
      "{'loss': 0.0891, 'grad_norm': 0.46312215924263, 'learning_rate': 3.448367457422497e-08, 'epoch': 2.86}\n",
      "{'loss': 0.0924, 'grad_norm': 0.39496850967407227, 'learning_rate': 1.4270192350775703e-08, 'epoch': 2.91}\n",
      "{'loss': 0.088, 'grad_norm': 0.4660615622997284, 'learning_rate': 2.820958494373083e-09, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc31dc2c897744b8817435bc4f029b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06848151236772537, 'eval_roc_auc_micro': 0.8312925595798287, 'eval_pr_auc_micro': 0.3840257925548896, 'eval_roc_auc_macro': 0.8150552904477685, 'eval_pr_auc_macro': 0.40023350945124253, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.337, 'eval_samples_per_second': 2326.654, 'eval_steps_per_second': 38.58, 'epoch': 2.98}\n",
      "{'train_runtime': 31.191, 'train_samples_per_second': 602.481, 'train_steps_per_second': 18.852, 'train_loss': 0.10037784663592877, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814b64912ec846f1b72c261fb541704e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 6] VAL pr_auc_macro=nan | dur=0.5 min\n",
      "\n",
      "[Trial 7] cfg={'loss': 'asl', 'learning_rate': 5e-06, 'weight_decay': 0.0, 'warmup_ratio': 0.1, 'batch_size': 32, 'max_length': 128, 'label_smoothing': 0.0, 'llrd_enable': False, 'llrd_decay': 0.95, 'augment': False, 'gamma_pos': 2.0, 'gamma_neg': 1.0, 'clip': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2752f2cde0514b14b08e23e5d4d5b5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2068, 'grad_norm': 1.2781728506088257, 'learning_rate': 8.474576271186441e-07, 'epoch': 0.05}\n",
      "{'loss': 0.2036, 'grad_norm': 1.2967710494995117, 'learning_rate': 1.6949152542372882e-06, 'epoch': 0.1}\n",
      "{'loss': 0.1692, 'grad_norm': 1.0536091327667236, 'learning_rate': 2.5423728813559323e-06, 'epoch': 0.15}\n",
      "{'loss': 0.1411, 'grad_norm': 0.6651315689086914, 'learning_rate': 3.3898305084745763e-06, 'epoch': 0.2}\n",
      "{'loss': 0.1205, 'grad_norm': 0.49128037691116333, 'learning_rate': 4.23728813559322e-06, 'epoch': 0.26}\n",
      "{'loss': 0.1067, 'grad_norm': 0.3164961040019989, 'learning_rate': 4.999955914361218e-06, 'epoch': 0.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258f0ad15b844e21952d97a55c9e583a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07534877210855484, 'eval_roc_auc_micro': 0.7885882282125048, 'eval_pr_auc_micro': 0.2798177621583246, 'eval_roc_auc_macro': 0.7756032992222285, 'eval_pr_auc_macro': 0.29903620443892726, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3365, 'eval_samples_per_second': 2329.821, 'eval_steps_per_second': 38.632, 'epoch': 0.33}\n",
      "{'loss': 0.1181, 'grad_norm': 0.3952575922012329, 'learning_rate': 4.9946675187988104e-06, 'epoch': 0.36}\n",
      "{'loss': 0.1052, 'grad_norm': 0.3876678943634033, 'learning_rate': 4.980583362063697e-06, 'epoch': 0.41}\n",
      "{'loss': 0.1037, 'grad_norm': 0.33647778630256653, 'learning_rate': 4.957753102428184e-06, 'epoch': 0.46}\n",
      "{'loss': 0.1046, 'grad_norm': 0.4038802981376648, 'learning_rate': 4.926257235393077e-06, 'epoch': 0.51}\n",
      "{'loss': 0.0973, 'grad_norm': 0.32396626472473145, 'learning_rate': 4.8862068098746246e-06, 'epoch': 0.56}\n",
      "{'loss': 0.1075, 'grad_norm': 0.39712944626808167, 'learning_rate': 4.837743036665477e-06, 'epoch': 0.61}\n",
      "{'loss': 0.1018, 'grad_norm': 0.4229896664619446, 'learning_rate': 4.781036790550134e-06, 'epoch': 0.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a16bf6d18a045f8b13488424b42a0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07464053481817245, 'eval_roc_auc_micro': 0.8112880641607613, 'eval_pr_auc_micro': 0.33246122719959004, 'eval_roc_auc_macro': 0.7940254732913248, 'eval_pr_auc_macro': 0.34659060050209445, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.336, 'eval_samples_per_second': 2333.32, 'eval_steps_per_second': 38.69, 'epoch': 0.66}\n",
      "{'loss': 0.1006, 'grad_norm': 0.37589171528816223, 'learning_rate': 4.716288007830357e-06, 'epoch': 0.71}\n",
      "{'loss': 0.0971, 'grad_norm': 0.4139067232608795, 'learning_rate': 4.6437249813847495e-06, 'epoch': 0.77}\n",
      "{'loss': 0.1024, 'grad_norm': 0.35268038511276245, 'learning_rate': 4.563603555748015e-06, 'epoch': 0.82}\n",
      "{'loss': 0.1004, 'grad_norm': 0.390546053647995, 'learning_rate': 4.476206225047889e-06, 'epoch': 0.87}\n",
      "{'loss': 0.101, 'grad_norm': 0.45121634006500244, 'learning_rate': 4.38184113698028e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0911, 'grad_norm': 0.3511559069156647, 'learning_rate': 4.280841006334403e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02af51ff46ea49eea6e2c93e61ccf20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07161368429660797, 'eval_roc_auc_micro': 0.8205789153857987, 'eval_pr_auc_micro': 0.3551567273505325, 'eval_roc_auc_macro': 0.8022049038218076, 'eval_pr_auc_macro': 0.37527232221186413, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3359, 'eval_samples_per_second': 2333.832, 'eval_steps_per_second': 38.699, 'epoch': 0.99}\n",
      "{'loss': 0.092, 'grad_norm': 0.29313233494758606, 'learning_rate': 4.173561941898656e-06, 'epoch': 1.02}\n",
      "{'loss': 0.098, 'grad_norm': 0.36861470341682434, 'learning_rate': 4.0603821908833386e-06, 'epoch': 1.07}\n",
      "{'loss': 0.0893, 'grad_norm': 0.5592856407165527, 'learning_rate': 3.941700805287168e-06, 'epoch': 1.12}\n",
      "{'loss': 0.0952, 'grad_norm': 0.4476100504398346, 'learning_rate': 3.817936234909763e-06, 'epoch': 1.17}\n",
      "{'loss': 0.0972, 'grad_norm': 0.4539039731025696, 'learning_rate': 3.6895248519708552e-06, 'epoch': 1.22}\n",
      "{'loss': 0.0918, 'grad_norm': 0.26031556725502014, 'learning_rate': 3.5569194125382122e-06, 'epoch': 1.28}\n",
      "{'loss': 0.0961, 'grad_norm': 0.3514987826347351, 'learning_rate': 3.4205874601889465e-06, 'epoch': 1.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e022caa698e4e93952c87f904bd1aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07054416835308075, 'eval_roc_auc_micro': 0.8240574907249137, 'eval_pr_auc_micro': 0.370362819755599, 'eval_roc_auc_macro': 0.807796297359063, 'eval_pr_auc_macro': 0.38762627308284264, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3377, 'eval_samples_per_second': 2321.344, 'eval_steps_per_second': 38.492, 'epoch': 1.33}\n",
      "{'loss': 0.0918, 'grad_norm': 0.3583292067050934, 'learning_rate': 3.2810096775326807e-06, 'epoch': 1.38}\n",
      "{'loss': 0.0889, 'grad_norm': 0.34692177176475525, 'learning_rate': 3.1386781914087644e-06, 'epoch': 1.43}\n",
      "{'loss': 0.0934, 'grad_norm': 0.3012702465057373, 'learning_rate': 2.9940948377331545e-06, 'epoch': 1.48}\n",
      "{'loss': 0.0929, 'grad_norm': 0.3520547151565552, 'learning_rate': 2.847769392112779e-06, 'epoch': 1.53}\n",
      "{'loss': 0.0923, 'grad_norm': 0.5159593224525452, 'learning_rate': 2.700217772465946e-06, 'epoch': 1.58}\n",
      "{'loss': 0.0868, 'grad_norm': 0.3591775894165039, 'learning_rate': 2.551960219986031e-06, 'epoch': 1.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a6f1050da9457393f60c2a7ee1ea97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0684095174074173, 'eval_roc_auc_micro': 0.827274390634241, 'eval_pr_auc_micro': 0.37393662499863045, 'eval_roc_auc_macro': 0.8095748699919506, 'eval_pr_auc_macro': 0.3931741120743659, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3457, 'eval_samples_per_second': 2267.984, 'eval_steps_per_second': 37.607, 'epoch': 1.66}\n",
      "{'loss': 0.0863, 'grad_norm': 0.2854832410812378, 'learning_rate': 2.4035194648620625e-06, 'epoch': 1.68}\n",
      "{'loss': 0.0923, 'grad_norm': 0.44905757904052734, 'learning_rate': 2.2554188832235363e-06, 'epoch': 1.73}\n",
      "{'loss': 0.0898, 'grad_norm': 0.3568965792655945, 'learning_rate': 2.1081806518077575e-06, 'epoch': 1.79}\n",
      "{'loss': 0.088, 'grad_norm': 0.4772495627403259, 'learning_rate': 1.9623239068560373e-06, 'epoch': 1.84}\n",
      "{'loss': 0.0915, 'grad_norm': 0.45554426312446594, 'learning_rate': 1.818362913730133e-06, 'epoch': 1.89}\n",
      "{'loss': 0.0895, 'grad_norm': 0.5670253038406372, 'learning_rate': 1.6768052537025697e-06, 'epoch': 1.94}\n",
      "{'loss': 0.0951, 'grad_norm': 0.4885518252849579, 'learning_rate': 1.5381500343138877e-06, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76757a522ea647839db3fc85d6064a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06880511343479156, 'eval_roc_auc_micro': 0.8290223968370594, 'eval_pr_auc_micro': 0.37923405145427447, 'eval_roc_auc_macro': 0.8125332375078992, 'eval_pr_auc_macro': 0.39728824657731304, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3463, 'eval_samples_per_second': 2263.619, 'eval_steps_per_second': 37.534, 'epoch': 1.99}\n",
      "{'loss': 0.0978, 'grad_norm': 0.3371701240539551, 'learning_rate': 1.4028861296067802e-06, 'epoch': 2.04}\n",
      "{'loss': 0.0913, 'grad_norm': 0.2902781069278717, 'learning_rate': 1.2714904564417623e-06, 'epoch': 2.09}\n",
      "{'loss': 0.0883, 'grad_norm': 0.3741152286529541, 'learning_rate': 1.1444262929717627e-06, 'epoch': 2.14}\n",
      "{'loss': 0.0936, 'grad_norm': 0.5421854853630066, 'learning_rate': 1.0221416452044237e-06, 'epoch': 2.19}\n",
      "{'loss': 0.0819, 'grad_norm': 0.3089121878147125, 'learning_rate': 9.050676674113071e-07, 'epoch': 2.24}\n",
      "{'loss': 0.0992, 'grad_norm': 0.35272493958473206, 'learning_rate': 7.936171419533653e-07, 'epoch': 2.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1408aba40dad44ecb3402e29f6239f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06877640634775162, 'eval_roc_auc_micro': 0.8314369528224639, 'eval_pr_auc_micro': 0.3838198950214917, 'eval_roc_auc_macro': 0.8147758372724865, 'eval_pr_auc_macro': 0.398820489012998, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3494, 'eval_samples_per_second': 2244.137, 'eval_steps_per_second': 37.211, 'epoch': 2.32}\n",
      "{'loss': 0.088, 'grad_norm': 0.43915873765945435, 'learning_rate': 6.881830238825699e-07, 'epoch': 2.35}\n",
      "{'loss': 0.089, 'grad_norm': 0.48133981227874756, 'learning_rate': 5.891370554511519e-07, 'epoch': 2.4}\n",
      "{'loss': 0.0889, 'grad_norm': 0.3496638536453247, 'learning_rate': 4.968284554134653e-07, 'epoch': 2.45}\n",
      "{'loss': 0.085, 'grad_norm': 0.3341969847679138, 'learning_rate': 4.115826877417631e-07, 'epoch': 2.5}\n",
      "{'loss': 0.0873, 'grad_norm': 0.35611292719841003, 'learning_rate': 3.3370031409717755e-07, 'epoch': 2.55}\n",
      "{'loss': 0.0914, 'grad_norm': 0.43154242634773254, 'learning_rate': 2.634559341018947e-07, 'epoch': 2.6}\n",
      "{'loss': 0.0872, 'grad_norm': 0.403942346572876, 'learning_rate': 2.0109721714893283e-07, 'epoch': 2.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99edcd4484994b1db3d0e013a33de6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06838088482618332, 'eval_roc_auc_micro': 0.8310225239126675, 'eval_pr_auc_micro': 0.38316150437072427, 'eval_roc_auc_macro': 0.814825774227366, 'eval_pr_auc_macro': 0.39984044057920687, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.348, 'eval_samples_per_second': 2252.861, 'eval_steps_per_second': 37.356, 'epoch': 2.65}\n",
      "{'loss': 0.0997, 'grad_norm': 0.6122041940689087, 'learning_rate': 1.468440291631984e-07, 'epoch': 2.7}\n",
      "{'loss': 0.0848, 'grad_norm': 0.2933502793312073, 'learning_rate': 1.0088765739270479e-07, 'epoch': 2.76}\n",
      "{'loss': 0.0899, 'grad_norm': 0.5001567006111145, 'learning_rate': 6.339013596320692e-08, 'epoch': 2.81}\n",
      "{'loss': 0.0891, 'grad_norm': 0.46312215924263, 'learning_rate': 3.448367457422497e-08, 'epoch': 2.86}\n",
      "{'loss': 0.0924, 'grad_norm': 0.39496850967407227, 'learning_rate': 1.4270192350775703e-08, 'epoch': 2.91}\n",
      "{'loss': 0.088, 'grad_norm': 0.4660615622997284, 'learning_rate': 2.820958494373083e-09, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88977aab897a4bb0aa70d855ca17e7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06848151236772537, 'eval_roc_auc_micro': 0.8312925595798287, 'eval_pr_auc_micro': 0.3840257925548896, 'eval_roc_auc_macro': 0.8150552904477685, 'eval_pr_auc_macro': 0.40023350945124253, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.346, 'eval_samples_per_second': 2265.892, 'eval_steps_per_second': 37.572, 'epoch': 2.98}\n",
      "{'train_runtime': 31.9768, 'train_samples_per_second': 587.677, 'train_steps_per_second': 18.388, 'train_loss': 0.10037784663592877, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6253cd7dab7f4e4da03f613bf025303b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 7] VAL pr_auc_macro=nan | dur=0.5 min\n",
      "\n",
      "[Trial 8] cfg={'loss': 'asl', 'learning_rate': 5e-06, 'weight_decay': 0.0, 'warmup_ratio': 0.1, 'batch_size': 32, 'max_length': 128, 'label_smoothing': 0.0, 'llrd_enable': False, 'llrd_decay': 0.95, 'augment': False, 'gamma_pos': 2.0, 'gamma_neg': 1.0, 'clip': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd057e3ca6949f6b904da12327e6005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2068, 'grad_norm': 1.2781728506088257, 'learning_rate': 8.474576271186441e-07, 'epoch': 0.05}\n",
      "{'loss': 0.2036, 'grad_norm': 1.2967710494995117, 'learning_rate': 1.6949152542372882e-06, 'epoch': 0.1}\n",
      "{'loss': 0.1692, 'grad_norm': 1.0536091327667236, 'learning_rate': 2.5423728813559323e-06, 'epoch': 0.15}\n",
      "{'loss': 0.1411, 'grad_norm': 0.6651315689086914, 'learning_rate': 3.3898305084745763e-06, 'epoch': 0.2}\n",
      "{'loss': 0.1205, 'grad_norm': 0.49128037691116333, 'learning_rate': 4.23728813559322e-06, 'epoch': 0.26}\n",
      "{'loss': 0.1067, 'grad_norm': 0.3164961040019989, 'learning_rate': 4.999955914361218e-06, 'epoch': 0.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c7abea57b34ec59419cd35297d0e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07534877210855484, 'eval_roc_auc_micro': 0.7885882282125048, 'eval_pr_auc_micro': 0.2798177621583246, 'eval_roc_auc_macro': 0.7756032992222285, 'eval_pr_auc_macro': 0.29903620443892726, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.352, 'eval_samples_per_second': 2227.289, 'eval_steps_per_second': 36.932, 'epoch': 0.33}\n",
      "{'loss': 0.1181, 'grad_norm': 0.3952575922012329, 'learning_rate': 4.9946675187988104e-06, 'epoch': 0.36}\n",
      "{'loss': 0.1052, 'grad_norm': 0.3876678943634033, 'learning_rate': 4.980583362063697e-06, 'epoch': 0.41}\n",
      "{'loss': 0.1037, 'grad_norm': 0.33647778630256653, 'learning_rate': 4.957753102428184e-06, 'epoch': 0.46}\n",
      "{'loss': 0.1046, 'grad_norm': 0.4038802981376648, 'learning_rate': 4.926257235393077e-06, 'epoch': 0.51}\n",
      "{'loss': 0.0973, 'grad_norm': 0.32396626472473145, 'learning_rate': 4.8862068098746246e-06, 'epoch': 0.56}\n",
      "{'loss': 0.1075, 'grad_norm': 0.39712944626808167, 'learning_rate': 4.837743036665477e-06, 'epoch': 0.61}\n",
      "{'loss': 0.1018, 'grad_norm': 0.4229896664619446, 'learning_rate': 4.781036790550134e-06, 'epoch': 0.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43b8d3077904439a2fabcb8fdd49b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07464053481817245, 'eval_roc_auc_micro': 0.8112880641607613, 'eval_pr_auc_micro': 0.33246122719959004, 'eval_roc_auc_macro': 0.7940254732913248, 'eval_pr_auc_macro': 0.34659060050209445, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.326, 'eval_samples_per_second': 2404.838, 'eval_steps_per_second': 39.876, 'epoch': 0.66}\n",
      "{'loss': 0.1006, 'grad_norm': 0.37589171528816223, 'learning_rate': 4.716288007830357e-06, 'epoch': 0.71}\n",
      "{'loss': 0.0971, 'grad_norm': 0.4139067232608795, 'learning_rate': 4.6437249813847495e-06, 'epoch': 0.77}\n",
      "{'loss': 0.1024, 'grad_norm': 0.35268038511276245, 'learning_rate': 4.563603555748015e-06, 'epoch': 0.82}\n",
      "{'loss': 0.1004, 'grad_norm': 0.390546053647995, 'learning_rate': 4.476206225047889e-06, 'epoch': 0.87}\n",
      "{'loss': 0.101, 'grad_norm': 0.45121634006500244, 'learning_rate': 4.38184113698028e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0911, 'grad_norm': 0.3511559069156647, 'learning_rate': 4.280841006334403e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6a2b5fcb374f92ba07266ffe2764f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07161368429660797, 'eval_roc_auc_micro': 0.8205789153857987, 'eval_pr_auc_micro': 0.3551567273505325, 'eval_roc_auc_macro': 0.8022049038218076, 'eval_pr_auc_macro': 0.37527232221186413, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.323, 'eval_samples_per_second': 2427.238, 'eval_steps_per_second': 40.248, 'epoch': 0.99}\n",
      "{'loss': 0.092, 'grad_norm': 0.29313233494758606, 'learning_rate': 4.173561941898656e-06, 'epoch': 1.02}\n",
      "{'loss': 0.098, 'grad_norm': 0.36861470341682434, 'learning_rate': 4.0603821908833386e-06, 'epoch': 1.07}\n",
      "{'loss': 0.0893, 'grad_norm': 0.5592856407165527, 'learning_rate': 3.941700805287168e-06, 'epoch': 1.12}\n",
      "{'loss': 0.0952, 'grad_norm': 0.4476100504398346, 'learning_rate': 3.817936234909763e-06, 'epoch': 1.17}\n",
      "{'loss': 0.0972, 'grad_norm': 0.4539039731025696, 'learning_rate': 3.6895248519708552e-06, 'epoch': 1.22}\n",
      "{'loss': 0.0918, 'grad_norm': 0.26031556725502014, 'learning_rate': 3.5569194125382122e-06, 'epoch': 1.28}\n",
      "{'loss': 0.0961, 'grad_norm': 0.3514987826347351, 'learning_rate': 3.4205874601889465e-06, 'epoch': 1.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd0d772ab00489fac18417bb3e7bfc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07054416835308075, 'eval_roc_auc_micro': 0.8240574907249137, 'eval_pr_auc_micro': 0.370362819755599, 'eval_roc_auc_macro': 0.807796297359063, 'eval_pr_auc_macro': 0.38762627308284264, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.318, 'eval_samples_per_second': 2465.414, 'eval_steps_per_second': 40.881, 'epoch': 1.33}\n",
      "{'loss': 0.0918, 'grad_norm': 0.3583292067050934, 'learning_rate': 3.2810096775326807e-06, 'epoch': 1.38}\n",
      "{'loss': 0.0889, 'grad_norm': 0.34692177176475525, 'learning_rate': 3.1386781914087644e-06, 'epoch': 1.43}\n",
      "{'loss': 0.0934, 'grad_norm': 0.3012702465057373, 'learning_rate': 2.9940948377331545e-06, 'epoch': 1.48}\n",
      "{'loss': 0.0929, 'grad_norm': 0.3520547151565552, 'learning_rate': 2.847769392112779e-06, 'epoch': 1.53}\n",
      "{'loss': 0.0923, 'grad_norm': 0.5159593224525452, 'learning_rate': 2.700217772465946e-06, 'epoch': 1.58}\n",
      "{'loss': 0.0868, 'grad_norm': 0.3591775894165039, 'learning_rate': 2.551960219986031e-06, 'epoch': 1.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c4a1d86a504c62a8008a9d06354bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0684095174074173, 'eval_roc_auc_micro': 0.827274390634241, 'eval_pr_auc_micro': 0.37393662499863045, 'eval_roc_auc_macro': 0.8095748699919506, 'eval_pr_auc_macro': 0.3931741120743659, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.322, 'eval_samples_per_second': 2434.781, 'eval_steps_per_second': 40.373, 'epoch': 1.66}\n",
      "{'loss': 0.0863, 'grad_norm': 0.2854832410812378, 'learning_rate': 2.4035194648620625e-06, 'epoch': 1.68}\n",
      "{'loss': 0.0923, 'grad_norm': 0.44905757904052734, 'learning_rate': 2.2554188832235363e-06, 'epoch': 1.73}\n",
      "{'loss': 0.0898, 'grad_norm': 0.3568965792655945, 'learning_rate': 2.1081806518077575e-06, 'epoch': 1.79}\n",
      "{'loss': 0.088, 'grad_norm': 0.4772495627403259, 'learning_rate': 1.9623239068560373e-06, 'epoch': 1.84}\n",
      "{'loss': 0.0915, 'grad_norm': 0.45554426312446594, 'learning_rate': 1.818362913730133e-06, 'epoch': 1.89}\n",
      "{'loss': 0.0895, 'grad_norm': 0.5670253038406372, 'learning_rate': 1.6768052537025697e-06, 'epoch': 1.94}\n",
      "{'loss': 0.0951, 'grad_norm': 0.4885518252849579, 'learning_rate': 1.5381500343138877e-06, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92db39f04734f7cac13fad37879ec2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06880511343479156, 'eval_roc_auc_micro': 0.8290223968370594, 'eval_pr_auc_micro': 0.37923405145427447, 'eval_roc_auc_macro': 0.8125332375078992, 'eval_pr_auc_macro': 0.39728824657731304, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3268, 'eval_samples_per_second': 2398.863, 'eval_steps_per_second': 39.777, 'epoch': 1.99}\n",
      "{'loss': 0.0978, 'grad_norm': 0.3371701240539551, 'learning_rate': 1.4028861296067802e-06, 'epoch': 2.04}\n",
      "{'loss': 0.0913, 'grad_norm': 0.2902781069278717, 'learning_rate': 1.2714904564417623e-06, 'epoch': 2.09}\n",
      "{'loss': 0.0883, 'grad_norm': 0.3741152286529541, 'learning_rate': 1.1444262929717627e-06, 'epoch': 2.14}\n",
      "{'loss': 0.0936, 'grad_norm': 0.5421854853630066, 'learning_rate': 1.0221416452044237e-06, 'epoch': 2.19}\n",
      "{'loss': 0.0819, 'grad_norm': 0.3089121878147125, 'learning_rate': 9.050676674113071e-07, 'epoch': 2.24}\n",
      "{'loss': 0.0992, 'grad_norm': 0.35272493958473206, 'learning_rate': 7.936171419533653e-07, 'epoch': 2.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38014cff4fd04ba881809ea99eb933e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06877640634775162, 'eval_roc_auc_micro': 0.8314369528224639, 'eval_pr_auc_micro': 0.3838198950214917, 'eval_roc_auc_macro': 0.8147758372724865, 'eval_pr_auc_macro': 0.398820489012998, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3223, 'eval_samples_per_second': 2432.844, 'eval_steps_per_second': 40.341, 'epoch': 2.32}\n",
      "{'loss': 0.088, 'grad_norm': 0.43915873765945435, 'learning_rate': 6.881830238825699e-07, 'epoch': 2.35}\n",
      "{'loss': 0.089, 'grad_norm': 0.48133981227874756, 'learning_rate': 5.891370554511519e-07, 'epoch': 2.4}\n",
      "{'loss': 0.0889, 'grad_norm': 0.3496638536453247, 'learning_rate': 4.968284554134653e-07, 'epoch': 2.45}\n",
      "{'loss': 0.085, 'grad_norm': 0.3341969847679138, 'learning_rate': 4.115826877417631e-07, 'epoch': 2.5}\n",
      "{'loss': 0.0873, 'grad_norm': 0.35611292719841003, 'learning_rate': 3.3370031409717755e-07, 'epoch': 2.55}\n",
      "{'loss': 0.0914, 'grad_norm': 0.43154242634773254, 'learning_rate': 2.634559341018947e-07, 'epoch': 2.6}\n",
      "{'loss': 0.0872, 'grad_norm': 0.403942346572876, 'learning_rate': 2.0109721714893283e-07, 'epoch': 2.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d86bf3102834a709391e69cfd0838f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06838088482618332, 'eval_roc_auc_micro': 0.8310225239126675, 'eval_pr_auc_micro': 0.38316150437072427, 'eval_roc_auc_macro': 0.814825774227366, 'eval_pr_auc_macro': 0.39984044057920687, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.319, 'eval_samples_per_second': 2457.682, 'eval_steps_per_second': 40.752, 'epoch': 2.65}\n",
      "{'loss': 0.0997, 'grad_norm': 0.6122041940689087, 'learning_rate': 1.468440291631984e-07, 'epoch': 2.7}\n",
      "{'loss': 0.0848, 'grad_norm': 0.2933502793312073, 'learning_rate': 1.0088765739270479e-07, 'epoch': 2.76}\n",
      "{'loss': 0.0899, 'grad_norm': 0.5001567006111145, 'learning_rate': 6.339013596320692e-08, 'epoch': 2.81}\n",
      "{'loss': 0.0891, 'grad_norm': 0.46312215924263, 'learning_rate': 3.448367457422497e-08, 'epoch': 2.86}\n",
      "{'loss': 0.0924, 'grad_norm': 0.39496850967407227, 'learning_rate': 1.4270192350775703e-08, 'epoch': 2.91}\n",
      "{'loss': 0.088, 'grad_norm': 0.4660615622997284, 'learning_rate': 2.820958494373083e-09, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87cf2bc869ff4f768227a6e5f2fe00c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06848151236772537, 'eval_roc_auc_micro': 0.8312925595798287, 'eval_pr_auc_micro': 0.3840257925548896, 'eval_roc_auc_macro': 0.8150552904477685, 'eval_pr_auc_macro': 0.40023350945124253, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.321, 'eval_samples_per_second': 2442.369, 'eval_steps_per_second': 40.498, 'epoch': 2.98}\n",
      "{'train_runtime': 30.0623, 'train_samples_per_second': 625.103, 'train_steps_per_second': 19.559, 'train_loss': 0.10037784663592877, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f690cadf91e146128f2d765d46aae210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 8] VAL pr_auc_macro=nan | dur=0.5 min\n",
      "\n",
      "[Trial 9] cfg={'loss': 'asl', 'learning_rate': 5e-06, 'weight_decay': 0.0, 'warmup_ratio': 0.1, 'batch_size': 32, 'max_length': 128, 'label_smoothing': 0.0, 'llrd_enable': False, 'llrd_decay': 0.95, 'augment': False, 'gamma_pos': 2.0, 'gamma_neg': 1.0, 'clip': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd88afae1f7b43c2835916152766c34a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2068, 'grad_norm': 1.2781728506088257, 'learning_rate': 8.474576271186441e-07, 'epoch': 0.05}\n",
      "{'loss': 0.2036, 'grad_norm': 1.2967710494995117, 'learning_rate': 1.6949152542372882e-06, 'epoch': 0.1}\n",
      "{'loss': 0.1692, 'grad_norm': 1.0536091327667236, 'learning_rate': 2.5423728813559323e-06, 'epoch': 0.15}\n",
      "{'loss': 0.1411, 'grad_norm': 0.6651315689086914, 'learning_rate': 3.3898305084745763e-06, 'epoch': 0.2}\n",
      "{'loss': 0.1205, 'grad_norm': 0.49128037691116333, 'learning_rate': 4.23728813559322e-06, 'epoch': 0.26}\n",
      "{'loss': 0.1067, 'grad_norm': 0.3164961040019989, 'learning_rate': 4.999955914361218e-06, 'epoch': 0.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14dbca80abde46eba338652fa0120baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07534877210855484, 'eval_roc_auc_micro': 0.7885882282125048, 'eval_pr_auc_micro': 0.2798177621583246, 'eval_roc_auc_macro': 0.7756032992222285, 'eval_pr_auc_macro': 0.29903620443892726, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.3261, 'eval_samples_per_second': 2404.527, 'eval_steps_per_second': 39.871, 'epoch': 0.33}\n",
      "{'loss': 0.1181, 'grad_norm': 0.3952575922012329, 'learning_rate': 4.9946675187988104e-06, 'epoch': 0.36}\n",
      "{'loss': 0.1052, 'grad_norm': 0.3876678943634033, 'learning_rate': 4.980583362063697e-06, 'epoch': 0.41}\n",
      "{'loss': 0.1037, 'grad_norm': 0.33647778630256653, 'learning_rate': 4.957753102428184e-06, 'epoch': 0.46}\n",
      "{'loss': 0.1046, 'grad_norm': 0.4038802981376648, 'learning_rate': 4.926257235393077e-06, 'epoch': 0.51}\n",
      "{'loss': 0.0973, 'grad_norm': 0.32396626472473145, 'learning_rate': 4.8862068098746246e-06, 'epoch': 0.56}\n",
      "{'loss': 0.1075, 'grad_norm': 0.39712944626808167, 'learning_rate': 4.837743036665477e-06, 'epoch': 0.61}\n",
      "{'loss': 0.1018, 'grad_norm': 0.4229896664619446, 'learning_rate': 4.781036790550134e-06, 'epoch': 0.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e67d2bf53f4b469d7d3807fb763711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07464053481817245, 'eval_roc_auc_micro': 0.8112880641607613, 'eval_pr_auc_micro': 0.33246122719959004, 'eval_roc_auc_macro': 0.7940254732913248, 'eval_pr_auc_macro': 0.34659060050209445, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.323, 'eval_samples_per_second': 2427.232, 'eval_steps_per_second': 40.247, 'epoch': 0.66}\n",
      "{'loss': 0.1006, 'grad_norm': 0.37589171528816223, 'learning_rate': 4.716288007830357e-06, 'epoch': 0.71}\n",
      "{'loss': 0.0971, 'grad_norm': 0.4139067232608795, 'learning_rate': 4.6437249813847495e-06, 'epoch': 0.77}\n",
      "{'loss': 0.1024, 'grad_norm': 0.35268038511276245, 'learning_rate': 4.563603555748015e-06, 'epoch': 0.82}\n",
      "{'loss': 0.1004, 'grad_norm': 0.390546053647995, 'learning_rate': 4.476206225047889e-06, 'epoch': 0.87}\n",
      "{'loss': 0.101, 'grad_norm': 0.45121634006500244, 'learning_rate': 4.38184113698028e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0911, 'grad_norm': 0.3511559069156647, 'learning_rate': 4.280841006334403e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709f9ca903b944d7a071b5d6dd324e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07161368429660797, 'eval_roc_auc_micro': 0.8205789153857987, 'eval_pr_auc_micro': 0.3551567273505325, 'eval_roc_auc_macro': 0.8022049038218076, 'eval_pr_auc_macro': 0.37527232221186413, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.322, 'eval_samples_per_second': 2434.768, 'eval_steps_per_second': 40.372, 'epoch': 0.99}\n",
      "{'loss': 0.092, 'grad_norm': 0.29313233494758606, 'learning_rate': 4.173561941898656e-06, 'epoch': 1.02}\n",
      "{'loss': 0.098, 'grad_norm': 0.36861470341682434, 'learning_rate': 4.0603821908833386e-06, 'epoch': 1.07}\n",
      "{'loss': 0.0893, 'grad_norm': 0.5592856407165527, 'learning_rate': 3.941700805287168e-06, 'epoch': 1.12}\n",
      "{'loss': 0.0952, 'grad_norm': 0.4476100504398346, 'learning_rate': 3.817936234909763e-06, 'epoch': 1.17}\n",
      "{'loss': 0.0972, 'grad_norm': 0.4539039731025696, 'learning_rate': 3.6895248519708552e-06, 'epoch': 1.22}\n",
      "{'loss': 0.0918, 'grad_norm': 0.26031556725502014, 'learning_rate': 3.5569194125382122e-06, 'epoch': 1.28}\n",
      "{'loss': 0.0961, 'grad_norm': 0.3514987826347351, 'learning_rate': 3.4205874601889465e-06, 'epoch': 1.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0e9fdb5d1e49a197adcd225a82b133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07054416835308075, 'eval_roc_auc_micro': 0.8240574907249137, 'eval_pr_auc_micro': 0.370362819755599, 'eval_roc_auc_macro': 0.807796297359063, 'eval_pr_auc_macro': 0.38762627308284264, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.319, 'eval_samples_per_second': 2457.662, 'eval_steps_per_second': 40.752, 'epoch': 1.33}\n",
      "{'loss': 0.0918, 'grad_norm': 0.3583292067050934, 'learning_rate': 3.2810096775326807e-06, 'epoch': 1.38}\n",
      "{'loss': 0.0889, 'grad_norm': 0.34692177176475525, 'learning_rate': 3.1386781914087644e-06, 'epoch': 1.43}\n",
      "{'loss': 0.0934, 'grad_norm': 0.3012702465057373, 'learning_rate': 2.9940948377331545e-06, 'epoch': 1.48}\n",
      "{'loss': 0.0929, 'grad_norm': 0.3520547151565552, 'learning_rate': 2.847769392112779e-06, 'epoch': 1.53}\n",
      "{'loss': 0.0923, 'grad_norm': 0.5159593224525452, 'learning_rate': 2.700217772465946e-06, 'epoch': 1.58}\n",
      "{'loss': 0.0868, 'grad_norm': 0.3591775894165039, 'learning_rate': 2.551960219986031e-06, 'epoch': 1.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50659b836c546b69dc664dc97be80ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0684095174074173, 'eval_roc_auc_micro': 0.827274390634241, 'eval_pr_auc_micro': 0.37393662499863045, 'eval_roc_auc_macro': 0.8095748699919506, 'eval_pr_auc_macro': 0.3931741120743659, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.32, 'eval_samples_per_second': 2449.997, 'eval_steps_per_second': 40.625, 'epoch': 1.66}\n",
      "{'loss': 0.0863, 'grad_norm': 0.2854832410812378, 'learning_rate': 2.4035194648620625e-06, 'epoch': 1.68}\n",
      "{'loss': 0.0923, 'grad_norm': 0.44905757904052734, 'learning_rate': 2.2554188832235363e-06, 'epoch': 1.73}\n",
      "{'loss': 0.0898, 'grad_norm': 0.3568965792655945, 'learning_rate': 2.1081806518077575e-06, 'epoch': 1.79}\n",
      "{'loss': 0.088, 'grad_norm': 0.4772495627403259, 'learning_rate': 1.9623239068560373e-06, 'epoch': 1.84}\n",
      "{'loss': 0.0915, 'grad_norm': 0.45554426312446594, 'learning_rate': 1.818362913730133e-06, 'epoch': 1.89}\n",
      "{'loss': 0.0895, 'grad_norm': 0.5670253038406372, 'learning_rate': 1.6768052537025697e-06, 'epoch': 1.94}\n",
      "{'loss': 0.0951, 'grad_norm': 0.4885518252849579, 'learning_rate': 1.5381500343138877e-06, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1120677fc84fd1bc0ad97561628899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06880511343479156, 'eval_roc_auc_micro': 0.8290223968370594, 'eval_pr_auc_micro': 0.37923405145427447, 'eval_roc_auc_macro': 0.8125332375078992, 'eval_pr_auc_macro': 0.39728824657731304, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.323, 'eval_samples_per_second': 2427.254, 'eval_steps_per_second': 40.248, 'epoch': 1.99}\n",
      "{'loss': 0.0978, 'grad_norm': 0.3371701240539551, 'learning_rate': 1.4028861296067802e-06, 'epoch': 2.04}\n",
      "{'loss': 0.0913, 'grad_norm': 0.2902781069278717, 'learning_rate': 1.2714904564417623e-06, 'epoch': 2.09}\n",
      "{'loss': 0.0883, 'grad_norm': 0.3741152286529541, 'learning_rate': 1.1444262929717627e-06, 'epoch': 2.14}\n",
      "{'loss': 0.0936, 'grad_norm': 0.5421854853630066, 'learning_rate': 1.0221416452044237e-06, 'epoch': 2.19}\n",
      "{'loss': 0.0819, 'grad_norm': 0.3089121878147125, 'learning_rate': 9.050676674113071e-07, 'epoch': 2.24}\n",
      "{'loss': 0.0992, 'grad_norm': 0.35272493958473206, 'learning_rate': 7.936171419533653e-07, 'epoch': 2.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe4b71f45754c47b1c80831cd7c47eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06877640634775162, 'eval_roc_auc_micro': 0.8314369528224639, 'eval_pr_auc_micro': 0.3838198950214917, 'eval_roc_auc_macro': 0.8147758372724865, 'eval_pr_auc_macro': 0.398820489012998, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.32, 'eval_samples_per_second': 2449.999, 'eval_steps_per_second': 40.625, 'epoch': 2.32}\n",
      "{'loss': 0.088, 'grad_norm': 0.43915873765945435, 'learning_rate': 6.881830238825699e-07, 'epoch': 2.35}\n",
      "{'loss': 0.089, 'grad_norm': 0.48133981227874756, 'learning_rate': 5.891370554511519e-07, 'epoch': 2.4}\n",
      "{'loss': 0.0889, 'grad_norm': 0.3496638536453247, 'learning_rate': 4.968284554134653e-07, 'epoch': 2.45}\n",
      "{'loss': 0.085, 'grad_norm': 0.3341969847679138, 'learning_rate': 4.115826877417631e-07, 'epoch': 2.5}\n",
      "{'loss': 0.0873, 'grad_norm': 0.35611292719841003, 'learning_rate': 3.3370031409717755e-07, 'epoch': 2.55}\n",
      "{'loss': 0.0914, 'grad_norm': 0.43154242634773254, 'learning_rate': 2.634559341018947e-07, 'epoch': 2.6}\n",
      "{'loss': 0.0872, 'grad_norm': 0.403942346572876, 'learning_rate': 2.0109721714893283e-07, 'epoch': 2.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25611442b2ec42999b5be57b3108818f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06838088482618332, 'eval_roc_auc_micro': 0.8310225239126675, 'eval_pr_auc_micro': 0.38316150437072427, 'eval_roc_auc_macro': 0.814825774227366, 'eval_pr_auc_macro': 0.39984044057920687, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.321, 'eval_samples_per_second': 2442.073, 'eval_steps_per_second': 40.494, 'epoch': 2.65}\n",
      "{'loss': 0.0997, 'grad_norm': 0.6122041940689087, 'learning_rate': 1.468440291631984e-07, 'epoch': 2.7}\n",
      "{'loss': 0.0848, 'grad_norm': 0.2933502793312073, 'learning_rate': 1.0088765739270479e-07, 'epoch': 2.76}\n",
      "{'loss': 0.0899, 'grad_norm': 0.5001567006111145, 'learning_rate': 6.339013596320692e-08, 'epoch': 2.81}\n",
      "{'loss': 0.0891, 'grad_norm': 0.46312215924263, 'learning_rate': 3.448367457422497e-08, 'epoch': 2.86}\n",
      "{'loss': 0.0924, 'grad_norm': 0.39496850967407227, 'learning_rate': 1.4270192350775703e-08, 'epoch': 2.91}\n",
      "{'loss': 0.088, 'grad_norm': 0.4660615622997284, 'learning_rate': 2.820958494373083e-09, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aedeb254129c4012b177a84ed4c253cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06848151236772537, 'eval_roc_auc_micro': 0.8312925595798287, 'eval_pr_auc_micro': 0.3840257925548896, 'eval_roc_auc_macro': 0.8150552904477685, 'eval_pr_auc_macro': 0.40023350945124253, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.319, 'eval_samples_per_second': 2457.656, 'eval_steps_per_second': 40.752, 'epoch': 2.98}\n",
      "{'train_runtime': 29.4891, 'train_samples_per_second': 637.252, 'train_steps_per_second': 19.94, 'train_loss': 0.10037784663592877, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3a1250063c4906b48f59a7f970fb11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 9] VAL pr_auc_macro=nan | dur=0.5 min\n",
      "\n",
      "[Trial 10] cfg={'loss': 'asl', 'learning_rate': 5e-06, 'weight_decay': 0.0, 'warmup_ratio': 0.1, 'batch_size': 32, 'max_length': 128, 'label_smoothing': 0.0, 'llrd_enable': False, 'llrd_decay': 0.95, 'augment': False, 'gamma_pos': 2.0, 'gamma_neg': 1.0, 'clip': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6419ddc890784dff99b0c62106dc4e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2068, 'grad_norm': 1.2781728506088257, 'learning_rate': 8.474576271186441e-07, 'epoch': 0.05}\n",
      "{'loss': 0.2036, 'grad_norm': 1.2967710494995117, 'learning_rate': 1.6949152542372882e-06, 'epoch': 0.1}\n",
      "{'loss': 0.1692, 'grad_norm': 1.0536091327667236, 'learning_rate': 2.5423728813559323e-06, 'epoch': 0.15}\n",
      "{'loss': 0.1411, 'grad_norm': 0.6651315689086914, 'learning_rate': 3.3898305084745763e-06, 'epoch': 0.2}\n",
      "{'loss': 0.1205, 'grad_norm': 0.49128037691116333, 'learning_rate': 4.23728813559322e-06, 'epoch': 0.26}\n",
      "{'loss': 0.1067, 'grad_norm': 0.3164961040019989, 'learning_rate': 4.999955914361218e-06, 'epoch': 0.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621d6eb38d3247f78604bb84ebc24203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07534877210855484, 'eval_roc_auc_micro': 0.7885882282125048, 'eval_pr_auc_micro': 0.2798177621583246, 'eval_roc_auc_macro': 0.7756032992222285, 'eval_pr_auc_macro': 0.29903620443892726, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.32, 'eval_samples_per_second': 2449.975, 'eval_steps_per_second': 40.625, 'epoch': 0.33}\n",
      "{'loss': 0.1181, 'grad_norm': 0.3952575922012329, 'learning_rate': 4.9946675187988104e-06, 'epoch': 0.36}\n",
      "{'loss': 0.1052, 'grad_norm': 0.3876678943634033, 'learning_rate': 4.980583362063697e-06, 'epoch': 0.41}\n",
      "{'loss': 0.1037, 'grad_norm': 0.33647778630256653, 'learning_rate': 4.957753102428184e-06, 'epoch': 0.46}\n",
      "{'loss': 0.1046, 'grad_norm': 0.4038802981376648, 'learning_rate': 4.926257235393077e-06, 'epoch': 0.51}\n",
      "{'loss': 0.0973, 'grad_norm': 0.32396626472473145, 'learning_rate': 4.8862068098746246e-06, 'epoch': 0.56}\n",
      "{'loss': 0.1075, 'grad_norm': 0.39712944626808167, 'learning_rate': 4.837743036665477e-06, 'epoch': 0.61}\n",
      "{'loss': 0.1018, 'grad_norm': 0.4229896664619446, 'learning_rate': 4.781036790550134e-06, 'epoch': 0.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d45d03a0dad4a0f8f04175a64e97a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07464053481817245, 'eval_roc_auc_micro': 0.8112880641607613, 'eval_pr_auc_micro': 0.33246122719959004, 'eval_roc_auc_macro': 0.7940254732913248, 'eval_pr_auc_macro': 0.34659060050209445, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.319, 'eval_samples_per_second': 2457.654, 'eval_steps_per_second': 40.752, 'epoch': 0.66}\n",
      "{'loss': 0.1006, 'grad_norm': 0.37589171528816223, 'learning_rate': 4.716288007830357e-06, 'epoch': 0.71}\n",
      "{'loss': 0.0971, 'grad_norm': 0.4139067232608795, 'learning_rate': 4.6437249813847495e-06, 'epoch': 0.77}\n",
      "{'loss': 0.1024, 'grad_norm': 0.35268038511276245, 'learning_rate': 4.563603555748015e-06, 'epoch': 0.82}\n",
      "{'loss': 0.1004, 'grad_norm': 0.390546053647995, 'learning_rate': 4.476206225047889e-06, 'epoch': 0.87}\n",
      "{'loss': 0.101, 'grad_norm': 0.45121634006500244, 'learning_rate': 4.38184113698028e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0911, 'grad_norm': 0.3511559069156647, 'learning_rate': 4.280841006334403e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ebe479c9434dc681f90276c9907c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07161368429660797, 'eval_roc_auc_micro': 0.8205789153857987, 'eval_pr_auc_micro': 0.3551567273505325, 'eval_roc_auc_macro': 0.8022049038218076, 'eval_pr_auc_macro': 0.37527232221186413, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.327, 'eval_samples_per_second': 2397.547, 'eval_steps_per_second': 39.755, 'epoch': 0.99}\n",
      "{'loss': 0.092, 'grad_norm': 0.29313233494758606, 'learning_rate': 4.173561941898656e-06, 'epoch': 1.02}\n",
      "{'loss': 0.098, 'grad_norm': 0.36861470341682434, 'learning_rate': 4.0603821908833386e-06, 'epoch': 1.07}\n",
      "{'loss': 0.0893, 'grad_norm': 0.5592856407165527, 'learning_rate': 3.941700805287168e-06, 'epoch': 1.12}\n",
      "{'loss': 0.0952, 'grad_norm': 0.4476100504398346, 'learning_rate': 3.817936234909763e-06, 'epoch': 1.17}\n",
      "{'loss': 0.0972, 'grad_norm': 0.4539039731025696, 'learning_rate': 3.6895248519708552e-06, 'epoch': 1.22}\n",
      "{'loss': 0.0918, 'grad_norm': 0.26031556725502014, 'learning_rate': 3.5569194125382122e-06, 'epoch': 1.28}\n",
      "{'loss': 0.0961, 'grad_norm': 0.3514987826347351, 'learning_rate': 3.4205874601889465e-06, 'epoch': 1.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd90c7bfda14c61a54f309235fcabf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07054416835308075, 'eval_roc_auc_micro': 0.8240574907249137, 'eval_pr_auc_micro': 0.370362819755599, 'eval_roc_auc_macro': 0.807796297359063, 'eval_pr_auc_macro': 0.38762627308284264, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.32, 'eval_samples_per_second': 2449.991, 'eval_steps_per_second': 40.625, 'epoch': 1.33}\n",
      "{'loss': 0.0918, 'grad_norm': 0.3583292067050934, 'learning_rate': 3.2810096775326807e-06, 'epoch': 1.38}\n",
      "{'loss': 0.0889, 'grad_norm': 0.34692177176475525, 'learning_rate': 3.1386781914087644e-06, 'epoch': 1.43}\n",
      "{'loss': 0.0934, 'grad_norm': 0.3012702465057373, 'learning_rate': 2.9940948377331545e-06, 'epoch': 1.48}\n",
      "{'loss': 0.0929, 'grad_norm': 0.3520547151565552, 'learning_rate': 2.847769392112779e-06, 'epoch': 1.53}\n",
      "{'loss': 0.0923, 'grad_norm': 0.5159593224525452, 'learning_rate': 2.700217772465946e-06, 'epoch': 1.58}\n",
      "{'loss': 0.0868, 'grad_norm': 0.3591775894165039, 'learning_rate': 2.551960219986031e-06, 'epoch': 1.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db1b743808142e0b18fa39ab6ee9e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0684095174074173, 'eval_roc_auc_micro': 0.827274390634241, 'eval_pr_auc_micro': 0.37393662499863045, 'eval_roc_auc_macro': 0.8095748699919506, 'eval_pr_auc_macro': 0.3931741120743659, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.32, 'eval_samples_per_second': 2450.006, 'eval_steps_per_second': 40.625, 'epoch': 1.66}\n",
      "{'loss': 0.0863, 'grad_norm': 0.2854832410812378, 'learning_rate': 2.4035194648620625e-06, 'epoch': 1.68}\n",
      "{'loss': 0.0923, 'grad_norm': 0.44905757904052734, 'learning_rate': 2.2554188832235363e-06, 'epoch': 1.73}\n",
      "{'loss': 0.0898, 'grad_norm': 0.3568965792655945, 'learning_rate': 2.1081806518077575e-06, 'epoch': 1.79}\n",
      "{'loss': 0.088, 'grad_norm': 0.4772495627403259, 'learning_rate': 1.9623239068560373e-06, 'epoch': 1.84}\n",
      "{'loss': 0.0915, 'grad_norm': 0.45554426312446594, 'learning_rate': 1.818362913730133e-06, 'epoch': 1.89}\n",
      "{'loss': 0.0895, 'grad_norm': 0.5670253038406372, 'learning_rate': 1.6768052537025697e-06, 'epoch': 1.94}\n",
      "{'loss': 0.0951, 'grad_norm': 0.4885518252849579, 'learning_rate': 1.5381500343138877e-06, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1bf52784d73490ba8573357bb0eccef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06880511343479156, 'eval_roc_auc_micro': 0.8290223968370594, 'eval_pr_auc_micro': 0.37923405145427447, 'eval_roc_auc_macro': 0.8125332375078992, 'eval_pr_auc_macro': 0.39728824657731304, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.318, 'eval_samples_per_second': 2465.384, 'eval_steps_per_second': 40.88, 'epoch': 1.99}\n",
      "{'loss': 0.0978, 'grad_norm': 0.3371701240539551, 'learning_rate': 1.4028861296067802e-06, 'epoch': 2.04}\n",
      "{'loss': 0.0913, 'grad_norm': 0.2902781069278717, 'learning_rate': 1.2714904564417623e-06, 'epoch': 2.09}\n",
      "{'loss': 0.0883, 'grad_norm': 0.3741152286529541, 'learning_rate': 1.1444262929717627e-06, 'epoch': 2.14}\n",
      "{'loss': 0.0936, 'grad_norm': 0.5421854853630066, 'learning_rate': 1.0221416452044237e-06, 'epoch': 2.19}\n",
      "{'loss': 0.0819, 'grad_norm': 0.3089121878147125, 'learning_rate': 9.050676674113071e-07, 'epoch': 2.24}\n",
      "{'loss': 0.0992, 'grad_norm': 0.35272493958473206, 'learning_rate': 7.936171419533653e-07, 'epoch': 2.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beabe0990dce40ea971d264e0254ae3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06877640634775162, 'eval_roc_auc_micro': 0.8314369528224639, 'eval_pr_auc_micro': 0.3838198950214917, 'eval_roc_auc_macro': 0.8147758372724865, 'eval_pr_auc_macro': 0.398820489012998, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.319, 'eval_samples_per_second': 2457.427, 'eval_steps_per_second': 40.748, 'epoch': 2.32}\n",
      "{'loss': 0.088, 'grad_norm': 0.43915873765945435, 'learning_rate': 6.881830238825699e-07, 'epoch': 2.35}\n",
      "{'loss': 0.089, 'grad_norm': 0.48133981227874756, 'learning_rate': 5.891370554511519e-07, 'epoch': 2.4}\n",
      "{'loss': 0.0889, 'grad_norm': 0.3496638536453247, 'learning_rate': 4.968284554134653e-07, 'epoch': 2.45}\n",
      "{'loss': 0.085, 'grad_norm': 0.3341969847679138, 'learning_rate': 4.115826877417631e-07, 'epoch': 2.5}\n",
      "{'loss': 0.0873, 'grad_norm': 0.35611292719841003, 'learning_rate': 3.3370031409717755e-07, 'epoch': 2.55}\n",
      "{'loss': 0.0914, 'grad_norm': 0.43154242634773254, 'learning_rate': 2.634559341018947e-07, 'epoch': 2.6}\n",
      "{'loss': 0.0872, 'grad_norm': 0.403942346572876, 'learning_rate': 2.0109721714893283e-07, 'epoch': 2.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427ffbc3f7344fefb18109208c60775d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06838088482618332, 'eval_roc_auc_micro': 0.8310225239126675, 'eval_pr_auc_micro': 0.38316150437072427, 'eval_roc_auc_macro': 0.814825774227366, 'eval_pr_auc_macro': 0.39984044057920687, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.318, 'eval_samples_per_second': 2465.41, 'eval_steps_per_second': 40.881, 'epoch': 2.65}\n",
      "{'loss': 0.0997, 'grad_norm': 0.6122041940689087, 'learning_rate': 1.468440291631984e-07, 'epoch': 2.7}\n",
      "{'loss': 0.0848, 'grad_norm': 0.2933502793312073, 'learning_rate': 1.0088765739270479e-07, 'epoch': 2.76}\n",
      "{'loss': 0.0899, 'grad_norm': 0.5001567006111145, 'learning_rate': 6.339013596320692e-08, 'epoch': 2.81}\n",
      "{'loss': 0.0891, 'grad_norm': 0.46312215924263, 'learning_rate': 3.448367457422497e-08, 'epoch': 2.86}\n",
      "{'loss': 0.0924, 'grad_norm': 0.39496850967407227, 'learning_rate': 1.4270192350775703e-08, 'epoch': 2.91}\n",
      "{'loss': 0.088, 'grad_norm': 0.4660615622997284, 'learning_rate': 2.820958494373083e-09, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d9bc9afae94c13838186799c7cba1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06848151236772537, 'eval_roc_auc_micro': 0.8312925595798287, 'eval_pr_auc_micro': 0.3840257925548896, 'eval_roc_auc_macro': 0.8150552904477685, 'eval_pr_auc_macro': 0.40023350945124253, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.314, 'eval_samples_per_second': 2496.818, 'eval_steps_per_second': 41.401, 'epoch': 2.98}\n",
      "{'train_runtime': 29.3507, 'train_samples_per_second': 640.257, 'train_steps_per_second': 20.034, 'train_loss': 0.10037784663592877, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3887b37d64d41109dfc90d304107a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 10] VAL pr_auc_macro=nan | dur=0.5 min\n",
      "\n",
      "=== HPO done ===\n",
      "Best trial: None  |  VAL pr_auc_macro=-1.0000\n",
      "Best config: None\n",
      "Saved results â†’ implementation\\models\\chemberta_v2\\hpo\\hpo_results.json\n",
      "Best hparams â†’ implementation\\models\\chemberta_v2\\metadata\\best_hparams.json\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 9a: Randomized HPO (fast trials on PR-AUC macro) ====\n",
    "import math, time, json, gc, copy, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import TrainingArguments, EarlyStoppingCallback, AutoConfig, AutoModelForSequenceClassification\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "SEARCH_DIR = V2_DIR / \"hpo\"\n",
    "SEARCH_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- Search space (edit if you like) ----\n",
    "LOSS_TYPES = [\"bce\", \"focal\", \"asl\"]             # which loss to use\n",
    "LRS         = [5e-6, 1e-5, 2e-5, 3e-5]           # learning rate\n",
    "WDS         = [0.0, 0.01, 0.05]                  # weight decay\n",
    "WARMS       = [0.0, 0.06, 0.1]                   # warmup ratio\n",
    "BSS         = [16, 32]                           # batch size\n",
    "MAX_LENS    = [128, 256, 320]                    # tokenizer max_length\n",
    "LSMOOTHS    = [0.0, 0.05]                        # label smoothing (BCE/Focal only)\n",
    "LLRD_EN     = [False, True]                      # layer-wise LR decay on/off\n",
    "LLRD_DECAYS = [0.85, 0.90, 0.95]                 # llrd decay\n",
    "AUG_ON      = [False, True]                      # random-SMILES augmentation\n",
    "ASL_GPOS    = [2.0, 2.2]                         # ASL gamma_pos\n",
    "ASL_GNEG    = [0.5, 1.0]                         # ASL gamma_neg\n",
    "ASL_CLIP    = [0.04, 0.06]                       # ASL negative clip\n",
    "FOCAL_G     = [1.5, 1.8, 2.0]                    # focal gamma (scalar across labels)\n",
    "TRIAL_EPOCHS = 3                                 # short runs\n",
    "N_TRIALS     = 10                                # set to 20+ if you have time\n",
    "\n",
    "# reuse alpha/gamma vectors from earlier (safe fallbacks)\n",
    "# if not present, build from prevalence (alpha) and use scalar gamma\n",
    "try:\n",
    "    with open(META_DIR / \"focal_suggest.json\") as f:\n",
    "        _fs = json.load(f)\n",
    "    focal_alpha_vec = torch.tensor([_fs.get(l, {}).get(\"alpha\", 0.5) for l in label_names], dtype=torch.float32).to(DEVICE)\n",
    "    focal_gamma_vec_base = torch.tensor([_fs.get(l, {}).get(\"gamma\", 1.5) for l in label_names], dtype=torch.float32).to(DEVICE)\n",
    "except Exception:\n",
    "    # build alpha from train prevalence\n",
    "    col = train_ds.df\n",
    "    av = []\n",
    "    for l in label_names:\n",
    "        pr = (col[l] == 1).sum() / max(1, col[l].notna().sum())\n",
    "        av.append(float(np.clip(1.0 - (0 if np.isnan(pr) else pr), 0.25, 0.75)))\n",
    "    focal_alpha_vec = torch.tensor(av, dtype=torch.float32).to(DEVICE)\n",
    "    focal_gamma_vec_base = torch.tensor([1.5]*len(label_names), dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "def sample_config():\n",
    "    cfg = {\n",
    "        \"loss\":            random.choice(LOSS_TYPES),\n",
    "        \"learning_rate\":   random.choice(LRS),\n",
    "        \"weight_decay\":    random.choice(WDS),\n",
    "        \"warmup_ratio\":    random.choice(WARMS),\n",
    "        \"batch_size\":      random.choice(BSS),\n",
    "        \"max_length\":      random.choice(MAX_LENS),\n",
    "        \"label_smoothing\": random.choice(LSMOOTHS),\n",
    "        \"llrd_enable\":     random.choice(LLRD_EN),\n",
    "        \"llrd_decay\":      random.choice(LLRD_DECAYS),\n",
    "        \"augment\":         random.choice(AUG_ON),\n",
    "    }\n",
    "    if cfg[\"loss\"] == \"asl\":\n",
    "        cfg.update({\n",
    "            \"gamma_pos\": random.choice(ASL_GPOS),\n",
    "            \"gamma_neg\": random.choice(ASL_GNEG),\n",
    "            \"clip\":      random.choice(ASL_CLIP),\n",
    "        })\n",
    "    elif cfg[\"loss\"] == \"focal\":\n",
    "        cfg.update({\n",
    "            \"gamma\": random.choice(FOCAL_G),\n",
    "        })\n",
    "    return cfg\n",
    "\n",
    "def build_model():\n",
    "    c = AutoConfig.from_pretrained(\n",
    "        str(V1_DIR),\n",
    "        num_labels=len(label_names),\n",
    "        id2label={i: lbl for i, lbl in id2label.items()},\n",
    "        label2id={lbl: i for lbl, i in label2id.items()},\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "    m = AutoModelForSequenceClassification.from_pretrained(str(V1_DIR), config=c).to(DEVICE)\n",
    "    if run_cfg.gradient_checkpointing:\n",
    "        m.gradient_checkpointing_enable()\n",
    "    if hasattr(m.config, \"use_cache\"):\n",
    "        m.config.use_cache = False\n",
    "    return m\n",
    "\n",
    "def get_datasets_for_maxlen(max_len, aug):\n",
    "    # rebuild datasets with new max_length & augmentation flag\n",
    "    tmp_train = Tox21Dataset(df_train, tokenizer, max_length=max_len, train=True)\n",
    "    tmp_val   = Tox21Dataset(df_val,   tokenizer, max_length=max_len, train=False)\n",
    "    # hack: set run_cfg.use_random_smiles so Dataset reads it\n",
    "    run_cfg.use_random_smiles = bool(aug)\n",
    "    return tmp_train, tmp_val\n",
    "\n",
    "def train_one_trial(trial_id, cfg):\n",
    "    global POS_WEIGHT  # from earlier\n",
    "    print(f\"\\n[Trial {trial_id}] cfg={cfg}\")\n",
    "    model = build_model()\n",
    "    train_tmp, val_tmp = get_datasets_for_maxlen(cfg[\"max_length\"], cfg[\"augment\"])\n",
    "\n",
    "    # choose Trainer class & loss\n",
    "    trainer_cls = V2Trainer\n",
    "    extra_kwargs = {}\n",
    "    metric_primary = \"pr_auc_macro\"  # optimize PR-macro\n",
    "\n",
    "    if cfg[\"loss\"] == \"asl\":\n",
    "        trainer_cls = V2TrainerASL\n",
    "        extra_kwargs.update(dict(\n",
    "            gamma_pos=cfg[\"gamma_pos\"], gamma_neg=cfg[\"gamma_neg\"],\n",
    "            clip=cfg[\"clip\"], alpha_vec=alpha_vec_asl.to(DEVICE) if 'alpha_vec_asl' in globals() else None\n",
    "        ))\n",
    "        lsmooth = 0.0\n",
    "        pos_weight_arg = None\n",
    "    elif cfg[\"loss\"] == \"focal\":\n",
    "        trainer_cls = V2TrainerFocal\n",
    "        # scale base gamma vector by scalar (simple scheme)\n",
    "        gvec = (focal_gamma_vec_base * 0 + cfg[\"gamma\"]).to(DEVICE)\n",
    "        extra_kwargs.update(dict(\n",
    "            use_focal=True,\n",
    "            focal_alpha=focal_alpha_vec,\n",
    "            focal_gamma=gvec,\n",
    "        ))\n",
    "        lsmooth = cfg[\"label_smoothing\"]\n",
    "        pos_weight_arg = POS_WEIGHT\n",
    "    else:  # bce\n",
    "        lsmooth = cfg[\"label_smoothing\"]\n",
    "        pos_weight_arg = POS_WEIGHT\n",
    "\n",
    "    # TrainingArguments (short run)\n",
    "    steps_per_epoch = math.ceil(len(train_tmp) / cfg[\"batch_size\"])\n",
    "    eval_steps = max(50, steps_per_epoch // 3)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=str(CKPT_DIR / f\"hpo_trial_{trial_id}\"),\n",
    "        overwrite_output_dir=True,\n",
    "        per_device_train_batch_size=cfg[\"batch_size\"],\n",
    "        per_device_eval_batch_size=max(cfg[\"batch_size\"], 64),\n",
    "        gradient_accumulation_steps=1,\n",
    "        learning_rate=cfg[\"learning_rate\"],\n",
    "        weight_decay=cfg[\"weight_decay\"],\n",
    "        warmup_ratio=cfg[\"warmup_ratio\"],\n",
    "        num_train_epochs=TRIAL_EPOCHS,\n",
    "        lr_scheduler_type=run_cfg.lr_schedule,\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        eval_steps=eval_steps,\n",
    "        save_steps=eval_steps,\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=metric_primary,\n",
    "        greater_is_better=True,\n",
    "        fp16=run_cfg.fp16,\n",
    "        bf16=run_cfg.bfloat16,\n",
    "        gradient_checkpointing=run_cfg.gradient_checkpointing,\n",
    "        max_grad_norm=run_cfg.max_grad_norm,\n",
    "        report_to=[],\n",
    "        dataloader_num_workers=0,\n",
    "        dataloader_pin_memory=True,\n",
    "        disable_tqdm=False,\n",
    "        remove_unused_columns=False,\n",
    "    )\n",
    "\n",
    "    trainer = trainer_cls(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_tmp,\n",
    "        eval_dataset=val_tmp,\n",
    "        data_collator=collator,\n",
    "        tokenizer=tokenizer,\n",
    "        pos_weight=pos_weight_arg,\n",
    "        label_smoothing=lsmooth,\n",
    "        llrd_enable=cfg[\"llrd_enable\"],\n",
    "        llrd_decay=cfg[\"llrd_decay\"],\n",
    "        **extra_kwargs\n",
    "    )\n",
    "    trainer.compute_metrics = make_compute_metrics(trainer)\n",
    "    trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=2))\n",
    "\n",
    "    t0 = time.time()\n",
    "    trainer.train()\n",
    "    val_metrics = trainer.evaluate(eval_dataset=val_tmp)\n",
    "    dur = time.time() - t0\n",
    "    score = float(val_metrics.get(\"pr_auc_macro\", float(\"nan\")))\n",
    "    print(f\"[Trial {trial_id}] VAL pr_auc_macro={score:.4f} | dur={dur/60:.1f} min\")\n",
    "\n",
    "    # cleanup\n",
    "    del trainer, model\n",
    "    torch.cuda.empty_cache(); gc.collect()\n",
    "    return score, val_metrics\n",
    "\n",
    "results = []\n",
    "best = {\"score\": -1, \"cfg\": None, \"trial\": None}\n",
    "for t in range(1, N_TRIALS+1):\n",
    "    cfg = sample_config()\n",
    "    # freeze augmentation flag inside dataset through run_cfg\n",
    "    s, vm = train_one_trial(t, cfg)\n",
    "    results.append({\"trial\": t, \"score\": s, \"cfg\": cfg, \"val_metrics\": vm})\n",
    "    if s > best[\"score\"]:\n",
    "        best = {\"score\": s, \"cfg\": cfg, \"trial\": t}\n",
    "\n",
    "# Save scoreboard\n",
    "with open(SEARCH_DIR / \"hpo_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2, default=lambda o: float(o) if isinstance(o, np.floating) else o)\n",
    "\n",
    "with open(META_DIR / \"best_hparams.json\", \"w\") as f:\n",
    "    json.dump(best, f, indent=2)\n",
    "\n",
    "print(\"\\n=== HPO done ===\")\n",
    "print(f\"Best trial: {best['trial']}  |  VAL pr_auc_macro={best['score']:.4f}\")\n",
    "print(\"Best config:\", best[\"cfg\"])\n",
    "print(f\"Saved results â†’ {SEARCH_DIR/'hpo_results.json'}\")\n",
    "print(f\"Best hparams â†’ {META_DIR/'best_hparams.json'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526e1483",
   "metadata": {},
   "source": [
    "### Refit best config longer (v2_best) and evaluate (VAL/TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3571b0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] No HPO config found; falling back to v2b-like defaults.\n",
      "Refitting with config: {'loss': 'bce', 'learning_rate': 1e-05, 'weight_decay': 0.01, 'warmup_ratio': 0.06, 'batch_size': 32, 'max_length': 256, 'label_smoothing': 0.0, 'llrd_enable': True, 'llrd_decay': 0.85, 'augment': False}\n",
      "Training v2_best...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92b53c842cb4dc88b9402d05979d956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1568 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9883, 'grad_norm': 3.2677667140960693, 'learning_rate': 3.3744956661184203e-07, 'epoch': 0.05}\n",
      "{'loss': 1.0287, 'grad_norm': 2.7980778217315674, 'learning_rate': 6.748991332236841e-07, 'epoch': 0.1}\n",
      "{'loss': 0.9718, 'grad_norm': 3.0769119262695312, 'learning_rate': 1.012348699835526e-06, 'epoch': 0.15}\n",
      "{'loss': 1.1192, 'grad_norm': 3.689868450164795, 'learning_rate': 1.3497982664473681e-06, 'epoch': 0.2}\n",
      "{'loss': 1.027, 'grad_norm': 5.775510311126709, 'learning_rate': 1.68724783305921e-06, 'epoch': 0.26}\n",
      "{'loss': 0.9633, 'grad_norm': 2.3651535511016846, 'learning_rate': 2.024697399671052e-06, 'epoch': 0.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3420245b3b204dc8ade4c1e5581562f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0115829706192017, 'eval_roc_auc_micro': 0.7987890315596572, 'eval_pr_auc_micro': 0.3159362171799144, 'eval_roc_auc_macro': 0.8016390434742079, 'eval_pr_auc_macro': 0.3428779551193, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.456, 'eval_samples_per_second': 1719.275, 'eval_steps_per_second': 28.508, 'epoch': 0.33}\n",
      "{'loss': 0.9611, 'grad_norm': 2.4376275539398193, 'learning_rate': 2.3621469662828943e-06, 'epoch': 0.36}\n",
      "{'loss': 0.9643, 'grad_norm': 2.8193962574005127, 'learning_rate': 2.6995965328947362e-06, 'epoch': 0.41}\n",
      "{'loss': 1.0054, 'grad_norm': 5.785123825073242, 'learning_rate': 3.037046099506578e-06, 'epoch': 0.46}\n",
      "{'loss': 1.0717, 'grad_norm': 7.093191623687744, 'learning_rate': 3.2056797441536563e-06, 'epoch': 0.51}\n",
      "{'loss': 0.9638, 'grad_norm': 2.8458516597747803, 'learning_rate': 3.204950697066504e-06, 'epoch': 0.56}\n",
      "{'loss': 0.93, 'grad_norm': 3.390779495239258, 'learning_rate': 3.203492934506589e-06, 'epoch': 0.61}\n",
      "{'loss': 0.9955, 'grad_norm': 3.394404172897339, 'learning_rate': 3.201307119551854e-06, 'epoch': 0.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2fde88c68264e008289ab4c6f409f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.001008152961731, 'eval_roc_auc_micro': 0.807203729907961, 'eval_pr_auc_micro': 0.31498727083464334, 'eval_roc_auc_macro': 0.8038372532105926, 'eval_pr_auc_macro': 0.3413996814261331, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.439, 'eval_samples_per_second': 1785.877, 'eval_steps_per_second': 29.613, 'epoch': 0.66}\n",
      "{'loss': 1.0397, 'grad_norm': 3.8904120922088623, 'learning_rate': 3.1983942464421853e-06, 'epoch': 0.71}\n",
      "{'loss': 1.0442, 'grad_norm': 5.368840217590332, 'learning_rate': 3.1947556401271743e-06, 'epoch': 0.77}\n",
      "{'loss': 1.015, 'grad_norm': 2.890768051147461, 'learning_rate': 3.190392955663449e-06, 'epoch': 0.82}\n",
      "{'loss': 1.0644, 'grad_norm': 4.093093395233154, 'learning_rate': 3.1853081774618576e-06, 'epoch': 0.87}\n",
      "{'loss': 0.9488, 'grad_norm': 2.756887912750244, 'learning_rate': 3.1795036183848367e-06, 'epoch': 0.92}\n",
      "{'loss': 1.0937, 'grad_norm': 7.253220558166504, 'learning_rate': 3.172981918694383e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626f90aadba04a3c8f77d999cd4eb712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.992998480796814, 'eval_roc_auc_micro': 0.8106279637041489, 'eval_pr_auc_micro': 0.3284647174723415, 'eval_roc_auc_macro': 0.8107279764639603, 'eval_pr_auc_macro': 0.3627809177235579, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.436, 'eval_samples_per_second': 1798.164, 'eval_steps_per_second': 29.816, 'epoch': 0.99}\n",
      "{'loss': 0.9809, 'grad_norm': 2.012822389602661, 'learning_rate': 3.1657460448511057e-06, 'epoch': 1.02}\n",
      "{'loss': 0.8743, 'grad_norm': 2.8600893020629883, 'learning_rate': 3.1577992881649e-06, 'epoch': 1.07}\n",
      "{'loss': 1.0655, 'grad_norm': 2.4377243518829346, 'learning_rate': 3.1491452632978617e-06, 'epoch': 1.12}\n",
      "{'loss': 0.8799, 'grad_norm': 2.9958620071411133, 'learning_rate': 3.1397879066201238e-06, 'epoch': 1.17}\n",
      "{'loss': 0.8696, 'grad_norm': 3.8646719455718994, 'learning_rate': 3.129731474419356e-06, 'epoch': 1.22}\n",
      "{'loss': 0.9876, 'grad_norm': 3.9025189876556396, 'learning_rate': 3.118980540964753e-06, 'epoch': 1.28}\n",
      "{'loss': 1.0477, 'grad_norm': 3.800187349319458, 'learning_rate': 3.107539996426379e-06, 'epoch': 1.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95128fb9975446a587caee5686025d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9811073541641235, 'eval_roc_auc_micro': 0.8141682853678648, 'eval_pr_auc_micro': 0.3325756688182812, 'eval_roc_auc_macro': 0.8128361597590531, 'eval_pr_auc_macro': 0.37123022127506794, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.458, 'eval_samples_per_second': 1711.791, 'eval_steps_per_second': 28.384, 'epoch': 1.33}\n",
      "{'loss': 1.0658, 'grad_norm': 8.529816627502441, 'learning_rate': 3.0954150446508266e-06, 'epoch': 1.38}\n",
      "{'loss': 0.9474, 'grad_norm': 2.8645172119140625, 'learning_rate': 3.082611200794195e-06, 'epoch': 1.43}\n",
      "{'loss': 0.9547, 'grad_norm': 4.846312999725342, 'learning_rate': 3.069134288813465e-06, 'epoch': 1.48}\n",
      "{'loss': 0.9092, 'grad_norm': 3.4791581630706787, 'learning_rate': 3.054990438817413e-06, 'epoch': 1.53}\n",
      "{'loss': 0.9279, 'grad_norm': 2.651700496673584, 'learning_rate': 3.0401860842782715e-06, 'epoch': 1.58}\n",
      "{'loss': 0.9196, 'grad_norm': 2.975569009780884, 'learning_rate': 3.0247279591053988e-06, 'epoch': 1.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc75724bf374d0d9410f13bdf5d89bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9729753732681274, 'eval_roc_auc_micro': 0.8173928289227906, 'eval_pr_auc_micro': 0.3378647530385933, 'eval_roc_auc_macro': 0.8150196703037769, 'eval_pr_auc_macro': 0.36496831160774684, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.424, 'eval_samples_per_second': 1848.954, 'eval_steps_per_second': 30.659, 'epoch': 1.66}\n",
      "{'loss': 0.9315, 'grad_norm': 3.5326642990112305, 'learning_rate': 3.008623094582292e-06, 'epoch': 1.68}\n",
      "{'loss': 0.8725, 'grad_norm': 6.635251522064209, 'learning_rate': 2.991878816168337e-06, 'epoch': 1.73}\n",
      "{'loss': 1.0027, 'grad_norm': 7.649639129638672, 'learning_rate': 2.9745027401667514e-06, 'epoch': 1.79}\n",
      "{'loss': 1.0447, 'grad_norm': 2.7702016830444336, 'learning_rate': 2.9565027702602298e-06, 'epoch': 1.84}\n",
      "{'loss': 0.9947, 'grad_norm': 4.11290979385376, 'learning_rate': 2.9378870939158776e-06, 'epoch': 1.89}\n",
      "{'loss': 0.8738, 'grad_norm': 4.1418070793151855, 'learning_rate': 2.9186641786610567e-06, 'epoch': 1.94}\n",
      "{'loss': 1.0025, 'grad_norm': 10.81208610534668, 'learning_rate': 2.8988427682318463e-06, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3377b9ffb6f544a48d18950020738def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0015699863433838, 'eval_roc_auc_micro': 0.8131151343227395, 'eval_pr_auc_micro': 0.339479957983263, 'eval_roc_auc_macro': 0.814450046765176, 'eval_pr_auc_macro': 0.3676986378226362, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4214, 'eval_samples_per_second': 1860.467, 'eval_steps_per_second': 30.85, 'epoch': 1.99}\n",
      "{'loss': 0.8809, 'grad_norm': 7.424968719482422, 'learning_rate': 2.878431878595868e-06, 'epoch': 2.04}\n",
      "{'loss': 0.9442, 'grad_norm': 4.559540271759033, 'learning_rate': 2.8574407938512804e-06, 'epoch': 2.09}\n",
      "{'loss': 0.892, 'grad_norm': 3.476072311401367, 'learning_rate': 2.835879062003815e-06, 'epoch': 2.14}\n",
      "{'loss': 0.8822, 'grad_norm': 5.186963081359863, 'learning_rate': 2.81375649062377e-06, 'epoch': 2.19}\n",
      "{'loss': 0.8404, 'grad_norm': 2.6833736896514893, 'learning_rate': 2.791083142384937e-06, 'epoch': 2.24}\n",
      "{'loss': 0.9128, 'grad_norm': 4.204206943511963, 'learning_rate': 2.767869330487496e-06, 'epoch': 2.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b12e7c28614cb982b83e18d9a70961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9551317095756531, 'eval_roc_auc_micro': 0.8238612640105635, 'eval_pr_auc_micro': 0.3525591852896823, 'eval_roc_auc_macro': 0.8208139987927027, 'eval_pr_auc_macro': 0.37901642854121803, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4226, 'eval_samples_per_second': 1855.0, 'eval_steps_per_second': 30.759, 'epoch': 2.32}\n",
      "{'loss': 0.9044, 'grad_norm': 5.236994743347168, 'learning_rate': 2.744125613966949e-06, 'epoch': 2.35}\n",
      "{'loss': 0.89, 'grad_norm': 3.7670581340789795, 'learning_rate': 2.719862792891238e-06, 'epoch': 2.4}\n",
      "{'loss': 0.7518, 'grad_norm': 2.9675543308258057, 'learning_rate': 2.695091903448226e-06, 'epoch': 2.45}\n",
      "{'loss': 1.0045, 'grad_norm': 11.244287490844727, 'learning_rate': 2.669824212925777e-06, 'epoch': 2.5}\n",
      "{'loss': 0.9912, 'grad_norm': 3.31449294090271, 'learning_rate': 2.6440712145867145e-06, 'epoch': 2.55}\n",
      "{'loss': 0.9708, 'grad_norm': 4.44471549987793, 'learning_rate': 2.617844622440998e-06, 'epoch': 2.6}\n",
      "{'loss': 0.9399, 'grad_norm': 3.4274702072143555, 'learning_rate': 2.591156365917486e-06, 'epoch': 2.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1a68f105e74d2f939408caab5d6f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9532455205917358, 'eval_roc_auc_micro': 0.8237444595512606, 'eval_pr_auc_micro': 0.3462195269752848, 'eval_roc_auc_macro': 0.8214356115095951, 'eval_pr_auc_macro': 0.3737127516285352, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.424, 'eval_samples_per_second': 1849.056, 'eval_steps_per_second': 30.66, 'epoch': 2.65}\n",
      "{'loss': 0.8377, 'grad_norm': 3.8307318687438965, 'learning_rate': 2.564018584437716e-06, 'epoch': 2.7}\n",
      "{'loss': 0.8998, 'grad_norm': 3.332369327545166, 'learning_rate': 2.5364436218941688e-06, 'epoch': 2.76}\n",
      "{'loss': 0.9946, 'grad_norm': 6.12642240524292, 'learning_rate': 2.50844402103552e-06, 'epoch': 2.81}\n",
      "{'loss': 0.8586, 'grad_norm': 3.4358456134796143, 'learning_rate': 2.4800325177614497e-06, 'epoch': 2.86}\n",
      "{'loss': 0.8985, 'grad_norm': 10.228839874267578, 'learning_rate': 2.4512220353295893e-06, 'epoch': 2.91}\n",
      "{'loss': 1.0014, 'grad_norm': 7.60757303237915, 'learning_rate': 2.4220256784772476e-06, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899a63c53a63403f92313d570101405c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9508757591247559, 'eval_roc_auc_micro': 0.8229540588235856, 'eval_pr_auc_micro': 0.35265704189307906, 'eval_roc_auc_macro': 0.8230437103454008, 'eval_pr_auc_macro': 0.3808235619080147, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.425, 'eval_samples_per_second': 1844.701, 'eval_steps_per_second': 30.588, 'epoch': 2.98}\n",
      "{'loss': 0.8448, 'grad_norm': 3.95308256149292, 'learning_rate': 2.3924567274605867e-06, 'epoch': 3.01}\n",
      "{'loss': 0.9066, 'grad_norm': 2.820171594619751, 'learning_rate': 2.3625286320139705e-06, 'epoch': 3.06}\n",
      "{'loss': 0.9163, 'grad_norm': 4.126598834991455, 'learning_rate': 2.3322550052322105e-06, 'epoch': 3.11}\n",
      "{'loss': 0.8311, 'grad_norm': 5.045871734619141, 'learning_rate': 2.3016496173785195e-06, 'epoch': 3.16}\n",
      "{'loss': 0.9764, 'grad_norm': 3.710827350616455, 'learning_rate': 2.2707263896209645e-06, 'epoch': 3.21}\n",
      "{'loss': 0.8829, 'grad_norm': 3.6518452167510986, 'learning_rate': 2.2394993877002857e-06, 'epoch': 3.27}\n",
      "{'loss': 0.8097, 'grad_norm': 3.5348803997039795, 'learning_rate': 2.207982815531952e-06, 'epoch': 3.32}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d1aacca7dd4f35bc5a1463d11e28c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9497093558311462, 'eval_roc_auc_micro': 0.827830107555648, 'eval_pr_auc_micro': 0.3676361431316489, 'eval_roc_auc_macro': 0.8238144816279146, 'eval_pr_auc_macro': 0.3935815181555171, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.423, 'eval_samples_per_second': 1853.415, 'eval_steps_per_second': 30.733, 'epoch': 3.32}\n",
      "{'loss': 0.9074, 'grad_norm': 2.531595468521118, 'learning_rate': 2.1761910087453674e-06, 'epoch': 3.37}\n",
      "{'loss': 0.8782, 'grad_norm': 8.609176635742188, 'learning_rate': 2.1441384281631695e-06, 'epoch': 3.42}\n",
      "{'loss': 0.8595, 'grad_norm': 3.28627872467041, 'learning_rate': 2.111839653223572e-06, 'epoch': 3.47}\n",
      "{'loss': 0.8533, 'grad_norm': 3.668383836746216, 'learning_rate': 2.0793093753487666e-06, 'epoch': 3.52}\n",
      "{'loss': 0.9603, 'grad_norm': 4.446681976318359, 'learning_rate': 2.0465623912623817e-06, 'epoch': 3.57}\n",
      "{'loss': 0.7748, 'grad_norm': 3.3622348308563232, 'learning_rate': 2.0136135962590407e-06, 'epoch': 3.62}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1166d38514471ea9855a8e1b490a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9603729844093323, 'eval_roc_auc_micro': 0.8252983888150534, 'eval_pr_auc_micro': 0.3553195750087579, 'eval_roc_auc_macro': 0.8248494363473036, 'eval_pr_auc_macro': 0.38601260740876525, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4222, 'eval_samples_per_second': 1857.099, 'eval_steps_per_second': 30.794, 'epoch': 3.65}\n",
      "{'loss': 0.7932, 'grad_norm': 8.082839012145996, 'learning_rate': 1.9804779774290904e-06, 'epoch': 3.67}\n",
      "{'loss': 0.8142, 'grad_norm': 3.0934195518493652, 'learning_rate': 1.9471706068415713e-06, 'epoch': 3.72}\n",
      "{'loss': 0.8261, 'grad_norm': 7.4291510581970215, 'learning_rate': 1.913706634688536e-06, 'epoch': 3.78}\n",
      "{'loss': 0.9037, 'grad_norm': 5.317044258117676, 'learning_rate': 1.8801012823938328e-06, 'epoch': 3.83}\n",
      "{'loss': 0.8621, 'grad_norm': 2.736701726913452, 'learning_rate': 1.846369835689486e-06, 'epoch': 3.88}\n",
      "{'loss': 0.8324, 'grad_norm': 3.754988431930542, 'learning_rate': 1.8125276376628297e-06, 'epoch': 3.93}\n",
      "{'loss': 0.8551, 'grad_norm': 3.1225688457489014, 'learning_rate': 1.7785900817775497e-06, 'epoch': 3.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624de13686904ffbb87790dfbf9ecc50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9540812969207764, 'eval_roc_auc_micro': 0.828555417863773, 'eval_pr_auc_micro': 0.36246262476238383, 'eval_roc_auc_macro': 0.8241575405362652, 'eval_pr_auc_macro': 0.3910332050659586, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.422, 'eval_samples_per_second': 1857.798, 'eval_steps_per_second': 30.805, 'epoch': 3.98}\n",
      "{'loss': 0.7142, 'grad_norm': 3.7437429428100586, 'learning_rate': 1.7445726048718096e-06, 'epoch': 4.03}\n",
      "{'loss': 0.8134, 'grad_norm': 3.269639253616333, 'learning_rate': 1.7104906801366548e-06, 'epoch': 4.08}\n",
      "{'loss': 0.7761, 'grad_norm': 2.721869707107544, 'learning_rate': 1.6763598100778703e-06, 'epoch': 4.13}\n",
      "{'loss': 0.85, 'grad_norm': 5.8254008293151855, 'learning_rate': 1.6421955194645155e-06, 'epoch': 4.18}\n",
      "{'loss': 0.9194, 'grad_norm': 4.201001167297363, 'learning_rate': 1.6080133482673238e-06, 'epoch': 4.23}\n",
      "{'loss': 0.8176, 'grad_norm': 4.578217029571533, 'learning_rate': 1.5738288445901915e-06, 'epoch': 4.29}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c281f71f3c024f339ee0d0543f81acc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9534304141998291, 'eval_roc_auc_micro': 0.8308591409879986, 'eval_pr_auc_micro': 0.3688827755246441, 'eval_roc_auc_macro': 0.8251728100154866, 'eval_pr_auc_macro': 0.3964230003705009, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4211, 'eval_samples_per_second': 1861.713, 'eval_steps_per_second': 30.87, 'epoch': 4.31}\n",
      "{'loss': 0.8204, 'grad_norm': 4.18611478805542, 'learning_rate': 1.5396575575979662e-06, 'epoch': 4.34}\n",
      "{'loss': 0.7779, 'grad_norm': 3.576756477355957, 'learning_rate': 1.505515030443755e-06, 'epoch': 4.39}\n",
      "{'loss': 0.8675, 'grad_norm': 3.251397132873535, 'learning_rate': 1.4714167931989645e-06, 'epoch': 4.44}\n",
      "{'loss': 0.7828, 'grad_norm': 3.7475147247314453, 'learning_rate': 1.4373783557892883e-06, 'epoch': 4.49}\n",
      "{'loss': 0.8338, 'grad_norm': 5.296436786651611, 'learning_rate': 1.4034152009398665e-06, 'epoch': 4.54}\n",
      "{'loss': 0.8689, 'grad_norm': 3.847587823867798, 'learning_rate': 1.3695427771328104e-06, 'epoch': 4.59}\n",
      "{'loss': 0.875, 'grad_norm': 2.952711582183838, 'learning_rate': 1.3357764915803045e-06, 'epoch': 4.64}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd8caa0cf4846b1b23f5c9604993b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9543907046318054, 'eval_roc_auc_micro': 0.8309727207843145, 'eval_pr_auc_micro': 0.36806813201079414, 'eval_roc_auc_macro': 0.8251970271379102, 'eval_pr_auc_macro': 0.3964332699439321, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.423, 'eval_samples_per_second': 1853.415, 'eval_steps_per_second': 30.733, 'epoch': 4.64}\n",
      "{'loss': 0.8677, 'grad_norm': 7.246727466583252, 'learning_rate': 1.3021317032164833e-06, 'epoch': 4.69}\n",
      "{'loss': 0.8292, 'grad_norm': 2.8217978477478027, 'learning_rate': 1.2686237157112628e-06, 'epoch': 4.74}\n",
      "{'loss': 0.9128, 'grad_norm': 3.5105738639831543, 'learning_rate': 1.2352677705093176e-06, 'epoch': 4.8}\n",
      "{'loss': 0.831, 'grad_norm': 3.723968982696533, 'learning_rate': 1.20207903989735e-06, 'epoch': 4.85}\n",
      "{'loss': 0.8379, 'grad_norm': 5.741933822631836, 'learning_rate': 1.1690726201028285e-06, 'epoch': 4.9}\n",
      "{'loss': 0.8336, 'grad_norm': 4.094814777374268, 'learning_rate': 1.1362635244273155e-06, 'epoch': 4.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5b6949ddbf408c89d96bed7795bfdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9520718455314636, 'eval_roc_auc_micro': 0.8287467478676618, 'eval_pr_auc_micro': 0.3608814980536222, 'eval_roc_auc_macro': 0.825167963149529, 'eval_pr_auc_macro': 0.39086388537344013, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.421, 'eval_samples_per_second': 1862.231, 'eval_steps_per_second': 30.879, 'epoch': 4.97}\n",
      "{'loss': 0.8751, 'grad_norm': 6.335660457611084, 'learning_rate': 1.1036666764175141e-06, 'epoch': 5.0}\n",
      "{'loss': 0.7585, 'grad_norm': 6.022943019866943, 'learning_rate': 1.0712969030771472e-06, 'epoch': 5.05}\n",
      "{'loss': 0.868, 'grad_norm': 5.998189449310303, 'learning_rate': 1.0391689281227417e-06, 'epoch': 5.1}\n",
      "{'loss': 0.8123, 'grad_norm': 6.4195966720581055, 'learning_rate': 1.0072973652864002e-06, 'epoch': 5.15}\n",
      "{'loss': 0.8429, 'grad_norm': 4.299705982208252, 'learning_rate': 9.756967116685987e-07, 'epoch': 5.2}\n",
      "{'loss': 0.8166, 'grad_norm': 8.219165802001953, 'learning_rate': 9.443813411440348e-07, 'epoch': 5.26}\n",
      "{'loss': 0.7134, 'grad_norm': 3.4614176750183105, 'learning_rate': 9.133654978235241e-07, 'epoch': 5.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69e564b6d0846f0968a715ef856ac4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9638780951499939, 'eval_roc_auc_micro': 0.8292506313173535, 'eval_pr_auc_micro': 0.3678353163051075, 'eval_roc_auc_macro': 0.8246419806109507, 'eval_pr_auc_macro': 0.39932934915715657, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4219, 'eval_samples_per_second': 1858.273, 'eval_steps_per_second': 30.813, 'epoch': 5.31}\n",
      "{'loss': 0.8197, 'grad_norm': 3.8561482429504395, 'learning_rate': 8.826632895749247e-07, 'epoch': 5.36}\n",
      "{'loss': 0.7442, 'grad_norm': 3.95208477973938, 'learning_rate': 8.522886816060341e-07, 'epoch': 5.41}\n",
      "{'loss': 0.8556, 'grad_norm': 8.625968933105469, 'learning_rate': 8.222554901123715e-07, 'epoch': 5.46}\n",
      "{'loss': 0.7803, 'grad_norm': 3.76936411857605, 'learning_rate': 7.925773759927412e-07, 'epoch': 5.51}\n",
      "{'loss': 0.7698, 'grad_norm': 7.236222267150879, 'learning_rate': 7.632678386354407e-07, 'epoch': 5.56}\n",
      "{'loss': 0.7975, 'grad_norm': 4.45320463180542, 'learning_rate': 7.343402097779223e-07, 'epoch': 5.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71f5aa01579474ba7a0cb3c56af4843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9535282850265503, 'eval_roc_auc_micro': 0.8340148917325373, 'eval_pr_auc_micro': 0.37659390594372993, 'eval_roc_auc_macro': 0.8272544477076803, 'eval_pr_auc_macro': 0.40287723703059736, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.422, 'eval_samples_per_second': 1857.823, 'eval_steps_per_second': 30.806, 'epoch': 5.64}\n",
      "{'loss': 0.8531, 'grad_norm': 3.124469041824341, 'learning_rate': 7.058076474427223e-07, 'epoch': 5.66}\n",
      "{'loss': 0.8419, 'grad_norm': 3.7462141513824463, 'learning_rate': 6.776831299524018e-07, 'epoch': 5.71}\n",
      "{'loss': 0.8583, 'grad_norm': 4.201752662658691, 'learning_rate': 6.499794500262255e-07, 'epoch': 5.77}\n",
      "{'loss': 0.858, 'grad_norm': 3.8069469928741455, 'learning_rate': 6.227092089612653e-07, 'epoch': 5.82}\n",
      "{'loss': 0.8593, 'grad_norm': 4.079127311706543, 'learning_rate': 5.958848109005725e-07, 'epoch': 5.87}\n",
      "{'loss': 0.8578, 'grad_norm': 7.362820625305176, 'learning_rate': 5.695184571910314e-07, 'epoch': 5.92}\n",
      "{'loss': 0.7354, 'grad_norm': 4.386382102966309, 'learning_rate': 5.436221408334514e-07, 'epoch': 5.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339f4a683f5a4e13bde4b95df780593c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9468305706977844, 'eval_roc_auc_micro': 0.83359269974518, 'eval_pr_auc_micro': 0.37557512849459573, 'eval_roc_auc_macro': 0.8276887571019059, 'eval_pr_auc_macro': 0.4046945331977679, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.424, 'eval_samples_per_second': 1849.061, 'eval_steps_per_second': 30.66, 'epoch': 5.97}\n",
      "{'loss': 0.7694, 'grad_norm': 4.792073726654053, 'learning_rate': 5.182076410274311e-07, 'epoch': 6.02}\n",
      "{'loss': 0.8727, 'grad_norm': 9.433794021606445, 'learning_rate': 4.932865178134725e-07, 'epoch': 6.07}\n",
      "{'loss': 0.6914, 'grad_norm': 4.941043376922607, 'learning_rate': 4.688701068147788e-07, 'epoch': 6.12}\n",
      "{'loss': 0.8099, 'grad_norm': 4.667636871337891, 'learning_rate': 4.4496951408113133e-07, 'epoch': 6.17}\n",
      "{'loss': 0.749, 'grad_norm': 5.169430255889893, 'learning_rate': 4.215956110371946e-07, 'epoch': 6.22}\n",
      "{'loss': 0.8239, 'grad_norm': 4.490485191345215, 'learning_rate': 3.987590295375371e-07, 'epoch': 6.28}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe73a7da6ee14210b23671c55c148239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9522552490234375, 'eval_roc_auc_micro': 0.8329390486145415, 'eval_pr_auc_micro': 0.377133555767456, 'eval_roc_auc_macro': 0.8275149099010711, 'eval_pr_auc_macro': 0.40794270874560556, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4234, 'eval_samples_per_second': 1851.553, 'eval_steps_per_second': 30.702, 'epoch': 6.3}\n",
      "{'loss': 0.8547, 'grad_norm': 8.22145938873291, 'learning_rate': 3.7647015703062476e-07, 'epoch': 6.33}\n",
      "{'loss': 0.8159, 'grad_norm': 9.46000862121582, 'learning_rate': 3.5473913183398905e-07, 'epoch': 6.38}\n",
      "{'loss': 0.869, 'grad_norm': 4.290520668029785, 'learning_rate': 3.335758385227071e-07, 'epoch': 6.43}\n",
      "{'loss': 0.722, 'grad_norm': 3.6784329414367676, 'learning_rate': 3.1298990343330766e-07, 'epoch': 6.48}\n",
      "{'loss': 0.7004, 'grad_norm': 5.699499130249023, 'learning_rate': 2.929906902851315e-07, 'epoch': 6.53}\n",
      "{'loss': 0.8711, 'grad_norm': 4.099853515625, 'learning_rate': 2.7358729592115255e-07, 'epoch': 6.58}\n",
      "{'loss': 0.7254, 'grad_norm': 2.8874473571777344, 'learning_rate': 2.5478854617018653e-07, 'epoch': 6.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da535473d48544c9a9ad8fb6a5342a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9590635299682617, 'eval_roc_auc_micro': 0.8325422956351918, 'eval_pr_auc_micro': 0.3782050368484001, 'eval_roc_auc_macro': 0.8269394612260396, 'eval_pr_auc_macro': 0.40607577301253733, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.424, 'eval_samples_per_second': 1849.058, 'eval_steps_per_second': 30.66, 'epoch': 6.63}\n",
      "{'loss': 0.8698, 'grad_norm': 2.9129183292388916, 'learning_rate': 2.3660299183237222e-07, 'epoch': 6.68}\n",
      "{'loss': 0.8191, 'grad_norm': 6.443553924560547, 'learning_rate': 2.190389047897578e-07, 'epoch': 6.73}\n",
      "{'loss': 0.7463, 'grad_norm': 3.6189162731170654, 'learning_rate': 2.0210427424374854e-07, 'epoch': 6.79}\n",
      "{'loss': 0.8629, 'grad_norm': 8.174485206604004, 'learning_rate': 1.8580680308114053e-07, 'epoch': 6.84}\n",
      "{'loss': 0.8033, 'grad_norm': 9.6724271774292, 'learning_rate': 1.7015390437038498e-07, 'epoch': 6.89}\n",
      "{'loss': 0.8086, 'grad_norm': 4.709192752838135, 'learning_rate': 1.5515269798967907e-07, 'epoch': 6.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2b555ad2e6496a9579e5052e7b1f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9518710374832153, 'eval_roc_auc_micro': 0.8331312146421674, 'eval_pr_auc_micro': 0.37760727533783056, 'eval_roc_auc_macro': 0.8274266019426978, 'eval_pr_auc_macro': 0.4063698201558621, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4271, 'eval_samples_per_second': 1835.683, 'eval_steps_per_second': 30.439, 'epoch': 6.96}\n",
      "{'loss': 0.9082, 'grad_norm': 4.194159507751465, 'learning_rate': 1.4081000738841802e-07, 'epoch': 6.99}\n",
      "{'loss': 0.7643, 'grad_norm': 4.248445510864258, 'learning_rate': 1.2713235648348005e-07, 'epoch': 7.04}\n",
      "{'loss': 0.7561, 'grad_norm': 3.295499801635742, 'learning_rate': 1.141259666917586e-07, 'epoch': 7.09}\n",
      "{'loss': 0.8094, 'grad_norm': 5.437462329864502, 'learning_rate': 1.0179675410028749e-07, 'epoch': 7.14}\n",
      "{'loss': 0.888, 'grad_norm': 3.833961009979248, 'learning_rate': 9.015032677524914e-08, 'epoch': 7.19}\n",
      "{'loss': 0.78, 'grad_norm': 3.2220189571380615, 'learning_rate': 7.919198221108907e-08, 'epoch': 7.24}\n",
      "{'loss': 0.8086, 'grad_norm': 4.452741622924805, 'learning_rate': 6.892670492089933e-08, 'epoch': 7.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a807c75796471a888897338fa66ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9530571699142456, 'eval_roc_auc_micro': 0.833076514803353, 'eval_pr_auc_micro': 0.37734814006039175, 'eval_roc_auc_macro': 0.8272896754736013, 'eval_pr_auc_macro': 0.4063904075888258, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4225, 'eval_samples_per_second': 1855.456, 'eval_steps_per_second': 30.766, 'epoch': 7.3}\n",
      "{'train_runtime': 83.4824, 'train_samples_per_second': 600.27, 'train_steps_per_second': 18.782, 'train_loss': 0.8809666436868948, 'epoch': 7.3}\n",
      "Done.\n",
      "\n",
      "Evaluating v2_best on VAL...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d8214627e94d7dbdb95e1563f22b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9522552490234375, 'eval_roc_auc_micro': 0.8329390486145415, 'eval_pr_auc_micro': 0.377133555767456, 'eval_roc_auc_macro': 0.8275149099010711, 'eval_pr_auc_macro': 0.40794270874560556, 'eval_macro_valid_labels': 12, 'eval_runtime': 0.4212, 'eval_samples_per_second': 1861.568, 'eval_steps_per_second': 30.868, 'epoch': 7.295918367346939}\n",
      "\n",
      "Evaluating v2_best on TEST...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ed8d53bed04e1faf0bf50c7eb49ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_pr_auc_macro so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 1.0026870965957642, 'test_roc_auc_micro': 0.8258904800440988, 'test_pr_auc_micro': 0.3882151959900294, 'test_roc_auc_macro': 0.8033095195160911, 'test_pr_auc_macro': 0.39577506851345007, 'test_macro_valid_labels': 12, 'test_runtime': 0.342, 'test_samples_per_second': 2289.475, 'test_steps_per_second': 38.012, 'epoch': 7.295918367346939}\n",
      "\n",
      "Dumping outputs for v2_best...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a64d730021c4f8a8c1708b96765d9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] val_*_v2best.npy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668bb7e0c126407680f3953b56d3a035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] test_*_v2best.npy\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 9b (patched): Refit best config robustly and evaluate ====\n",
    "import json, math, gc, numpy as np, torch\n",
    "from pathlib import Path\n",
    "from transformers import TrainingArguments, EarlyStoppingCallback, AutoConfig, AutoModelForSequenceClassification\n",
    "\n",
    "META_DIR = Path(\"implementation/models/chemberta_v2/metadata\")\n",
    "V2_DIR   = Path(\"implementation/models/chemberta_v2\")\n",
    "OUT_DIR  = V2_DIR / \"outputs\"\n",
    "CKPT_DIR = V2_DIR / \"checkpoints\"\n",
    "\n",
    "# 1) Load best_hparams.json if present; otherwise fall back to v2b-style defaults\n",
    "best_json_path = META_DIR / \"best_hparams.json\"\n",
    "if best_json_path.exists():\n",
    "    with open(best_json_path) as f:\n",
    "        BEST = json.load(f)\n",
    "    best_cfg = BEST.get(\"cfg\", None)\n",
    "else:\n",
    "    BEST = {}\n",
    "    best_cfg = None\n",
    "\n",
    "if best_cfg is None:\n",
    "    print(\"[WARN] No HPO config found; falling back to v2b-like defaults.\")\n",
    "    best_cfg = {\n",
    "        \"loss\": \"bce\",\n",
    "        \"learning_rate\": float(run_cfg.learning_rate),   # e.g., 1e-5 from your v2b\n",
    "        \"weight_decay\": float(run_cfg.weight_decay),     # e.g., 0.01\n",
    "        \"warmup_ratio\": float(run_cfg.warmup_ratio),     # e.g., 0.06\n",
    "        \"batch_size\": int(run_cfg.train_batch_size),     # e.g., 32\n",
    "        \"max_length\": int(run_cfg.max_length),           # e.g., 256\n",
    "        \"label_smoothing\": float(run_cfg.label_smoothing),  # e.g., 0.05 (v2b)\n",
    "        \"llrd_enable\": bool(run_cfg.llrd_enable),        # e.g., True (v2b)\n",
    "        \"llrd_decay\": float(run_cfg.llrd_decay),         # e.g., 0.90\n",
    "        \"augment\": bool(run_cfg.use_random_smiles),      # e.g., True (v2b)\n",
    "        # if your HPO picked focal/asl, add keys here; BCE default is fine\n",
    "    }\n",
    "\n",
    "print(\"Refitting with config:\", best_cfg)\n",
    "\n",
    "# 2) Rebuild datasets with chosen max_length & augmentation\n",
    "run_cfg.use_random_smiles = bool(best_cfg.get(\"augment\", False))\n",
    "train_best = Tox21Dataset(df_train, tokenizer, max_length=int(best_cfg[\"max_length\"]), train=True)\n",
    "val_best   = Tox21Dataset(df_val,   tokenizer, max_length=int(best_cfg[\"max_length\"]), train=False)\n",
    "test_best  = Tox21Dataset(df_test,  tokenizer, max_length=int(best_cfg[\"max_length\"]), train=False)\n",
    "\n",
    "# 3) Fresh model from v1\n",
    "config_v2best = AutoConfig.from_pretrained(\n",
    "    str(V1_DIR),\n",
    "    num_labels=len(label_names),\n",
    "    id2label={i: lbl for i, lbl in id2label.items()},\n",
    "    label2id={lbl: i for lbl, i in label2id.items()},\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "model_best = AutoModelForSequenceClassification.from_pretrained(str(V1_DIR), config=config_v2best).to(DEVICE)\n",
    "if run_cfg.gradient_checkpointing: model_best.gradient_checkpointing_enable()\n",
    "if hasattr(model_best.config, \"use_cache\"): model_best.config.use_cache = False\n",
    "\n",
    "# 4) Ensure auxiliary vectors exist (alpha_vec_asl, focal_*); build if missing\n",
    "if \"alpha_vec_asl\" not in globals():\n",
    "    # build positive-class alpha from TRAIN prevalence (0.25..0.75)\n",
    "    col = train_best.df\n",
    "    av = []\n",
    "    for l in label_names:\n",
    "        pos_rate = (col[l] == 1).sum() / max(1, col[l].notna().sum())\n",
    "        if np.isnan(pos_rate) or pos_rate == 0:\n",
    "            a = 0.5\n",
    "        else:\n",
    "            a = float(np.clip(1.0 - pos_rate, 0.25, 0.75))\n",
    "        av.append(a)\n",
    "    alpha_vec_asl = torch.tensor(av, dtype=torch.float32)\n",
    "\n",
    "if \"focal_alpha_vec\" not in globals():\n",
    "    focal_alpha_vec = alpha_vec_asl.clone()\n",
    "\n",
    "if \"focal_gamma_vec_base\" not in globals():\n",
    "    focal_gamma_vec_base = torch.tensor([1.5]*len(label_names), dtype=torch.float32)\n",
    "\n",
    "# 5) Pick Trainer & loss based on best_cfg\n",
    "trainer_cls = V2Trainer\n",
    "extra_kwargs = {}\n",
    "metric_primary = \"pr_auc_macro\"  # we optimized PR-macro in HPO\n",
    "loss_kind = best_cfg.get(\"loss\", \"bce\").lower()\n",
    "\n",
    "if loss_kind == \"asl\":\n",
    "    trainer_cls = V2TrainerASL\n",
    "    # default if HPO keys missing\n",
    "    gpos = float(best_cfg.get(\"gamma_pos\", 2.0))\n",
    "    gneg = float(best_cfg.get(\"gamma_neg\", 1.0))\n",
    "    clip = float(best_cfg.get(\"clip\", 0.05))\n",
    "    extra_kwargs.update(dict(\n",
    "        gamma_pos=gpos, gamma_neg=gneg, clip=clip,\n",
    "        alpha_vec=alpha_vec_asl.to(DEVICE)\n",
    "    ))\n",
    "    lsmooth = 0.0\n",
    "    pos_weight_arg = None\n",
    "elif loss_kind == \"focal\":\n",
    "    trainer_cls = V2TrainerFocal\n",
    "    gscalar = float(best_cfg.get(\"gamma\", 1.8))\n",
    "    gvec = (focal_gamma_vec_base * 0 + gscalar).to(DEVICE)\n",
    "    extra_kwargs.update(dict(\n",
    "        use_focal=True,\n",
    "        focal_alpha=focal_alpha_vec.to(DEVICE),\n",
    "        focal_gamma=gvec,\n",
    "    ))\n",
    "    lsmooth = float(best_cfg.get(\"label_smoothing\", 0.0))\n",
    "    pos_weight_arg = POS_WEIGHT\n",
    "else:  # BCE\n",
    "    lsmooth = float(best_cfg.get(\"label_smoothing\", 0.0))\n",
    "    pos_weight_arg = POS_WEIGHT\n",
    "\n",
    "# 6) Train longer\n",
    "EPOCHS_BEST = 8\n",
    "steps_per_epoch = math.ceil(len(train_best) / int(best_cfg[\"batch_size\"]))\n",
    "eval_steps = max(50, steps_per_epoch // 3)\n",
    "\n",
    "args_best = TrainingArguments(\n",
    "    output_dir=str(CKPT_DIR / \"v2_best\"),\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=int(best_cfg[\"batch_size\"]),\n",
    "    per_device_eval_batch_size=max(int(best_cfg[\"batch_size\"]), 64),\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=float(best_cfg[\"learning_rate\"]),\n",
    "    weight_decay=float(best_cfg[\"weight_decay\"]),\n",
    "    warmup_ratio=float(best_cfg[\"warmup_ratio\"]),\n",
    "    num_train_epochs=EPOCHS_BEST,\n",
    "    lr_scheduler_type=run_cfg.lr_schedule,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=eval_steps,\n",
    "    save_steps=eval_steps,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_primary,\n",
    "    greater_is_better=True,\n",
    "    fp16=run_cfg.fp16,\n",
    "    bf16=run_cfg.bfloat16,\n",
    "    gradient_checkpointing=run_cfg.gradient_checkpointing,\n",
    "    max_grad_norm=run_cfg.max_grad_norm,\n",
    "    report_to=[],\n",
    "    dataloader_num_workers=0,\n",
    "    dataloader_pin_memory=True,\n",
    "    disable_tqdm=False,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer_best = trainer_cls(\n",
    "    model=model_best,\n",
    "    args=args_best,\n",
    "    train_dataset=train_best,\n",
    "    eval_dataset=val_best,\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    "    pos_weight=pos_weight_arg,\n",
    "    label_smoothing=lsmooth,\n",
    "    llrd_enable=bool(best_cfg.get(\"llrd_enable\", False)),\n",
    "    llrd_decay=float(best_cfg.get(\"llrd_decay\", 0.9)),\n",
    "    **extra_kwargs\n",
    ")\n",
    "trainer_best.compute_metrics = make_compute_metrics(trainer_best)\n",
    "trainer_best.add_callback(EarlyStoppingCallback(early_stopping_patience=3))\n",
    "\n",
    "print(\"Training v2_best...\")\n",
    "train_out_best = trainer_best.train()\n",
    "print(\"Done.\")\n",
    "\n",
    "# 7) Evaluate & dump outputs with suffix _v2best\n",
    "print(\"\\nEvaluating v2_best on VAL...\")\n",
    "val_metrics_best = trainer_best.evaluate(eval_dataset=val_best)\n",
    "print(val_metrics_best)\n",
    "\n",
    "print(\"\\nEvaluating v2_best on TEST...\")\n",
    "test_metrics_best = trainer_best.evaluate(eval_dataset=test_best, metric_key_prefix=\"test\")\n",
    "print(test_metrics_best)\n",
    "\n",
    "trainer_best.save_model(str(V2_DIR / \"v2_best\"))\n",
    "tokenizer.save_pretrained(str(V2_DIR / \"v2_best\"))\n",
    "\n",
    "def dump_outputs_best(tr, ds, prefix):\n",
    "    preds = tr.predict(ds)\n",
    "    logits = preds.predictions if not isinstance(preds.predictions, tuple) else preds.predictions[0]\n",
    "    labels = preds.label_ids\n",
    "    mask   = torch.cat(tr._eval_label_masks, dim=0).numpy().astype(np.float32) if len(tr._eval_label_masks) else np.ones_like(labels, dtype=np.float32)\n",
    "    probs = 1/(1+np.exp(-logits))\n",
    "    np.save(OUT_DIR / f\"{prefix}_logits_v2best.npy\", logits.astype(np.float32))\n",
    "    np.save(OUT_DIR / f\"{prefix}_prob_v2best.npy\",    probs.astype(np.float32))\n",
    "    np.save(OUT_DIR / f\"{prefix}_y_v2best.npy\",       labels.astype(np.float32))\n",
    "    np.save(OUT_DIR / f\"{prefix}_mask_v2best.npy\",    mask.astype(np.float32))\n",
    "    print(f\"[SAVED] {prefix}_*_v2best.npy\")\n",
    "\n",
    "print(\"\\nDumping outputs for v2_best...\")\n",
    "dump_outputs_best(trainer_best, val_best, \"val\")\n",
    "dump_outputs_best(trainer_best, test_best, \"test\")\n",
    "\n",
    "# Save metrics/json\n",
    "METRICS_DIR = V2_DIR / \"metrics\"\n",
    "METRICS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "with open(METRICS_DIR / \"val_metrics_v2best.json\", \"w\") as f:\n",
    "    json.dump({k: float(v) if isinstance(v, (int,float,np.floating)) else v for k,v in val_metrics_best.items()}, f, indent=2)\n",
    "with open(METRICS_DIR / \"test_metrics_v2best.json\", \"w\") as f:\n",
    "    json.dump({k: float(v) if isinstance(v, (int,float,np.floating)) else v for k,v in test_metrics_best.items()}, f, indent=2)\n",
    "\n",
    "gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ae737d",
   "metadata": {},
   "source": [
    "### Quick summary & comparison (v2b vs v2_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9572d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== v2_best vs v2b (VAL) ===\n",
      "AUROC micro: nan  (Î” nan)\n",
      "AUROC macro: nan   (Î” nan)\n",
      "PR   micro: nan   (Î” nan)\n",
      "PR   macro: nan    (Î” nan)\n",
      "\n",
      "=== v2_best vs v2b (TEST) ===\n",
      "AUROC micro: 0.8259 (Î” 0.0039)\n",
      "AUROC macro: 0.8033  (Î” 0.0042)\n",
      "PR   micro: 0.3882  (Î” 0.0023)\n",
      "PR   macro: 0.3958   (Î” 0.0062)\n",
      "\n",
      "Artifacts:\n",
      "- Best hparams â†’ implementation\\models\\chemberta_v2\\metadata\\best_hparams.json\n",
      "- v2_best metrics â†’ implementation\\models\\chemberta_v2\\metrics\\val_metrics_v2best.json and implementation\\models\\chemberta_v2\\metrics\\test_metrics_v2best.json\n",
      "- v2b metrics â†’ implementation\\models\\chemberta_v2\\metrics\\val_metrics.json and implementation\\models\\chemberta_v2\\metrics\\test_metrics.json\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 9c: Compare v2_best vs v2b (VAL/TEST PR & AUROC) ====\n",
    "import numpy as np, json\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_DIR   = Path(\"implementation/models/chemberta_v2/outputs\")\n",
    "METRICS_DIR = Path(\"implementation/models/chemberta_v2/metrics\")\n",
    "\n",
    "def load_json(p): \n",
    "    with open(p) as f: return json.load(f)\n",
    "\n",
    "def peek(metrics, prefix=\"\"):\n",
    "    am = metrics.get(f\"{prefix}roc_auc_macro\", np.nan)\n",
    "    ami= metrics.get(f\"{prefix}roc_auc_micro\", np.nan)\n",
    "    pm = metrics.get(f\"{prefix}pr_auc_macro\",  np.nan)\n",
    "    pmi= metrics.get(f\"{prefix}pr_auc_micro\",  np.nan)\n",
    "    return float(ami), float(am), float(pmi), float(pm)\n",
    "\n",
    "# v2b (baseline tuned)\n",
    "vb_val  = load_json(METRICS_DIR / \"val_metrics.json\")       if (METRICS_DIR / \"val_metrics.json\").exists() else {}\n",
    "vb_test = load_json(METRICS_DIR / \"test_metrics.json\")      if (METRICS_DIR / \"test_metrics.json\").exists() else {}\n",
    "\n",
    "# v2_best\n",
    "vbest_val  = load_json(METRICS_DIR / \"val_metrics_v2best.json\")\n",
    "vbest_test = load_json(METRICS_DIR / \"test_metrics_v2best.json\")\n",
    "\n",
    "ami_b, am_b, pmi_b, pm_b   = peek(vb_val, \"\")\n",
    "amit_b, amt_b, pmit_b, pmt_b = peek(vb_test, \"test_\")\n",
    "\n",
    "ami_v, am_v, pmi_v, pm_v   = peek(vbest_val, \"\")\n",
    "amit_v, amt_v, pmit_v, pmt_v = peek(vbest_test, \"test_\")\n",
    "\n",
    "def fmt(x): \n",
    "    return \"nan\" if (x!=x) else f\"{x:.4f}\"\n",
    "\n",
    "print(\"=== v2_best vs v2b (VAL) ===\")\n",
    "print(f\"AUROC micro: {fmt(ami_v)}  (Î” {fmt(ami_v - ami_b) if ami_b==ami_b else 'nan'})\")\n",
    "print(f\"AUROC macro: {fmt(am_v)}   (Î” {fmt(am_v  - am_b ) if am_b==am_b else 'nan'})\")\n",
    "print(f\"PR   micro: {fmt(pmi_v)}   (Î” {fmt(pmi_v - pmi_b) if pmi_b==pmi_b else 'nan'})\")\n",
    "print(f\"PR   macro: {fmt(pm_v)}    (Î” {fmt(pm_v  - pm_b ) if pm_b==pm_b else 'nan'})\")\n",
    "\n",
    "print(\"\\n=== v2_best vs v2b (TEST) ===\")\n",
    "print(f\"AUROC micro: {fmt(amit_v)} (Î” {fmt(amit_v - amit_b) if amit_b==amit_b else 'nan'})\")\n",
    "print(f\"AUROC macro: {fmt(amt_v)}  (Î” {fmt(amt_v  - amt_b ) if amt_b==amt_b else 'nan'})\")\n",
    "print(f\"PR   micro: {fmt(pmit_v)}  (Î” {fmt(pmit_v - pmit_b) if pmit_b==pmit_b else 'nan'})\")\n",
    "print(f\"PR   macro: {fmt(pmt_v)}   (Î” {fmt(pmt_v  - pmt_b ) if pmt_b==pmt_b else 'nan'})\")\n",
    "\n",
    "print(\"\\nArtifacts:\")\n",
    "print(\"- Best hparams â†’\", META_DIR / \"best_hparams.json\")\n",
    "print(\"- v2_best metrics â†’\", METRICS_DIR / \"val_metrics_v2best.json\", \"and\", METRICS_DIR / \"test_metrics_v2best.json\")\n",
    "print(\"- v2b metrics â†’\", METRICS_DIR / \"val_metrics.json\", \"and\", METRICS_DIR / \"test_metrics.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf13331",
   "metadata": {},
   "source": [
    "### Recompute VAL metrics for v2_best and patch the JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c55710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== v2_best VAL (recomputed) ===\n",
      "roc_auc_micro     : 0.832939\n",
      "pr_auc_micro      : 0.377134\n",
      "roc_auc_macro     : 0.827515\n",
      "pr_auc_macro      : 0.407943\n",
      "macro_valid_labels: 12.000000\n",
      "Patched: implementation\\models\\chemberta_v2\\metrics\\val_metrics_v2best.json\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 9d: Recompute VAL metrics for v2_best & patch JSON ====\n",
    "import numpy as np, json\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "V2 = Path(\"implementation/models/chemberta_v2\")\n",
    "OUT = V2 / \"outputs\"\n",
    "MET = V2 / \"metrics\"\n",
    "\n",
    "# load arrays saved in 9b\n",
    "logits = np.load(OUT / \"val_logits_v2best.npy\")\n",
    "probs  = 1/(1+np.exp(-logits))\n",
    "y      = np.load(OUT / \"val_y_v2best.npy\").astype(int)\n",
    "mask   = np.load(OUT / \"val_mask_v2best.npy\").astype(int)\n",
    "\n",
    "# masked micro/macro metrics\n",
    "def masked_micro(y, p, m):\n",
    "    y_flat = y[m==1]; p_flat = p[m==1]\n",
    "    return dict(\n",
    "        roc_auc_micro=float(roc_auc_score(y_flat, p_flat)),\n",
    "        pr_auc_micro=float(average_precision_score(y_flat, p_flat)),\n",
    "    )\n",
    "\n",
    "def masked_macro(y, p, m):\n",
    "    aucs, aps, valid = [], [], 0\n",
    "    for j in range(y.shape[1]):\n",
    "        idx = m[:, j] == 1\n",
    "        yj, pj = y[idx, j], p[idx, j]\n",
    "        if len(yj) < 2 or (yj.max()==yj.min()): \n",
    "            continue\n",
    "        aucs.append(roc_auc_score(yj, pj))\n",
    "        aps.append(average_precision_score(yj, pj))\n",
    "        valid += 1\n",
    "    return dict(\n",
    "        roc_auc_macro=float(np.mean(aucs)) if aucs else float(\"nan\"),\n",
    "        pr_auc_macro=float(np.mean(aps)) if aps else float(\"nan\"),\n",
    "        macro_valid_labels=int(valid),\n",
    "    )\n",
    "\n",
    "val_micro = masked_micro(y, probs, mask)\n",
    "val_macro = masked_macro(y, probs, mask)\n",
    "val_metrics_fixed = {**val_micro, **val_macro}\n",
    "\n",
    "print(\"=== v2_best VAL (recomputed) ===\")\n",
    "for k,v in val_metrics_fixed.items():\n",
    "    print(f\"{k:18s}: {v:.6f}\" if isinstance(v,(int,float)) else f\"{k:18s}: {v}\")\n",
    "\n",
    "# patch metrics file so 9c can read next time\n",
    "(MET).mkdir(parents=True, exist_ok=True)\n",
    "with open(MET / \"val_metrics_v2best.json\", \"w\") as f:\n",
    "    json.dump(val_metrics_fixed, f, indent=2)\n",
    "print(\"Patched:\", MET / \"val_metrics_v2best.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64577d00",
   "metadata": {},
   "source": [
    "## 10: Calibrate (T + per-label Platt/Isotonic) â†’ Thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17597de",
   "metadata": {},
   "source": [
    "### calibration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b70dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Calibration] T = 1.000\n",
      "[Calibration] chosen: {'temp': 0, 'platt': 0, 'iso': 12}\n",
      "\n",
      "Saved:\n",
      "- temperature.npy\n",
      "- calibration_methods.json\n",
      "- platt_params.json\n",
      "- isotonic_params.json\n",
      "- thresholds.json\n",
      "- selected_run.json\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 10: Calibrate chosen run and compute thresholds ====\n",
    "import json, numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "V2_DIR  = Path(\"implementation/models/chemberta_v2\")\n",
    "OUT_DIR = V2_DIR / \"outputs\"\n",
    "META    = V2_DIR / \"metadata\"\n",
    "META.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# choose which run to finalize\n",
    "SELECT_SUFFIX = \"_v2best\"   # change to \"_v2b\" or \"_v2c\" if you prefer those\n",
    "\n",
    "# labels\n",
    "with open(META / \"labels.json\") as f:\n",
    "    LBL = json.load(f)\n",
    "id2label = {int(k): v for k, v in LBL[\"id2label\"].items()}\n",
    "label_names = [id2label[i] for i in range(LBL[\"n_labels\"])]\n",
    "\n",
    "# load VAL arrays\n",
    "val_logits = np.load(OUT_DIR / f\"val_logits{SELECT_SUFFIX}.npy\")\n",
    "val_y      = np.load(OUT_DIR / f\"val_y{SELECT_SUFFIX}.npy\")\n",
    "val_mask   = np.load(OUT_DIR / f\"val_mask{SELECT_SUFFIX}.npy\")\n",
    "\n",
    "# --- helpers ---\n",
    "def brier(y, p): return float(np.mean((p - y)**2))\n",
    "\n",
    "def fit_temperature(logits, y_true, mask):\n",
    "    idx = mask.astype(bool)\n",
    "    z = logits[idx]; y = y_true[idx]\n",
    "    def loss(t):\n",
    "        t = max(1e-6, float(t[0]))\n",
    "        p = 1/(1+np.exp(-(z / t)))\n",
    "        return np.mean((p - y)**2)\n",
    "    res = minimize(loss, x0=[1.0], method=\"L-BFGS-B\", bounds=[(1e-3, 100.0)])\n",
    "    return float(res.x[0])\n",
    "\n",
    "def fit_platt(z, y):\n",
    "    def nll(ab):\n",
    "        A,B = ab\n",
    "        p = 1/(1+np.exp(-(A*z + B)))\n",
    "        eps = 1e-9\n",
    "        return -np.mean(y*np.log(p+eps) + (1-y)*np.log(1-p+eps))\n",
    "    res = minimize(nll, x0=[1.0, 0.0], method=\"L-BFGS-B\")\n",
    "    A,B = map(float, res.x)\n",
    "    return A,B\n",
    "\n",
    "def fit_isotonic(p, y):\n",
    "    ir = IsotonicRegression(y_min=0.0, y_max=1.0, out_of_bounds=\"clip\")\n",
    "    ir.fit(p, y)\n",
    "    return ir.X_thresholds_.tolist(), ir.y_thresholds_.tolist()\n",
    "\n",
    "# 1) global temperature\n",
    "T = fit_temperature(val_logits, val_y, val_mask)\n",
    "print(f\"[Calibration] T = {T:.3f}\")\n",
    "temp_probs = 1/(1+np.exp(-(val_logits / max(T,1e-6))))\n",
    "\n",
    "# 2) per-label method selection (temp / platt / iso) by Brier score\n",
    "calibration_methods, platt_params, iso_params = {}, {}, {}\n",
    "for j, lbl in enumerate(label_names):\n",
    "    m = val_mask[:, j].astype(bool)\n",
    "    y = val_y[m, j].astype(int)\n",
    "    if y.size < 10 or (y.max()==y.min()):\n",
    "        calibration_methods[lbl] = {\"method\":\"temp\"}; continue\n",
    "\n",
    "    z  = val_logits[m, j]\n",
    "    pt = temp_probs[m, j]\n",
    "\n",
    "    b_temp = brier(y, pt)\n",
    "\n",
    "    try:\n",
    "        A,B   = fit_platt(z, y)\n",
    "        pp    = 1/(1+np.exp(-(A*z + B)))\n",
    "        b_pl  = brier(y, pp)\n",
    "    except Exception:\n",
    "        A=B=None; b_pl = np.inf\n",
    "\n",
    "    try:\n",
    "        X,Y   = fit_isotonic(pt, y)\n",
    "        pi    = np.interp(pt, np.asarray(X), np.asarray(Y))\n",
    "        b_iso = brier(y, pi)\n",
    "    except Exception:\n",
    "        X=Y=None; b_iso = np.inf\n",
    "\n",
    "    pick = min({\"temp\":b_temp, \"platt\":b_pl, \"iso\":b_iso}, key=lambda k: {\"temp\":b_temp, \"platt\":b_pl, \"iso\":b_iso}[k])\n",
    "    calibration_methods[lbl] = {\"method\": pick}\n",
    "    if pick == \"platt\" and A is not None: platt_params[lbl] = {\"A\":A,\"B\":B}\n",
    "    if pick == \"iso\"   and X is not None: iso_params[lbl]   = {\"X\":X,\"Y\":Y}\n",
    "\n",
    "print(\"[Calibration] chosen:\", {m: list(calibration_methods.values()).count({\"method\": m}) for m in [\"temp\",\"platt\",\"iso\"]})\n",
    "\n",
    "# 3) thresholds on calibrated VAL probs (Youden J)\n",
    "def apply_calibration(lbl, z_col):\n",
    "    p = 1/(1+np.exp(-(z_col / max(T,1e-6))))\n",
    "    meth = calibration_methods.get(lbl, {}).get(\"method\",\"temp\")\n",
    "    if meth == \"platt\" and lbl in platt_params:\n",
    "        A,B = platt_params[lbl][\"A\"], platt_params[lbl][\"B\"]\n",
    "        p = 1/(1+np.exp(-(A*z_col + B)))\n",
    "    elif meth == \"iso\" and lbl in iso_params:\n",
    "        X, Y = np.asarray(iso_params[lbl][\"X\"]), np.asarray(iso_params[lbl][\"Y\"])\n",
    "        p = np.interp(p, X, Y)\n",
    "    return p\n",
    "\n",
    "thresholds = {}\n",
    "for j, lbl in enumerate(label_names):\n",
    "    m = val_mask[:, j].astype(bool)\n",
    "    y = val_y[m, j].astype(int)\n",
    "    if y.size < 10 or (y.max()==y.min()):\n",
    "        thresholds[lbl] = 0.5; continue\n",
    "    z = val_logits[m, j]\n",
    "    p_cal = apply_calibration(lbl, z)\n",
    "\n",
    "    best_thr, best_score = 0.5, -1\n",
    "    for thr in np.linspace(0.05, 0.95, 19):\n",
    "        yp = (p_cal >= thr).astype(int)\n",
    "        tp = ((yp == 1) & (y == 1)).sum()\n",
    "        tn = ((yp == 0) & (y == 0)).sum()\n",
    "        fp = ((yp == 1) & (y == 0)).sum()\n",
    "        fn = ((yp == 0) & (y == 1)).sum()\n",
    "        tpr = tp / (tp + fn + 1e-8)\n",
    "        fpr = fp / (fp + tn + 1e-8)\n",
    "        J   = tpr - fpr\n",
    "        if J > best_score:\n",
    "            best_score, best_thr = J, thr\n",
    "    thresholds[lbl] = round(float(best_thr), 3)\n",
    "\n",
    "# 4) save artifacts for the app/utils\n",
    "np.save(META / \"temperature.npy\", np.array([T], dtype=np.float32))\n",
    "with open(META / \"calibration_methods.json\",\"w\") as f: json.dump(calibration_methods, f, indent=2)\n",
    "with open(META / \"platt_params.json\",\"w\") as f: json.dump(platt_params, f, indent=2)\n",
    "with open(META / \"isotonic_params.json\",\"w\") as f: json.dump(iso_params, f, indent=2)\n",
    "with open(META / \"thresholds.json\",\"w\") as f: json.dump(thresholds, f, indent=2)\n",
    "with open(META / \"selected_run.json\",\"w\") as f: json.dump({\"suffix\": SELECT_SUFFIX, \"note\": \"calibrated from this run\"}, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\"- temperature.npy\")\n",
    "print(\"- calibration_methods.json\")\n",
    "print(\"- platt_params.json\")\n",
    "print(\"- isotonic_params.json\")\n",
    "print(\"- thresholds.json\")\n",
    "print(\"- selected_run.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0a80f",
   "metadata": {},
   "source": [
    "### Sanity check calibration & thresholds on TEST (Brier + F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ada734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEST calibration sanity ===\n",
      "Brier (raw)        : 0.1350\n",
      "Brier (calibrated) : 0.0542  (Î” -0.0808 â†’ lower is better)\n",
      "Micro-F1 (raw thr) : 0.1981\n",
      "Micro-F1 (cal thr) : 0.8173  (Î” +0.6193)\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 10b: Evaluate calibration impact on TEST ====\n",
    "import json, numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "V2 = Path(\"implementation/models/chemberta_v2\")\n",
    "OUT = V2 / \"outputs\"\n",
    "META = V2 / \"metadata\"\n",
    "\n",
    "with open(META / \"labels.json\") as f:\n",
    "    LBL = json.load(f)\n",
    "id2label = {int(k): v for k, v in LBL[\"id2label\"].items()}\n",
    "labels = [id2label[i] for i in range(LBL[\"n_labels\"])]\n",
    "\n",
    "with open(META / \"selected_run.json\") as f:\n",
    "    sel = json.load(f)\n",
    "SUFFIX = sel[\"suffix\"]  # e.g., \"_v2best\"\n",
    "\n",
    "# load TEST arrays\n",
    "z = np.load(OUT / f\"test_logits{SUFFIX}.npy\")\n",
    "y = np.load(OUT / f\"test_y{SUFFIX}.npy\").astype(int)\n",
    "m = np.load(OUT / f\"test_mask{SUFFIX}.npy\").astype(int)\n",
    "p_raw = 1/(1+np.exp(-z))\n",
    "\n",
    "# load calibration artifacts + thresholds\n",
    "T = float(np.load(META / \"temperature.npy\")[0])\n",
    "with open(META / \"calibration_methods.json\") as f: methods = json.load(f)\n",
    "with open(META / \"platt_params.json\") as f: platt = json.load(f)\n",
    "with open(META / \"isotonic_params.json\") as f: iso = json.load(f)\n",
    "with open(META / \"thresholds.json\") as f: thr = json.load(f)\n",
    "\n",
    "def apply_cal(lbl, zcol):\n",
    "    p = 1/(1+np.exp(-(zcol / max(T,1e-6))))\n",
    "    meth = methods.get(lbl, {}).get(\"method\", \"temp\")\n",
    "    if meth == \"platt\" and lbl in platt:\n",
    "        A, B = platt[lbl][\"A\"], platt[lbl][\"B\"]\n",
    "        p = 1/(1+np.exp(-(A*zcol + B)))\n",
    "    elif meth == \"iso\" and lbl in iso:\n",
    "        X, Y = np.asarray(iso[lbl][\"X\"]), np.asarray(iso[lbl][\"Y\"])\n",
    "        p = np.interp(p, X, Y)\n",
    "    return p\n",
    "\n",
    "# calibrated probs\n",
    "p_cal = np.zeros_like(p_raw)\n",
    "for j, lbl in enumerate(labels):\n",
    "    p_cal[:, j] = apply_cal(lbl, z[:, j])\n",
    "\n",
    "def brier(y_true, p_pred, mask):\n",
    "    idx = mask == 1\n",
    "    return float(np.mean((p_pred[idx] - y_true[idx])**2))\n",
    "\n",
    "# Brier scores (micro over observed entries)\n",
    "brier_raw = brier(y, p_raw, m)\n",
    "brier_cal = brier(y, p_cal, m)\n",
    "\n",
    "# micro-F1 using per-label thresholds (from VAL) on TEST\n",
    "yhat_raw = np.zeros_like(y)\n",
    "yhat_cal = np.zeros_like(y)\n",
    "for j, lbl in enumerate(labels):\n",
    "    t = float(thr.get(lbl, 0.5))\n",
    "    yhat_raw[:, j] = (p_raw[:, j] >= t).astype(int)\n",
    "    yhat_cal[:, j] = (p_cal[:, j] >= t).astype(int)\n",
    "\n",
    "# compute micro-F1 only where labels observed\n",
    "idx = (m == 1)\n",
    "f1_raw = f1_score(y[idx], yhat_raw[idx], average=\"micro\", zero_division=0)\n",
    "f1_cal = f1_score(y[idx], yhat_cal[idx], average=\"micro\", zero_division=0)\n",
    "\n",
    "print(\"=== TEST calibration sanity ===\")\n",
    "print(f\"Brier (raw)        : {brier_raw:.4f}\")\n",
    "print(f\"Brier (calibrated) : {brier_cal:.4f}  (Î” {brier_cal - brier_raw:+.4f} â†’ lower is better)\")\n",
    "print(f\"Micro-F1 (raw thr) : {f1_raw:.4f}\")\n",
    "print(f\"Micro-F1 (cal thr) : {f1_cal:.4f}  (Î” {f1_cal - f1_raw:+.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cb43ca",
   "metadata": {},
   "source": [
    "### Post-calibration quality checks (positive F1/precision/recall + coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be129d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Pred_Pos_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SR-MMP</td>\n",
       "      <td>0.541516</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.815217</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-AR</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.030513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>0.496000</td>\n",
       "      <td>0.358382</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.262121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>0.435233</td>\n",
       "      <td>0.371681</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.177673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.691489</td>\n",
       "      <td>0.357766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.078635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NR-ER-LBD</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.216495</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.137980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SR-ATAD5</td>\n",
       "      <td>0.295082</td>\n",
       "      <td>0.189474</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.133615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>0.287770</td>\n",
       "      <td>0.183486</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.187285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>0.229358</td>\n",
       "      <td>0.138122</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.276336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.122222</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.135747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SR-p53</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.105105</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.481910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label        F1  Precision    Recall  Pred_Pos_Rate\n",
       "10         SR-MMP  0.541516   0.405405  0.815217       0.312500\n",
       "0           NR-AR  0.538462   0.636364  0.466667       0.030513\n",
       "2          NR-AhR  0.496000   0.358382  0.805195       0.262121\n",
       "4           NR-ER  0.435233   0.371681  0.525000       0.177673\n",
       "7          SR-ARE  0.434783   0.317073  0.691489       0.357766\n",
       "1       NR-AR-LBD  0.389610   0.283019  0.625000       0.078635\n",
       "5       NR-ER-LBD  0.318182   0.216495  0.600000       0.137980\n",
       "8        SR-ATAD5  0.295082   0.189474  0.666667       0.133615\n",
       "3    NR-Aromatase  0.287770   0.183486  0.666667       0.187285\n",
       "9          SR-HSE  0.229358   0.138122  0.675676       0.276336\n",
       "6   NR-PPAR-gamma  0.203704   0.122222  0.611111       0.135747\n",
       "11         SR-p53  0.186667   0.105105  0.833333       0.481910"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Positive-class (micro over all observed entries) ===\n",
      "F1=0.3595  Precision=0.2434  Recall=0.6877\n",
      "Coverage (predicted positive rate) overall: 0.2107\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 10c: Positive-class F1/precision/recall + coverage after calibration ====\n",
    "import json, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "V2 = Path(\"implementation/models/chemberta_v2\")\n",
    "OUT = V2 / \"outputs\"\n",
    "META = V2 / \"metadata\"\n",
    "\n",
    "with open(META / \"labels.json\") as f:\n",
    "    LBL = json.load(f)\n",
    "id2label = {int(k): v for k, v in LBL[\"id2label\"].items()}\n",
    "labels = [id2label[i] for i in range(LBL[\"n_labels\"])]\n",
    "\n",
    "with open(META / \"selected_run.json\") as f:\n",
    "    sel = json.load(f)\n",
    "SUFFIX = sel[\"suffix\"]  # e.g., \"_v2best\"\n",
    "\n",
    "# test arrays\n",
    "z = np.load(OUT / f\"test_logits{SUFFIX}.npy\")\n",
    "y = np.load(OUT / f\"test_y{SUFFIX}.npy\").astype(int)\n",
    "m = np.load(OUT / f\"test_mask{SUFFIX}.npy\").astype(int)\n",
    "\n",
    "# calibration + thresholds\n",
    "T = float(np.load(META / \"temperature.npy\")[0])\n",
    "with open(META / \"calibration_methods.json\") as f: methods = json.load(f)\n",
    "with open(META / \"platt_params.json\") as f: platt = json.load(f)\n",
    "with open(META / \"isotonic_params.json\") as f: iso = json.load(f)\n",
    "with open(META / \"thresholds.json\") as f: thr = json.load(f)\n",
    "\n",
    "def apply_cal(lbl, zcol):\n",
    "    p = 1/(1+np.exp(-(zcol / max(T,1e-6))))\n",
    "    meth = methods.get(lbl, {}).get(\"method\", \"temp\")\n",
    "    if meth == \"platt\" and lbl in platt:\n",
    "        A,B = platt[lbl][\"A\"], platt[lbl][\"B\"]\n",
    "        p = 1/(1+np.exp(-(A*zcol + B)))\n",
    "    elif meth == \"iso\" and lbl in iso:\n",
    "        X, Y = np.asarray(iso[lbl][\"X\"]), np.asarray(iso[lbl][\"Y\"])\n",
    "        p = np.interp(p, X, Y)\n",
    "    return p\n",
    "\n",
    "# calibrated probs + hard predictions\n",
    "P = np.zeros_like(z, dtype=float)\n",
    "YH = np.zeros_like(y, dtype=int)\n",
    "for j, lbl in enumerate(labels):\n",
    "    pj = apply_cal(lbl, z[:, j])\n",
    "    P[:, j] = pj\n",
    "    YH[:, j] = (pj >= float(thr.get(lbl, 0.5))).astype(int)\n",
    "\n",
    "# micro positive-only metrics (flatten observed entries)\n",
    "idx = (m == 1)\n",
    "y_obs  = y[idx].ravel()\n",
    "yh_obs = YH[idx].ravel()\n",
    "\n",
    "f1_pos   = f1_score(y_obs, yh_obs, average=\"binary\", zero_division=0)\n",
    "prec_pos = precision_score(y_obs, yh_obs, average=\"binary\", zero_division=0)\n",
    "rec_pos  = recall_score(y_obs, yh_obs, average=\"binary\", zero_division=0)\n",
    "\n",
    "# coverage: fraction predicted positive overall and per label\n",
    "coverage_overall = float(yh_obs.mean())\n",
    "per_label = []\n",
    "for j, lbl in enumerate(labels):\n",
    "    mj = m[:, j] == 1\n",
    "    if mj.sum() == 0:\n",
    "        per_label.append((lbl, np.nan, np.nan, np.nan, np.nan))\n",
    "        continue\n",
    "    f1j   = f1_score(y[mj, j], YH[mj, j], average=\"binary\", zero_division=0)\n",
    "    prj   = precision_score(y[mj, j], YH[mj, j], average=\"binary\", zero_division=0)\n",
    "    rcj   = recall_score(y[mj, j], YH[mj, j], average=\"binary\", zero_division=0)\n",
    "    covj  = float(YH[mj, j].mean())\n",
    "    per_label.append((lbl, f1j, prj, rcj, covj))\n",
    "\n",
    "tbl = pd.DataFrame(per_label, columns=[\"label\",\"F1\",\"Precision\",\"Recall\",\"Pred_Pos_Rate\"]).sort_values(\"F1\", ascending=False)\n",
    "display(tbl)\n",
    "\n",
    "print(\"=== Positive-class (micro over all observed entries) ===\")\n",
    "print(f\"F1={f1_pos:.4f}  Precision={prec_pos:.4f}  Recall={rec_pos:.4f}\")\n",
    "print(f\"Coverage (predicted positive rate) overall: {coverage_overall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7089e0e1",
   "metadata": {},
   "source": [
    "## 11: Recompute TCAV for ChemBERTa v2 (embed â†’ CAV â†’ TCAV â†’ save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09db524",
   "metadata": {},
   "source": [
    "### New Concept_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04791086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:40:58] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept</th>\n",
       "      <th>smarts</th>\n",
       "      <th>n_pos</th>\n",
       "      <th>n_rand</th>\n",
       "      <th>kept</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>a1aaaaa1</td>\n",
       "      <td>4800</td>\n",
       "      <td>3031.0</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phenol</td>\n",
       "      <td>c1ccc(cc1)O</td>\n",
       "      <td>1695</td>\n",
       "      <td>1695.0</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TertiaryAmine</td>\n",
       "      <td>[NX3]([#6])([#6])[#6]</td>\n",
       "      <td>1495</td>\n",
       "      <td>1495.0</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ester</td>\n",
       "      <td>[CX3](=O)[OX2H0][#6]</td>\n",
       "      <td>1482</td>\n",
       "      <td>1482.0</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Aniline</td>\n",
       "      <td>Nc1ccccc1</td>\n",
       "      <td>1366</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ArylHalide</td>\n",
       "      <td>[$([Cl,Br,I])]-c</td>\n",
       "      <td>998</td>\n",
       "      <td>998.0</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CarboxylicAcid</td>\n",
       "      <td>[CX3](=O)[OX2H1]</td>\n",
       "      <td>811</td>\n",
       "      <td>811.0</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MichaelAcceptor</td>\n",
       "      <td>C=CC=O</td>\n",
       "      <td>622</td>\n",
       "      <td>622.0</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pyridine</td>\n",
       "      <td>n1ccccc1</td>\n",
       "      <td>473</td>\n",
       "      <td>473.0</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nitro</td>\n",
       "      <td>[N+](=O)[O-]</td>\n",
       "      <td>343</td>\n",
       "      <td>343.0</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sulfonamide</td>\n",
       "      <td>S(=O)(=O)N</td>\n",
       "      <td>261</td>\n",
       "      <td>261.0</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Carboxylate</td>\n",
       "      <td>[CX3](=O)[O-]</td>\n",
       "      <td>180</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SKIP_TOO_FEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>QuaternaryAmmonium</td>\n",
       "      <td>[N+](C)(C)C</td>\n",
       "      <td>145</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SKIP_TOO_FEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Aldehyde</td>\n",
       "      <td>[CX3H1](=O)[#6]</td>\n",
       "      <td>131</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SKIP_TOO_FEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indole</td>\n",
       "      <td>c1ccc2[nH]ccc2c1</td>\n",
       "      <td>92</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SKIP_TOO_FEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Imidazole</td>\n",
       "      <td>n1c[nH]cc1</td>\n",
       "      <td>88</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SKIP_TOO_FEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Acrylamide</td>\n",
       "      <td>C=CC(=O)N</td>\n",
       "      <td>78</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SKIP_TOO_FEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Epoxide</td>\n",
       "      <td>C1OC1</td>\n",
       "      <td>70</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SKIP_TOO_FEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Quinone</td>\n",
       "      <td>O=C1C=CC(=O)C=C1</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SKIP_TOO_FEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FusedArenes</td>\n",
       "      <td>c1ccc2cccc2c1</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SKIP_TOO_FEW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               concept                 smarts  n_pos  n_rand  kept  \\\n",
       "0         AromaticRing               a1aaaaa1   4800  3031.0  True   \n",
       "3               Phenol            c1ccc(cc1)O   1695  1695.0  True   \n",
       "4        TertiaryAmine  [NX3]([#6])([#6])[#6]   1495  1495.0  True   \n",
       "16               Ester   [CX3](=O)[OX2H0][#6]   1482  1482.0  True   \n",
       "18             Aniline              Nc1ccccc1   1366  1366.0  True   \n",
       "2           ArylHalide       [$([Cl,Br,I])]-c    998   998.0  True   \n",
       "14      CarboxylicAcid       [CX3](=O)[OX2H1]    811   811.0  True   \n",
       "5      MichaelAcceptor                 C=CC=O    622   622.0  True   \n",
       "8             Pyridine               n1ccccc1    473   473.0  True   \n",
       "1                Nitro           [N+](=O)[O-]    343   343.0  True   \n",
       "17         Sulfonamide             S(=O)(=O)N    261   261.0  True   \n",
       "15         Carboxylate          [CX3](=O)[O-]    180                 \n",
       "19  QuaternaryAmmonium            [N+](C)(C)C    145                 \n",
       "11            Aldehyde        [CX3H1](=O)[#6]    131                 \n",
       "7               Indole       c1ccc2[nH]ccc2c1     92                 \n",
       "9            Imidazole             n1c[nH]cc1     88                 \n",
       "12          Acrylamide              C=CC(=O)N     78                 \n",
       "13             Epoxide                  C1OC1     70                 \n",
       "6              Quinone       O=C1C=CC(=O)C=C1     11                 \n",
       "10         FusedArenes          c1ccc2cccc2c1      4                 \n",
       "\n",
       "            note  \n",
       "0                 \n",
       "3                 \n",
       "4                 \n",
       "16                \n",
       "18                \n",
       "2                 \n",
       "14                \n",
       "5                 \n",
       "8                 \n",
       "1                 \n",
       "17                \n",
       "15  SKIP_TOO_FEW  \n",
       "19  SKIP_TOO_FEW  \n",
       "11  SKIP_TOO_FEW  \n",
       "7   SKIP_TOO_FEW  \n",
       "9   SKIP_TOO_FEW  \n",
       "12  SKIP_TOO_FEW  \n",
       "13  SKIP_TOO_FEW  \n",
       "6   SKIP_TOO_FEW  \n",
       "10  SKIP_TOO_FEW  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved 11 concepts to: implementation\\concepts\\concept_list_v2.yaml\n",
      "Cohorts written under: implementation\\concept_cohorts_v2\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 11a: Build concept_list_v2 + cohorts (pos_ids/rand_ids) ====\n",
    "import os, json, random, yaml\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# RDKit for SMARTS matching\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "random.seed(42); np.random.seed(42)\n",
    "\n",
    "ROOT          = Path(\"implementation\")\n",
    "TOX_CSV       = ROOT / \"data\" / \"tox21.csv\"\n",
    "CONCEPTS_DIR  = ROOT / \"concepts\"\n",
    "COHORTS_DIR   = ROOT / \"concept_cohorts_v2\"\n",
    "CONCEPTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "COHORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Candidate concept bank (curated) ----------\n",
    "# Notes (why each matters) live as Python comments for your report & code readability.\n",
    "CANDIDATE_CONCEPTS = [\n",
    "    # Existing baseline 7 (kept for continuity)\n",
    "    {\"name\": \"AromaticRing\",     \"smarts\": \"a1aaaaa1\"},               # planarity/Ï€-Ï€ (AhR, ER scaffolds)\n",
    "    {\"name\": \"Nitro\",            \"smarts\": \"[N+](=O)[O-]\"},           # EWG, bioactivation risk\n",
    "    {\"name\": \"ArylHalide\",       \"smarts\": \"[$([Cl,Br,I])]-c\"},       # halogen bonding, lipophilicity\n",
    "    {\"name\": \"Phenol\",           \"smarts\": \"c1ccc(cc1)O\"},            # H-bond donor/acidic OH, redox-prone\n",
    "    {\"name\": \"TertiaryAmine\",    \"smarts\": \"[NX3]([#6])([#6])[#6]\"},  # cationic center, permeability, binding\n",
    "    {\"name\": \"MichaelAcceptor\",  \"smarts\": \"C=CC=O\"},                 # electrophile (protein adducts)\n",
    "    {\"name\": \"Quinone\",          \"smarts\": \"O=C1C=CC(=O)C=C1\"},       # redox cycling/ROS\n",
    "\n",
    "    # New heteroaromatic & planarity motifs\n",
    "    {\"name\": \"Indole\",           \"smarts\": \"c1ccc2[nH]ccc2c1\"},       # common bioactive heteroaromatic\n",
    "    {\"name\": \"Pyridine\",         \"smarts\": \"n1ccccc1\"},               # basic heteroaromatic (HBA)\n",
    "    {\"name\": \"Imidazole\",        \"smarts\": \"n1c[nH]cc1\"},             # metal-binding / basic heteroaromatic\n",
    "    {\"name\": \"FusedArenes\",      \"smarts\": \"c1ccc2cccc2c1\"},          # generic 2-ring PAH (planarity/AhR-like)\n",
    "\n",
    "    # Electrophiles & carbonyl chemistry\n",
    "    {\"name\": \"Aldehyde\",         \"smarts\": \"[CX3H1](=O)[#6]\"},        # reactive carbonyl\n",
    "    {\"name\": \"Acrylamide\",       \"smarts\": \"C=CC(=O)N\"},              # Michael acceptor amide variant\n",
    "    {\"name\": \"Epoxide\",          \"smarts\": \"C1OC1\"},                  # strained electrophile\n",
    "\n",
    "    # Acid/base handles and polar groups\n",
    "    {\"name\": \"CarboxylicAcid\",   \"smarts\": \"[CX3](=O)[OX2H1]\"},       # acidic handle, transporter interactions\n",
    "    {\"name\": \"Carboxylate\",      \"smarts\": \"[CX3](=O)[O-]\"},          # deprotonated acid (ionic)\n",
    "    {\"name\": \"Ester\",            \"smarts\": \"[CX3](=O)[OX2H0][#6]\"},   # prodrug-like, polar surface tuning\n",
    "    {\"name\": \"Sulfonamide\",      \"smarts\": \"S(=O)(=O)N\"},             # H-bonding, acidity shifts\n",
    "\n",
    "    # Aniline-like & cations\n",
    "    {\"name\": \"Aniline\",          \"smarts\": \"Nc1ccccc1\"},              # aromatic amine (metabolic flags)\n",
    "    {\"name\": \"QuaternaryAmmonium\",\"smarts\": \"[N+](C)(C)C\"},          # permanent cation (permeation/targets)\n",
    "]\n",
    "\n",
    "# ---------- Load Tox21 ----------\n",
    "tox = pd.read_csv(TOX_CSV)\n",
    "tox[\"mol_id\"] = tox[\"mol_id\"].astype(str)\n",
    "tox[\"smiles\"] = tox[\"smiles\"].astype(str)\n",
    "\n",
    "# Pre-create RDKit mols\n",
    "def mol_from_smiles(s):\n",
    "    try:\n",
    "        return Chem.MolFromSmiles(s)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "mols = {mid: mol_from_smiles(smi) for mid, smi in zip(tox[\"mol_id\"], tox[\"smiles\"])}\n",
    "valid_mask = pd.Series([m is not None for m in mols.values()], index=tox[\"mol_id\"])\n",
    "tox_valid = tox[valid_mask.values].reset_index(drop=True)\n",
    "\n",
    "# ---------- Coverage scan & cohort construction ----------\n",
    "MIN_POS   = 200    # minimum positives to keep concept\n",
    "MAX_POS   = 5000   # cap positives for cohort\n",
    "MAX_RAND  = 5000   # cap random negatives for cohort\n",
    "SUMMARY   = []\n",
    "\n",
    "def substruct_match(mol, patt):\n",
    "    try:\n",
    "        return mol.HasSubstructMatch(patt)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "kept = []\n",
    "for c in CANDIDATE_CONCEPTS:\n",
    "    name, smarts = c[\"name\"], c[\"smarts\"]\n",
    "    patt = Chem.MolFromSmarts(smarts)\n",
    "    if patt is None:\n",
    "        SUMMARY.append(dict(concept=name, smarts=smarts, n_pos=0, note=\"INVALID_SMARTS\"))\n",
    "        continue\n",
    "\n",
    "    pos_ids = []\n",
    "    for mid in tox_valid[\"mol_id\"].astype(str).values:\n",
    "        m = mols.get(mid)\n",
    "        if m is not None and substruct_match(m, patt):\n",
    "            pos_ids.append(mid)\n",
    "\n",
    "    n_pos = len(pos_ids)\n",
    "    n_total = len(tox_valid)\n",
    "    prop = n_pos / max(1, n_total)\n",
    "\n",
    "    if n_pos < MIN_POS:\n",
    "        SUMMARY.append(dict(concept=name, smarts=smarts, n_pos=n_pos, note=\"SKIP_TOO_FEW\"))\n",
    "        continue\n",
    "\n",
    "    # construct balanced cohorts\n",
    "    pos_ids = pos_ids[:MAX_POS]\n",
    "    nonmatch_ids = [mid for mid in tox_valid[\"mol_id\"].astype(str).values if mid not in set(pos_ids)]\n",
    "    # draw random negatives matched to pos length\n",
    "    n_rand = min(len(pos_ids), len(nonmatch_ids), MAX_RAND)\n",
    "    rand_ids = random.sample(nonmatch_ids, n_rand)\n",
    "\n",
    "    # save cohorts\n",
    "    cdir = COHORTS_DIR / name\n",
    "    cdir.mkdir(parents=True, exist_ok=True)\n",
    "    (cdir / \"pos_ids.txt\").write_text(\"\\n\".join(pos_ids), encoding=\"utf-8\")\n",
    "    (cdir / \"rand_ids.txt\").write_text(\"\\n\".join(rand_ids), encoding=\"utf-8\")\n",
    "\n",
    "    kept.append({\"name\": name, \"smarts\": smarts})\n",
    "    SUMMARY.append(dict(concept=name, smarts=smarts, n_pos=n_pos, n_rand=n_rand, kept=True))\n",
    "\n",
    "# Save final concept_list_v2.yaml with only kept concepts\n",
    "final_yaml = {\"concepts\": kept}\n",
    "YAML_PATH = CONCEPTS_DIR / \"concept_list_v2.yaml\"\n",
    "with open(YAML_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(final_yaml, f, sort_keys=False)\n",
    "\n",
    "# Print summary table\n",
    "sum_df = pd.DataFrame(SUMMARY).sort_values([\"kept\",\"n_pos\"], ascending=[False, False], na_position=\"last\")\n",
    "display(sum_df.fillna(\"\"))\n",
    "print(f\"\\nSaved {len(kept)} concepts to: {YAML_PATH}\")\n",
    "print(f\"Cohorts written under: {COHORTS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adf025b",
   "metadata": {},
   "source": [
    "### Recompute TCAV for v2 with the new cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f70e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at implementation\\models\\chemberta_v2\\v2_best and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using 11 concepts: ['AromaticRing', 'Nitro', 'ArylHalide', 'Phenol', 'TertiaryAmine', 'MichaelAcceptor', 'Pyridine', 'CarboxylicAcid']...\n",
      "[EMB] saved: 0 | skipped: 7831 | dim=768\n",
      "[CAV] AromaticRing: vecs=(10, 768) | acc_tr=0.996 | acc_va=0.972 | n_pos=3031 n_rand=3031\n",
      "[CAV] Nitro: vecs=(10, 768) | acc_tr=1.000 | acc_va=0.967 | n_pos=343 n_rand=343\n",
      "[CAV] ArylHalide: vecs=(10, 768) | acc_tr=0.994 | acc_va=0.900 | n_pos=998 n_rand=998\n",
      "[CAV] Phenol: vecs=(10, 768) | acc_tr=0.957 | acc_va=0.867 | n_pos=1695 n_rand=1695\n",
      "[CAV] TertiaryAmine: vecs=(10, 768) | acc_tr=0.981 | acc_va=0.876 | n_pos=1495 n_rand=1495\n",
      "[CAV] MichaelAcceptor: vecs=(10, 768) | acc_tr=0.996 | acc_va=0.910 | n_pos=622 n_rand=622\n",
      "[CAV] Pyridine: vecs=(10, 768) | acc_tr=0.995 | acc_va=0.797 | n_pos=473 n_rand=473\n",
      "[CAV] CarboxylicAcid: vecs=(10, 768) | acc_tr=0.996 | acc_va=0.912 | n_pos=811 n_rand=811\n",
      "[CAV] Ester: vecs=(10, 768) | acc_tr=0.952 | acc_va=0.840 | n_pos=1482 n_rand=1482\n",
      "[CAV] Sulfonamide: vecs=(10, 768) | acc_tr=1.000 | acc_va=0.961 | n_pos=261 n_rand=261\n",
      "[CAV] Aniline: vecs=(10, 768) | acc_tr=0.972 | acc_va=0.855 | n_pos=1366 n_rand=1366\n",
      "[TCAV] AromaticRing done.\n",
      "[TCAV] Nitro done.\n",
      "[TCAV] ArylHalide done.\n",
      "[TCAV] Phenol done.\n",
      "[TCAV] TertiaryAmine done.\n",
      "[TCAV] MichaelAcceptor done.\n",
      "[TCAV] Pyridine done.\n",
      "[TCAV] CarboxylicAcid done.\n",
      "[TCAV] Ester done.\n",
      "[TCAV] Sulfonamide done.\n",
      "[TCAV] Aniline done.\n",
      "\n",
      "=== TCAV v2 (k=10 runs) summary ===\n",
      "Saved CSV  â†’ implementation\\cav_v2\\stats\\tcav_summary_v2best_v2concepts_k10.csv\n",
      "Saved JSON â†’ implementation\\cav_v2\\stats\\tcav_summary_v2best_v2concepts_k10.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept</th>\n",
       "      <th>label</th>\n",
       "      <th>tcav_mean</th>\n",
       "      <th>p_value_ttest</th>\n",
       "      <th>p_value_binom</th>\n",
       "      <th>n</th>\n",
       "      <th>ci95_t</th>\n",
       "      <th>cav_acc_train_mean</th>\n",
       "      <th>cav_acc_val_mean</th>\n",
       "      <th>cav_runs</th>\n",
       "      <th>eval_count</th>\n",
       "      <th>C_choice_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>NR-AR</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8000</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>1.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>CarboxylicAcid</td>\n",
       "      <td>NR-AR</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8000</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>1.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Sulfonamide</td>\n",
       "      <td>NR-AR</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8000</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9610</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>TertiaryAmine</td>\n",
       "      <td>NR-AR</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>2.059406e-20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8000</td>\n",
       "      <td>[0.9953, 1.001]</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>0.8759</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>1.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Aniline</td>\n",
       "      <td>NR-AR</td>\n",
       "      <td>0.7710</td>\n",
       "      <td>6.560466e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8000</td>\n",
       "      <td>[0.5966, 0.9454]</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.8550</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>1.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Pyridine</td>\n",
       "      <td>NR-AR</td>\n",
       "      <td>0.6516</td>\n",
       "      <td>1.733859e-01</td>\n",
       "      <td>2.037198e-164</td>\n",
       "      <td>8000</td>\n",
       "      <td>[0.4196, 0.8836]</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>0.7974</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>1.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>MichaelAcceptor</td>\n",
       "      <td>NR-AR</td>\n",
       "      <td>0.6289</td>\n",
       "      <td>2.609748e-01</td>\n",
       "      <td>8.520862e-119</td>\n",
       "      <td>8000</td>\n",
       "      <td>[0.3858, 0.8719]</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Phenol</td>\n",
       "      <td>NR-AR</td>\n",
       "      <td>0.4661</td>\n",
       "      <td>6.656403e-01</td>\n",
       "      <td>1.441196e-09</td>\n",
       "      <td>8000</td>\n",
       "      <td>[0.2946, 0.6377]</td>\n",
       "      <td>0.9568</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ArylHalide</td>\n",
       "      <td>NR-AR</td>\n",
       "      <td>0.1771</td>\n",
       "      <td>2.009440e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8000</td>\n",
       "      <td>[0.0555, 0.2987]</td>\n",
       "      <td>0.9939</td>\n",
       "      <td>0.9002</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nitro</td>\n",
       "      <td>NR-AR</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>3.848981e-25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8000</td>\n",
       "      <td>[-0.0005, 0.0012]</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ester</td>\n",
       "      <td>NR-AR</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.946737e-29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8000</td>\n",
       "      <td>[-0.0002, 0.0004]</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.8405</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Nitro</td>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8000</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>MichaelAcceptor</td>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8000</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Sulfonamide</td>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>0.9734</td>\n",
       "      <td>4.292436e-09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8000</td>\n",
       "      <td>[0.9242, 1.0226]</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9610</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Aniline</td>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>0.9234</td>\n",
       "      <td>3.284272e-05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8000</td>\n",
       "      <td>[0.7976, 1.0492]</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.8550</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>1.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Ester</td>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>0.7614</td>\n",
       "      <td>1.155339e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8000</td>\n",
       "      <td>[0.635, 0.8878]</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.8405</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Pyridine</td>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>0.4726</td>\n",
       "      <td>8.063381e-01</td>\n",
       "      <td>1.023977e-06</td>\n",
       "      <td>8000</td>\n",
       "      <td>[0.2274, 0.7179]</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>0.7974</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>1.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>TertiaryAmine</td>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>0.3352</td>\n",
       "      <td>6.811596e-02</td>\n",
       "      <td>2.539216e-194</td>\n",
       "      <td>8000</td>\n",
       "      <td>[0.1554, 0.5151]</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>0.8759</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>1.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>0.3291</td>\n",
       "      <td>1.214512e-02</td>\n",
       "      <td>3.422572e-209</td>\n",
       "      <td>8000</td>\n",
       "      <td>[0.2056, 0.4527]</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>1.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Phenol</td>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>0.2093</td>\n",
       "      <td>2.191539e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8000</td>\n",
       "      <td>[0.0539, 0.3646]</td>\n",
       "      <td>0.9568</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             concept      label  tcav_mean  p_value_ttest  p_value_binom  \\\n",
       "0       AromaticRing      NR-AR     1.0000   0.000000e+00   0.000000e+00   \n",
       "84    CarboxylicAcid      NR-AR     1.0000   0.000000e+00   0.000000e+00   \n",
       "108      Sulfonamide      NR-AR     1.0000   0.000000e+00   0.000000e+00   \n",
       "48     TertiaryAmine      NR-AR     0.9981   2.059406e-20   0.000000e+00   \n",
       "120          Aniline      NR-AR     0.7710   6.560466e-03   0.000000e+00   \n",
       "72          Pyridine      NR-AR     0.6516   1.733859e-01  2.037198e-164   \n",
       "60   MichaelAcceptor      NR-AR     0.6289   2.609748e-01  8.520862e-119   \n",
       "36            Phenol      NR-AR     0.4661   6.656403e-01   1.441196e-09   \n",
       "24        ArylHalide      NR-AR     0.1771   2.009440e-04   0.000000e+00   \n",
       "12             Nitro      NR-AR     0.0004   3.848981e-25   0.000000e+00   \n",
       "96             Ester      NR-AR     0.0001   1.946737e-29   0.000000e+00   \n",
       "13             Nitro  NR-AR-LBD     1.0000   0.000000e+00   0.000000e+00   \n",
       "61   MichaelAcceptor  NR-AR-LBD     1.0000   0.000000e+00   0.000000e+00   \n",
       "109      Sulfonamide  NR-AR-LBD     0.9734   4.292436e-09   0.000000e+00   \n",
       "121          Aniline  NR-AR-LBD     0.9234   3.284272e-05   0.000000e+00   \n",
       "97             Ester  NR-AR-LBD     0.7614   1.155339e-03   0.000000e+00   \n",
       "73          Pyridine  NR-AR-LBD     0.4726   8.063381e-01   1.023977e-06   \n",
       "49     TertiaryAmine  NR-AR-LBD     0.3352   6.811596e-02  2.539216e-194   \n",
       "1       AromaticRing  NR-AR-LBD     0.3291   1.214512e-02  3.422572e-209   \n",
       "37            Phenol  NR-AR-LBD     0.2093   2.191539e-03   0.000000e+00   \n",
       "\n",
       "        n             ci95_t  cav_acc_train_mean  cav_acc_val_mean  cav_runs  \\\n",
       "0    8000         [1.0, 1.0]              0.9959            0.9724        10   \n",
       "84   8000         [1.0, 1.0]              0.9960            0.9120        10   \n",
       "108  8000         [1.0, 1.0]              1.0000            0.9610        10   \n",
       "48   8000    [0.9953, 1.001]              0.9811            0.8759        10   \n",
       "120  8000   [0.5966, 0.9454]              0.9719            0.8550        10   \n",
       "72   8000   [0.4196, 0.8836]              0.9947            0.7974        10   \n",
       "60   8000   [0.3858, 0.8719]              0.9960            0.9100        10   \n",
       "36   8000   [0.2946, 0.6377]              0.9568            0.8673        10   \n",
       "24   8000   [0.0555, 0.2987]              0.9939            0.9002        10   \n",
       "12   8000  [-0.0005, 0.0012]              1.0000            0.9674        10   \n",
       "96   8000  [-0.0002, 0.0004]              0.9524            0.8405        10   \n",
       "13   8000         [1.0, 1.0]              1.0000            0.9674        10   \n",
       "61   8000         [1.0, 1.0]              0.9960            0.9100        10   \n",
       "109  8000   [0.9242, 1.0226]              1.0000            0.9610        10   \n",
       "121  8000   [0.7976, 1.0492]              0.9719            0.8550        10   \n",
       "97   8000    [0.635, 0.8878]              0.9524            0.8405        10   \n",
       "73   8000   [0.2274, 0.7179]              0.9947            0.7974        10   \n",
       "49   8000   [0.1554, 0.5151]              0.9811            0.8759        10   \n",
       "1    8000   [0.2056, 0.4527]              0.9959            0.9724        10   \n",
       "37   8000   [0.0539, 0.3646]              0.9568            0.8673        10   \n",
       "\n",
       "     eval_count  C_choice_mean  \n",
       "0           800          1.225  \n",
       "84          800          1.825  \n",
       "108         800          0.325  \n",
       "48          800          1.150  \n",
       "120         800          1.075  \n",
       "72          800          1.225  \n",
       "60          800          1.000  \n",
       "36          800          0.250  \n",
       "24          800          0.925  \n",
       "12          800          0.775  \n",
       "96          800          0.400  \n",
       "13          800          0.775  \n",
       "61          800          1.000  \n",
       "109         800          0.325  \n",
       "121         800          1.075  \n",
       "97          800          0.400  \n",
       "73          800          1.225  \n",
       "49          800          1.150  \n",
       "1           800          1.225  \n",
       "37          800          0.250  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==== Cell 11b (patched): TCAV with 10 CAV runs + run-level stats ====\n",
    "import os, json, math, gc, random, yaml\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Optional SciPy for exact tests\n",
    "try:\n",
    "    from scipy.stats import binomtest, ttest_1samp, t\n",
    "    HAVE_SCIPY = True\n",
    "except Exception:\n",
    "    HAVE_SCIPY = False\n",
    "\n",
    "random.seed(42); np.random.seed(42); torch.manual_seed(42)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---- Paths ----\n",
    "V2_DIR    = Path(\"implementation/models/chemberta_v2\")\n",
    "META      = V2_DIR / \"metadata\"\n",
    "with open(META / \"labels.json\") as f:\n",
    "    LBL = json.load(f)\n",
    "id2label    = {int(k): v for k, v in LBL[\"id2label\"].items()}\n",
    "label_names = [id2label[i] for i in range(LBL[\"n_labels\"])]\n",
    "\n",
    "try:\n",
    "    sel = json.load(open(META / \"selected_run.json\"))\n",
    "    RUN_SUFFIX = sel.get(\"suffix\", \"_v2best\")\n",
    "except Exception:\n",
    "    RUN_SUFFIX = \"_v2best\"\n",
    "\n",
    "MODEL_DIR  = V2_DIR / (\"v2_best\" if RUN_SUFFIX == \"_v2best\" else RUN_SUFFIX.strip(\"_\"))\n",
    "TOKEN_DIR  = MODEL_DIR\n",
    "\n",
    "CAV_ROOT   = Path(\"implementation/cav_v2\")\n",
    "EMB_DIR    = CAV_ROOT / f\"embeddings{RUN_SUFFIX}\"\n",
    "CAV_DIR    = CAV_ROOT / f\"cavs{RUN_SUFFIX}\"\n",
    "STATS_DIR  = CAV_ROOT / \"stats\"\n",
    "for d in [EMB_DIR, CAV_DIR, STATS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CONCEPTS_YAML = Path(\"implementation/concepts/concept_list_v2.yaml\")\n",
    "COHORTS_DIR   = Path(\"implementation/concept_cohorts_v2\")\n",
    "TOX_CSV       = Path(\"implementation/data/tox21.csv\")\n",
    "\n",
    "concepts = yaml.safe_load(open(CONCEPTS_YAML))[\"concepts\"]\n",
    "concept_names = [c[\"name\"] for c in concepts]\n",
    "print(f\"[INFO] Using {len(concept_names)} concepts: {concept_names[:8]}{'...' if len(concept_names)>8 else ''}\")\n",
    "\n",
    "tox = pd.read_csv(TOX_CSV)\n",
    "tox[\"mol_id\"] = tox[\"mol_id\"].astype(str)\n",
    "mol2smi = dict(zip(tox[\"mol_id\"], tox[\"smiles\"].astype(str)))\n",
    "\n",
    "# ---- Models ----\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(str(TOKEN_DIR))\n",
    "enc_model = AutoModel.from_pretrained(str(MODEL_DIR)).eval().to(DEVICE)\n",
    "clf_model = AutoModelForSequenceClassification.from_pretrained(str(MODEL_DIR)).eval().to(DEVICE)\n",
    "\n",
    "# ---- Embed any missing mol_ids (cohorts + eval pool) ----\n",
    "def read_ids(p: Path):\n",
    "    return [ln.strip() for ln in open(p, \"r\") if ln.strip()] if p.exists() else []\n",
    "\n",
    "need_ids = set()\n",
    "for cname in concept_names:\n",
    "    need_ids.update(read_ids(COHORTS_DIR / cname / \"pos_ids.txt\"))\n",
    "    need_ids.update(read_ids(COHORTS_DIR / cname / \"rand_ids.txt\"))\n",
    "\n",
    "obs_any = tox[label_names].notna().any(axis=1)\n",
    "need_ids.update(tox.loc[obs_any, \"mol_id\"].astype(str).tolist())\n",
    "\n",
    "@torch.inference_mode()\n",
    "def embed_smiles(smi: str, max_length: int = 256) -> np.ndarray:\n",
    "    enc = tokenizer(smi, truncation=True, padding=False, max_length=max_length, return_tensors=\"pt\")\n",
    "    enc = {k: v.to(DEVICE) for k,v in enc.items()}\n",
    "    out = enc_model(**enc)\n",
    "    return out.last_hidden_state[:,0,:].squeeze(0).detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "saved = skipped = 0\n",
    "for mid in need_ids:\n",
    "    f = EMB_DIR / f\"{mid}.npy\"\n",
    "    if f.exists():\n",
    "        skipped += 1; continue\n",
    "    smi = mol2smi.get(mid)\n",
    "    if not smi: continue\n",
    "    try:\n",
    "        np.save(f, embed_smiles(smi))\n",
    "        saved += 1\n",
    "    except Exception:\n",
    "        pass\n",
    "print(f\"[EMB] saved: {saved} | skipped: {skipped} | dim={np.load(next(iter(EMB_DIR.glob('*.npy')))).shape[0] if list(EMB_DIR.glob('*.npy')) else 'n/a'}\")\n",
    "\n",
    "def load_emb(mid: str) -> np.ndarray:\n",
    "    return np.load(EMB_DIR / f\"{mid}.npy\")\n",
    "\n",
    "# =========================\n",
    "# CONFIG KNOBS (easy tweaks)\n",
    "# =========================\n",
    "K_RUNS            = 10          # â† increase runs for stability\n",
    "MAX_PER_CLASS_CAV = 4000        # cap for pos/rand in each CAV run\n",
    "EVAL_MAX_PER_LBL  = 800         # â†‘ if GPU allows, tighter TCAV CI\n",
    "C_GRID            = (0.25, 1.0, 4.0)  # tiny grid for LR strength\n",
    "VAL_SPLIT         = 0.2\n",
    "\n",
    "# ---- CAV training with tiny C grid per run ----\n",
    "@dataclass\n",
    "class CAVPack:\n",
    "    name: str\n",
    "    vectors: np.ndarray  # [k, H]\n",
    "    acc_train: list\n",
    "    acc_val: list\n",
    "    n_pos: int\n",
    "    n_rand: int\n",
    "    Cs: list\n",
    "\n",
    "def fit_logreg_bestC(X, y, C_grid=C_GRID, random_state=42):\n",
    "    Xtr, Xva, ytr, yva = train_test_split(X, y, test_size=VAL_SPLIT, stratify=y, random_state=random_state)\n",
    "    best = None\n",
    "    for C in C_grid:\n",
    "        clf = LogisticRegression(\n",
    "            penalty=\"l2\", C=C, solver=\"liblinear\", max_iter=500, n_jobs=1\n",
    "        ).fit(Xtr, ytr)\n",
    "        # liblinear is deterministic given data; good for reproducibility\n",
    "        atr = clf.score(Xtr, ytr)\n",
    "        ava = clf.score(Xva, yva)\n",
    "        w   = clf.coef_.ravel().astype(np.float32)\n",
    "        w   = w / (np.linalg.norm(w) + 1e-8)\n",
    "        cand = (ava, atr, C, w)\n",
    "        if best is None or ava > best[0]:\n",
    "            best = cand\n",
    "    ava, atr, Cbest, wbest = best\n",
    "    return wbest, atr, ava, Cbest\n",
    "\n",
    "def train_cav(cname: str, k_runs=K_RUNS, max_per_class=MAX_PER_CLASS_CAV) -> CAVPack:\n",
    "    pos_ids = read_ids(COHORTS_DIR / cname / \"pos_ids.txt\")\n",
    "    rnd_ids = read_ids(COHORTS_DIR / cname / \"rand_ids.txt\")\n",
    "    n = min(len(pos_ids), len(rnd_ids), max_per_class)\n",
    "    if n == 0:\n",
    "        return CAVPack(cname, np.zeros((0,768), np.float32), [], [], 0, 0, [])\n",
    "    pos = np.stack([load_emb(i) for i in pos_ids[:n]])\n",
    "    rnd = np.stack([load_emb(i) for i in rnd_ids[:n]])\n",
    "    X = np.vstack([pos, rnd]); y = np.array([1]*n + [0]*n)\n",
    "\n",
    "    vecs, acc_tr, acc_va, Cs = [], [], [], []\n",
    "    for r in range(k_runs):\n",
    "        Xr, yr = shuffle(X, y, random_state=42+r)\n",
    "        w, atr, ava, Cbest = fit_logreg_bestC(Xr, yr, C_grid=C_GRID, random_state=777+r)\n",
    "        vecs.append(w)\n",
    "        acc_tr.append(float(atr))\n",
    "        acc_va.append(float(ava))\n",
    "        Cs.append(float(Cbest))\n",
    "    vecs = np.stack(vecs, axis=0)\n",
    "    np.savez(CAV_DIR / f\"{cname}_k{k_runs}.npz\",\n",
    "             vectors=vecs,\n",
    "             acc_train=np.array(acc_tr, np.float32),\n",
    "             acc_val=np.array(acc_va, np.float32),\n",
    "             Cs=np.array(Cs, np.float32),\n",
    "             n_pos=n, n_rand=n)\n",
    "    return CAVPack(cname, vecs, acc_tr, acc_va, n, n, Cs)\n",
    "\n",
    "cav_bank = {}\n",
    "for cname in concept_names:\n",
    "    pack = train_cav(cname, k_runs=K_RUNS)\n",
    "    cav_bank[cname] = pack\n",
    "    print(f\"[CAV] {cname}: vecs={pack.vectors.shape} | acc_tr={np.mean(pack.acc_train):.3f} | acc_va={np.mean(pack.acc_val):.3f} | n_pos={pack.n_pos} n_rand={pack.n_rand}\")\n",
    "\n",
    "# ---- TCAV (gradients wrt CLS) ----\n",
    "@torch.enable_grad()\n",
    "def grad_cls(smiles_batch, label_idx: int, max_length=256) -> np.ndarray:\n",
    "    enc = tokenizer(smiles_batch, truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
    "    outputs = clf_model.roberta(**enc, return_dict=True)  # encoder of classifier\n",
    "    last = outputs.last_hidden_state\n",
    "    last.retain_grad()\n",
    "    logits = clf_model.classifier(last)  # [B, L]\n",
    "    target = logits[:, label_idx].sum()\n",
    "    clf_model.zero_grad(set_to_none=True)\n",
    "    if last.grad is not None: last.grad.zero_()\n",
    "    target.backward()\n",
    "    g = last.grad[:, 0, :].detach().cpu().numpy().astype(np.float32)\n",
    "    return g\n",
    "\n",
    "# sample up to EVAL_MAX_PER_LBL molecules per label\n",
    "label_to_ids = {}\n",
    "for lbl in label_names:\n",
    "    mids = tox.loc[tox[lbl].notna(), \"mol_id\"].astype(str).tolist()\n",
    "    random.shuffle(mids)\n",
    "    label_to_ids[lbl] = mids[:EVAL_MAX_PER_LBL]\n",
    "\n",
    "def run_tcav(concept_vecs: np.ndarray, lbl: str, sample_ids: list, batch_size=32) -> dict:\n",
    "    j = label_names.index(lbl)\n",
    "    grads = []\n",
    "    for i in range(0, len(sample_ids), batch_size):\n",
    "        block = sample_ids[i:i+batch_size]\n",
    "        smiles = [mol2smi[mid] for mid in block if mid in mol2smi]\n",
    "        if not smiles: continue\n",
    "        grads.append(grad_cls(smiles, j))\n",
    "        torch.cuda.empty_cache()\n",
    "    if not grads:\n",
    "        return {\"n\": 0, \"mean\": float(\"nan\"), \"p_ttest\": float(\"nan\"),\n",
    "                \"p_binom\": float(\"nan\"), \"ci95_t\": [float(\"nan\"), float(\"nan\")]}\n",
    "\n",
    "    G = np.vstack(grads)  # [N,H]\n",
    "    # compute per-run positive fractions\n",
    "    run_fracs = []\n",
    "    for r in range(concept_vecs.shape[0]):\n",
    "        v = concept_vecs[r]\n",
    "        dots = G @ v\n",
    "        run_fracs.append((dots > 0).mean())\n",
    "    run_fracs = np.array(run_fracs, dtype=np.float64)\n",
    "    mean_tcav = float(run_fracs.mean())\n",
    "\n",
    "    # --- run-level t-test vs 0.5 (classic TCAV) ---\n",
    "    if HAVE_SCIPY and len(run_fracs) >= 2:\n",
    "        tstat, p_t = ttest_1samp(run_fracs, popmean=0.5, alternative=\"two-sided\")\n",
    "        p_t = float(p_t)\n",
    "        # 95% CI for mean via t distribution\n",
    "        df = len(run_fracs) - 1\n",
    "        s = run_fracs.std(ddof=1)\n",
    "        half = (t.ppf(0.975, df) * s / np.sqrt(len(run_fracs))) if df > 0 else 0.0\n",
    "        ci_t = [float(mean_tcav - half), float(mean_tcav + half)]\n",
    "    else:\n",
    "        # fallback normal approx\n",
    "        s = run_fracs.std(ddof=1)\n",
    "        half = 1.96 * s / max(1e-6, np.sqrt(len(run_fracs)))\n",
    "        p_t = float(\"nan\")\n",
    "        ci_t = [float(mean_tcav - half), float(mean_tcav + half)]\n",
    "\n",
    "    # --- pooled binomial on all (runs Ã— samples) for reference ---\n",
    "    N = len(G) * concept_vecs.shape[0]\n",
    "    k = int(round(mean_tcav * N))\n",
    "    if HAVE_SCIPY and N > 0:\n",
    "        p_bin = float(binomtest(k, N, 0.5, alternative=\"two-sided\").pvalue)\n",
    "    else:\n",
    "        # rough normal approx\n",
    "        z = (k - 0.5*N) / math.sqrt(max(1e-8, N*0.25))\n",
    "        p_bin = float(2 * (1 - 0.5*(1 + math.erf(abs(z)/math.sqrt(2)))))\n",
    "\n",
    "    return {\"n\": int(N), \"mean\": mean_tcav, \"p_ttest\": p_t, \"p_binom\": p_bin, \"ci95_t\": [round(ci_t[0],4), round(ci_t[1],4)]}\n",
    "\n",
    "# ---- Execute TCAV for all (concept Ã— label) ----\n",
    "rows = []\n",
    "for cname in concept_names:\n",
    "    pack = cav_bank[cname]\n",
    "    if pack.vectors.size == 0:\n",
    "        continue\n",
    "    for lbl in label_names:\n",
    "        stats = run_tcav(pack.vectors, lbl, label_to_ids[lbl])\n",
    "        rows.append({\n",
    "            \"concept\": cname,\n",
    "            \"label\": lbl,\n",
    "            \"tcav_mean\": round(stats[\"mean\"], 4),\n",
    "            \"p_value_ttest\": stats[\"p_ttest\"],\n",
    "            \"p_value_binom\": stats[\"p_binom\"],\n",
    "            \"n\": stats[\"n\"],\n",
    "            \"ci95_t\": stats[\"ci95_t\"],\n",
    "            \"cav_acc_train_mean\": round(float(np.mean(pack.acc_train)), 4),\n",
    "            \"cav_acc_val_mean\": round(float(np.mean(pack.acc_val)), 4),\n",
    "            \"cav_runs\": int(pack.vectors.shape[0]),\n",
    "            \"eval_count\": int(len(label_to_ids[lbl])),\n",
    "            \"C_choice_mean\": round(float(np.mean(pack.Cs)), 3),\n",
    "        })\n",
    "    print(f\"[TCAV] {cname} done.\")\n",
    "\n",
    "tcav_df = pd.DataFrame(rows)\n",
    "\n",
    "# Save with k10 suffix to keep previous results\n",
    "csv_out  = STATS_DIR / f\"tcav_summary{RUN_SUFFIX}_v2concepts_k10.csv\"\n",
    "json_out = STATS_DIR / f\"tcav_summary{RUN_SUFFIX}_v2concepts_k10.json\"\n",
    "tcav_df.to_csv(csv_out, index=False)\n",
    "with open(json_out, \"w\") as f:\n",
    "    json.dump(tcav_df.to_dict(orient=\"records\"), f, indent=2)\n",
    "\n",
    "print(\"\\n=== TCAV v2 (k=10 runs) summary ===\")\n",
    "print(f\"Saved CSV  â†’ {csv_out}\")\n",
    "print(f\"Saved JSON â†’ {json_out}\")\n",
    "display(tcav_df.sort_values(['label','tcav_mean'], ascending=[True, False]).head(20))\n",
    "\n",
    "gc.collect(); torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd60f37c",
   "metadata": {},
   "source": [
    "## 12: Eval between V1 and V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d74c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Per-Label Accuracy â€” Split: ALL (N=7831) ===\n",
      "        label    n   acc_v1   acc_v2    delta\n",
      "        NR-AR 7265 0.927736 0.965864 0.038128\n",
      "    NR-AR-LBD 6758 0.880734 0.926458 0.045724\n",
      "     SR-ATAD5 7072 0.333993 0.888433 0.554440\n",
      "NR-PPAR-gamma 6450 0.028837 0.876279 0.847442\n",
      "    NR-ER-LBD 6955 0.582459 0.874910 0.292451\n",
      " NR-Aromatase 5821 0.051538 0.835252 0.783714\n",
      "        NR-ER 6193 0.733570 0.833199 0.099629\n",
      "       NR-AhR 6549 0.621774 0.805008 0.183234\n",
      "       SR-MMP 5810 0.693976 0.779174 0.085198\n",
      "       SR-HSE 6467 0.057523 0.767280 0.709757\n",
      "       SR-ARE 5832 0.581962 0.727366 0.145405\n",
      "       SR-p53 6774 0.062445 0.572188 0.509743\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "customdata": [
          [
           7265,
           "ChemBERTa v1"
          ],
          [
           6758,
           "ChemBERTa v1"
          ],
          [
           6549,
           "ChemBERTa v1"
          ],
          [
           5821,
           "ChemBERTa v1"
          ],
          [
           6193,
           "ChemBERTa v1"
          ],
          [
           6955,
           "ChemBERTa v1"
          ],
          [
           6450,
           "ChemBERTa v1"
          ],
          [
           5832,
           "ChemBERTa v1"
          ],
          [
           7072,
           "ChemBERTa v1"
          ],
          [
           6467,
           "ChemBERTa v1"
          ],
          [
           5810,
           "ChemBERTa v1"
          ],
          [
           6774,
           "ChemBERTa v1"
          ]
         ],
         "hovertemplate": "model=%{customdata[1]}<br>label=%{x}<br>accuracy=%{y:.3f}<br>n=%{customdata[0]}<extra></extra>",
         "legendgroup": "ChemBERTa v1",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "ChemBERTa v1",
         "offsetgroup": "ChemBERTa v1",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "NR-AR",
          "NR-AR-LBD",
          "NR-AhR",
          "NR-Aromatase",
          "NR-ER",
          "NR-ER-LBD",
          "NR-PPAR-gamma",
          "SR-ARE",
          "SR-ATAD5",
          "SR-HSE",
          "SR-MMP",
          "SR-p53"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "FKup0QKw7T/wwkH0+C7sPyGVdUCT5eM/9QOewyBjqj94KL0gaHnnPwhmhFmAo+I/nxFyW4CHnT8mSzrqbZ/iPxElYBElYNU/B3AmJ6FzrT9/jkf0DDXmP5FZLXi++K8/",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "customdata": [
          [
           7265,
           "ChemBERTa v2"
          ],
          [
           6758,
           "ChemBERTa v2"
          ],
          [
           6549,
           "ChemBERTa v2"
          ],
          [
           5821,
           "ChemBERTa v2"
          ],
          [
           6193,
           "ChemBERTa v2"
          ],
          [
           6955,
           "ChemBERTa v2"
          ],
          [
           6450,
           "ChemBERTa v2"
          ],
          [
           5832,
           "ChemBERTa v2"
          ],
          [
           7072,
           "ChemBERTa v2"
          ],
          [
           6467,
           "ChemBERTa v2"
          ],
          [
           5810,
           "ChemBERTa v2"
          ],
          [
           6774,
           "ChemBERTa v2"
          ]
         ],
         "hovertemplate": "model=%{customdata[1]}<br>label=%{x}<br>accuracy=%{y:.3f}<br>n=%{customdata[0]}<extra></extra>",
         "legendgroup": "ChemBERTa v2",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "ChemBERTa v2",
         "offsetgroup": "ChemBERTa v2",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "NR-AR",
          "NR-AR-LBD",
          "NR-AhR",
          "NR-Aromatase",
          "NR-ER",
          "NR-ER-LBD",
          "NR-PPAR-gamma",
          "SR-ARE",
          "SR-ATAD5",
          "SR-HSE",
          "SR-MMP",
          "SR-p53"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "0BW1DVvo7j/VyQhEiqXtP4q67Pigwuk/aZp9uGG66j8w4wh5kKnqPx1N84pD/+s/QEFaZ3oK7D/418GYlUbnP5ULbpULbuw/dY9I3Y6N6D9rVyD5/e7oP1/8j71cT+I/",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "group",
        "legend": {
         "title": {
          "text": "model"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Per-Label Accuracy (split: ALL)"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "tickangle": 45,
         "title": {
          "text": "label"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          1
         ],
         "title": {
          "text": "accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": {
          "bdata": "nxFyW4CHnT9AQVpnegrsPwAAAAAAMrlA9QOewyBjqj9pmn24YbrqPwAAAAAAvbZAB3AmJ6FzrT91j0jdjo3oPwAAAAAAQ7lAESVgESVg1T+VC26VC27sPwAAAAAAoLtAkVkteL74rz9f/I+9XE/iPwAAAAAAdrpACGaEWYCj4j8dTfOKQ//rPwAAAAAAK7tAIZV1QJPl4z+Kuuz4oMLpPwAAAAAAlblAJks66m2f4j/418GYlUbnPwAAAAAAyLZAeCi9IGh55z8w4wh5kKnqPwAAAAAAMbhAf45H9Aw15j9rVyD5/e7oPwAAAAAAsrZA8MJB9Pgu7D/VyQhEiqXtPwAAAAAAZrpAFKup0QKw7T/QFbUNW+juPwAAAAAAYbxA",
          "dtype": "f8",
          "shape": "12, 3"
         },
         "hovertemplate": "label=%{x}<br>delta=%{y}<br>acc_v1=%{customdata[0]:.3f}<br>acc_v2=%{customdata[1]:.3f}<br>n=%{customdata[2]}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "NR-PPAR-gamma",
          "NR-Aromatase",
          "SR-HSE",
          "SR-ATAD5",
          "SR-p53",
          "NR-ER-LBD",
          "NR-AhR",
          "SR-ARE",
          "NR-ER",
          "SR-MMP",
          "NR-AR-LBD",
          "NR-AR"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "s7B+ZD4e6z8qukOsLxTpP3Uo1spUtuY/DPm9DPm94T/GJg3W0E/gPyrO3WKGt9I/pJXc4TZ0xz9IMx66npzCP8DVXcJCgbk/YEfGJojPtT9QbnD8FGmnP8CrtsCDhaM/",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "shapes": [
         {
          "line": {
           "dash": "dash"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 0,
          "y1": 0,
          "yref": "y"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Accuracy Î” (v2 - v1) by label"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "tickangle": 45,
         "title": {
          "text": "label"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "delta"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === ChemBERTa v1 vs v2 â€” Per-Label Accuracy + Visualization ===\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "import plotly.express as px\n",
    "\n",
    "DATA_CSV   = Path(\"implementation/data/tox21.csv\")\n",
    "V1_DIR     = Path(\"implementation/models/chemberta_v1\")\n",
    "V1_META    = V1_DIR / \"metadata\"\n",
    "V1_META_FALLBACK = Path(\"implementation/models/metadata\")  # legacy, if present\n",
    "\n",
    "V2_DIR     = Path(\"implementation/models/chemberta_v2\")\n",
    "V2_BEST    = V2_DIR / \"v2_best\"\n",
    "V2_META    = V2_DIR / \"metadata\"\n",
    "SPLITS_JSON= V2_META / \"splits.json\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH  = 64\n",
    "MAXLEN = 256\n",
    "\n",
    "# ---------------- helpers ----------------\n",
    "def _load_thresholds(meta_dir: Path, fallback_dir: Path = None):\n",
    "    cands = [meta_dir / \"thresholds.json\"]\n",
    "    if fallback_dir: cands.append(fallback_dir / \"thresholds.json\")\n",
    "    for p in cands:\n",
    "        if p.exists():\n",
    "            return json.load(open(p))\n",
    "    return None  # -> default 0.5\n",
    "\n",
    "def _load_calibration(meta_dir: Path):\n",
    "    # v2 artifacts; return None if missing\n",
    "    temp = (np.load(meta_dir / \"temperature.npy\")[0]\n",
    "            if (meta_dir / \"temperature.npy\").exists() else 1.0)\n",
    "    cal_methods = json.load(open(meta_dir / \"calibration_methods.json\")) if (meta_dir / \"calibration_methods.json\").exists() else {}\n",
    "    platt = json.load(open(meta_dir / \"platt_params.json\")) if (meta_dir / \"platt_params.json\").exists() else {}\n",
    "    iso   = json.load(open(meta_dir / \"isotonic_params.json\")) if (meta_dir / \"isotonic_params.json\").exists() else {}\n",
    "    return float(temp), cal_methods, platt, iso\n",
    "\n",
    "def _apply_calibration_block(logits: np.ndarray, labels: list, cal_bundle: tuple | None):\n",
    "    # logits: [N, L] â†’ calibrated probs [N, L]\n",
    "    sig = lambda x: 1.0 / (1.0 + np.exp(-x))\n",
    "    if cal_bundle is None:  # v1 or missing\n",
    "        return sig(logits)\n",
    "    temp, cal_methods, platt, iso = cal_bundle\n",
    "    p_temp = sig(logits / max(temp, 1e-6))\n",
    "    out = np.zeros_like(p_temp)\n",
    "    for j, lbl in enumerate(labels):\n",
    "        meth = cal_methods.get(lbl, {}).get(\"method\", \"temp\")\n",
    "        if meth == \"platt\" and lbl in platt:\n",
    "            A, B = platt[lbl][\"A\"], platt[lbl][\"B\"]\n",
    "            out[:, j] = sig(A * logits[:, j] + B)\n",
    "        elif meth == \"iso\" and lbl in iso:\n",
    "            X = np.asarray(iso[lbl][\"X\"]); Y = np.asarray(iso[lbl][\"Y\"])\n",
    "            out[:, j] = np.interp(p_temp[:, j], X, Y)\n",
    "        else:\n",
    "            out[:, j] = p_temp[:, j]\n",
    "    return out\n",
    "\n",
    "def _predict_logits(smiles_list, model_dir: Path):\n",
    "    tok = AutoTokenizer.from_pretrained(str(model_dir))\n",
    "    cfg = AutoConfig.from_pretrained(str(model_dir))\n",
    "    mdl = AutoModelForSequenceClassification.from_pretrained(str(model_dir), config=cfg).to(DEVICE).eval()\n",
    "    if hasattr(mdl.config, \"use_cache\"): mdl.config.use_cache = False\n",
    "    outs = []\n",
    "    for i in range(0, len(smiles_list), BATCH):\n",
    "        enc = tok(smiles_list[i:i+BATCH], truncation=True, padding=True, max_length=MAXLEN, return_tensors=\"pt\").to(DEVICE)\n",
    "        with torch.inference_mode():\n",
    "            logits = mdl(**enc).logits.detach().cpu().numpy()\n",
    "        outs.append(logits)\n",
    "    logits = np.vstack(outs)\n",
    "    id2label = cfg.id2label\n",
    "    labels_model = [id2label[i] for i in range(len(id2label))]\n",
    "    return logits, labels_model\n",
    "\n",
    "def _align_logits_to_df_labels(logits: np.ndarray, model_labels: list, df_labels: list):\n",
    "    if model_labels == df_labels:\n",
    "        return logits\n",
    "    take = [model_labels.index(c) for c in df_labels]\n",
    "    return logits[:, take]\n",
    "\n",
    "def _per_label_accuracy(y_true: np.ndarray, y_prob: np.ndarray, thresholds: dict, labels: list):\n",
    "    \"\"\"\n",
    "    y_true: [N, L] with NaN for unknown; y_prob: [N, L] probs\n",
    "    returns DataFrame: label, n, accuracy\n",
    "    \"\"\"\n",
    "    accs, ns = [], []\n",
    "    for j, lbl in enumerate(labels):\n",
    "        thr = float(thresholds.get(lbl, 0.5)) if thresholds else 0.5\n",
    "        mask = ~np.isnan(y_true[:, j])\n",
    "        yt = y_true[mask, j].astype(int)\n",
    "        yp = (y_prob[mask, j] >= thr).astype(int)\n",
    "        n = int(mask.sum())\n",
    "        acc = float((yt == yp).mean()) if n > 0 else np.nan\n",
    "        accs.append(acc); ns.append(n)\n",
    "    return pd.DataFrame({\"label\": labels, \"n\": ns, \"accuracy\": accs})\n",
    "\n",
    "# ---------------- data & split ----------------\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "label_cols = [c for c in df.columns if c not in (\"mol_id\",\"smiles\")]\n",
    "X_smiles = df[\"smiles\"].astype(str).tolist()\n",
    "Y = df[label_cols].to_numpy(dtype=float)  # NaNs ok\n",
    "\n",
    "split_tag = \"TEST\"\n",
    "if SPLITS_JSON.exists():\n",
    "    sp = json.load(open(SPLITS_JSON))\n",
    "    val_idx = np.array(sp.get(\"val_idx\", []), dtype=int) if \"val_idx\" in sp else None\n",
    "    test_idx= np.array(sp.get(\"test_idx\", []), dtype=int) if \"test_idx\" in sp else None\n",
    "else:\n",
    "    val_idx = test_idx = None\n",
    "\n",
    "if test_idx is not None and test_idx.size > 0:\n",
    "    idx = test_idx\n",
    "elif val_idx is not None and val_idx.size > 0:\n",
    "    idx = val_idx; split_tag = \"VAL\"\n",
    "else:\n",
    "    idx = np.arange(len(df)); split_tag = \"ALL\"\n",
    "\n",
    "Xs = [X_smiles[i] for i in idx]\n",
    "Yt = Y[idx]\n",
    "\n",
    "# ---------------- v1 ----------------\n",
    "logits_v1, labels_v1 = _predict_logits(Xs, V1_DIR)\n",
    "logits_v1 = _align_logits_to_df_labels(logits_v1, labels_v1, label_cols)\n",
    "probs_v1 = 1.0 / (1.0 + np.exp(-logits_v1))\n",
    "thr_v1 = _load_thresholds(V1_META, V1_META_FALLBACK) or {lbl:0.5 for lbl in label_cols}\n",
    "acc_v1 = _per_label_accuracy(Yt, probs_v1, thr_v1, label_cols).rename(columns={\"accuracy\":\"acc_v1\"})\n",
    "\n",
    "# ---------------- v2 (calibrated) ----------------\n",
    "logits_v2, labels_v2 = _predict_logits(Xs, V2_BEST)\n",
    "logits_v2 = _align_logits_to_df_labels(logits_v2, labels_v2, label_cols)\n",
    "cal_bundle = _load_calibration(V2_META)\n",
    "probs_v2 = _apply_calibration_block(logits_v2, label_cols, cal_bundle)\n",
    "thr_v2 = _load_thresholds(V2_META) or {lbl:0.5 for lbl in label_cols}\n",
    "acc_v2 = _per_label_accuracy(Yt, probs_v2, thr_v2, label_cols).rename(columns={\"accuracy\":\"acc_v2\"})\n",
    "\n",
    "# ---------------- combine + visualize ----------------\n",
    "acc_df = acc_v1.merge(acc_v2, on=[\"label\",\"n\"])\n",
    "acc_df[\"delta\"] = acc_df[\"acc_v2\"] - acc_df[\"acc_v1\"]\n",
    "\n",
    "print(f\"=== Per-Label Accuracy â€” Split: {split_tag} (N={len(idx)}) ===\")\n",
    "print(acc_df.sort_values(\"acc_v2\", ascending=False).to_string(index=False))\n",
    "\n",
    "# Grouped bars (v1 vs v2)\n",
    "plot_df = acc_df.melt(id_vars=[\"label\",\"n\"], value_vars=[\"acc_v1\",\"acc_v2\"],\n",
    "                      var_name=\"model\", value_name=\"accuracy\")\n",
    "plot_df[\"model\"] = plot_df[\"model\"].map({\"acc_v1\":\"ChemBERTa v1\",\"acc_v2\":\"ChemBERTa v2\"})\n",
    "\n",
    "fig1 = px.bar(plot_df, x=\"label\", y=\"accuracy\", color=\"model\", barmode=\"group\",\n",
    "              title=f\"Per-Label Accuracy (split: {split_tag})\",\n",
    "              hover_data={\"n\":True, \"model\":True, \"label\":True, \"accuracy\":\":.3f\"})\n",
    "fig1.update_layout(xaxis_tickangle=45, yaxis=dict(range=[0,1]))\n",
    "fig1.show()\n",
    "\n",
    "# Delta bars (v2 - v1)\n",
    "fig2 = px.bar(acc_df.sort_values(\"delta\", ascending=False),\n",
    "              x=\"label\", y=\"delta\",\n",
    "              title=\"Accuracy Î” (v2 - v1) by label\",\n",
    "              hover_data={\"acc_v1\":\":.3f\",\"acc_v2\":\":.3f\",\"n\":True})\n",
    "fig2.update_layout(xaxis_tickangle=45)\n",
    "fig2.add_hline(y=0, line_dash=\"dash\")\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2594c0dc",
   "metadata": {},
   "source": [
    "# Targeted Train AKA ChemBERTa_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d1c8df",
   "metadata": {},
   "source": [
    "## 0: setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c57b0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA] N=7831 | labels=12 â†’ ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER'] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-100M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MODEL] Base: DeepChem/ChemBERTa-100M-MLM\n",
      "  hidden_size        : 768\n",
      "  num_hidden_layers  : 12\n",
      "  vocab_size         : 7924\n",
      "  classifier_dropout : 0.2\n",
      "  problem_type       : multi_label_classification\n",
      "\n",
      "[FORWARD] logits shape: (1, 12)\n",
      "  (expect [1, num_labels] â‡’ 12 )\n",
      "  OK: batched label logits ([B, L]).\n",
      "\n",
      "[ENV] Python 3.11.9 | Torch 2.6.0+cu124 | Device: cuda\n",
      "[ENV] RDKit: 2022.09.5\n",
      "\n",
      "Saved run config â†’ implementation\\models\\chemberta_v3\\metadata\\run_cfg.json\n"
     ]
    }
   ],
   "source": [
    "# === Cell 0 â€” v3 fresh setup with a strong ChemBERTa base ===\n",
    "import os, json, random, sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# ---------------- paths ----------------\n",
    "ROOT      = Path(\"implementation\")\n",
    "DATA_CSV  = ROOT / \"data\" / \"tox21.csv\"\n",
    "\n",
    "V3_DIR    = ROOT / \"models\" / \"chemberta_v3\"\n",
    "V3_BEST   = V3_DIR / \"v3_best\"       # will be created after training\n",
    "V3_META   = V3_DIR / \"metadata\"\n",
    "(V3_DIR / \"checkpoints\").mkdir(parents=True, exist_ok=True)\n",
    "V3_META.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------- choose base ChemBERTa ----------------\n",
    "# options   \n",
    "#   - \"DeepChem/ChemBERTa-100M-MLM\"   (large, recent pretrain)                  Starting with the largest \n",
    "#   - \"DeepChem/ChemBERTa-77M-MTR\"    (masked token regression pretrain)        might try this  \n",
    "#   - \"DeepChem/ChemBERTa-77M-MLM\"    (77M MLM)\n",
    "BASE_MODEL = \"DeepChem/ChemBERTa-100M-MLM\"\n",
    "\n",
    "# ---------------- reproducibility ----------------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MAX_LEN = 256\n",
    "BATCH   = 32\n",
    "\n",
    "# ---------------- data ----------------\n",
    "assert DATA_CSV.exists(), f\"Missing {DATA_CSV}\"\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "label_cols = [c for c in df.columns if c not in (\"mol_id\",\"smiles\")]\n",
    "num_labels = len(label_cols)\n",
    "print(f\"[DATA] N={len(df)} | labels={num_labels} â†’ {label_cols[:5]} ...\")\n",
    "\n",
    "# ---------------- model + tokenizer (classification head, default linear) ----------------\n",
    "cfg = AutoConfig.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    num_labels=num_labels,\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    finetuning_task=\"tox21\",\n",
    ")\n",
    "# optional: slightly higher dropout for regularization\n",
    "if not hasattr(cfg, \"classifier_dropout\") or cfg.classifier_dropout is None:\n",
    "    cfg.classifier_dropout = 0.2\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    config=cfg\n",
    ").to(DEVICE).eval()\n",
    "\n",
    "# ---------------- quick sanity pass ----------------\n",
    "print(\"\\n[MODEL] Base:\", BASE_MODEL)\n",
    "print(\"  hidden_size        :\", getattr(model.config, \"hidden_size\", None))\n",
    "print(\"  num_hidden_layers  :\", getattr(model.config, \"num_hidden_layers\", None))\n",
    "print(\"  vocab_size         :\", getattr(model.config, \"vocab_size\", None))\n",
    "print(\"  classifier_dropout :\", getattr(model.config, \"classifier_dropout\", None))\n",
    "print(\"  problem_type       :\", getattr(model.config, \"problem_type\", None))\n",
    "\n",
    "# forward sanity on one SMILES\n",
    "sample = df[\"smiles\"].astype(str).iloc[0]\n",
    "enc = tok(sample, truncation=True, padding=True, max_length=MAX_LEN, return_tensors=\"pt\").to(DEVICE)\n",
    "with torch.inference_mode():\n",
    "    out = model(**enc)\n",
    "logits = out.logits\n",
    "print(\"\\n[FORWARD] logits shape:\", tuple(logits.shape))\n",
    "print(\"  (expect [1, num_labels] â‡’\", num_labels, \")\")\n",
    "if logits.ndim == 3:\n",
    "    print(\"  NOTE: token-level logits detected ([B, T, L]). We will pool to [CLS] later.\")\n",
    "else:\n",
    "    print(\"  OK: batched label logits ([B, L]).\")\n",
    "\n",
    "# ---------------- environment debug ----------------\n",
    "print(\"\\n[ENV] Python\", sys.version.split()[0], \"| Torch\", torch.__version__, \"| Device:\", DEVICE)\n",
    "try:\n",
    "    import rdkit\n",
    "    from rdkit import Chem\n",
    "    print(\"[ENV] RDKit:\", rdkit.__version__)\n",
    "except Exception as e:\n",
    "    print(\"[ENV] RDKit not found (augmentation will skip RDKit-dependent transforms).\")\n",
    "\n",
    "# ---------------- save run config ----------------\n",
    "run_cfg = {\n",
    "    \"seed\": SEED,\n",
    "    \"device\": str(DEVICE),\n",
    "    \"max_len\": MAX_LEN,\n",
    "    \"batch_size\": BATCH,\n",
    "    \"base_model\": BASE_MODEL,\n",
    "    \"labels\": label_cols,\n",
    "}\n",
    "with open(V3_META / \"run_cfg.json\", \"w\") as f:\n",
    "    json.dump(run_cfg, f, indent=2)\n",
    "print(\"\\nSaved run config â†’\", V3_META / \"run_cfg.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15af12c6",
   "metadata": {},
   "source": [
    "## 1: Build stratified splits (train/val/test) + debug prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "138cea83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Splits created via: iterstrat.MultilabelStratifiedShuffleSplit ===\n",
      "Counts â†’ train=6264 | val=783 | test=784 (sum=7831)\n",
      "\n",
      "Per-label prevalence (train/val/test/all) and drift:\n",
      "        label  prev_train  prev_val  prev_test  prev_all  |train-val|  |train-test|\n",
      "       SR-ARE       0.161     0.163      0.165     0.162        0.002         0.005\n",
      "       SR-p53       0.063     0.061      0.061     0.062        0.001         0.002\n",
      "       SR-MMP       0.158     0.161      0.159     0.158        0.003         0.001\n",
      "       SR-HSE       0.058     0.057      0.056     0.058        0.000         0.001\n",
      "        NR-ER       0.128     0.128      0.127     0.128        0.000         0.001\n",
      "     SR-ATAD5       0.037     0.037      0.037     0.037        0.000         0.001\n",
      "    NR-ER-LBD       0.050     0.051      0.050     0.050        0.001         0.001\n",
      "NR-PPAR-gamma       0.029     0.030      0.029     0.029        0.002         0.000\n",
      "        NR-AR       0.043     0.042      0.042     0.043        0.000         0.000\n",
      "    NR-AR-LBD       0.035     0.036      0.035     0.035        0.001         0.000\n",
      " NR-Aromatase       0.052     0.051      0.052     0.052        0.000         0.000\n",
      "       NR-AhR       0.117     0.118      0.117     0.117        0.001         0.000\n",
      "\n",
      "Saved:\n",
      " - splits â†’ implementation\\models\\chemberta_v3\\metadata\\splits.json\n",
      " - prevalence debug â†’ implementation\\models\\chemberta_v3\\metadata\\split_prevalence_debug.csv\n"
     ]
    }
   ],
   "source": [
    "import json, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# reuse vars from Cell 0\n",
    "# df, label_cols, SEED, V3_META already defined\n",
    "\n",
    "def build_splits_stratified(df, label_cols, seed=42, train=0.8, val=0.1, test=0.1):\n",
    "    Y = df[label_cols].to_numpy(dtype=float)\n",
    "    Yb = np.nan_to_num(Y, nan=0.0)  # binarize NaNsâ†’0 for stratification\n",
    "    idx = np.arange(len(df))\n",
    "\n",
    "    # Try iterative stratified splitter (iterstrat)\n",
    "    try:\n",
    "        from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit as MLSSS\n",
    "        m1 = MLSSS(n_splits=1, test_size=test, random_state=seed)\n",
    "        trv_idx, te_idx = next(m1.split(idx, Yb))\n",
    "        # val proportion relative to train+val\n",
    "        val_rel = val / (train + val)\n",
    "        m2 = MLSSS(n_splits=1, test_size=val_rel, random_state=seed)\n",
    "        tr_idx, va_idx = next(m2.split(idx[trv_idx], Yb[trv_idx]))\n",
    "        tr_idx = idx[trv_idx][tr_idx]\n",
    "        va_idx = idx[trv_idx][va_idx]\n",
    "        return tr_idx, va_idx, idx[te_idx], \"iterstrat.MultilabelStratifiedShuffleSplit\"\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback: stratify by label-count buckets (0,1,2,3,â‰¥4)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    counts = np.nan_to_num(Y, nan=0).sum(axis=1)\n",
    "    buckets = np.clip(counts, 0, 4)\n",
    "    idx_tv, idx_te = train_test_split(idx, test_size=test, stratify=buckets, random_state=seed)\n",
    "    buckets_tv = np.clip(np.nan_to_num(df.iloc[idx_tv][label_cols].to_numpy(), nan=0).sum(axis=1), 0, 4)\n",
    "    idx_tr, idx_va = train_test_split(idx_tv, test_size=(val/(train+val)), stratify=buckets_tv, random_state=seed)\n",
    "    return np.array(idx_tr), np.array(idx_va), np.array(idx_te), \"bucketed label-count stratify\"\n",
    "\n",
    "def _prev_table(df, label_cols, idx):\n",
    "    Y = df.iloc[idx][label_cols].to_numpy(dtype=float)\n",
    "    pos = np.nansum((Y==1).astype(float), axis=0)\n",
    "    neg = np.nansum((Y==0).astype(float), axis=0)\n",
    "    tot = pos + neg\n",
    "    prev = np.divide(pos, np.maximum(tot, 1), out=np.zeros_like(pos), where=tot>0)\n",
    "    return pd.DataFrame({\n",
    "        \"label\": label_cols,\n",
    "        \"n_total\": tot.astype(int),\n",
    "        \"n_pos\": pos.astype(int),\n",
    "        \"prev\": prev\n",
    "    })\n",
    "\n",
    "# Build splits\n",
    "idx_train, idx_val, idx_test, src = build_splits_stratified(df, label_cols, seed=SEED, train=0.8, val=0.1, test=0.1)\n",
    "\n",
    "# Sanity checks\n",
    "assert len(set(idx_train)&set(idx_val))==0 and len(set(idx_train)&set(idx_test))==0 and len(set(idx_val)&set(idx_test))==0\n",
    "assert len(idx_train)+len(idx_val)+len(idx_test) == len(df)\n",
    "\n",
    "# Debug prevalence tables\n",
    "tab_all = _prev_table(df, label_cols, np.arange(len(df)))\n",
    "tab_tr  = _prev_table(df, label_cols, idx_train)\n",
    "tab_va  = _prev_table(df, label_cols, idx_val)\n",
    "tab_te  = _prev_table(df, label_cols, idx_test)\n",
    "\n",
    "dbg = tab_tr[[\"label\",\"prev\"]].rename(columns={\"prev\":\"prev_train\"}).merge(\n",
    "      tab_va[[\"label\",\"prev\"]].rename(columns={\"prev\":\"prev_val\"}), on=\"label\").merge(\n",
    "      tab_te[[\"label\",\"prev\"]].rename(columns={\"prev\":\"prev_test\"}), on=\"label\").merge(\n",
    "      tab_all[[\"label\",\"prev\"]].rename(columns={\"prev\":\"prev_all\"}), on=\"label\")\n",
    "\n",
    "dbg[\"|train-val|\"]  = (dbg[\"prev_train\"] - dbg[\"prev_val\"]).abs()\n",
    "dbg[\"|train-test|\"] = (dbg[\"prev_train\"] - dbg[\"prev_test\"]).abs()\n",
    "\n",
    "print(f\"=== Splits created via: {src} ===\")\n",
    "print(f\"Counts â†’ train={len(idx_train)} | val={len(idx_val)} | test={len(idx_test)} (sum={len(df)})\")\n",
    "\n",
    "print(\"\\nPer-label prevalence (train/val/test/all) and drift:\")\n",
    "print(dbg.sort_values(\"|train-test|\", ascending=False).to_string(index=False, float_format=lambda x: f\"{x:.3f}\"))\n",
    "\n",
    "# Save splits + debug CSV\n",
    "V3_META.mkdir(parents=True, exist_ok=True)\n",
    "json.dump({\"train_idx\": idx_train.tolist(),\n",
    "           \"val_idx\":   idx_val.tolist(),\n",
    "           \"test_idx\":  idx_test.tolist(),\n",
    "           \"source\":    src},\n",
    "          open(V3_META / \"splits.json\",\"w\"), indent=2)\n",
    "\n",
    "dbg_path = V3_META / \"split_prevalence_debug.csv\"\n",
    "dbg.to_csv(dbg_path, index=False)\n",
    "print(\"\\nSaved:\")\n",
    "print(\" - splits â†’\", V3_META / \"splits.json\")\n",
    "print(\" - prevalence debug â†’\", dbg_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34dba60",
   "metadata": {},
   "source": [
    "## 2: Augmented dataset (Curriculum augmentation (mildâ†’strong) + quieter RDKit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a0032d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets â†’ train 6264 | val 783 | test 784\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2 â€” Curriculum augmentation (mildâ†’strong) + quieter RDKit ===\n",
    "import json, numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.warning')\n",
    "\n",
    "# Tautomer enumerator with safe caps\n",
    "try:\n",
    "    from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "    opts = rdMolStandardize.TautomerEnumeratorOptions()\n",
    "    opts.maxTautomers = 25\n",
    "    opts.maxTransforms = 75\n",
    "    _TAUT_ENUM = rdMolStandardize.TautomerEnumerator(opts)\n",
    "except Exception:\n",
    "    _TAUT_ENUM = None\n",
    "\n",
    "# --- load splits from Cell 1\n",
    "splits = json.load(open(V3_META / \"splits.json\"))\n",
    "idx_train = np.array(splits[\"train_idx\"], dtype=int)\n",
    "idx_val   = np.array(splits[\"val_idx\"], dtype=int)\n",
    "idx_test  = np.array(splits[\"test_idx\"], dtype=int)\n",
    "\n",
    "def _randomize_smiles(s: str) -> str:\n",
    "    mol = Chem.MolFromSmiles(s)\n",
    "    if not mol: return s\n",
    "    return Chem.MolToSmiles(mol, canonical=False, doRandom=True)\n",
    "\n",
    "def _tautomerize(s: str) -> str:\n",
    "    if _TAUT_ENUM is None: return s\n",
    "    mol = Chem.MolFromSmiles(s)\n",
    "    if not mol: return s\n",
    "    try:\n",
    "        tset = list(_TAUT_ENUM.Enumerate(mol))\n",
    "        if len(tset) <= 1: return s\n",
    "        return Chem.MolToSmiles(np.random.choice(tset), canonical=True)\n",
    "    except Exception:\n",
    "        return s\n",
    "\n",
    "def _kekulize_toggle(s: str) -> str:\n",
    "    mol = Chem.MolFromSmiles(s)\n",
    "    if not mol: return s\n",
    "    try:\n",
    "        m2 = Chem.Mol(mol)\n",
    "        Chem.Kekulize(m2, clearAromaticFlags=True)\n",
    "        return Chem.MolToSmiles(m2, canonical=True)\n",
    "    except Exception:\n",
    "        return s  # swallow failures quietly\n",
    "\n",
    "class Tox21AugDataset(Dataset):\n",
    "    def __init__(self, frame, indices, tokenizer, label_cols, max_len=256, train=False,\n",
    "                 p_rand=0.3, p_mask=0.02, p_taut=0.02, p_kek=0.02, span_min=2, span_max=4):\n",
    "        self.df = frame.iloc[indices].reset_index(drop=True)\n",
    "        self.smiles = self.df[\"smiles\"].astype(str).tolist()\n",
    "        self.y = self.df[label_cols].to_numpy(dtype=float)\n",
    "        self.tok = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.train = train\n",
    "\n",
    "        # augmentation controls (will be updated per epoch)\n",
    "        self.p_rand = float(p_rand)\n",
    "        self.p_mask = float(p_mask)\n",
    "        self.p_taut = float(p_taut)\n",
    "        self.p_kek  = float(p_kek)\n",
    "        self.span_min, self.span_max = int(span_min), int(span_max)\n",
    "\n",
    "        # tokens for masking\n",
    "        self.mask_id = tokenizer.mask_token_id\n",
    "        specials = [tokenizer.cls_token, tokenizer.sep_token, tokenizer.pad_token]\n",
    "        self.special_ids = set(tokenizer.convert_tokens_to_ids([t for t in specials if t is not None]))\n",
    "\n",
    "    def set_epoch(self, ep: int, total_ep: int):\n",
    "        \"\"\"\n",
    "        Curriculum: ramp augmentation linearly from mild â†’ strong across training.\n",
    "        Start:  p_rand=0.3, p_mask=0.02, p_taut=0.02, p_kek=0.02\n",
    "        End:    p_rand=0.8, p_mask=0.04, p_taut=0.08, p_kek=0.04\n",
    "        \"\"\"\n",
    "        phase = max(0.0, min(1.0, (ep-1) / max(1, total_ep-1)))\n",
    "        self.p_rand = 0.3 + 0.5 * phase\n",
    "        self.p_mask = 0.02 + 0.02 * phase\n",
    "        self.p_taut = 0.02 + 0.06 * phase\n",
    "        self.p_kek  = 0.02 + 0.02 * phase\n",
    "\n",
    "    def _maybe_augment_smiles(self, s: str) -> str:\n",
    "        if not self.train: return s\n",
    "        if np.random.rand() < self.p_rand: s = _randomize_smiles(s)\n",
    "        if np.random.rand() < self.p_taut: s = _tautomerize(s)\n",
    "        if np.random.rand() < self.p_kek:  s = _kekulize_toggle(s)\n",
    "        return s\n",
    "\n",
    "    def _span_mask(self, ids: torch.Tensor) -> torch.Tensor:\n",
    "        if not self.train or self.mask_id is None or self.p_mask <= 0:\n",
    "            return ids\n",
    "        toks = ids.clone()\n",
    "        maskable = [i for i, t in enumerate(toks.tolist()) if t not in self.special_ids]\n",
    "        if not maskable: return ids\n",
    "        target = max(1, int(len(maskable) * self.p_mask))\n",
    "        covered = 0; trials = 0\n",
    "        while covered < target and trials < 10 * target:\n",
    "            trials += 1\n",
    "            L = np.random.randint(self.span_min, self.span_max + 1)\n",
    "            start = np.random.choice(maskable)\n",
    "            span = [i for i in range(start, min(start + L, len(toks))) if toks[i].item() not in self.special_ids]\n",
    "            if not span: continue\n",
    "            toks[span] = self.mask_id\n",
    "            covered += len(span)\n",
    "        return toks\n",
    "\n",
    "    def __len__(self): return len(self.smiles)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        s = self._maybe_augment_smiles(self.smiles[i])\n",
    "        enc = self.tok(s, truncation=True, padding=\"max_length\", max_length=self.max_len, return_tensors=\"pt\")\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        item[\"input_ids\"] = self._span_mask(item[\"input_ids\"])\n",
    "        item[\"labels\"] = torch.tensor(self.y[i], dtype=torch.float32)\n",
    "        return item\n",
    "\n",
    "# build datasets with initial mild augmentation (will ramp during training)\n",
    "train_ds = Tox21AugDataset(df, idx_train, tok, label_cols, max_len=MAX_LEN, train=True)\n",
    "val_ds   = Tox21AugDataset(df, idx_val,   tok, label_cols, max_len=MAX_LEN, train=False)\n",
    "test_ds  = Tox21AugDataset(df, idx_test,  tok, label_cols, max_len=MAX_LEN, train=False)\n",
    "\n",
    "print(\"Datasets â†’\", \"train\", len(train_ds), \"| val\", len(val_ds), \"| test\", len(test_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bf7076",
   "metadata": {},
   "source": [
    "## 3: Imbalance handling & DataLoaders (class-balanced + sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eb70264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved reweighting.json\n",
      "Batch keys: ['input_ids', 'attention_mask', 'labels'] | shapes: {'input_ids': (32, 256), 'attention_mask': (32, 256), 'labels': (32, 12)}\n",
      "Loader sanity OK in 0.02s  | workers=0\n"
     ]
    }
   ],
   "source": [
    "# === Cell 3 â€” Imbalance handling + Windows-safe DataLoaders ===\n",
    "import sys, os, time, json, numpy as np, torch\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# ---------- target labels to boost ----------\n",
    "TARGET_LABELS = [\"SR-ATAD5\",\"SR-MMP\",\"SR-HSE\",\"SR-ARE\",\"SR-p53\",\"NR-ER\",\"NR-AhR\"]\n",
    "\n",
    "# ---------- class priors / weights (TRAIN only) ----------\n",
    "Ytr = df.iloc[idx_train][label_cols].to_numpy(dtype=float)\n",
    "valid = ~np.isnan(Ytr)\n",
    "pos_counts = np.where(valid & (Ytr == 1), 1, 0).sum(axis=0).astype(float)\n",
    "neg_counts = np.where(valid & (Ytr == 0), 1, 0).sum(axis=0).astype(float)\n",
    "tot_counts = pos_counts + neg_counts\n",
    "priors = np.where(tot_counts > 0, pos_counts / np.clip(tot_counts, 1, None), 0.0)\n",
    "\n",
    "# class-balanced positive weights (Cui et al.)\n",
    "beta = 0.999\n",
    "eff_num = (1.0 - np.power(beta, np.clip(pos_counts, 0, None))) / (1.0 - beta)\n",
    "cb_pos_w = 1.0 / np.clip(eff_num, 1e-6, None)\n",
    "cb_pos_w = cb_pos_w / cb_pos_w.max()\n",
    "cb_pos_w = 0.25 + 0.75 * cb_pos_w\n",
    "\n",
    "# boost targets\n",
    "BOOST = 2.0\n",
    "for k, lbl in enumerate(label_cols):\n",
    "    if lbl in TARGET_LABELS:\n",
    "        cb_pos_w[k] *= BOOST\n",
    "cb_pos_w = np.clip(cb_pos_w, 0.25, 3.0)\n",
    "\n",
    "# logit adjustment (Menon et al.)\n",
    "tau = 1.0\n",
    "log_prior = np.log(np.clip(priors, 1e-6, 1 - 1e-6)) - np.log(np.clip(1 - priors, 1e-6, 1 - 1e-6))\n",
    "log_prior = tau * log_prior\n",
    "\n",
    "# save reweighting meta for training\n",
    "V3_META.mkdir(parents=True, exist_ok=True)\n",
    "json.dump({\n",
    "    \"priors\":        {l: float(priors[i]) for i, l in enumerate(label_cols)},\n",
    "    \"pos_counts\":    {l: int(pos_counts[i]) for i, l in enumerate(label_cols)},\n",
    "    \"neg_counts\":    {l: int(neg_counts[i]) for i, l in enumerate(label_cols)},\n",
    "    \"cb_pos_w\":      {l: float(cb_pos_w[i]) for i, l in enumerate(label_cols)},\n",
    "    \"logit_adjust\":  {l: float(log_prior[i]) for i, l in enumerate(label_cols)},\n",
    "    \"beta\": float(beta), \"tau\": float(tau),\n",
    "    \"targets\": TARGET_LABELS, \"boost\": float(BOOST)\n",
    "}, open(V3_META / \"reweighting.json\", \"w\"), indent=2)\n",
    "print(\"Saved reweighting.json\")\n",
    "\n",
    "# ---------- label-aware sampler ----------\n",
    "K = 4.0\n",
    "Ytr_full = df.iloc[idx_train][label_cols].to_numpy(dtype=float)\n",
    "sample_w = np.ones(len(idx_train), dtype=float)\n",
    "for t_lbl in TARGET_LABELS:\n",
    "    j = label_cols.index(t_lbl)\n",
    "    is_pos = np.nan_to_num(Ytr_full[:, j], nan=0.0) == 1.0\n",
    "    sample_w += K * is_pos.astype(float)\n",
    "sampler = WeightedRandomSampler(sample_w, num_samples=len(sample_w), replacement=True)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    keys = batch[0].keys()\n",
    "    return {k: torch.stack([b[k] for b in batch], dim=0) for k in keys}\n",
    "\n",
    "# ---------- Windows-safe DataLoader builder ----------\n",
    "if sys.platform.startswith(\"win\"):\n",
    "    try:\n",
    "        mp.set_start_method(\"spawn\", force=True)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    torch.set_num_threads(1)\n",
    "\n",
    "# flip this to 2 after you confirm a batch runs end-to-end\n",
    "WORKERS = 0   # 0 = simplest/stable; set to 2 when stable\n",
    "\n",
    "def _mk_loader(dataset, sampler=None, shuffle=False):\n",
    "    kwargs = dict(\n",
    "        dataset=dataset,\n",
    "        batch_size=BATCH,\n",
    "        drop_last=False,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True,\n",
    "        num_workers=WORKERS,\n",
    "    )\n",
    "    if sampler is not None:\n",
    "        kwargs.update(sampler=sampler, shuffle=False)\n",
    "    else:\n",
    "        kwargs.update(shuffle=shuffle)\n",
    "\n",
    "    # only valid when num_workers > 0\n",
    "    if WORKERS > 0:\n",
    "        kwargs.update(prefetch_factor=2, persistent_workers=True)\n",
    "    else:\n",
    "        kwargs.update(prefetch_factor=None, persistent_workers=False)\n",
    "\n",
    "    return DataLoader(**kwargs)\n",
    "\n",
    "train_loader = _mk_loader(train_ds, sampler=sampler)\n",
    "val_loader   = _mk_loader(val_ds,   sampler=None, shuffle=False)\n",
    "test_loader  = _mk_loader(test_ds,  sampler=None, shuffle=False)\n",
    "\n",
    "# ---------- quick sanity (iterate a couple of batches) ----------\n",
    "t0 = time.time()\n",
    "b = next(iter(train_loader))\n",
    "print(\"Batch keys:\", list(b.keys()), \"| shapes:\",\n",
    "      {k: tuple(v.shape) for k,v in b.items()})\n",
    "# one forward to ensure model/criterion path is fine\n",
    "labels = b[\"labels\"].to(DEVICE)\n",
    "batch  = {k: v.to(DEVICE) for k,v in b.items() if k!=\"labels\"}\n",
    "with torch.no_grad():\n",
    "    out = model(**batch)\n",
    "    _ = out.logits\n",
    "print(f\"Loader sanity OK in {time.time()-t0:.2f}s  | workers={WORKERS}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4df9c1",
   "metadata": {},
   "source": [
    "## 4: Model to train + loss (CB + logit-adjust) + optim/sched factory (+ smoke test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7bb2678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 92136204\n",
      "[SMOKE] one-batch loss: 0.4907\n"
     ]
    }
   ],
   "source": [
    "# === Cell 4 â€” Model to train + loss (CB + logit-adjust) + optim/sched factory + smoke test ===\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "# Ensure model from Cell 0 is in scope:\n",
    "# model, tok, DEVICE, label_cols, V3_META, MAX_LEN, BATCH are already defined\n",
    "\n",
    "model.train()\n",
    "FREEZE_LAYERS = 0\n",
    "if FREEZE_LAYERS and hasattr(model, \"roberta\"):\n",
    "    for i in range(FREEZE_LAYERS):\n",
    "        for p in model.roberta.encoder.layer[i].parameters():\n",
    "            p.requires_grad = False\n",
    "print(\"Trainable params:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "rw = json.load(open(V3_META / \"reweighting.json\"))\n",
    "cb_pos_w_t = torch.tensor([rw[\"cb_pos_w\"][l]     for l in label_cols], dtype=torch.float32, device=DEVICE)\n",
    "log_adj_t  = torch.tensor([rw[\"logit_adjust\"][l] for l in label_cols], dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "class AsymmetricCBLoss(nn.Module):\n",
    "    def __init__(self, gamma_pos=0.0, gamma_neg=2.0, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.gp = float(gamma_pos)\n",
    "        self.gn = float(gamma_neg)\n",
    "        self.eps = float(eps)\n",
    "\n",
    "    def _to_2d(self, logits: torch.Tensor) -> torch.Tensor:\n",
    "        if logits.ndim == 2:\n",
    "            return logits\n",
    "        if logits.ndim == 3:\n",
    "            return logits.mean(dim=1)\n",
    "        return logits.view(logits.size(0), -1)\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        logits = self._to_2d(logits)\n",
    "        mask = ~torch.isnan(targets)\n",
    "        B, L = targets.shape\n",
    "        la = log_adj_t.unsqueeze(0).expand(B, L)\n",
    "        logits = logits + la\n",
    "        logits = logits[mask]\n",
    "        t = targets[mask]\n",
    "\n",
    "        p = torch.sigmoid(logits).clamp(self.eps, 1 - self.eps)\n",
    "        pt = torch.where(t > 0.5, p, 1 - p)\n",
    "        gamma = torch.where(t > 0.5,\n",
    "                            torch.full_like(pt, self.gp),\n",
    "                            torch.full_like(pt, self.gn))\n",
    "        focal = (1.0 - pt) ** gamma\n",
    "\n",
    "        idx_all = torch.arange(L, device=targets.device).repeat(B, 1)\n",
    "        idx_masked = idx_all[mask]\n",
    "        wpos = cb_pos_w_t[idx_masked]\n",
    "        w = torch.where(t > 0.5, wpos, torch.ones_like(wpos))\n",
    "\n",
    "        loss_pos = -t * torch.log(p)\n",
    "        loss_neg = -(1.0 - t) * torch.log(1.0 - p)\n",
    "        loss = focal * torch.where(t > 0.5, loss_pos, loss_neg) * w\n",
    "        return loss.mean()\n",
    "\n",
    "criterion = AsymmetricCBLoss(gamma_pos=0.0, gamma_neg=2.0)\n",
    "\n",
    "def make_optim_sched(model, epochs:int, lr:float=2e-5, weight_decay:float=0.01, warmup_ratio:float=0.1):\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    total_steps = epochs * len(train_loader)\n",
    "    warmup_steps = max(1, int(total_steps * warmup_ratio))\n",
    "    sched = get_cosine_schedule_with_warmup(optim, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "    return optim, sched\n",
    "\n",
    "# Smoke test\n",
    "batch = next(iter(train_loader))\n",
    "labels = batch.pop(\"labels\").to(DEVICE)\n",
    "for k in list(batch.keys()): batch[k] = batch[k].to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    out = model(**batch)\n",
    "    loss_val = criterion(out.logits, labels)\n",
    "print(f\"[SMOKE] one-batch loss: {loss_val.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bb088d",
   "metadata": {},
   "source": [
    "## 5: Train loop (AMP + cosine warmup + early stop on target macro-PR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae642c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b156f5e96374c82bc8138208e8b7c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 01] loss=0.4624 | PR-micro=0.1246 | PR-macro=0.1386 | PR-macro(TGT)=0.1759 | lr=5.00e-06\n",
      "âœ“ Saved v3_best (ep 1 )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1166808aacd14a55bda9f8d4aff2a02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 02] loss=0.2729 | PR-micro=0.0936 | PR-macro=0.2239 | PR-macro(TGT)=0.2277 | lr=1.00e-05\n",
      "âœ“ Saved v3_best (ep 2 )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d914824c3f2c4de8abe3668ebc8016c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 03] loss=0.2326 | PR-micro=0.1485 | PR-macro=0.2805 | PR-macro(TGT)=0.2779 | lr=1.50e-05\n",
      "âœ“ Saved v3_best (ep 3 )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6665ce09c33547ebab3c3f026fed520c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 04] loss=0.2195 | PR-micro=0.2047 | PR-macro=0.3144 | PR-macro(TGT)=0.3121 | lr=2.00e-05\n",
      "âœ“ Saved v3_best (ep 4 )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11615c74edd04bcfb9d4e3a8e2f6231e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 05] loss=0.2053 | PR-micro=0.2634 | PR-macro=0.3236 | PR-macro(TGT)=0.3291 | lr=2.00e-05\n",
      "âœ“ Saved v3_best (ep 5 )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f26be610f3046729acca412313de6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 06] loss=0.1933 | PR-micro=0.2950 | PR-macro=0.3433 | PR-macro(TGT)=0.3443 | lr=1.98e-05\n",
      "âœ“ Saved v3_best (ep 6 )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a12b77b6a454dc383fc080a10184aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 07] loss=0.1815 | PR-micro=0.3150 | PR-macro=0.3586 | PR-macro(TGT)=0.3624 | lr=1.97e-05\n",
      "âœ“ Saved v3_best (ep 7 )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c87e59f5ec435e930676c7c511d1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 08] loss=0.1763 | PR-micro=0.3394 | PR-macro=0.3659 | PR-macro(TGT)=0.3689 | lr=1.94e-05\n",
      "âœ“ Saved v3_best (ep 8 )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5166deb66eba44b5a9c4e1157924786e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 09] loss=0.1696 | PR-micro=0.3405 | PR-macro=0.3687 | PR-macro(TGT)=0.3737 | lr=1.91e-05\n",
      "âœ“ Saved v3_best (ep 9 )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1755ac7eec674524a6ce5cca1bcbe5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 10] loss=0.1613 | PR-micro=0.3674 | PR-macro=0.3871 | PR-macro(TGT)=0.3957 | lr=1.87e-05\n",
      "âœ“ Saved v3_best (ep 10 )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f3de4de77341c2a0353013a0d7fc6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 11] loss=0.1564 | PR-micro=0.3837 | PR-macro=0.3905 | PR-macro(TGT)=0.3912 | lr=1.82e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801c5518b4e64ce181758278c886d7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 12] loss=0.1533 | PR-micro=0.3777 | PR-macro=0.3989 | PR-macro(TGT)=0.3973 | lr=1.77e-05\n",
      "âœ“ Saved v3_best (ep 12 )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715510d3ece040dea1322eb932e3fb48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 13] loss=0.1489 | PR-micro=0.3675 | PR-macro=0.3941 | PR-macro(TGT)=0.3956 | lr=1.71e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bad3a40f50e4b65990dcc3f2414c5b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 14] loss=0.1437 | PR-micro=0.3843 | PR-macro=0.4012 | PR-macro(TGT)=0.4070 | lr=1.64e-05\n",
      "âœ“ Saved v3_best (ep 14 )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971671fcd0014af4a2625b350290d80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 15] loss=0.1401 | PR-micro=0.3871 | PR-macro=0.3979 | PR-macro(TGT)=0.4043 | lr=1.57e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251494a0dc9447b9b4cd44e790e5ac0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 16] loss=0.1370 | PR-micro=0.3929 | PR-macro=0.3998 | PR-macro(TGT)=0.4032 | lr=1.50e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead035c137d04a36a9cd3e7dc9508496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 17] loss=0.1376 | PR-micro=0.4000 | PR-macro=0.4035 | PR-macro(TGT)=0.4091 | lr=1.42e-05\n",
      "âœ“ Saved v3_best (ep 17 )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9235755075814cf2aeee4fcd75744cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 18] loss=0.1320 | PR-micro=0.4022 | PR-macro=0.4026 | PR-macro(TGT)=0.4101 | lr=1.34e-05\n",
      "âœ“ Saved v3_best (ep 18 )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bc9efc17f64b8fb2bfd9a80d7ad57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 19] loss=0.1250 | PR-micro=0.4147 | PR-macro=0.4160 | PR-macro(TGT)=0.4221 | lr=1.26e-05\n",
      "âœ“ Saved v3_best (ep 19 )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507c646d32664931b68d8c3986366494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 20] loss=0.1305 | PR-micro=0.4171 | PR-macro=0.4167 | PR-macro(TGT)=0.4276 | lr=1.17e-05\n",
      "âœ“ Saved v3_best (ep 20 )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03bd948f06b049bbbb3f06acb830c956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 21] loss=0.1264 | PR-micro=0.4075 | PR-macro=0.4054 | PR-macro(TGT)=0.4214 | lr=1.09e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9262f84c9f8f48098651ec5816d834aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 22] loss=0.1235 | PR-micro=0.4022 | PR-macro=0.4002 | PR-macro(TGT)=0.4119 | lr=1.00e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3562be67d9449ba15319d8f4a1a7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 23] loss=0.1221 | PR-micro=0.4211 | PR-macro=0.4196 | PR-macro(TGT)=0.4349 | lr=9.13e-06\n",
      "âœ“ Saved v3_best (ep 23 )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4acc833d7cf4fdeadae0b205e0fdf56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 24] loss=0.1212 | PR-micro=0.4138 | PR-macro=0.4068 | PR-macro(TGT)=0.4168 | lr=8.26e-06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e967a67cda41829d7ae6cef456215f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 25] loss=0.1191 | PR-micro=0.4225 | PR-macro=0.4152 | PR-macro(TGT)=0.4255 | lr=7.41e-06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1b77f7036b4b79aafac30ac0b6a129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 26] loss=0.1180 | PR-micro=0.4255 | PR-macro=0.4191 | PR-macro(TGT)=0.4345 | lr=6.58e-06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6be487401224a4e85e30376d8c66b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/40:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL ep 27] loss=0.1190 | PR-micro=0.4216 | PR-macro=0.4153 | PR-macro(TGT)=0.4293 | lr=5.77e-06\n",
      "Early stopping (no improvement 4 â‰¥ 4). Best target-macro PR=0.4349\n",
      "Training done. Best PR-macro(TARGETS): 0.4349\n",
      "History saved â†’ implementation\\models\\chemberta_v3\\metadata\\train_history_v3.csv\n"
     ]
    }
   ],
   "source": [
    "# === Cell 5 â€” Train (AMP new API + cosine warmup + early stop on target macro-PR) ===\n",
    "import json, csv, numpy as np, torch\n",
    "from sklearn.metrics import average_precision_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "EPOCHS, LR, WEIGHT_DECAY, WARMUP_RATIO = 40, 2e-5, 0.01, 0.1\n",
    "PATIENCE, GRAD_ACCUM, MAX_NORM = 4, 1, 1.0\n",
    "USE_AMP = torch.cuda.is_available()\n",
    "\n",
    "optim, sched = make_optim_sched(model, epochs=EPOCHS, lr=LR, weight_decay=WEIGHT_DECAY, warmup_ratio=WARMUP_RATIO)\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=USE_AMP)   # new API\n",
    "\n",
    "def _to_2d(x): \n",
    "    return x if x.ndim==2 else (x[:,0,:] if x.ndim==3 and x.size(1)>0 else x.mean(1))\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_loop(loader):\n",
    "    model.eval()\n",
    "    all_y, all_p = [], []\n",
    "    for batch in loader:\n",
    "        labels = batch.pop(\"labels\").to(DEVICE)\n",
    "        for k in list(batch.keys()): batch[k] = batch[k].to(DEVICE)\n",
    "        with torch.amp.autocast('cuda', dtype=torch.float16, enabled=USE_AMP):\n",
    "            probs = torch.sigmoid(_to_2d(model(**batch).logits)).float().cpu().numpy()\n",
    "        all_p.append(probs); all_y.append(labels.cpu().numpy())\n",
    "    P = np.concatenate(all_p, 0); Y = np.concatenate(all_y, 0)\n",
    "    mask = ~np.isnan(Y)\n",
    "    try: pr_micro = average_precision_score(Y[mask], P[mask])\n",
    "    except: pr_micro = np.nan\n",
    "    aps_all, aps_t = [], []\n",
    "    for j, lbl in enumerate(label_cols):\n",
    "        m = ~np.isnan(Y[:,j]); yj, pj = Y[m,j], P[m,j]\n",
    "        if np.unique(yj).size == 2:\n",
    "            try: aps_all.append(average_precision_score(yj, pj))\n",
    "            except: pass\n",
    "    for lbl in [\"SR-ATAD5\",\"SR-MMP\",\"SR-HSE\",\"SR-ARE\",\"SR-p53\",\"NR-ER\",\"NR-AhR\"]:\n",
    "        j = label_cols.index(lbl); m = ~np.isnan(Y[:,j]); yj, pj = Y[m,j], P[m,j]\n",
    "        if np.unique(yj).size == 2:\n",
    "            try: aps_t.append(average_precision_score(yj, pj))\n",
    "            except: pass\n",
    "    return {\"pr_micro\": float(pr_micro), \"pr_macro\": float(np.mean(aps_all)) if aps_all else np.nan,\n",
    "            \"pr_macro_targets\": float(np.mean(aps_t)) if aps_t else np.nan}\n",
    "\n",
    "history_path = V3_META / \"train_history_v3.csv\"\n",
    "with open(history_path, \"w\", newline=\"\") as f:\n",
    "    csv.writer(f).writerow([\"epoch\",\"train_loss\",\"val_pr_micro\",\"val_pr_macro\",\"val_pr_macro_targets\",\"lr\"])\n",
    "\n",
    "best_score, no_improve = -1.0, 0\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    train_ds.set_epoch(ep, EPOCHS)  # curriculum augmentation per epoch\n",
    "    model.train()\n",
    "    running = steps = 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {ep}/{EPOCHS}\", leave=True)\n",
    "    for it, batch in enumerate(pbar, start=1):\n",
    "        labels = batch.pop(\"labels\").to(DEVICE)\n",
    "        for k in list(batch.keys()): batch[k] = batch[k].to(DEVICE)\n",
    "\n",
    "        with torch.amp.autocast('cuda', dtype=torch.float16, enabled=USE_AMP):\n",
    "            out = model(**batch)\n",
    "            loss = criterion(out.logits, labels) / GRAD_ACCUM\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        if it % GRAD_ACCUM == 0:\n",
    "            scaler.unscale_(optim)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_NORM)\n",
    "            scaler.step(optim); scaler.update()\n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            sched.step()\n",
    "\n",
    "        running += loss.item() * GRAD_ACCUM; steps += 1\n",
    "        if steps % 10 == 0:\n",
    "            pbar.set_postfix(loss=f\"{running/steps:.4f}\", lr=f\"{sched.get_last_lr()[0]:.2e}\")\n",
    "\n",
    "    metr = eval_loop(val_loader)\n",
    "    train_loss = running / max(1, steps)\n",
    "    curr_lr = sched.get_last_lr()[0]\n",
    "    print(f\"[VAL ep {ep:02d}] loss={train_loss:.4f} | PR-micro={metr['pr_micro']:.4f} | \"\n",
    "          f\"PR-macro={metr['pr_macro']:.4f} | PR-macro(TGT)={metr['pr_macro_targets']:.4f} | lr={curr_lr:.2e}\")\n",
    "\n",
    "    with open(history_path, \"a\", newline=\"\") as f:\n",
    "        csv.writer(f).writerow([ep, f\"{train_loss:.6f}\", f\"{metr['pr_micro']:.6f}\",\n",
    "                                f\"{metr['pr_macro']:.6f}\", f\"{metr['pr_macro_targets']:.6f}\", f\"{curr_lr:.6e}\"])\n",
    "\n",
    "    score = metr[\"pr_macro_targets\"]\n",
    "    if score > best_score + 1e-5:\n",
    "        best_score, no_improve = score, 0\n",
    "        V3_BEST.mkdir(parents=True, exist_ok=True)\n",
    "        model.eval().save_pretrained(str(V3_BEST))\n",
    "        tok.save_pretrained(str(V3_BEST))\n",
    "        model.config.save_pretrained(str(V3_BEST))\n",
    "        json.dump({\"epoch\": ep, \"val_pr_macro_targets\": float(best_score)},\n",
    "                  open(V3_META / \"best.json\", \"w\"), indent=2)\n",
    "        print(\"âœ“ Saved v3_best (ep\", ep, \")\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= PATIENCE:\n",
    "            print(f\"Early stopping (no improvement {no_improve} â‰¥ {PATIENCE}). Best target-macro PR={best_score:.4f}\")\n",
    "            break\n",
    "\n",
    "print(\"Training done. Best PR-macro(TARGETS):\", round(best_score, 4))\n",
    "print(\"History saved â†’\", history_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb1659f",
   "metadata": {},
   "source": [
    "## 6: Evaluation (VALâ†’TEST thresholds) with sklearn MCC (no overflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22115e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VAL (thr via mcc) ===\n",
      "        label   n    auroc       ap  thr      acc     prec      rec       f1\n",
      "       SR-MMP 573 0.921789 0.753813 0.95 0.902269 0.709302 0.663043 0.685393\n",
      "        NR-AR 734 0.789978 0.613642 0.96 0.979564 1.000000 0.516129 0.680851\n",
      "    NR-AR-LBD 676 0.892063 0.565526 0.98 0.974852 0.652174 0.625000 0.638298\n",
      "       NR-AhR 653 0.871911 0.552433 0.98 0.911179 0.731707 0.389610 0.508475\n",
      "       SR-ARE 577 0.796793 0.495131 0.96 0.859619 0.618182 0.361702 0.456376\n",
      "       SR-p53 685 0.857180 0.334896 0.95 0.908029 0.352113 0.595238 0.442478\n",
      "        NR-ER 616 0.634444 0.404139 0.97 0.891234 0.714286 0.253165 0.373832\n",
      "     SR-ATAD5 703 0.772469 0.288747 0.97 0.950213 0.344828 0.384615 0.363636\n",
      "NR-PPAR-gamma 630 0.805496 0.219710 0.97 0.955556 0.304348 0.368421 0.333333\n",
      "    NR-ER-LBD 687 0.717134 0.342243 0.98 0.949054 0.500000 0.228571 0.313725\n",
      "       SR-HSE 644 0.734984 0.223258 0.98 0.936335 0.409091 0.243243 0.305085\n",
      " NR-Aromatase 583 0.773599 0.266732 0.98 0.951973 0.600000 0.200000 0.300000\n",
      "\n",
      "=== TEST (VAL-chosen thr) ===\n",
      "        label   n    auroc       ap  thr      acc     prec      rec       f1\n",
      "    NR-AR-LBD 680 0.834985 0.666583 0.98 0.980882 0.789474 0.625000 0.697674\n",
      "       SR-MMP 579 0.892889 0.722550 0.95 0.898100 0.714286 0.597826 0.650888\n",
      "        NR-AR 733 0.835999 0.627421 0.96 0.974079 0.800000 0.516129 0.627451\n",
      "    NR-ER-LBD 703 0.770359 0.539933 0.98 0.967283 0.875000 0.400000 0.549020\n",
      "       SR-ARE 568 0.822897 0.600057 0.96 0.871479 0.698113 0.393617 0.503401\n",
      "        NR-ER 622 0.785999 0.574167 0.97 0.903537 0.731707 0.379747 0.500000\n",
      "       NR-AhR 657 0.846328 0.594611 0.98 0.913242 0.777778 0.363636 0.495575\n",
      "     SR-ATAD5 709 0.819293 0.326065 0.97 0.957687 0.428571 0.461538 0.444444\n",
      "       SR-HSE 655 0.832371 0.480519 0.98 0.949618 0.600000 0.324324 0.421053\n",
      "       SR-p53 687 0.818236 0.403334 0.95 0.906841 0.288462 0.357143 0.319149\n",
      "NR-PPAR-gamma 654 0.654206 0.286994 0.97 0.966361 0.384615 0.263158 0.312500\n",
      " NR-Aromatase 579 0.885610 0.441835 0.98 0.948187 0.500000 0.200000 0.285714\n",
      "\n",
      "Saved thresholds â†’ implementation\\models\\chemberta_v3\\metadata\\thresholds_v3.json\n"
     ]
    }
   ],
   "source": [
    "# === Cell 6 â€” Evaluation: thresholds on VAL, report TEST (MCC/F1/F1@rec-floor) ===\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, precision_score, recall_score, matthews_corrcoef\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "ROOT     = Path(\"implementation\")\n",
    "DATA_CSV = ROOT / \"data\" / \"tox21.csv\"\n",
    "V3_DIR   = ROOT / \"models\" / \"chemberta_v3\"\n",
    "V3_META  = V3_DIR / \"metadata\"\n",
    "V3_BEST  = V3_DIR / \"v3_best\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_EVAL, MAXLEN = 64, 256\n",
    "\n",
    "# strategy: \"mcc\" | \"f1\" | \"f1_rfloor\"\n",
    "STRATEGY = \"mcc\"\n",
    "RECALL_FLOOR = 0.60\n",
    "GRID = np.linspace(0.02, 0.98, 97)\n",
    "\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "label_cols = [c for c in df.columns if c not in (\"mol_id\",\"smiles\")]\n",
    "spl = json.load(open(V3_META / \"splits.json\"))\n",
    "idx_val  = np.array(spl[\"val_idx\"], dtype=int)\n",
    "idx_test = np.array(spl[\"test_idx\"], dtype=int)\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(str(V3_BEST))\n",
    "cfg = AutoConfig.from_pretrained(str(V3_BEST))\n",
    "model = AutoModelForSequenceClassification.from_pretrained(str(V3_BEST), config=cfg).to(DEVICE).eval()\n",
    "if hasattr(model.config, \"use_cache\"): model.config.use_cache = False\n",
    "\n",
    "def _to_2d(x): \n",
    "    return x if x.ndim==2 else (x[:,0,:] if x.ndim==3 and x.size(1)>0 else x.mean(1))\n",
    "\n",
    "def _pred(smiles):\n",
    "    out=[]\n",
    "    for i in range(0,len(smiles),BATCH_EVAL):\n",
    "        enc = tok(smiles[i:i+BATCH_EVAL], truncation=True, padding=True, max_length=MAXLEN, return_tensors=\"pt\").to(DEVICE)\n",
    "        with torch.inference_mode():\n",
    "            p = torch.sigmoid(_to_2d(model(**enc).logits)).cpu().numpy()\n",
    "        out.append(p)\n",
    "    return np.vstack(out)\n",
    "\n",
    "X = df[\"smiles\"].astype(str).tolist()\n",
    "def _split(idx):\n",
    "    Xs=[X[i] for i in idx]\n",
    "    Y = df.iloc[idx][label_cols].to_numpy(dtype=float)\n",
    "    return Xs, Y\n",
    "\n",
    "Xv,Yv = _split(idx_val);  Pv = _pred(Xv)\n",
    "Xt,Yt = _split(idx_test); Pt = _pred(Xt)\n",
    "\n",
    "def _aupr(y, p):\n",
    "    if y.size==0 or np.unique(y).size<2: return (np.nan, np.nan)\n",
    "    au=ap=np.nan\n",
    "    try: au = roc_auc_score(y, p)\n",
    "    except: pass\n",
    "    try: ap = average_precision_score(y, p)\n",
    "    except: pass\n",
    "    return au, ap\n",
    "\n",
    "def _choose_thr(y, p):\n",
    "    if y.size==0 or np.unique(y).size<2: return 0.5\n",
    "    best, thr = -1e9, 0.5\n",
    "    for t in GRID:\n",
    "        yb = (p>=t).astype(int)\n",
    "        if STRATEGY==\"mcc\":\n",
    "            try: s = matthews_corrcoef(y, yb)\n",
    "            except: s = -1e9\n",
    "        elif STRATEGY==\"f1\":\n",
    "            s = f1_score(y, yb, zero_division=0)\n",
    "        else:  # f1_rfloor\n",
    "            rec = recall_score(y, yb, zero_division=0)\n",
    "            if rec < RECALL_FLOOR: \n",
    "                continue\n",
    "            s = f1_score(y, yb, zero_division=0)\n",
    "        if s > best:\n",
    "            best, thr = s, float(t)\n",
    "    return thr\n",
    "\n",
    "def _bin_metrics(y, p, thr):\n",
    "    if y.size==0: return (np.nan,)*4\n",
    "    yb=(p>=thr).astype(int)\n",
    "    return ((yb==y).mean(),\n",
    "            precision_score(y, yb, zero_division=0),\n",
    "            recall_score(y, yb, zero_division=0),\n",
    "            f1_score(y, yb, zero_division=0))\n",
    "\n",
    "thr_map = {}\n",
    "rows_v, rows_t = [], []\n",
    "for j, lbl in enumerate(label_cols):\n",
    "    mv = ~np.isnan(Yv[:,j]); yv, pv = Yv[mv,j].astype(int), Pv[mv,j]\n",
    "    mt = ~np.isnan(Yt[:,j]); yt, pt = Yt[mt,j].astype(int), Pt[mt,j]\n",
    "\n",
    "    au_v, ap_v = _aupr(yv, pv)\n",
    "    thr = _choose_thr(yv, pv); thr_map[lbl] = float(thr)\n",
    "\n",
    "    acc_v, pr_v, rc_v, f1_v = _bin_metrics(yv, pv, thr)\n",
    "    au_t, ap_t = _aupr(yt, pt)\n",
    "    acc_t, pr_t, rc_t, f1_t = _bin_metrics(yt, pt, thr)\n",
    "\n",
    "    rows_v.append([lbl, yv.size, au_v, ap_v, thr, acc_v, pr_v, rc_v, f1_v])\n",
    "    rows_t.append([lbl, yt.size, au_t, ap_t, thr, acc_t, pr_t, rc_t, f1_t])\n",
    "\n",
    "val_df  = pd.DataFrame(rows_v, columns=[\"label\",\"n\",\"auroc\",\"ap\",\"thr\",\"acc\",\"prec\",\"rec\",\"f1\"])\n",
    "test_df = pd.DataFrame(rows_t, columns=[\"label\",\"n\",\"auroc\",\"ap\",\"thr\",\"acc\",\"prec\",\"rec\",\"f1\"])\n",
    "\n",
    "print(f\"=== VAL (thr via {STRATEGY}) ===\")\n",
    "print(val_df.sort_values('f1', ascending=False).to_string(index=False))\n",
    "print(\"\\n=== TEST (VAL-chosen thr) ===\")\n",
    "print(test_df.sort_values('f1', ascending=False).to_string(index=False))\n",
    "\n",
    "# save thresholds for later use\n",
    "save_thr = V3_META / \"thresholds_v3.json\"\n",
    "json.dump(thr_map, open(save_thr, \"w\"), indent=2)\n",
    "print(\"\\nSaved thresholds â†’\", save_thr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153d49cf",
   "metadata": {},
   "source": [
    "### Sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6a37d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted hits: ['NR-AhR']\n",
      "Top-5: [('NR-AhR', 0.9891173), ('SR-ARE', 0.9389017), ('SR-ATAD5', 0.9214757), ('NR-ER', 0.91614175), ('NR-AR', 0.87063503)]\n"
     ]
    }
   ],
   "source": [
    "# === Cell 6b â€” Sanity: reload v3_best and predict one SMILES ===\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch, numpy as np, json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "V3 = Path(\"implementation/models/chemberta_v3\")\n",
    "V3_BEST = V3/\"v3_best\"\n",
    "V3_META = V3/\"metadata\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tok  = AutoTokenizer.from_pretrained(str(V3_BEST))\n",
    "mdl  = AutoModelForSequenceClassification.from_pretrained(str(V3_BEST)).to(DEVICE).eval()\n",
    "thr  = json.load(open(V3_META/\"thresholds_v3.json\"))\n",
    "labels = list(pd.read_csv(\"implementation/data/tox21.csv\").columns.drop([\"mol_id\",\"smiles\"]))\n",
    "\n",
    "def predict(smiles):\n",
    "    enc = tok(smiles, truncation=True, padding=True, max_length=256, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.inference_mode():\n",
    "        p = torch.sigmoid(mdl(**enc).logits).cpu().numpy()[0]\n",
    "    hits = [lbl for lbl, pr in zip(labels, p) if pr >= float(thr.get(lbl, 0.5))]\n",
    "    return dict(zip(labels, p)), hits\n",
    "\n",
    "sm = \"CCOc1ccc2nc(S(N)(=O)=O)sc2c1\"  # example\n",
    "probs, hits = predict(sm)\n",
    "print(\"Predicted hits:\", hits)\n",
    "print(\"Top-5:\", sorted(probs.items(), key=lambda kv: kv[1], reverse=True)[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7528d2d7",
   "metadata": {},
   "source": [
    "## 7: V2 VS V3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a19b7805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== v3 vs v2 â€” per-label on v3 TEST split ===\n",
      "        label   n  acc_v2  acc_v3   Î”acc  f1_v2  f1_v3    Î”f1  thr_v2  thr_v3\n",
      "        NR-AR 733  0.0423  0.9741 0.9318 0.0812 0.6275 0.5463  0.0300  0.9600\n",
      "    NR-AR-LBD 680  0.7265  0.9809 0.2544 0.1983 0.6977 0.4994  0.1900  0.9800\n",
      "    NR-ER-LBD 703  0.3144  0.9673 0.6529 0.1268 0.5490 0.4222  0.1100  0.9800\n",
      "     SR-ATAD5 709  0.3625  0.9577 0.5952 0.1032 0.4444 0.3413  0.0700  0.9700\n",
      "       SR-HSE 655  0.1573  0.9496 0.7924 0.1182 0.4211 0.3028  0.1100  0.9800\n",
      "        NR-ER 622  0.1270  0.9035 0.7765 0.2254 0.5000 0.2746  0.1000  0.9700\n",
      "NR-PPAR-gamma 654  0.3853  0.9664 0.5810 0.0822 0.3125 0.2303  0.1300  0.9700\n",
      "       SR-MMP 579  0.6615  0.8981 0.2366 0.4645 0.6509 0.1864  0.2600  0.9500\n",
      "       NR-AhR 657  0.5053  0.9132 0.4079 0.3158 0.4956 0.1798  0.1900  0.9800\n",
      "       SR-p53 687  0.4148  0.9068 0.4920 0.1728 0.3191 0.1463  0.0900  0.9500\n",
      " NR-Aromatase 579  0.3834  0.9482 0.5648 0.1439 0.2857 0.1418  0.1100  0.9800\n",
      "       SR-ARE 568  0.6162  0.8715 0.2553 0.4323 0.5034 0.0711  0.2800  0.9600\n",
      "\n",
      "=== Overall F1 (TEST) ===\n",
      "Macro F1  v2: 0.2054 | v3: 0.4839 | Î” +0.2785\n",
      "Micro F1  v2: 0.1897 | v3: 0.5036 | Î” +0.3139\n",
      "\n",
      "Top 5 Î”F1 improvements:\n",
      "    label  f1_v2  f1_v3    Î”f1\n",
      "    NR-AR 0.0812 0.6275 0.5463\n",
      "NR-AR-LBD 0.1983 0.6977 0.4994\n",
      "NR-ER-LBD 0.1268 0.5490 0.4222\n",
      " SR-ATAD5 0.1032 0.4444 0.3413\n",
      "   SR-HSE 0.1182 0.4211 0.3028\n",
      "\n",
      "Top 5 Î”F1 regressions:\n",
      "       label  f1_v2  f1_v3    Î”f1\n",
      "      SR-ARE 0.4323 0.5034 0.0711\n",
      "NR-Aromatase 0.1439 0.2857 0.1418\n",
      "      SR-p53 0.1728 0.3191 0.1463\n",
      "      NR-AhR 0.3158 0.4956 0.1798\n",
      "      SR-MMP 0.4645 0.6509 0.1864\n"
     ]
    }
   ],
   "source": [
    "# === Cell 7 â€” Compare v3 vs v2 on the same TEST split (console print) ===\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "ROOT     = Path(\"implementation\")\n",
    "DATA_CSV = ROOT / \"data\" / \"tox21.csv\"\n",
    "\n",
    "V2_DIR   = ROOT / \"models\" / \"chemberta_v2\"\n",
    "V2_BEST  = V2_DIR / \"v2_best\"\n",
    "V2_META  = V2_DIR / \"metadata\"\n",
    "\n",
    "V3_DIR   = ROOT / \"models\" / \"chemberta_v3\"\n",
    "V3_BEST  = V3_DIR / \"v3_best\"\n",
    "V3_META  = V3_DIR / \"metadata\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH  = 64\n",
    "MAXLEN = 256\n",
    "\n",
    "# --- data/splits\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "label_cols = [c for c in df.columns if c not in (\"mol_id\",\"smiles\")]\n",
    "spl = json.load(open(V3_META / \"splits.json\"))  # use v3's test split for fairness\n",
    "idx_test = np.array(spl[\"test_idx\"], dtype=int)\n",
    "X = df[\"smiles\"].astype(str).tolist()\n",
    "Xt = [X[i] for i in idx_test]\n",
    "Yt = df.iloc[idx_test][label_cols].to_numpy(dtype=float)\n",
    "\n",
    "def _load(model_dir):\n",
    "    tok = AutoTokenizer.from_pretrained(str(model_dir))\n",
    "    cfg = AutoConfig.from_pretrained(str(model_dir))\n",
    "    mdl = AutoModelForSequenceClassification.from_pretrained(str(model_dir), config=cfg).to(DEVICE).eval()\n",
    "    if hasattr(mdl.config, \"use_cache\"): mdl.config.use_cache = False\n",
    "    return tok, mdl\n",
    "\n",
    "def _predict(tok, mdl, smiles_list):\n",
    "    outs=[]\n",
    "    for i in range(0, len(smiles_list), BATCH):\n",
    "        enc = tok(smiles_list[i:i+BATCH], truncation=True, padding=True, max_length=MAXLEN, return_tensors=\"pt\").to(DEVICE)\n",
    "        with torch.inference_mode():\n",
    "            logits = mdl(**enc).logits\n",
    "            if logits.ndim == 3: logits = logits.mean(dim=1)\n",
    "            probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "        outs.append(probs)\n",
    "    return np.vstack(outs)\n",
    "\n",
    "def _load_thresholds(meta_dir):\n",
    "    # prefer thresholds_v3.json then thresholds.json, else default 0.5\n",
    "    for name in (\"thresholds_v3.json\", \"thresholds.json\"):\n",
    "        p = Path(meta_dir) / name\n",
    "        if p.exists():\n",
    "            return json.load(open(p))\n",
    "    return {lbl: 0.5 for lbl in label_cols}\n",
    "\n",
    "# load models + thresholds\n",
    "tok2, mdl2 = _load(V2_BEST)\n",
    "tok3, mdl3 = _load(V3_BEST)\n",
    "thr2 = _load_thresholds(V2_META)\n",
    "thr3 = _load_thresholds(V3_META)\n",
    "\n",
    "# predict\n",
    "P2 = _predict(tok2, mdl2, Xt)\n",
    "P3 = _predict(tok3, mdl3, Xt)\n",
    "\n",
    "def _per_label(y, p, thr_map):\n",
    "    rows=[]\n",
    "    for j, lbl in enumerate(label_cols):\n",
    "        m = ~np.isnan(y[:, j])\n",
    "        yt = y[m, j].astype(int)\n",
    "        pt = p[m, j]\n",
    "        if yt.size == 0 or np.unique(yt).size < 2:\n",
    "            rows.append([lbl, yt.size, np.nan, np.nan, np.nan, np.nan, np.nan, float(thr_map.get(lbl, 0.5))])\n",
    "            continue\n",
    "        yb = (pt >= float(thr_map.get(lbl, 0.5))).astype(int)\n",
    "        acc = (yb == yt).mean()\n",
    "        prec = precision_score(yt, yb, zero_division=0)\n",
    "        rec  = recall_score(yt, yb, zero_division=0)\n",
    "        f1   = f1_score(yt, yb, zero_division=0)\n",
    "        # optional AUROC/AP for reference\n",
    "        try: auroc = roc_auc_score(yt, pt)\n",
    "        except: auroc = np.nan\n",
    "        try: ap = average_precision_score(yt, pt)\n",
    "        except: ap = np.nan\n",
    "        rows.append([lbl, yt.size, acc, prec, rec, f1, auroc, ap, float(thr_map.get(lbl, 0.5))])\n",
    "    return pd.DataFrame(rows, columns=[\"label\",\"n\",\"acc\",\"prec\",\"rec\",\"f1\",\"auroc\",\"ap\",\"thr\"])\n",
    "\n",
    "def _overall_micro_macro(df_metrics):\n",
    "    # micro/macro F1 over labels (ignore NaNs)\n",
    "    f1_macro = np.nanmean(df_metrics[\"f1\"].values)\n",
    "    # micro: aggregate all decisions\n",
    "    return f1_macro\n",
    "\n",
    "m2 = _per_label(Yt, P2, thr2)\n",
    "m3 = _per_label(Yt, P3, thr3)\n",
    "\n",
    "# join & deltas\n",
    "j = m2.merge(m3, on=[\"label\",\"n\"], suffixes=(\"_v2\",\"_v3\"))\n",
    "j[\"Î”acc\"] = j[\"acc_v3\"] - j[\"acc_v2\"]\n",
    "j[\"Î”f1\"]  = j[\"f1_v3\"]  - j[\"f1_v2\"]\n",
    "j = j.sort_values(\"Î”f1\", ascending=False)\n",
    "\n",
    "print(\"=== v3 vs v2 â€” per-label on v3 TEST split ===\")\n",
    "cols = [\"label\",\"n\",\"acc_v2\",\"acc_v3\",\"Î”acc\",\"f1_v2\",\"f1_v3\",\"Î”f1\",\"thr_v2\",\"thr_v3\"]\n",
    "print(j[cols].to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "# overall micro/macro F1\n",
    "def _micro_f1(Y, P, thr_map):\n",
    "    y_true=[]; y_pred=[]\n",
    "    for j, lbl in enumerate(label_cols):\n",
    "        m = ~np.isnan(Y[:, j])\n",
    "        if m.sum()==0: continue\n",
    "        yt = Y[m, j].astype(int)\n",
    "        yb = (P[m, j] >= float(thr_map.get(lbl, 0.5))).astype(int)\n",
    "        y_true.append(yt); y_pred.append(yb)\n",
    "    yt = np.concatenate(y_true); yp = np.concatenate(y_pred)\n",
    "    return f1_score(yt, yp, zero_division=0)\n",
    "\n",
    "f1_macro_v2 = np.nanmean(m2[\"f1\"].values)\n",
    "f1_macro_v3 = np.nanmean(m3[\"f1\"].values)\n",
    "f1_micro_v2 = _micro_f1(Yt, P2, thr2)\n",
    "f1_micro_v3 = _micro_f1(Yt, P3, thr3)\n",
    "\n",
    "print(\"\\n=== Overall F1 (TEST) ===\")\n",
    "print(f\"Macro F1  v2: {f1_macro_v2:.4f} | v3: {f1_macro_v3:.4f} | Î” {f1_macro_v3 - f1_macro_v2:+.4f}\")\n",
    "print(f\"Micro F1  v2: {f1_micro_v2:.4f} | v3: {f1_micro_v3:.4f} | Î” {f1_micro_v3 - f1_micro_v2:+.4f}\")\n",
    "\n",
    "# top improvements / regressions\n",
    "print(\"\\nTop 5 Î”F1 improvements:\")\n",
    "print(j.nlargest(5, \"Î”f1\")[[\"label\",\"f1_v2\",\"f1_v3\",\"Î”f1\"]].to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "print(\"\\nTop 5 Î”F1 regressions:\")\n",
    "print(j.nsmallest(5, \"Î”f1\")[[\"label\",\"f1_v2\",\"f1_v3\",\"Î”f1\"]].to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d631c80",
   "metadata": {},
   "source": [
    "## 8: Calibration + Thresholds (VAL) and save artifacts, with TEST sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "982f4566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEST calibration sanity ===\n",
      "Brier (raw)        : 0.4629\n",
      "Brier (calibrated) : 0.0838  (Î” -0.3791 â†’ lower is better)\n",
      "Micro-F1 (raw thr) : 0.3646\n",
      "Micro-F1 (cal thr) : 0.3097  (Î” -0.0550)\n",
      "\n",
      "Saved:\n",
      " - temperature.npy\n",
      " - calibration_methods.json\n",
      " - platt_params.json\n",
      " - isotonic_params.json\n",
      " - thresholds_v3.json\n"
     ]
    }
   ],
   "source": [
    "import json, numpy as np, pandas as pd, torch\n",
    "from pathlib import Path\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import (\n",
    "    brier_score_loss, f1_score, precision_score, recall_score,\n",
    "    roc_auc_score, average_precision_score\n",
    ")\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "# ----- Paths / constants\n",
    "ROOT     = Path(\"implementation\")\n",
    "DATA_CSV = ROOT / \"data\" / \"tox21.csv\"\n",
    "V3_DIR   = ROOT / \"models\" / \"chemberta_v3\"\n",
    "V3_META  = V3_DIR / \"metadata\"\n",
    "V3_BEST  = V3_DIR / \"v3_best\"\n",
    "V3_META.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH, MAXLEN = 64, 256\n",
    "\n",
    "THR_STRATEGY   = \"f1_rfloor\"  # \"mcc\" | \"f1\" | \"f1_rfloor\"\n",
    "RECALL_FLOOR   = 0.60\n",
    "THR_GRID       = np.linspace(0.02, 0.98, 97)\n",
    "MIN_POS_FOR_CAL= 20           # need at least this many positives for Platt/Iso\n",
    "N_EPOCHS_TEMP  = 250          # temperature fit steps\n",
    "\n",
    "# ----- Data & splits\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "label_cols = [c for c in df.columns if c not in (\"mol_id\",\"smiles\")]\n",
    "\n",
    "spl = json.load(open(V3_META / \"splits.json\"))\n",
    "idx_val  = np.array(spl[\"val_idx\"], dtype=int)\n",
    "idx_test = np.array(spl[\"test_idx\"], dtype=int)\n",
    "\n",
    "X  = df[\"smiles\"].astype(str).tolist()\n",
    "Yv = df.iloc[idx_val][label_cols].to_numpy(dtype=float)\n",
    "Yt = df.iloc[idx_test][label_cols].to_numpy(dtype=float)\n",
    "Xv = [X[i] for i in idx_val]\n",
    "Xt = [X[i] for i in idx_test]\n",
    "\n",
    "# ----- Load model\n",
    "tok = AutoTokenizer.from_pretrained(str(V3_BEST))\n",
    "cfg = AutoConfig.from_pretrained(str(V3_BEST))\n",
    "mdl = AutoModelForSequenceClassification.from_pretrained(str(V3_BEST), config=cfg).to(DEVICE).eval()\n",
    "if hasattr(mdl.config, \"use_cache\"): mdl.config.use_cache = False\n",
    "\n",
    "def _to_2d(x):\n",
    "    return x if x.ndim==2 else (x[:,0,:] if x.ndim==3 and x.size(1)>0 else x.mean(1))\n",
    "\n",
    "def _predict_logits(smiles_list):\n",
    "    outs = []\n",
    "    for i in range(0, len(smiles_list), BATCH):\n",
    "        enc = tok(smiles_list[i:i+BATCH], truncation=True, padding=True,\n",
    "                  max_length=MAXLEN, return_tensors=\"pt\").to(DEVICE)\n",
    "        with torch.inference_mode():\n",
    "            logits = _to_2d(mdl(**enc).logits).detach().cpu().numpy()\n",
    "        outs.append(logits)\n",
    "    return np.vstack(outs)\n",
    "\n",
    "Lv = _predict_logits(Xv)   # [Nv, L]\n",
    "Lt = _predict_logits(Xt)   # [Nt, L]\n",
    "\n",
    "# ----- Global temperature (minimise BCE on VAL)\n",
    "def fit_temperature(logits, y):\n",
    "    # flatten across labels with valid targets\n",
    "    mask = ~np.isnan(y)\n",
    "    z = torch.tensor(logits[mask], dtype=torch.float32, device=DEVICE)\n",
    "    t = torch.tensor(y[mask],      dtype=torch.float32, device=DEVICE)\n",
    "    logT = torch.nn.Parameter(torch.zeros([], device=DEVICE))  # T = exp(logT)\n",
    "    opt  = torch.optim.LBFGS([logT], lr=0.5, max_iter=100)\n",
    "\n",
    "    bce = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def closure():\n",
    "        opt.zero_grad()\n",
    "        T = torch.exp(logT).clamp(1e-3, 100.0)\n",
    "        loss = bce(z / T, t)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    for _ in range(N_EPOCHS_TEMP // 25):\n",
    "        opt.step(closure)\n",
    "    T = float(torch.exp(logT).detach().cpu().item())\n",
    "    return T\n",
    "\n",
    "T = fit_temperature(Lv, Yv)\n",
    "np.save(V3_META / \"temperature.npy\", np.array([T], dtype=np.float32))\n",
    "\n",
    "# ----- Per-label calibrators (choose temp / platt / isotonic by Brier on VAL)\n",
    "def sigmoid(x): return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def fit_platt(logits, y):\n",
    "    # torch fit A,B: minimise BCEWithLogits(A*z + B, y)\n",
    "    z = torch.tensor(logits, dtype=torch.float32, device=DEVICE)\n",
    "    t = torch.tensor(y,      dtype=torch.float32, device=DEVICE)\n",
    "    A = torch.nn.Parameter(torch.tensor(1.0, device=DEVICE))\n",
    "    B = torch.nn.Parameter(torch.tensor(0.0, device=DEVICE))\n",
    "    opt = torch.optim.LBFGS([A,B], lr=0.5, max_iter=100)\n",
    "    bce = torch.nn.BCEWithLogitsLoss()\n",
    "    def closure():\n",
    "        opt.zero_grad()\n",
    "        loss = bce(A*z + B, t)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    for _ in range(6):\n",
    "        opt.step(closure)\n",
    "    return float(A.detach().cpu()), float(B.detach().cpu())\n",
    "\n",
    "calib_methods = {}\n",
    "platt_params  = {}\n",
    "iso_params    = {}\n",
    "\n",
    "# baseline temp probabilities on VAL\n",
    "Pv_temp = sigmoid(Lv / T)\n",
    "\n",
    "def _brier(y, p):\n",
    "    m = ~np.isnan(y)\n",
    "    if m.sum()==0: return np.nan\n",
    "    yv, pv = y[m], p[m]\n",
    "    return brier_score_loss(yv, np.clip(pv, 1e-6, 1-1e-6))\n",
    "\n",
    "for j, lbl in enumerate(label_cols):\n",
    "    yv = Yv[:, j]\n",
    "    zv = Lv[:, j]\n",
    "    m  = ~np.isnan(yv)\n",
    "    yj, zj, pj_temp = yv[m].astype(int), zv[m], Pv_temp[m, j]\n",
    "\n",
    "    # default to temp if not enough signal\n",
    "    method, b_best = \"temp\", _brier(yj, pj_temp)\n",
    "    best_p = pj_temp\n",
    "\n",
    "    # try Platt if enough positives & both classes present\n",
    "    if (yj.sum() >= MIN_POS_FOR_CAL) and (len(np.unique(yj)) == 2):\n",
    "        A, B = fit_platt(zj, yj)\n",
    "        pj_platt = sigmoid(A * zj + B)\n",
    "        b_platt  = _brier(yj, pj_platt)\n",
    "        if b_platt + 1e-6 < b_best:\n",
    "            method, b_best, best_p = \"platt\", b_platt, pj_platt\n",
    "            platt_params[lbl] = {\"A\": float(A), \"B\": float(B)}\n",
    "\n",
    "    # try Isotonic on temp probs\n",
    "    if (yj.sum() >= MIN_POS_FOR_CAL) and (len(np.unique(yj)) == 2):\n",
    "        iso = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "        try:\n",
    "            iso.fit(pj_temp, yj)\n",
    "            # store a vectorized mapping by interpolation points\n",
    "            X_m = np.linspace(0.0, 1.0, 101)\n",
    "            Y_m = iso.predict(X_m)\n",
    "            pj_iso = iso.predict(pj_temp)\n",
    "            b_iso  = _brier(yj, pj_iso)\n",
    "            if b_iso + 1e-6 < b_best:\n",
    "                method, b_best, best_p = \"iso\", b_iso, pj_iso\n",
    "                iso_params[lbl] = {\"X\": X_m.tolist(), \"Y\": Y_m.tolist()}\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    calib_methods[lbl] = {\"method\": method}\n",
    "\n",
    "# Save calibration artifacts\n",
    "json.dump(calib_methods, open(V3_META / \"calibration_methods.json\", \"w\"), indent=2)\n",
    "json.dump(platt_params,  open(V3_META / \"platt_params.json\", \"w\"), indent=2)\n",
    "json.dump(iso_params,    open(V3_META / \"isotonic_params.json\", \"w\"), indent=2)\n",
    "\n",
    "# ----- Helper to apply calibration to a logits matrix\n",
    "def apply_calibration(L):\n",
    "    P_temp = sigmoid(L / max(T, 1e-6))\n",
    "    P_out  = np.zeros_like(P_temp)\n",
    "    for j, lbl in enumerate(label_cols):\n",
    "        meth = calib_methods.get(lbl, {}).get(\"method\", \"temp\")\n",
    "        if meth == \"platt\" and lbl in platt_params:\n",
    "            A = platt_params[lbl][\"A\"]; B = platt_params[lbl][\"B\"]\n",
    "            P_out[:, j] = sigmoid(L[:, j] * A + B)\n",
    "        elif meth == \"iso\" and lbl in iso_params:\n",
    "            X = np.asarray(iso_params[lbl][\"X\"]); Y = np.asarray(iso_params[lbl][\"Y\"])\n",
    "            P_out[:, j] = np.interp(P_temp[:, j], X, Y)\n",
    "        else:\n",
    "            P_out[:, j] = P_temp[:, j]\n",
    "    return P_out\n",
    "\n",
    "# ----- Threshold selection on VAL\n",
    "def choose_thresholds(Y, L, strategy=THR_STRATEGY, recall_floor=RECALL_FLOOR):\n",
    "    P_cal = apply_calibration(L)\n",
    "    P_raw = sigmoid(L)  # for a baseline comparison (uncalibrated)\n",
    "\n",
    "    thr_cal, thr_raw = {}, {}\n",
    "    def _pick(yt, p, strat):\n",
    "        best, thr = -1e9, 0.5\n",
    "        for t in THR_GRID:\n",
    "            yb = (p >= t).astype(int)\n",
    "            prec = precision_score(yt, yb, zero_division=0)\n",
    "            rec  = recall_score(yt, yb, zero_division=0)\n",
    "            if strat == \"mcc\":\n",
    "                # use sklearn for stability\n",
    "                from sklearn.metrics import matthews_corrcoef\n",
    "                s = matthews_corrcoef(yt, yb)\n",
    "            elif strat == \"f1\":\n",
    "                s = f1_score(yt, yb, zero_division=0)\n",
    "            else:\n",
    "                if rec < recall_floor: \n",
    "                    continue\n",
    "                s = f1_score(yt, yb, zero_division=0)\n",
    "            if s > best: best, thr = s, float(t)\n",
    "        return thr\n",
    "\n",
    "    for j, lbl in enumerate(label_cols):\n",
    "        m = ~np.isnan(Y[:, j])\n",
    "        if m.sum() == 0 or len(np.unique(Y[m, j])) < 2:\n",
    "            thr_cal[lbl] = 0.5; thr_raw[lbl] = 0.5\n",
    "            continue\n",
    "        yj = Y[m, j].astype(int)\n",
    "        thr_cal[lbl] = _pick(yj, P_cal[m, j], strategy)\n",
    "        thr_raw[lbl] = _pick(yj, P_raw[m, j], strategy)\n",
    "    return thr_cal, thr_raw\n",
    "\n",
    "thr_cal, thr_raw = choose_thresholds(Yv, Lv, strategy=THR_STRATEGY, recall_floor=RECALL_FLOOR)\n",
    "\n",
    "# Save chosen thresholds\n",
    "json.dump(thr_cal, open(V3_META / \"thresholds_v3.json\", \"w\"), indent=2)\n",
    "\n",
    "# ----- TEST sanity: Brier + micro-F1 (raw vs calibrated)\n",
    "def _brier_all(Y, P):\n",
    "    mask = ~np.isnan(Y)\n",
    "    return brier_score_loss(Y[mask], np.clip(P[mask], 1e-6, 1-1e-6))\n",
    "\n",
    "def _micro_f1(Y, P, thr_map):\n",
    "    y_true=[]; y_pred=[]\n",
    "    for j, lbl in enumerate(label_cols):\n",
    "        m = ~np.isnan(Y[:, j])\n",
    "        if m.sum()==0: continue\n",
    "        yt = Y[m, j].astype(int)\n",
    "        yb = (P[m, j] >= float(thr_map.get(lbl, 0.5))).astype(int)\n",
    "        y_true.append(yt); y_pred.append(yb)\n",
    "    yt = np.concatenate(y_true); yp = np.concatenate(y_pred)\n",
    "    return f1_score(yt, yp, zero_division=0)\n",
    "\n",
    "Pt_raw = sigmoid(Lt)\n",
    "Pt_cal = apply_calibration(Lt)\n",
    "\n",
    "brier_raw = _brier_all(Yt, Pt_raw)\n",
    "brier_cal = _brier_all(Yt, Pt_cal)\n",
    "micro_raw = _micro_f1(Yt, Pt_raw, thr_raw)\n",
    "micro_cal = _micro_f1(Yt, Pt_cal, thr_cal)\n",
    "\n",
    "print(\"=== TEST calibration sanity ===\")\n",
    "print(f\"Brier (raw)        : {brier_raw:.4f}\")\n",
    "print(f\"Brier (calibrated) : {brier_cal:.4f}  (Î” {brier_cal - brier_raw:+.4f} â†’ lower is better)\")\n",
    "print(f\"Micro-F1 (raw thr) : {micro_raw:.4f}\")\n",
    "print(f\"Micro-F1 (cal thr) : {micro_cal:.4f}  (Î” {micro_cal - micro_raw:+.4f})\")\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" - temperature.npy\")\n",
    "print(\" - calibration_methods.json\")\n",
    "print(\" - platt_params.json\")\n",
    "print(\" - isotonic_params.json\")\n",
    "print(\" - thresholds_v3.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc47da",
   "metadata": {},
   "source": [
    "## 9: new embeddings for v3 integration "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29e9256",
   "metadata": {},
   "source": [
    "### 9a) new embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a962b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1c75a7cf62474d828c724e9ddfee32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding (v3):   0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example embedding file: TOX1002.npy | shape=(768,)\n",
      "Embeddings saved: 7831 | skipped existing: 0\n",
      "Output dir â†’ implementation\\v3\\embeddings\n"
     ]
    }
   ],
   "source": [
    "import os, json, numpy as np, pandas as pd, torch\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "ROOT      = Path(\"implementation\")\n",
    "DATA_CSV  = ROOT / \"data\" / \"tox21.csv\"\n",
    "V3_DIR    = ROOT / \"models\" / \"chemberta_v3\"\n",
    "V3_BEST   = V3_DIR / \"v3_best\"\n",
    "OUT_ROOT  = ROOT / \"v3\"\n",
    "EMB_DIR   = OUT_ROOT / \"embeddings\"\n",
    "META_DIR  = OUT_ROOT / \"metadata\"\n",
    "\n",
    "EMB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "META_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DEVICE   = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH    = 64\n",
    "MAXLEN   = 256\n",
    "USE_AMP  = torch.cuda.is_available()\n",
    "\n",
    "# ---- load data\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "mol_ids = df[\"mol_id\"].astype(str).tolist()\n",
    "smiles  = df[\"smiles\"].astype(str).tolist()\n",
    "\n",
    "# ---- load v3_best with hidden states\n",
    "tok = AutoTokenizer.from_pretrained(str(V3_BEST))\n",
    "cfg = AutoConfig.from_pretrained(str(V3_BEST))\n",
    "cfg.output_hidden_states = True  # ensure we get token-level states\n",
    "mdl = AutoModelForSequenceClassification.from_pretrained(str(V3_BEST), config=cfg).to(DEVICE).eval()\n",
    "if hasattr(mdl.config, \"use_cache\"): mdl.config.use_cache = False\n",
    "\n",
    "@torch.no_grad()\n",
    "def _batch_embed(smiles_batch):\n",
    "    enc = tok(smiles_batch, truncation=True, padding=True, max_length=MAXLEN, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.amp.autocast('cuda', dtype=torch.float16, enabled=USE_AMP):\n",
    "        out = mdl(**enc)\n",
    "        # last hidden layer: [B, T, H]\n",
    "        last = out.hidden_states[-1]\n",
    "        mask = enc[\"attention_mask\"].unsqueeze(-1)  # [B, T, 1]\n",
    "        summed = (last * mask).sum(dim=1)           # [B, H]\n",
    "        lengths = mask.sum(dim=1).clamp(min=1)      # [B, 1]\n",
    "        mean_pooled = (summed / lengths).float()    # [B, H] -> use mean pooling over non-pad\n",
    "    return mean_pooled.cpu().numpy()\n",
    "\n",
    "# ---- iterate & cache (skip existing)\n",
    "saved, skipped = 0, 0\n",
    "all_vecs, all_ids = [], []\n",
    "pbar = tqdm(range(0, len(smiles), BATCH), desc=\"Embedding (v3)\")\n",
    "for i in pbar:\n",
    "    j = min(i+BATCH, len(smiles))\n",
    "    batch_ids = mol_ids[i:j]\n",
    "    batch_sm  = smiles[i:j]\n",
    "\n",
    "    # figure which need computing\n",
    "    keep_mask = [not (EMB_DIR / f\"{mid}.npy\").exists() for mid in batch_ids]\n",
    "    if any(keep_mask):\n",
    "        # compute once for whole batch, then save per sample\n",
    "        vecs = _batch_embed(batch_sm)\n",
    "        for k, mid in enumerate(batch_ids):\n",
    "            fn = EMB_DIR / f\"{mid}.npy\"\n",
    "            if fn.exists():\n",
    "                skipped += 1\n",
    "            else:\n",
    "                np.save(fn, vecs[k])\n",
    "                saved += 1\n",
    "                all_vecs.append(vecs[k])\n",
    "                all_ids.append(mid)\n",
    "    else:\n",
    "        skipped += len(batch_ids)\n",
    "\n",
    "    pbar.set_postfix(saved=saved, skipped=skipped)\n",
    "\n",
    "# ---- also save a compact bulk matrix for fast downstream use (optional)\n",
    "# (Only for vectors we just computed in this run; older cached ones are already on disk per-sample.)\n",
    "if all_vecs:\n",
    "    M = np.vstack(all_vecs).astype(np.float32)\n",
    "    np.save(META_DIR / \"embeddings_newrun.npy\", M)\n",
    "    json.dump(all_ids, open(META_DIR / \"embeddings_newrun_ids.json\", \"w\"))\n",
    "\n",
    "# write a small manifest for reference\n",
    "manifest = {\n",
    "    \"model_dir\": str(V3_BEST),\n",
    "    \"embedding_dim\": int(np.load(next((EMB_DIR.iterdir()))).shape[0]) if any(EMB_DIR.iterdir()) else 768,\n",
    "    \"count_files\": len(list(EMB_DIR.glob(\"*.npy\"))),\n",
    "}\n",
    "json.dump(manifest, open(META_DIR / \"embeddings_manifest.json\", \"w\"), indent=2)\n",
    "\n",
    "# sanity check on one example\n",
    "some = next(iter(EMB_DIR.glob(\"*.npy\")), None)\n",
    "if some is not None:\n",
    "    vec = np.load(some)\n",
    "    print(f\"\\nExample embedding file: {some.name} | shape={tuple(vec.shape)}\")\n",
    "print(f\"Embeddings saved: {saved} | skipped existing: {skipped}\\nOutput dir â†’ {EMB_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61ad4b8",
   "metadata": {},
   "source": [
    "### 9b) sorting the missing coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebe85395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings present: 7831 / 7831 | missing: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0760e79bd14c4320967e5a82dbb0b6e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backfilling v3 embeddings: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backfilled: 0 | Now total files: 7831\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, torch\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "ROOT      = Path(\"implementation\")\n",
    "DATA_CSV  = ROOT / \"data\" / \"tox21.csv\"\n",
    "V3_DIR    = ROOT / \"models\" / \"chemberta_v3\"\n",
    "V3_BEST   = V3_DIR / \"v3_best\"\n",
    "OUT_ROOT  = ROOT / \"v3\"\n",
    "EMB_DIR   = OUT_ROOT / \"embeddings\"\n",
    "EMB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH, MAXLEN = 64, 256\n",
    "USE_AMP = torch.cuda.is_available()\n",
    "\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "mol_ids = df[\"mol_id\"].astype(str).str.strip().tolist()\n",
    "smiles  = df[\"smiles\"].astype(str).tolist()\n",
    "id2smiles = dict(zip(mol_ids, smiles))\n",
    "\n",
    "# Existing\n",
    "existing = {p.stem for p in EMB_DIR.glob(\"*.npy\")}\n",
    "missing  = [mid for mid in mol_ids if mid not in existing]\n",
    "print(f\"Embeddings present: {len(existing)} / {len(mol_ids)} | missing: {len(missing)}\")\n",
    "\n",
    "# Load v3_best with hidden states\n",
    "tok = AutoTokenizer.from_pretrained(str(V3_BEST))\n",
    "cfg = AutoConfig.from_pretrained(str(V3_BEST)); cfg.output_hidden_states = True\n",
    "mdl = AutoModelForSequenceClassification.from_pretrained(str(V3_BEST), config=cfg).to(DEVICE).eval()\n",
    "if hasattr(mdl.config, \"use_cache\"): mdl.config.use_cache = False\n",
    "\n",
    "@torch.no_grad()\n",
    "def _batch_embed(smi_list):\n",
    "    enc = tok(smi_list, truncation=True, padding=True, max_length=MAXLEN, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.amp.autocast('cuda', dtype=torch.float16, enabled=USE_AMP):\n",
    "        out = mdl(**enc)\n",
    "        last = out.hidden_states[-1]  # [B, T, H]\n",
    "        mask = enc[\"attention_mask\"].unsqueeze(-1)\n",
    "        pooled = (last * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1)\n",
    "        return pooled.float().cpu().numpy()\n",
    "\n",
    "saved = 0\n",
    "for i in tqdm(range(0, len(missing), BATCH), desc=\"Backfilling v3 embeddings\"):\n",
    "    mids = missing[i:i+BATCH]\n",
    "    smi  = [id2smiles[m] for m in mids]\n",
    "    vecs = _batch_embed(smi)\n",
    "    for k, mid in enumerate(mids):\n",
    "        np.save(EMB_DIR / f\"{mid}.npy\", vecs[k])\n",
    "        saved += 1\n",
    "\n",
    "print(f\"Backfilled: {saved} | Now total files: {len(list(EMB_DIR.glob('*.npy')))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8686fd",
   "metadata": {},
   "source": [
    "## 10 building our embeddings and cohorts  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366ad7ba",
   "metadata": {},
   "source": [
    "### 10a) Rebuild v3 cohorts from SMARTS using concept list v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c60aefc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:03:55] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cohorts to: implementation\\concept_cohorts_v3\n",
      "        concept                smarts  n_pos  n_neg_pool  kept note\n",
      "   AromaticRing              a1aaaaa1   4800        3031  True     \n",
      "          Nitro          [N+](=O)[O-]    343        7488  True     \n",
      "     ArylHalide      [$([Cl,Br,I])]-c    998        6833  True     \n",
      "         Phenol           c1ccc(cc1)O   1695        6136  True     \n",
      "  TertiaryAmine [NX3]([#6])([#6])[#6]   1495        6336  True     \n",
      "MichaelAcceptor                C=CC=O    622        7209  True     \n",
      "       Pyridine              n1ccccc1    473        7358  True     \n",
      " CarboxylicAcid      [CX3](=O)[OX2H1]    811        7020  True     \n",
      "          Ester  [CX3](=O)[OX2H0][#6]   1482        6349  True     \n",
      "    Sulfonamide            S(=O)(=O)N    261        7570  True     \n",
      "        Aniline             Nc1ccccc1   1366        6465  True     \n"
     ]
    }
   ],
   "source": [
    "# === Cell 10a â€” Build concept_cohorts_v3 from SMARTS (using concept_list_v2.yaml) ===\n",
    "import yaml, random\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT       = Path(\"implementation\")\n",
    "DATA_CSV   = ROOT / \"data\" / \"tox21.csv\"\n",
    "CONC_YAML  = ROOT / \"concepts\" / \"concept_list_v2.yaml\"  # reuse your v2 list\n",
    "OUT_DIR    = ROOT / \"concept_cohorts_v3\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "mol_ids = df[\"mol_id\"].astype(str).str.strip().tolist()\n",
    "smiles  = df[\"smiles\"].astype(str).tolist()\n",
    "id2sm   = dict(zip(mol_ids, smiles))\n",
    "\n",
    "spec = yaml.safe_load(open(CONC_YAML, \"r\"))\n",
    "concepts = spec[\"concepts\"] if isinstance(spec, dict) and \"concepts\" in spec else spec\n",
    "\n",
    "def safe_mol(s):\n",
    "    try:\n",
    "        return Chem.MolFromSmiles(s)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "mols = {mid: safe_mol(id2sm[mid]) for mid in mol_ids}\n",
    "\n",
    "rows = []\n",
    "RAND_SEEDS = [0,1,2,3,4]       # 5 cohorts\n",
    "MIN_POS    = 30                # drop concepts with too few positives\n",
    "rand_state = random.Random(42)\n",
    "\n",
    "for c in concepts:\n",
    "    cname  = c[\"name\"]\n",
    "    smarts = c[\"smarts\"]\n",
    "    patt   = Chem.MolFromSmarts(smarts)\n",
    "    if patt is None:\n",
    "        rows.append([cname, smarts, 0, 0, False, \"BAD_SMARTS\"]); continue\n",
    "\n",
    "    pos_ids = [mid for mid in mol_ids if (mols[mid] is not None and mols[mid].HasSubstructMatch(patt))]\n",
    "    neg_pool= [mid for mid in mol_ids if mid not in set(pos_ids)]\n",
    "\n",
    "    kept = len(pos_ids) >= MIN_POS\n",
    "    note = \"\" if kept else f\"SKIP_TOO_FEW_POS({len(pos_ids)})\"\n",
    "    rows.append([cname, smarts, len(pos_ids), len(neg_pool), kept, note])\n",
    "\n",
    "    if not kept:\n",
    "        continue\n",
    "\n",
    "    # write positives\n",
    "    (OUT_DIR / f\"{cname}_pos.txt\").write_text(\"\\n\".join(pos_ids), encoding=\"utf-8\")\n",
    "\n",
    "    # write multiple random cohorts (size = len(pos))\n",
    "    for r in RAND_SEEDS:\n",
    "        rand_state.seed(r)\n",
    "        rand_ids = rand_state.sample(neg_pool, k=min(len(neg_pool), len(pos_ids)))\n",
    "        (OUT_DIR / f\"{cname}_rand{r}.txt\").write_text(\"\\n\".join(rand_ids), encoding=\"utf-8\")\n",
    "\n",
    "diag = pd.DataFrame(rows, columns=[\"concept\",\"smarts\",\"n_pos\",\"n_neg_pool\",\"kept\",\"note\"])\n",
    "diag.to_csv(ROOT / \"v3\" / \"cav\" / \"cohort_build_v3_diag.csv\", index=False)\n",
    "print(\"Saved cohorts to:\", OUT_DIR)\n",
    "print(diag.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aa5a24",
   "metadata": {},
   "source": [
    "### 10b) Train CAVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0fea9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts with usable cohorts: 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ed448b8373471f9f494d9ecef69dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CAV training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CAV] Saved: implementation\\v3\\cav\\cav_summary.csv\n",
      "        concept  cav_acc_train_mean  cav_acc_val_mean  cav_runs\n",
      "          Nitro            1.000000          0.980435        10\n",
      "   AromaticRing            1.000000          0.968000        10\n",
      "    Sulfonamide            1.000000          0.940000        10\n",
      "     ArylHalide            0.999248          0.935000        10\n",
      " CarboxylicAcid            1.000000          0.926154        10\n",
      "MichaelAcceptor            1.000000          0.916466        10\n",
      "  TertiaryAmine            0.999687          0.912500        10\n",
      "          Ester            0.999250          0.903000        10\n",
      "        Aniline            0.999875          0.903000        10\n",
      "         Phenol            0.999625          0.893750        10\n"
     ]
    }
   ],
   "source": [
    "# === Cell 10b â€” Train CAVs using v3 embeddings + v3 cohorts ===\n",
    "import json, random, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ROOT         = Path(\"implementation\")\n",
    "EMB_DIR      = ROOT / \"v3\" / \"embeddings\"\n",
    "COHORT_DIR   = ROOT / \"concept_cohorts_v3\"\n",
    "CAV_DIR      = ROOT / \"v3\" / \"cav\"\n",
    "CAV_VEC_DIR  = CAV_DIR / \"vectors\"\n",
    "CAV_META_DIR = CAV_DIR / \"meta\"\n",
    "for p in [CAV_DIR, CAV_VEC_DIR, CAV_META_DIR]: p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _read_ids(p): return [ln.strip() for ln in open(p, \"r\", encoding=\"utf-8\") if ln.strip()]\n",
    "def _has(mid):    return (EMB_DIR / f\"{mid}.npy\").exists()\n",
    "def _vec(mid):    return np.load(EMB_DIR / f\"{mid}.npy\")\n",
    "\n",
    "# collect concepts\n",
    "concepts = []\n",
    "for pos_file in sorted(COHORT_DIR.glob(\"*_pos.txt\")):\n",
    "    cname = pos_file.stem.replace(\"_pos\",\"\")\n",
    "    pos = [m for m in _read_ids(pos_file) if _has(m)]\n",
    "    neg = []\n",
    "    for rf in sorted(COHORT_DIR.glob(f\"{cname}_rand*.txt\")):\n",
    "        neg.extend([m for m in _read_ids(rf) if _has(m)])\n",
    "    neg = [m for m in neg if m not in set(pos)]\n",
    "    if not neg: continue\n",
    "    concepts.append((cname, pos, neg))\n",
    "\n",
    "print(f\"Concepts with usable cohorts: {len(concepts)}\")\n",
    "\n",
    "CAV_RUNS = 10\n",
    "VAL_FRAC = 0.2\n",
    "MAX_POS_PER_RUN = 1000\n",
    "\n",
    "summ_rows = []\n",
    "random.seed(42); np.random.seed(42)\n",
    "\n",
    "for cname, pos_ids, neg_ids in tqdm(concepts, desc=\"CAV training\"):\n",
    "    if len(pos_ids) < 20 or len(neg_ids) < 20:\n",
    "        continue\n",
    "    W = []; runs=[]\n",
    "    for r in range(CAV_RUNS):\n",
    "        n_pos = min(len(pos_ids), MAX_POS_PER_RUN)\n",
    "        n_neg = n_pos\n",
    "        pos_s = random.sample(pos_ids, n_pos)\n",
    "        neg_s = random.sample(neg_ids, n_neg)\n",
    "        Xp = np.vstack([_vec(m) for m in pos_s]).astype(np.float32)\n",
    "        Xn = np.vstack([_vec(m) for m in neg_s]).astype(np.float32)\n",
    "        X  = np.vstack([Xp, Xn]); y = np.array([1]*n_pos + [0]*n_neg, np.int64)\n",
    "        Xtr, Xva, ytr, yva = train_test_split(X, y, test_size=VAL_FRAC, stratify=y, random_state=r)\n",
    "        sc = StandardScaler().fit(Xtr)\n",
    "        Xtr_s, Xva_s = sc.transform(Xtr), sc.transform(Xva)\n",
    "        clf = LogisticRegression(solver=\"liblinear\", penalty=\"l2\", C=1.0, max_iter=1000, random_state=r)\n",
    "        clf.fit(Xtr_s, ytr)\n",
    "        acc_tr = float(clf.score(Xtr_s, ytr)); acc_va = float(clf.score(Xva_s, yva))\n",
    "        w_std = clf.coef_.reshape(-1)\n",
    "        w = (w_std / (sc.scale_ + 1e-8)); w = w / (np.linalg.norm(w) + 1e-12)\n",
    "        W.append(w); runs.append({\"run\": r, \"acc_train\": acc_tr, \"acc_val\": acc_va, \"n\": int(n_pos+n_neg)})\n",
    "    w_mean = np.vstack(W).mean(axis=0); w_mean /= (np.linalg.norm(w_mean)+1e-12)\n",
    "    np.save(CAV_VEC_DIR / f\"{cname}_cav.npy\", w_mean.astype(np.float32))\n",
    "    json.dump(runs, open(CAV_META_DIR / f\"{cname}_cav_runs.json\",\"w\"), indent=2)\n",
    "    summ_rows.append({\"concept\": cname,\n",
    "                      \"cav_acc_train_mean\": float(np.mean([m[\"acc_train\"] for m in runs])),\n",
    "                      \"cav_acc_val_mean\":   float(np.mean([m[\"acc_val\"]   for m in runs])),\n",
    "                      \"cav_runs\": CAV_RUNS})\n",
    "\n",
    "if summ_rows:\n",
    "    cav_summary = pd.DataFrame(summ_rows).sort_values(\"cav_acc_val_mean\", ascending=False)\n",
    "    cav_summary.to_csv(CAV_DIR / \"cav_summary.csv\", index=False)\n",
    "    print(\"\\n[CAV] Saved:\", CAV_DIR / \"cav_summary.csv\")\n",
    "    print(cav_summary.head(10).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n[CAV] No concepts trained. Check cohort sizes and embeddings.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5056e2",
   "metadata": {},
   "source": [
    "### 10c) TCAV (v3) using the newly trained v3 CAVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8340a0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] TCAV with 11 concepts: ['Aniline', 'AromaticRing', 'ArylHalide', 'CarboxylicAcid', 'Ester', 'MichaelAcceptor', 'Nitro', 'Phenol'] ...\n",
      "[INFO] Using BATCH=128 | AMP=on\n",
      "\n",
      "[TCAV] Label: NR-AR\n",
      "  run 1/12: 600 mols in 29.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 2/12: 600 mols in 29.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 3/12: 600 mols in 27.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 4/12: 600 mols in 27.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 5/12: 600 mols in 28.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 6/12: 600 mols in 163.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 7/12: 600 mols in 29.2s\n",
      "  early-stop: CI width 0.028 < 0.03\n",
      "\n",
      "[TCAV] Label: NR-AR-LBD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 1/12: 600 mols in 27.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 2/12: 600 mols in 30.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 3/12: 600 mols in 31.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 4/12: 600 mols in 27.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 5/12: 600 mols in 26.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 6/12: 600 mols in 25.3s\n",
      "  early-stop: CI width 0.029 < 0.03\n",
      "\n",
      "[TCAV] Label: NR-AhR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 1/12: 600 mols in 29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 2/12: 600 mols in 26.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 3/12: 600 mols in 26.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 4/12: 600 mols in 26.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 5/12: 600 mols in 1424.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 6/12: 600 mols in 3821.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 7/12: 600 mols in 48.1s\n",
      "  early-stop: CI width 0.030 < 0.03\n",
      "\n",
      "[TCAV] Label: NR-Aromatase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 1/12: 600 mols in 40.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 2/12: 600 mols in 984.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 3/12: 600 mols in 173.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 4/12: 600 mols in 30.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 5/12: 600 mols in 27.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 6/12: 600 mols in 28.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 7/12: 600 mols in 30.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 8/12: 600 mols in 28.5s\n",
      "  early-stop: CI width 0.028 < 0.03\n",
      "\n",
      "[TCAV] Label: NR-ER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 1/12: 600 mols in 27.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 2/12: 600 mols in 28.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 3/12: 600 mols in 28.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 4/12: 600 mols in 28.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 5/12: 600 mols in 28.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 6/12: 600 mols in 28.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 7/12: 600 mols in 30.2s\n",
      "  early-stop: CI width 0.030 < 0.03\n",
      "\n",
      "[TCAV] Label: NR-ER-LBD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 1/12: 600 mols in 29.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 2/12: 600 mols in 27.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 3/12: 600 mols in 27.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 4/12: 600 mols in 27.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 5/12: 600 mols in 28.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 6/12: 600 mols in 29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 7/12: 600 mols in 29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 8/12: 600 mols in 28.8s\n",
      "  early-stop: CI width 0.028 < 0.03\n",
      "\n",
      "[TCAV] Label: NR-PPAR-gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 1/12: 600 mols in 27.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 2/12: 600 mols in 28.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 3/12: 600 mols in 27.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 4/12: 600 mols in 27.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 5/12: 600 mols in 27.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 6/12: 600 mols in 27.1s\n",
      "  early-stop: CI width 0.022 < 0.03\n",
      "\n",
      "[TCAV] Label: SR-ARE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 1/12: 600 mols in 27.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 2/12: 600 mols in 28.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 3/12: 600 mols in 28.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 4/12: 600 mols in 30.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 5/12: 600 mols in 26.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 6/12: 600 mols in 26.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 7/12: 600 mols in 26.8s\n",
      "  early-stop: CI width 0.030 < 0.03\n",
      "\n",
      "[TCAV] Label: SR-ATAD5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 1/12: 600 mols in 28.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 2/12: 600 mols in 27.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 3/12: 600 mols in 26.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 4/12: 600 mols in 31.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 5/12: 600 mols in 27.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 6/12: 600 mols in 30.9s\n",
      "  early-stop: CI width 0.029 < 0.03\n",
      "\n",
      "[TCAV] Label: SR-HSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 1/12: 600 mols in 615.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 2/12: 600 mols in 313.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 3/12: 600 mols in 1600.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 4/12: 600 mols in 4029.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 5/12: 600 mols in 25.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 6/12: 600 mols in 26.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 7/12: 600 mols in 26.1s\n",
      "  early-stop: CI width 0.029 < 0.03\n",
      "\n",
      "[TCAV] Label: SR-MMP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 1/12: 600 mols in 26.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 2/12: 600 mols in 26.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 3/12: 600 mols in 24.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 4/12: 600 mols in 26.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 5/12: 600 mols in 26.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 6/12: 600 mols in 26.1s\n",
      "  early-stop: CI width 0.029 < 0.03\n",
      "\n",
      "[TCAV] Label: SR-p53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 1/12: 600 mols in 30.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 2/12: 600 mols in 190.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 3/12: 600 mols in 28.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 4/12: 600 mols in 27.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 5/12: 600 mols in 28.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 6/12: 600 mols in 28.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  run 7/12: 600 mols in 28.3s\n",
      "  early-stop: CI width 0.029 < 0.03\n",
      "\n",
      "[TCAV] Saved:\n",
      " - per-run â†’ implementation\\v3\\tcav\\tcav_runs.csv\n",
      " - summary â†’ implementation\\v3\\tcav\\tcav_summary.csv\n",
      "        concept     label  tcav_mean  p_value_ttest  n_runs             ci95  eval_count_total\n",
      "        Aniline     NR-AR     1.0000       0.000000       7         [1.0, 1]              4200\n",
      "MichaelAcceptor     NR-AR     1.0000       0.000000       7         [1.0, 1]              4200\n",
      "       Pyridine     NR-AR     1.0000       0.000000       7         [1.0, 1]              4200\n",
      "  TertiaryAmine     NR-AR     1.0000       0.000000       7         [1.0, 1]              4200\n",
      "   AromaticRing     NR-AR     0.9998       0.000000       7      [0.9993, 1]              4200\n",
      "         Phenol     NR-AR     0.9979       0.000000       7 [0.9965, 0.9993]              4200\n",
      "          Ester     NR-AR     0.9971       0.000000       7 [0.9955, 0.9988]              4200\n",
      "    Sulfonamide     NR-AR     0.5295       0.000143       7 [0.5144, 0.5446]              4200\n",
      "     ArylHalide     NR-AR     0.0007       0.000000       7      [0, 0.0015]              4200\n",
      " CarboxylicAcid     NR-AR     0.0000       0.000000       7         [0, 0.0]              4200\n",
      "          Nitro     NR-AR     0.0000       0.000000       7         [0, 0.0]              4200\n",
      "        Aniline NR-AR-LBD     1.0000       0.000000       6         [1.0, 1]              3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_2364\\540137093.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([runs_df, part_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# === Cell 10c â€” TCAV on v3 (optimized: pretokenize, AMP, resume, coverage, early-stop) ===\n",
    "import math, time, json, numpy as np, pandas as pd, torch\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "# --------------------\n",
    "# CONFIG\n",
    "# --------------------\n",
    "ROOT        = Path(\"implementation\")\n",
    "DATA_CSV    = ROOT / \"data\" / \"tox21.csv\"\n",
    "V3_BEST     = ROOT / \"models\" / \"chemberta_v3\" / \"v3_best\"\n",
    "CAV_VEC_DIR = ROOT / \"v3\" / \"cav\" / \"vectors\"\n",
    "TCAV_DIR    = ROOT / \"v3\" / \"tcav\"\n",
    "TCAV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DEVICE      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MAXLEN      = 256\n",
    "MIXED_PREC  = torch.cuda.is_available()\n",
    "BASE_BATCH  = 128 if torch.cuda.is_available() else 64   # will auto-downgrade on OOM\n",
    "TCAV_RUNS   = 12    # set 8â€“20; early-stopping can finish earlier\n",
    "EVAL_PER_LABEL = 600  # per run; total evals per label ~ TCAV_RUNS * EVAL_PER_LABEL\n",
    "EARLYSTOP_MIN_RUNS = 6\n",
    "EARLYSTOP_CI_WIDTH = 0.03   # stop when 95% CI width < this\n",
    "\n",
    "RNG = np.random.default_rng(42)\n",
    "\n",
    "# --------------------\n",
    "# Load data & labels\n",
    "# --------------------\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "mol_ids  = df[\"mol_id\"].astype(str).tolist()\n",
    "smiles   = df[\"smiles\"].astype(str).tolist()\n",
    "mol2sm   = dict(zip(mol_ids, smiles))\n",
    "label_cols = [c for c in df.columns if c not in (\"mol_id\",\"smiles\")]\n",
    "N = len(mol_ids)\n",
    "\n",
    "# --------------------\n",
    "# Load model\n",
    "# --------------------\n",
    "tok = AutoTokenizer.from_pretrained(str(V3_BEST))\n",
    "cfg = AutoConfig.from_pretrained(str(V3_BEST)); cfg.output_hidden_states = True\n",
    "mdl = AutoModelForSequenceClassification.from_pretrained(str(V3_BEST), config=cfg).to(DEVICE).eval()\n",
    "if hasattr(mdl.config, \"use_cache\"): mdl.config.use_cache = False\n",
    "\n",
    "# --------------------\n",
    "# Load CAVs\n",
    "# --------------------\n",
    "CAVS = {}\n",
    "for fp in CAV_VEC_DIR.glob(\"*_cav.npy\"):\n",
    "    v = np.load(fp)\n",
    "    v = v / (np.linalg.norm(v) + 1e-12)\n",
    "    CAVS[fp.stem.replace(\"_cav\",\"\")] = v.astype(np.float32)\n",
    "if not CAVS:\n",
    "    raise RuntimeError(f\"No CAVs found in {CAV_VEC_DIR}\")\n",
    "concept_names = list(CAVS.keys())\n",
    "print(f\"[INFO] TCAV with {len(concept_names)} concepts:\", concept_names[:8], \"...\" if len(concept_names)>8 else \"\")\n",
    "\n",
    "# --------------------\n",
    "# Pre-tokenize (CPU) once for speed\n",
    "# --------------------\n",
    "enc_all = tok(smiles, truncation=True, padding=True, max_length=MAXLEN)\n",
    "# Convert to torch tensors for quick slicing\n",
    "input_ids_all    = torch.tensor(enc_all[\"input_ids\"], dtype=torch.long)\n",
    "attn_mask_all    = torch.tensor(enc_all[\"attention_mask\"], dtype=torch.long)\n",
    "\n",
    "# --------------------\n",
    "# Helpers\n",
    "# --------------------\n",
    "@torch.enable_grad()\n",
    "def _batch_grads_from_encoded(input_ids, attn_mask, label_idx: int, use_amp=MIXED_PREC):\n",
    "    \"\"\"\n",
    "    Gradient of logit[label_idx] w.r.t. mean-pooled last hidden state.\n",
    "    We (1) compute pooled; (2) DETACH to make it a leaf; (3) set requires_grad_;\n",
    "    (4) run classifier sublayers manually; (5) backprop and read pooled.grad.\n",
    "    \"\"\"\n",
    "    enc = {\"input_ids\": input_ids.to(DEVICE, non_blocking=True),\n",
    "           \"attention_mask\": attn_mask.to(DEVICE, non_blocking=True)}\n",
    "    with torch.amp.autocast('cuda', dtype=torch.float16, enabled=use_amp):\n",
    "        out   = mdl(**enc, output_hidden_states=True, return_dict=True)\n",
    "        last  = out.hidden_states[-1]                     # [B, T, H]\n",
    "        mask  = enc[\"attention_mask\"].unsqueeze(-1)       # [B, T, 1]\n",
    "        pooled_raw = (last * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1)  # [B, H]\n",
    "\n",
    "    # Make pooled a leaf so .grad will be populated\n",
    "    pooled = pooled_raw.detach()\n",
    "    pooled.requires_grad_(True)\n",
    "\n",
    "    # RobertaClassificationHead sublayers\n",
    "    head = mdl.classifier\n",
    "    with torch.amp.autocast('cuda', dtype=torch.float16, enabled=use_amp):\n",
    "        x = head.dropout(pooled)\n",
    "        x = head.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = head.dropout(x)\n",
    "        logits = head.out_proj(x)                         # [B, num_labels]\n",
    "\n",
    "        target = logits[:, label_idx].sum()\n",
    "\n",
    "    mdl.zero_grad(set_to_none=True)\n",
    "    target.backward()\n",
    "    g = pooled.grad.detach().cpu().numpy()                # [B, H]\n",
    "    return g\n",
    "\n",
    "def _ci95(p, n):\n",
    "    z = 1.96\n",
    "    se = math.sqrt(max(p*(1-p), 1e-12)/max(n,1))\n",
    "    return (p - z*se, p + z*se)\n",
    "\n",
    "def _auto_batch_try(b):\n",
    "    # quick memory probe to find a safe batch size (only first label/run)\n",
    "    try:\n",
    "        idx0 = np.arange(min(b, N))\n",
    "        _ = _batch_grads_from_encoded(input_ids_all[idx0], attn_mask_all[idx0], 0)\n",
    "        return b\n",
    "    except RuntimeError as e:\n",
    "        if \"CUDA out of memory\" in str(e):\n",
    "            torch.cuda.empty_cache()\n",
    "            return max(16, b//2)\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "# --------------------\n",
    "# Resume (optional): if per-run CSV exists, load and continue\n",
    "# --------------------\n",
    "runs_path = TCAV_DIR / \"tcav_runs.csv\"\n",
    "runs_df = pd.read_csv(runs_path) if runs_path.exists() else pd.DataFrame(\n",
    "    columns=[\"concept\",\"label\",\"run\",\"tcav_frac_pos\",\"n_eval\"]\n",
    ")\n",
    "\n",
    "# For coverage: create a deterministic index schedule per label (chunks across the dataset)\n",
    "def _label_chunks(n_total, chunk_size, n_runs):\n",
    "    order = np.arange(n_total); RNG.shuffle(order)\n",
    "    chunks = [order[i:i+chunk_size] for i in range(0, n_total, chunk_size)]\n",
    "    # if fewer chunks than runs, we wrap around\n",
    "    while len(chunks) < n_runs:\n",
    "        RNG.shuffle(order)\n",
    "        chunks += [order[i:i+chunk_size] for i in range(0, n_total, chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "# Determine a safe batch size once\n",
    "BATCH = _auto_batch_try(BASE_BATCH)\n",
    "print(f\"[INFO] Using BATCH={BATCH} | AMP={'on' if MIXED_PREC else 'off'}\")\n",
    "\n",
    "rows_new = []\n",
    "\n",
    "for lbl_idx, lbl in enumerate(label_cols):\n",
    "    print(f\"\\n[TCAV] Label: {lbl}\")\n",
    "    # skip runs already done (per label) if resuming\n",
    "    done_runs = set(runs_df.query(\"label == @lbl\")[\"run\"].tolist())\n",
    "    # coverage chunks for this label\n",
    "    chunks = _label_chunks(N, EVAL_PER_LABEL, TCAV_RUNS)\n",
    "\n",
    "    # online stats for early-stop\n",
    "    run_vals = []\n",
    "\n",
    "    for run in range(TCAV_RUNS):\n",
    "        if run in done_runs:\n",
    "            continue\n",
    "\n",
    "        idx = chunks[run][:EVAL_PER_LABEL]  # integer indices\n",
    "        # tqdm on batches\n",
    "        t0 = time.perf_counter()\n",
    "        grads_list = []\n",
    "        for i in range(0, len(idx), BATCH):\n",
    "            sl = idx[i:i+BATCH]\n",
    "            grads_list.append(_batch_grads_from_encoded(\n",
    "                input_ids_all[sl], attn_mask_all[sl], lbl_idx, use_amp=MIXED_PREC\n",
    "            ))\n",
    "        G = np.vstack(grads_list).astype(np.float32)  # [M, H]\n",
    "\n",
    "        # directional derivatives\n",
    "        for cname, cav in CAVS.items():\n",
    "            dd = (G @ cav.reshape(-1,1)).reshape(-1)\n",
    "            rows_new.append({\n",
    "                \"concept\": cname, \"label\": lbl, \"run\": run,\n",
    "                \"tcav_frac_pos\": float((dd > 0).mean()), \"n_eval\": int(G.shape[0])\n",
    "            })\n",
    "\n",
    "        dt = time.perf_counter() - t0\n",
    "        print(f\"  run {run+1}/{TCAV_RUNS}: {len(idx)} mols in {dt:.1f}s\")\n",
    "\n",
    "        # checkpoint after each run\n",
    "        part_df = pd.DataFrame(rows_new)\n",
    "        full_df = pd.concat([runs_df, part_df], ignore_index=True)\n",
    "        full_df.to_csv(runs_path, index=False)\n",
    "\n",
    "        # early stop based on CI width (compute over aggregate of all concepts for stability)\n",
    "        vals = full_df.query(\"label == @lbl\")[\"tcav_frac_pos\"].to_numpy()\n",
    "        if len(vals) >= EARLYSTOP_MIN_RUNS * len(CAVS):  # approx >= min runs across concepts\n",
    "            mean = float(vals.mean()); lo, hi = _ci95(mean, int(full_df.query(\"label == @lbl\")[\"n_eval\"].mean() * (run+1)))\n",
    "            if (hi - lo) < EARLYSTOP_CI_WIDTH:\n",
    "                print(f\"  early-stop: CI width {(hi-lo):.3f} < {EARLYSTOP_CI_WIDTH}\")\n",
    "                break\n",
    "\n",
    "# --------------------\n",
    "# Aggregate to summary\n",
    "# --------------------\n",
    "tcav_runs = pd.read_csv(runs_path)\n",
    "def _agg_ci(p, n):\n",
    "    lo, hi = _ci95(p, n)\n",
    "    return [round(max(0, lo), 4), round(min(1, hi), 4)]\n",
    "\n",
    "summary = []\n",
    "for (c,l), grp in tcav_runs.groupby([\"concept\",\"label\"]):\n",
    "    vals = grp[\"tcav_frac_pos\"].to_numpy()\n",
    "    mean = float(vals.mean())\n",
    "    var  = float(vals.var(ddof=1)) if len(vals)>1 else 0.0\n",
    "    se   = math.sqrt(max(var,1e-12)/max(len(vals),1))\n",
    "    from math import erf, sqrt\n",
    "    z    = (mean - 0.5) / max(se,1e-9)\n",
    "    p_t  = 2 * (1 - 0.5*(1 + erf(abs(z)/sqrt(2))))\n",
    "    n_eval = int(grp[\"n_eval\"].mean()) * len(vals)  # approx total evals\n",
    "    summary.append({\n",
    "        \"concept\": c, \"label\": l,\n",
    "        \"tcav_mean\": round(mean, 4),\n",
    "        \"p_value_ttest\": p_t,\n",
    "        \"n_runs\": int(len(vals)),\n",
    "        \"ci95\": _agg_ci(mean, n_eval),\n",
    "        \"eval_count_total\": int(n_eval)\n",
    "    })\n",
    "\n",
    "tcav_summary = pd.DataFrame(summary).sort_values([\"label\",\"tcav_mean\"], ascending=[True, False])\n",
    "tcav_summary.to_csv(TCAV_DIR / \"tcav_summary.csv\", index=False)\n",
    "print(\"\\n[TCAV] Saved:\")\n",
    "print(\" - per-run â†’\", TCAV_DIR / \"tcav_runs.csv\")\n",
    "print(\" - summary â†’\", TCAV_DIR / \"tcav_summary.csv\")\n",
    "print(tcav_summary.head(12).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b7bf09",
   "metadata": {},
   "source": [
    "## 11: Test run before the final integration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c15ac494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harness ready. Labels: ['LABEL_0', 'LABEL_1', 'LABEL_2', 'LABEL_3', 'LABEL_4'] ...\n",
      "Thresholds file: found\n",
      "TCAV rows: 132\n"
     ]
    }
   ],
   "source": [
    "# === Sanity harness for ChemBERTa v3 + TCAV ===\n",
    "import json, math, numpy as np, pandas as pd, torch\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "# Paths\n",
    "ROOT      = Path(\"implementation\")\n",
    "DATA_CSV  = ROOT / \"data\" / \"tox21.csv\"\n",
    "V3_DIR    = ROOT / \"models\" / \"chemberta_v3\"\n",
    "V3_BEST   = V3_DIR / \"v3_best\"\n",
    "V3_META   = V3_DIR / \"metadata\"\n",
    "TCAV_SUM  = ROOT / \"v3\" / \"tcav\" / \"tcav_summary.csv\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MAXLEN = 256\n",
    "BATCH  = 64\n",
    "\n",
    "# Load labels\n",
    "cfg = AutoConfig.from_pretrained(str(V3_BEST))\n",
    "id2label = cfg.id2label\n",
    "label_cols = [id2label[i] for i in range(len(id2label))]\n",
    "\n",
    "# Thresholds (fall back to 0.5 if missing)\n",
    "thr_path = V3_META / \"thresholds_v3.json\"\n",
    "if thr_path.exists():\n",
    "    thresholds = json.load(open(thr_path))\n",
    "else:\n",
    "    thresholds = {lbl: 0.5 for lbl in label_cols}\n",
    "\n",
    "# Calibration (optional artifacts)\n",
    "def _apply_calibration(logits: np.ndarray) -> np.ndarray:\n",
    "    sig = lambda x: 1.0 / (1.0 + np.exp(-x))\n",
    "    temp = (np.load(V3_META / \"temperature.npy\")[0]\n",
    "            if (V3_META / \"temperature.npy\").exists() else 1.0)\n",
    "    cal_methods = json.load(open(V3_META / \"calibration_methods.json\")) if (V3_META / \"calibration_methods.json\").exists() else {}\n",
    "    platt = json.load(open(V3_META / \"platt_params.json\")) if (V3_META / \"platt_params.json\").exists() else {}\n",
    "    iso   = json.load(open(V3_META / \"isotonic_params.json\")) if (V3_META / \"isotonic_params.json\").exists() else {}\n",
    "\n",
    "    p_temp = sig(logits / max(float(temp), 1e-6))\n",
    "    out = np.zeros_like(p_temp)\n",
    "    for j, lbl in enumerate(label_cols):\n",
    "        meth = cal_methods.get(lbl, {}).get(\"method\", \"temp\")\n",
    "        if meth == \"platt\" and lbl in platt:\n",
    "            A, B = platt[lbl][\"A\"], platt[lbl][\"B\"]\n",
    "            out[:, j] = sig(A * logits[:, j] + B)\n",
    "        elif meth == \"iso\" and lbl in iso:\n",
    "            X = np.asarray(iso[lbl][\"X\"]); Y = np.asarray(iso[lbl][\"Y\"])\n",
    "            out[:, j] = np.interp(p_temp[:, j], X, Y)\n",
    "        else:  # pure temperature or nothing\n",
    "            out[:, j] = p_temp[:, j]\n",
    "    return out\n",
    "\n",
    "# Model\n",
    "tok = AutoTokenizer.from_pretrained(str(V3_BEST))\n",
    "mdl = AutoModelForSequenceClassification.from_pretrained(str(V3_BEST), config=cfg).to(DEVICE).eval()\n",
    "if hasattr(mdl.config, \"use_cache\"): mdl.config.use_cache = False\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs(smiles_list):\n",
    "    logits_all = []\n",
    "    for i in range(0, len(smiles_list), BATCH):\n",
    "        enc = tok(smiles_list[i:i+BATCH], truncation=True, padding=True, max_length=MAXLEN, return_tensors=\"pt\").to(DEVICE)\n",
    "        logits = mdl(**enc).logits.detach().cpu().numpy()\n",
    "        logits_all.append(logits)\n",
    "    logits = np.vstack(logits_all)\n",
    "    probs  = _apply_calibration(logits)\n",
    "    return probs\n",
    "\n",
    "# TCAV summary\n",
    "assert TCAV_SUM.exists(), f\"Missing TCAV summary at {TCAV_SUM}\"\n",
    "tcav_df = pd.read_csv(TCAV_SUM)\n",
    "# Keep simple columns\n",
    "keep_cols = [c for c in [\"concept\",\"label\",\"tcav_mean\",\"p_value_ttest\",\"ci95\",\"n_runs\"] if c in tcav_df.columns]\n",
    "tcav_df = tcav_df[keep_cols].copy()\n",
    "\n",
    "def top_tcav_for_label(label, k=5):\n",
    "    sdf = tcav_df[tcav_df[\"label\"] == label].copy()\n",
    "    if sdf.empty: return pd.DataFrame(columns=[\"concept\",\"tcav_mean\",\"p_value_ttest\",\"ci95\"])\n",
    "    return sdf.sort_values(\"tcav_mean\", ascending=False).head(k).reset_index(drop=True)\n",
    "\n",
    "print(\"Harness ready. Labels:\", label_cols[:5], \"...\")\n",
    "print(\"Thresholds file:\", (\"found\" if thr_path.exists() else \"default 0.5\"))\n",
    "print(\"TCAV rows:\", len(tcav_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d233dbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE mol_id=TOX3021 | SMILES=CCOc1ccc2nc(S(N)(=O)=O)sc2c1\n",
      "Top-5 probs: [('LABEL_2', 0.5086461901664734), ('LABEL_7', 0.5052387118339539), ('LABEL_8', 0.5047217607498169), ('LABEL_4', 0.5045846104621887), ('LABEL_0', 0.503655731678009)]\n",
      "Predicted labels (>= thr): ['LABEL_0', 'LABEL_1', 'LABEL_2', 'LABEL_3', 'LABEL_4', 'LABEL_5', 'LABEL_6', 'LABEL_7', 'LABEL_8', 'LABEL_9', 'LABEL_10', 'LABEL_11']\n",
      "\n",
      "ðŸ” LABEL_0 â€” p=0.50 (thr=0.50)\n",
      "  (no TCAV rows for this label)\n",
      "\n",
      "ðŸ” LABEL_1 â€” p=0.50 (thr=0.50)\n",
      "  (no TCAV rows for this label)\n",
      "\n",
      "ðŸ” LABEL_2 â€” p=0.51 (thr=0.50)\n",
      "  (no TCAV rows for this label)\n"
     ]
    }
   ],
   "source": [
    "# === Quick checks ===\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Take first row from tox21.csv\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "ex_mid, ex_smiles = df.loc[0, \"mol_id\"], df.loc[0, \"smiles\"]\n",
    "probs = predict_probs([ex_smiles])[0]\n",
    "preds = [(lbl, float(probs[j]), thresholds.get(lbl, 0.5)) for j, lbl in enumerate(label_cols)]\n",
    "pred_hits = [ (lbl, p, thr) if p >= thr else None for lbl, p, thr in preds ]\n",
    "pred_hits = [h for h in pred_hits if h is not None]\n",
    "print(f\"EXAMPLE mol_id={ex_mid} | SMILES={ex_smiles}\")\n",
    "print(\"Top-5 probs:\", sorted([(lbl, p) for lbl,p,_ in preds], key=lambda x: -x[1])[:5])\n",
    "print(\"Predicted labels (>= thr):\", [lbl for (lbl,_,_) in pred_hits])\n",
    "\n",
    "# 2) For each predicted label, show top-5 TCAV concepts\n",
    "for lbl, p, thr in pred_hits[:3]:  # show up to 3 labels for brevity\n",
    "    print(f\"\\nðŸ” {lbl} â€” p={p:.2f} (thr={thr:.2f})\")\n",
    "    top = top_tcav_for_label(lbl, k=5)\n",
    "    if top.empty:\n",
    "        print(\"  (no TCAV rows for this label)\")\n",
    "    else:\n",
    "        for r in top.itertuples():\n",
    "            ci = r.ci95 if isinstance(r.ci95, str) else str(r.ci95)\n",
    "            print(f\"  - {r.concept:16s}  TCAV={r.tcav_mean:.3f}  p={getattr(r,'p_value_ttest',float('nan')):.2e}  CI={ci}\")\n",
    "\n",
    "# 3) Optional: test a custom SMILES\n",
    "custom = None  # e.g., 'O=c1ccc(O)cc1'  # put a SMILES here or leave as None\n",
    "if custom:\n",
    "    p2 = predict_probs([custom])[0]\n",
    "    preds2 = [(lbl, float(p2[j]), thresholds.get(lbl, 0.5)) for j, lbl in enumerate(label_cols)]\n",
    "    hits2 = [lbl for (lbl,p,thr) in preds2 if p >= thr]\n",
    "    print(f\"\\nCUSTOM SMILES={custom}\")\n",
    "    print(\"Top-5 probs:\", sorted([(lbl,p) for lbl,p,_ in preds2], key=lambda x: -x[1])[:5])\n",
    "    print(\"Predicted labels (>= thr):\", hits2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f785f2",
   "metadata": {},
   "source": [
    "# Improving thr concept knowledge    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc2f8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved concept knowledge to: D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\implementation\\concept_Knowledge\\concept_knowledge_auto_v2.json\n",
      "NR-AR -> 200\n",
      "NR-AR-LBD -> 200\n",
      "NR-AhR -> 200\n",
      "NR-Aromatase -> 200\n",
      "NR-ER -> 200\n",
      "NR-ER-LBD -> 200\n",
      "NR-PPAR-gamma -> 200\n",
      "SR-ARE -> 200\n",
      "SR-ATAD5 -> 200\n",
      "SR-HSE -> 200\n",
      "SR-MMP -> 200\n",
      "SR-p53 -> 200\n"
     ]
    }
   ],
   "source": [
    "# === Build a large concept-knowledge file (~200 items/label) ===\n",
    "# Sources: Wikipedia (no key), OpenAlex (no key), optional Europe PMC (no key).\n",
    "# Output: implementation/concept_Knowledge/concept_knowledge_auto_v2.json\n",
    "\n",
    "import os, re, json, time, math, html\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import requests\n",
    "\n",
    "# ---------------- CFG ----------------\n",
    "SAVE_DIR = Path(\"implementation/concept_Knowledge\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_PATH = SAVE_DIR / \"concept_knowledge_auto_v2.json\"\n",
    "\n",
    "# Target size per label\n",
    "MIN_PER_LABEL = 200\n",
    "MAX_PER_CONCEPT_PER_LABEL = 30     # cap per concept to maintain diversity\n",
    "KEEP_PER_SOURCE = 400              # how many sentences per source we keep before mapping\n",
    "ALLOW_SYNTHETIC_PAD = True         # if True, pad to MIN_PER_LABEL with clearly-marked entries\n",
    "\n",
    "# Sources toggles (turn on to get more text = slower)\n",
    "USE_OPENALEX   = True\n",
    "OPENALEX_MAX   = 120               # number of works to fetch per label (up to ~120 abstracts)\n",
    "USE_EPMC       = True              # Europe PMC text mining\n",
    "EPMC_MAX       = 200               # max results (batches of 25-100 are ok)\n",
    "\n",
    "# HTTP etiquette\n",
    "WIKI_TIMEOUT, OPENALEX_TIMEOUT, EPMC_TIMEOUT = 12, 20, 15\n",
    "SLEEP = 0.25  # seconds between calls\n",
    "\n",
    "# ------------- Tox21 endpoints & wiki targets -------------\n",
    "WIKI_TARGETS = {\n",
    "    \"NR-AR\":             [\"Androgen receptor\"],\n",
    "    \"NR-AR-LBD\":         [\"Androgen receptor\"],\n",
    "    \"NR-AhR\":            [\"Aryl hydrocarbon receptor\"],\n",
    "    \"NR-Aromatase\":      [\"Aromatase\", \"CYP19A1\"],\n",
    "    \"NR-ER\":             [\"Estrogen receptor\"],\n",
    "    \"NR-ER-LBD\":         [\"Estrogen receptor\"],\n",
    "    \"NR-PPAR-gamma\":     [\"Peroxisome proliferator-activated receptor gamma\", \"PPARG\"],\n",
    "    \"SR-ARE\":            [\"Nrf2\", \"Antioxidant response element\", \"Keap1\"],\n",
    "    \"SR-ATAD5\":          [\"ATAD5\", \"DNA replication\", \"PCNA\"],\n",
    "    \"SR-HSE\":            [\"Heat shock response\", \"Heat shock factor 1\"],\n",
    "    \"SR-MMP\":            [\"Mitochondrial membrane potential\", \"Mitochondrial uncoupler\"],\n",
    "    \"SR-p53\":            [\"TP53\", \"p53\"],\n",
    "}\n",
    "\n",
    "# ------------- Expanded concept dictionary (name -> regex list) -------------\n",
    "CONCEPTS = {\n",
    "    # core you had\n",
    "    \"AromaticRing\":     [r\"\\baromatic\\b\", r\"Ï€[-â€“]?\\s*Ï€\", r\"pi[- ]stack\", r\"planar ring\", r\"\\bpolycyclic\\b\"],\n",
    "    \"Nitro\":            [r\"\\bnitro\\b\", r\"\\bNO2\\b\", r\"nitroar\"],\n",
    "    \"ArylHalide\":       [r\"aryl halide\", r\"halogenat(ed|ion)\", r\"\\bchloro(benzene|aryl)\\b\", r\"\\bfluoro(aryl|benzene)\\b\", r\"bromo(benzene|aryl)\"],\n",
    "    \"Phenol\":           [r\"\\bphenol(ic)?\\b\", r\"phenolic OH\", r\"phenoxide\"],\n",
    "    \"TertiaryAmine\":    [r\"\\btertiary amine\\b\", r\"trialkylamine\", r\"cationic amine\", r\"\\bquaternary ammonium\\b\"],\n",
    "    \"MichaelAcceptor\":  [r\"michael( addition| acceptor)?\", r\"\\b\\w*enone\\b\", r\"Î±,?Î²[-â€“ ]?unsaturated\", r\"\\b(enal|enone)\\b\", r\"electrophile\"],\n",
    "    \"Quinone\":          [r\"\\bquinone\\b\", r\"redox cycl\", r\"\\bsemiquinone\\b\", r\"ROS\", r\"oxidative stress\"],\n",
    "    \"CarboxylicAcid\":   [r\"carboxylic acid\", r\"\\bCOOH\\b\"],\n",
    "    \"Sulfonamide\":      [r\"sulfonamide\", r\"sulphonamide\"],\n",
    "    \"Ester\":            [r\"\\bester\\b\", r\"transesterification\"],\n",
    "    \"Aniline\":          [r\"\\baniline\\b\", r\"arylamine\", r\"aromatic amine\"],\n",
    "    \"Pyridine\":         [r\"\\bpyridine\\b\", r\"pyridyl\"],\n",
    "    # more chemotypes / motifs\n",
    "    \"Catechol\":         [r\"\\bcatechol\\b\", r\"o[- ]?dihydroxybenzene\", r\"pyrocatechol\"],\n",
    "    \"Aldehyde\":         [r\"\\baldehyde\\b\", r\"\\bâ€“CHO\\b\"],\n",
    "    \"Ketone\":           [r\"\\bketone\\b\", r\"carbonyl\"],\n",
    "    \"Epoxide\":          [r\"\\bepoxid\", r\"oxirane\"],\n",
    "    \"Aziridine\":        [r\"\\baziridin\", r\"aziridinium\"],\n",
    "    \"Isothiocyanate\":   [r\"isothiocyanate\", r\"\\bNCS\\b\"],\n",
    "    \"Acrylamide\":       [r\"\\bacrylamide\\b\"],\n",
    "    \"Nitroso\":          [r\"\\bnitroso\\b\", r\"N=O\"],\n",
    "    \"Hydrazine\":        [r\"\\bhydrazin\"],\n",
    "    \"PhenylAzo\":        [r\"\\bazo\\b\", r\"[- ]N=N[- ]\"],\n",
    "    \"Haloalkane\":       [r\"chloroform\", r\"haloalkane\", r\"alkyl halide\"],\n",
    "    \"Perfluoro\":        [r\"perfluor\", r\"PFAS\", r\"fluorinated alkyl\"],\n",
    "    \"Thiol\":            [r\"\\bthiol\\b\", r\"sulfhydryl\", r\"â€“SH\"],\n",
    "    \"Disulfide\":        [r\"disulfide\", r\"â€“Sâ€“Sâ€“\"],\n",
    "    \"Imide\":            [r\"\\bimide\\b\"],\n",
    "    \"Imidazole\":        [r\"\\bimidazol\"],\n",
    "    \"Thiazole\":         [r\"\\bthiazol\"],\n",
    "    \"Pyrimidine\":       [r\"\\bpyrimidin\"],\n",
    "    \"Urea\":             [r\"\\burea\\b\", r\"carbamoyl\"],\n",
    "    \"Carbamate\":        [r\"\\bcarbamate\\b\"],\n",
    "    \"Sulfone\":          [r\"\\bsulfone\\b\"],\n",
    "    \"Sulfoxide\":        [r\"\\bsulfoxide\\b\"],\n",
    "    \"Phosphate\":        [r\"\\bphosphate\\b\", r\"phosphoryl\"],\n",
    "    \"CationicAmphiphile\":[r\"cationic amphiphile\", r\"lysosomotropic\", r\"lysosomotrop\"],\n",
    "    \"MitoUncoupler\":    [r\"uncoupler\", r\"protonophore\", r\"collapse of (mitochondrial )?membrane potential\", r\"Î”Î¨m\"],\n",
    "    \"DNAAlkylator\":     [r\"DNA alkylat\", r\"alkylation of DNA\", r\"guanine adduct\"],\n",
    "    \"TopoisomeraseInhibitor\":[r\"topoisomerase (I|II)\", r\"etoposide\", r\"camptothecin\"],\n",
    "    \"CYPInhibitor\":     [r\"CYP\\d+\", r\"cytochrome P450\", r\"metabolic inactiv\"],\n",
    "}\n",
    "\n",
    "GENERIC_PHRASE = {\n",
    "    # same generic explanations, extended where useful\n",
    "    \"AromaticRing\":     \"planar Ï€-system enabling hydrophobic/Ï€â€“Ï€ interactions\",\n",
    "    \"Nitro\":            \"nitro functionality linked to bioactivation and potential DNA/protein adducts\",\n",
    "    \"ArylHalide\":       \"halogenated aryl increasing lipophilicity and metabolic stability\",\n",
    "    \"Phenol\":           \"phenolic OH capable of hydrogen bonding and metabolic conjugation\",\n",
    "    \"TertiaryAmine\":    \"basic amine promoting cationic binding and membrane permeability\",\n",
    "    \"MichaelAcceptor\":  \"Î±,Î²-unsaturated system acting as a soft electrophile (Michael acceptor)\",\n",
    "    \"Quinone\":          \"redox-active scaffold often associated with ROS generation\",\n",
    "    \"CarboxylicAcid\":   \"acidic handle increasing polarity and H-bonding potential\",\n",
    "    \"Sulfonamide\":      \"H-bond rich motif impacting acidity and binding patterns\",\n",
    "    \"Ester\":            \"polar carbonyl/alkoxy modulating permeability and metabolism\",\n",
    "    \"Aniline\":          \"aromatic amine potentially linked to metabolic liabilities\",\n",
    "    \"Pyridine\":         \"heteroaromatic ring providing hydrogen bond acceptor capabilities\",\n",
    "    \"Catechol\":         \"o-dihydroxybenzene capable of redox cycling and metal chelation\",\n",
    "    \"Aldehyde\":         \"electrophilic carbonyl capable of forming adducts with nucleophiles\",\n",
    "    \"Ketone\":           \"polar carbonyl that can influence binding and metabolism\",\n",
    "    \"Epoxide\":          \"strained electrophile reactive towards nucleophilic residues\",\n",
    "    \"Aziridine\":        \"strained three-membered ring prone to nucleophilic attack\",\n",
    "    \"Isothiocyanate\":   \"electrophile reactive with cysteine and lysine residues\",\n",
    "    \"Acrylamide\":       \"soft electrophile forming Michael adducts with cysteine\",\n",
    "    \"Nitroso\":          \"nitrosating agent with potential to modify biomolecules\",\n",
    "    \"Hydrazine\":        \"nucleophilic base prone to oxidative activation\",\n",
    "    \"PhenylAzo\":        \"azo linkage that can be reductively cleaved to arylamines\",\n",
    "    \"Haloalkane\":       \"alkyl halides can undergo SN1/SN2 forming covalent adducts\",\n",
    "    \"Perfluoro\":        \"highly fluorinated chains affecting membrane interactions and persistence\",\n",
    "    \"Thiol\":            \"nucleophile capable of forming disulfides or Michael adducts\",\n",
    "    \"Disulfide\":        \"reversible redox-sensitive linkage influencing protein structure\",\n",
    "    \"Imide\":            \"dicarbonyl motif influencing polarity and reactivity\",\n",
    "    \"Imidazole\":        \"basic heterocycle frequently involved in metal binding\",\n",
    "    \"Thiazole\":         \"sulfur-containing heteroaromatic impacting electronics\",\n",
    "    \"Pyrimidine\":       \"heteroaromatic core common in nucleobase analogs\",\n",
    "    \"Urea\":             \"bifunctional H-bond donor/acceptor motif\",\n",
    "    \"Carbamate\":        \"urethane group modulating permeability and stability\",\n",
    "    \"Sulfone\":          \"highly polar sulfonyl increasing electron-withdrawing character\",\n",
    "    \"Sulfoxide\":        \"polar sulfinyl impacting solubility and metabolism\",\n",
    "    \"Phosphate\":        \"anionic group affecting transport and binding\",\n",
    "    \"CationicAmphiphile\":\"cationic lipophilic motif prone to lysosomal accumulation\",\n",
    "    \"MitoUncoupler\":    \"weak acid/protonophore collapsing mitochondrial membrane potential\",\n",
    "    \"DNAAlkylator\":     \"moieties capable of forming covalent DNA adducts\",\n",
    "    \"TopoisomeraseInhibitor\":\"scaffolds interfering with DNA topology and replication\",\n",
    "    \"CYPInhibitor\":     \"chemotypes known to inhibit cytochrome P450 enzymes\",\n",
    "}\n",
    "\n",
    "ENDPOINT_HINTS = {\n",
    "    \"NR-AR\":            [r\"\\bandrogen\\b\", r\"\\bAR\\b\", r\"\\bligand\\b\", r\"\\bagonist\\b\", r\"\\bantagonist\\b\"],\n",
    "    \"NR-AR-LBD\":        [r\"\\bandrogen\\b\", r\"\\bLBD\\b\", r\"\\bligand[- ]binding\"],\n",
    "    \"NR-AhR\":           [r\"\\bAhR\\b\", r\"\\baromatic\\b\", r\"planar\", r\"dioxin\", r\"xenobiotic\"],\n",
    "    \"NR-Aromatase\":     [r\"\\baromatase\\b\", r\"\\bCYP19\\b\", r\"\\binhibitor\\b\", r\"\\bestrogen biosynth\"],\n",
    "    \"NR-ER\":            [r\"\\bestrogen\\b\", r\"\\bER\\b\", r\"\\bagonist\\b\", r\"\\bantagonist\\b\"],\n",
    "    \"NR-ER-LBD\":        [r\"\\bestrogen\\b\", r\"\\bLBD\\b\", r\"binding pocket\", r\"\\bhormone\\b\"],\n",
    "    \"NR-PPAR-gamma\":    [r\"\\bPPAR-?Î³\\b\", r\"\\bPPARG\\b\", r\"\\bligand\\b\", r\"thiazolidinedione\"],\n",
    "    \"SR-ARE\":           [r\"\\bNrf2\\b\", r\"\\bARE\\b\", r\"Keap1\", r\"oxidative stress\", r\"electrophile\", r\"cysteine\"],\n",
    "    \"SR-ATAD5\":         [r\"\\bATAD5\\b\", r\"DNA repair\", r\"PCNA\", r\"replication stress\"],\n",
    "    \"SR-HSE\":           [r\"\\bheat shock\\b\", r\"\\bHSF1\\b\", r\"proteotoxic\", r\"chaperone\"],\n",
    "    \"SR-MMP\":           [r\"\\bmitochondrial membrane potential\\b\", r\"\\bÎ”Î¨m\\b\", r\"uncoupling\", r\"protonophore\"],\n",
    "    \"SR-p53\":           [r\"\\bp53\\b\", r\"\\bTP53\\b\", r\"DNA damage\", r\"cell cycle arrest\", r\"apoptosis\"],\n",
    "}\n",
    "\n",
    "SENT_SPLIT = re.compile(r\"(?<=[.!?])\\s+\")\n",
    "\n",
    "# ---------------- HTTP helpers ----------------\n",
    "def wiki_summary(title: str):\n",
    "    url = f\"https://en.wikipedia.org/api/rest_v1/page/summary/{requests.utils.quote(title)}\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=WIKI_TIMEOUT, headers={\"accept\":\"application/json\"})\n",
    "        if r.status_code == 200:\n",
    "            j = r.json()\n",
    "            txt = j.get(\"extract\") or \"\"\n",
    "            link = j.get(\"content_urls\",{}).get(\"desktop\",{}).get(\"page\") or j.get(\"content_urls\",{}).get(\"mobile\",{}).get(\"page\")\n",
    "            return txt, (link or f\"https://en.wikipedia.org/wiki/{title.replace(' ','_')}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    return \"\", \"\"\n",
    "\n",
    "def openalex_snippets(query: str, limit=OPENALEX_MAX):\n",
    "    out = []\n",
    "    per_page = 25\n",
    "    pages = math.ceil(limit / per_page)\n",
    "    for p in range(1, pages+1):\n",
    "        n_fetch = min(per_page, limit - (p-1)*per_page)\n",
    "        if n_fetch <= 0: break\n",
    "        try:\n",
    "            url = \"https://api.openalex.org/works\"\n",
    "            params = {\"search\": query, \"per_page\": n_fetch, \"mailto\": \"noreply@example.com\"}\n",
    "            r = requests.get(url, params=params, timeout=OPENALEX_TIMEOUT)\n",
    "            if r.status_code != 200:\n",
    "                break\n",
    "            j = r.json()\n",
    "            for w in j.get(\"results\", []):\n",
    "                abstract = (w.get(\"abstract_inverted_index\") or {})\n",
    "                text = \"\"\n",
    "                if abstract:\n",
    "                    inv = abstract\n",
    "                    max_i = max([max(v) for v in inv.values()]) if inv else -1\n",
    "                    words = [\"\"]*(max_i+1)\n",
    "                    for token, idxs in inv.items():\n",
    "                        for idx in idxs:\n",
    "                            words[idx] = token\n",
    "                    text = \" \".join(words).strip()\n",
    "                else:\n",
    "                    text = (w.get(\"title\") or \"\")\n",
    "                url_w = w.get(\"primary_location\",{}).get(\"source\",{}).get(\"homepage_url\") or w.get(\"open_access\",{}).get(\"oa_url\") or w.get(\"ids\",{}).get(\"openalex\")\n",
    "                out.append((text, url_w or \"https://api.openalex.org/\"))\n",
    "        except Exception:\n",
    "            break\n",
    "        time.sleep(SLEEP)\n",
    "    return out\n",
    "\n",
    "def epmc_snippets(query: str, limit=EPMC_MAX):\n",
    "    out = []\n",
    "    page_size = 100\n",
    "    pages = math.ceil(limit / page_size)\n",
    "    for p in range(1, pages+1):\n",
    "        try:\n",
    "            url = \"https://www.ebi.ac.uk/europepmc/webservices/rest/search\"\n",
    "            params = {\"query\": query, \"format\": \"json\", \"pageSize\": page_size, \"page\": p}\n",
    "            r = requests.get(url, params=params, timeout=EPMC_TIMEOUT)\n",
    "            if r.status_code != 200: break\n",
    "            j = r.json()\n",
    "            hits = j.get(\"resultList\", {}).get(\"result\", [])\n",
    "            for h in hits:\n",
    "                ab = h.get(\"abstractText\") or \"\"\n",
    "                if ab:\n",
    "                    out.append((ab, f\"https://europepmc.org/article/{h.get('source', 'MED')}/{h.get('id','')}\"))\n",
    "        except Exception:\n",
    "            break\n",
    "        time.sleep(SLEEP)\n",
    "    return out\n",
    "\n",
    "# ---------------- Text processing ----------------\n",
    "def extract_sentences(text: str, endpoint: str):\n",
    "    if not text: return []\n",
    "    text = html.unescape(text)\n",
    "    sents = SENT_SPLIT.split(text)\n",
    "    hints = ENDPOINT_HINTS.get(endpoint, [])\n",
    "    out = []\n",
    "    for s in sents:\n",
    "        st = s.strip()\n",
    "        if len(st) < 40 or len(st) > 400: \n",
    "            continue\n",
    "        # prefer sentences that look mechanistic / endpoint-relevant\n",
    "        if not hints or any(re.search(h, st, flags=re.I) for h in hints) or endpoint.startswith(\"SR-\"):\n",
    "            out.append(st)\n",
    "    # keep a lot; we'll filter later\n",
    "    return out[:KEEP_PER_SOURCE]\n",
    "\n",
    "def map_sentences_to_concepts(sentences):\n",
    "    bag = defaultdict(list)\n",
    "    for sent in sentences:\n",
    "        for cname, patterns in CONCEPTS.items():\n",
    "            if any(re.search(p, sent, flags=re.I) for p in patterns):\n",
    "                bag[cname].append(sent)\n",
    "    return bag  # concept -> [sentences]\n",
    "\n",
    "def clean_sentence(s):\n",
    "    s = re.sub(r\"\\[[^\\]]+\\]\", \"\", s)        # remove [1], [citation needed]\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s[:350]\n",
    "\n",
    "def pick_diverse(sent_list, cap):\n",
    "    # simple diversity: prefer short, different beginnings\n",
    "    seen_heads = set()\n",
    "    out = []\n",
    "    for s in sorted(sent_list, key=len):\n",
    "        head = s[:30].lower()\n",
    "        if head in seen_heads: \n",
    "            continue\n",
    "        out.append(clean_sentence(s))\n",
    "        seen_heads.add(head)\n",
    "        if len(out) >= cap:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "# ---------------- Harvest ----------------\n",
    "final_data = {}\n",
    "source_log = defaultdict(set)\n",
    "\n",
    "for label, titles in WIKI_TARGETS.items():\n",
    "    raw_sentences = []\n",
    "    # Wikipedia\n",
    "    for t in titles:\n",
    "        txt, url = wiki_summary(t)\n",
    "        if txt:\n",
    "            raw_sentences += extract_sentences(txt, label)\n",
    "            if url: source_log[label].add(url)\n",
    "        time.sleep(SLEEP)\n",
    "\n",
    "    # OpenAlex\n",
    "    if USE_OPENALEX:\n",
    "        q = f\"{label} toxicity mechanism OR {' OR '.join(titles)}\"\n",
    "        for text, url in openalex_snippets(q, limit=OPENALEX_MAX):\n",
    "            raw_sentences += extract_sentences(text, label)\n",
    "            if url: source_log[label].add(url)\n",
    "\n",
    "    # Europe PMC\n",
    "    if USE_EPMC:\n",
    "        q = f'({label} OR {\" OR \".join(titles)}) AND (mechanism OR toxicity OR stress OR receptor OR ligand)'\n",
    "        for text, url in epmc_snippets(q, limit=EPMC_MAX):\n",
    "            raw_sentences += extract_sentences(text, label)\n",
    "            if url: source_log[label].add(url)\n",
    "\n",
    "    # Map to concepts\n",
    "    concept_to_sents = map_sentences_to_concepts(raw_sentences)\n",
    "\n",
    "    # Build items per concept (keep multiple sentences per concept for volume/diversity)\n",
    "    items = []\n",
    "    for cname, sents in concept_to_sents.items():\n",
    "        chosen = pick_diverse(sents, cap=MAX_PER_CONCEPT_PER_LABEL)\n",
    "        for s in chosen:\n",
    "            items.append({\"name\": cname, \"explanation\": s, \"sources\": sorted(list(source_log[label]))})\n",
    "\n",
    "    # If below MIN_PER_LABEL, pad with generic (marked synthetic)\n",
    "    if ALLOW_SYNTHETIC_PAD and len(items) < MIN_PER_LABEL:\n",
    "        needed = MIN_PER_LABEL - len(items)\n",
    "        generic_cycle = list(GENERIC_PHRASE.items())\n",
    "        k = 0\n",
    "        while needed > 0 and k < 2000:  # safety\n",
    "            cname, expl = generic_cycle[k % len(generic_cycle)]\n",
    "            # make a label-flavored variant\n",
    "            variant = f\"{expl} â€” relevant to {label} pathway/context.\"\n",
    "            items.append({\"name\": cname, \"explanation\": variant, \"sources\": [], \"synthetic\": True})\n",
    "            needed -= 1\n",
    "            k += 1\n",
    "\n",
    "    # Trim to exactly MIN_PER_LABEL (optional)\n",
    "    if len(items) > MIN_PER_LABEL:\n",
    "        # keep concepts balanced\n",
    "        per_concept = defaultdict(list)\n",
    "        for it in items:\n",
    "            per_concept[it[\"name\"]].append(it)\n",
    "        balanced = []\n",
    "        # round-robin sampling across concepts\n",
    "        rounds = 0\n",
    "        while len(balanced) < MIN_PER_LABEL and rounds < MAX_PER_CONCEPT_PER_LABEL+5:\n",
    "            for cname in sorted(per_concept.keys()):\n",
    "                if per_concept[cname]:\n",
    "                    balanced.append(per_concept[cname].pop(0))\n",
    "                    if len(balanced) >= MIN_PER_LABEL:\n",
    "                        break\n",
    "            rounds += 1\n",
    "        items = balanced\n",
    "\n",
    "    final_data[label] = items\n",
    "\n",
    "# Add _generic bucket\n",
    "final_data[\"_generic\"] = [\n",
    "    {\"name\": c, \"explanation\": GENERIC_PHRASE[c], \"sources\": []}\n",
    "    for c in sorted(GENERIC_PHRASE.keys())\n",
    "]\n",
    "\n",
    "# Save\n",
    "with open(OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved concept knowledge to: {OUT_PATH.resolve()}\")\n",
    "# Quick counts\n",
    "for lbl in WIKI_TARGETS:\n",
    "    print(lbl, \"->\", len(final_data.get(lbl, [])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a23958",
   "metadata": {},
   "source": [
    "# Re-computing the TCAVs for v2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf95dbb3",
   "metadata": {},
   "source": [
    "## 1: Setup & config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ceff5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Setup Diagnostics ===\n",
      "Device:               cuda\n",
      "PyTorch CUDA:         True\n",
      "Seed:                 42\n",
      "\n",
      "Model dir:            implementation\\models\\chemberta_v2\\v2_best   [OK]\n",
      "Model loaded:         True\n",
      "Labels (12):      ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53']\n",
      "\n",
      "Metadata dir:         implementation\\models\\chemberta_v2\\metadata   [OK]\n",
      "SMARTS path:          implementation\\v2\\smarts_rules_final.json   [WILL CREATE]\n",
      "Background CSV:       implementation\\v2\\background_smiles.csv   [WILL CREATE]\n",
      "Concept knowledge:    implementation\\concept_Knowledge\\concept_knowledge_auto_v2.json\n",
      "CK labels present:    13 (missing for model: [])\n",
      "CK sample 'NR-AR': ['Acrylamide', 'Aldehyde', 'Aniline', 'AromaticRing', 'ArylHalide', 'Aziridine', 'CYPInhibitor', 'Carbamate']\n",
      "\n",
      "TCAV outputs will be saved to:\n",
      " - CSV:  implementation\\v2\\tcav_summary_recomp_v2concepts_k10.csv\n",
      " - JSON: implementation\\v2\\tcav_summary_recomp_v2concepts_k10.json\n",
      "\n",
      "Next steps:\n"
     ]
    }
   ],
   "source": [
    "# === Cell 1: Setup & Diagnostics (save paths to implementation/v2) ===\n",
    "\n",
    "import os, json, random, hashlib, warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "# -----------------------\n",
    "# Reproducibility & device\n",
    "# -----------------------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# -----------------------\n",
    "# Paths\n",
    "# -----------------------\n",
    "ROOT        = Path(\"implementation\")\n",
    "V2_DIR      = ROOT / \"v2\"                       # <-- all TCAV outputs will go here\n",
    "V2_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Model (ChemBERTa v2)\n",
    "MODEL_DIR   = ROOT / \"models\" / \"chemberta_v2\" / \"v2_best\"\n",
    "META_DIR    = ROOT / \"models\" / \"chemberta_v2\" / \"metadata\"\n",
    "\n",
    "# Inputs weâ€™ll try to use / create:\n",
    "SMARTS_PATH = V2_DIR / \"smarts_rules_final.json\"           # will create if missing\n",
    "BG_PATH     = V2_DIR / \"background_smiles.csv\"             # will create if missing\n",
    "\n",
    "# Concept knowledge (to keep concept names consistent with your app)\n",
    "CK_CANDIDATES = [\n",
    "    ROOT / \"concept_Knowledge\" / \"concept_knowledge_auto_v2.json\",\n",
    "    ROOT / \"concept_Knowledge\" / \"concept_knowledge_auto.json\",\n",
    "    ROOT / \"concept_Knowledgev2\" / \"concept_knowledge_auto_v2.json\",  # just in case\n",
    "]\n",
    "\n",
    "# TCAV outputs (weâ€™ll write both CSV and JSON)\n",
    "RUN_SUFFIX  = \"_recomp\"\n",
    "TCAV_CSV    = V2_DIR / f\"tcav_summary{RUN_SUFFIX}_v2concepts_k10.csv\"\n",
    "TCAV_JSON   = V2_DIR / f\"tcav_summary{RUN_SUFFIX}_v2concepts_k10.json\"\n",
    "\n",
    "# -----------------------\n",
    "# Load model & labels\n",
    "# -----------------------\n",
    "def _file_sig(p: Path) -> str:\n",
    "    try:\n",
    "        h = hashlib.sha256()\n",
    "        with open(p, \"rb\") as f:\n",
    "            for chunk in iter(lambda: f.read(8192), b\"\"):\n",
    "                h.update(chunk)\n",
    "        return h.hexdigest()[:12]\n",
    "    except Exception:\n",
    "        return \"missing\"\n",
    "\n",
    "model_ok = MODEL_DIR.exists()\n",
    "try:\n",
    "    cfg = AutoConfig.from_pretrained(str(MODEL_DIR))\n",
    "    tok = AutoTokenizer.from_pretrained(str(MODEL_DIR))\n",
    "    mdl = AutoModelForSequenceClassification.from_pretrained(str(MODEL_DIR), config=cfg).to(DEVICE).eval()\n",
    "    if hasattr(mdl.config, \"use_cache\"):\n",
    "        mdl.config.use_cache = False\n",
    "    id2label = mdl.config.id2label\n",
    "    label_cols = [id2label[i] for i in range(len(id2label))]\n",
    "    model_loaded = True\n",
    "except Exception as e:\n",
    "    model_loaded = False\n",
    "    label_cols = []\n",
    "    print(\"!! Model load failed:\", repr(e))\n",
    "\n",
    "# -----------------------\n",
    "# Concept knowledge (optional, for naming consistency)\n",
    "# -----------------------\n",
    "ck_path = None\n",
    "ck_data: Dict[str, List[Dict]] = {}\n",
    "for cand in CK_CANDIDATES:\n",
    "    if cand.exists():\n",
    "        ck_path = cand\n",
    "        try:\n",
    "            ck_data = json.load(open(cand, \"r\", encoding=\"utf-8\"))\n",
    "        except Exception as e:\n",
    "            print(f\"!! Failed to read concept knowledge at {cand}: {e}\")\n",
    "        break\n",
    "\n",
    "# summarize concept names per label from concept knowledge (if present)\n",
    "ck_summary = {}\n",
    "if ck_data:\n",
    "    for lbl, items in ck_data.items():\n",
    "        names = [it.get(\"name\") for it in items if isinstance(it, dict) and it.get(\"name\")]\n",
    "        ck_summary[lbl] = sorted(set(names))\n",
    "\n",
    "# -----------------------\n",
    "# Diagnostics printout\n",
    "# -----------------------\n",
    "print(\"=== Setup Diagnostics ===\")\n",
    "print(f\"Device:               {DEVICE}\")\n",
    "print(f\"PyTorch CUDA:         {torch.cuda.is_available()}\")\n",
    "print(f\"Seed:                 {SEED}\")\n",
    "print()\n",
    "print(f\"Model dir:            {MODEL_DIR}   [{'OK' if model_ok else 'MISSING'}]\")\n",
    "print(f\"Model loaded:         {model_loaded}\")\n",
    "if model_loaded:\n",
    "    print(f\"Labels ({len(label_cols)}):      {label_cols}\")\n",
    "print()\n",
    "print(f\"Metadata dir:         {META_DIR}   [{'OK' if META_DIR.exists() else 'MISSING'}]\")\n",
    "print(f\"SMARTS path:          {SMARTS_PATH}   [{'EXISTS' if SMARTS_PATH.exists() else 'WILL CREATE'}]\")\n",
    "print(f\"Background CSV:       {BG_PATH}   [{'EXISTS' if BG_PATH.exists() else 'WILL CREATE'}]\")\n",
    "print(f\"Concept knowledge:    {ck_path if ck_path else '(not found)'}\")\n",
    "if ck_summary:\n",
    "    # show overlap between model labels and CK labels\n",
    "    missing_in_ck = [l for l in label_cols if l not in ck_summary]\n",
    "    print(f\"CK labels present:    {len(ck_summary)} (missing for model: {missing_in_ck})\")\n",
    "    # show a small sample of concept names for the first available label\n",
    "    first_lbl = next(iter(ck_summary.keys()))\n",
    "    print(f\"CK sample '{first_lbl}': {ck_summary[first_lbl][:8]}\")\n",
    "print()\n",
    "print(\"TCAV outputs will be saved to:\")\n",
    "print(f\" - CSV:  {TCAV_CSV}\")\n",
    "print(f\" - JSON: {TCAV_JSON}\")\n",
    "print(\"\\nNext steps:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59589731",
   "metadata": {},
   "source": [
    "## 2: curated names per label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803b78c9",
   "metadata": {},
   "source": [
    "### 2a: NAME lists per Tox21 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5550f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NR-AR        12 names\n",
      "NR-AR-LBD    10 names\n",
      "NR-AhR       11 names\n",
      "NR-Aromatase 10 names\n",
      "NR-ER        11 names\n",
      "NR-ER-LBD    10 names\n",
      "NR-PPAR-gamma 10 names\n",
      "SR-ARE       11 names\n",
      "SR-ATAD5     10 names\n",
      "SR-HSE       10 names\n",
      "SR-MMP       10 names\n",
      "SR-p53       10 names\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2a: curated NAME lists per Tox21 labels (10â€“15 each) ===\n",
    "# These are names only; next cell resolves them to canonical SMILES via PubChem.\n",
    "LABEL_TO_NAMES = {\n",
    "    # ---- Nuclear Receptors ----\n",
    "    \"NR-AR\": [\n",
    "        \"Dihydrotestosterone\", \"Testosterone\", \"Nandrolone\", \"Oxandrolone\",\n",
    "        \"Flutamide\", \"Hydroxyflutamide\", \"Bicalutamide\", \"Enzalutamide\",\n",
    "        \"Nilutamide\", \"Cyproterone acetate\", \"Mesterolone\", \"Mifepristone\"\n",
    "    ],\n",
    "    \"NR-AR-LBD\": [\n",
    "        \"Flutamide\", \"Hydroxyflutamide\", \"Bicalutamide\", \"Enzalutamide\",\n",
    "        \"Apalutamide\", \"Darolutamide\", \"Nilutamide\", \"Cyproterone acetate\",\n",
    "        \"Dihydrotestosterone\", \"Testosterone\"\n",
    "    ],\n",
    "    \"NR-AhR\": [\n",
    "        \"2,3,7,8-Tetrachlorodibenzo-p-dioxin\", \"Benzo[a]pyrene\",\n",
    "        \"Beta-naphthoflavone\", \"3-Methylcholanthrene\",\n",
    "        \"6-Formylindolo[3,2-b]carbazole\", \"Indolo[3,2-b]carbazole\",\n",
    "        \"PCB-126\", \"Omeprazole\", \"Fipronil\", \"Quinoline\", \"Indirubin\"\n",
    "    ],\n",
    "    \"NR-Aromatase\": [\n",
    "        \"Letrozole\", \"Anastrozole\", \"Exemestane\", \"Formestane\",\n",
    "        \"Fadrozole\", \"Vorozole\", \"Testolactone\", \"Aminoglutethimide\",\n",
    "        \"Finrozole\", \"Atamestane\"\n",
    "    ],\n",
    "    \"NR-ER\": [\n",
    "        \"Estradiol\", \"Estrone\", \"Estriol\", \"Ethinylestradiol\",\n",
    "        \"Diethylstilbestrol\", \"Genistein\", \"Daidzein\",\n",
    "        \"Bisphenol A\", \"Nonylphenol\", \"Zearalenone\", \"Coumestrol\"\n",
    "    ],\n",
    "    \"NR-ER-LBD\": [\n",
    "        \"Estradiol\", \"Ethinylestradiol\", \"Diethylstilbestrol\",\n",
    "        \"Estrone\", \"Estriol\", \"Genistein\", \"Bisphenol A\",\n",
    "        \"Nonylphenol\", \"Zearalenone\", \"Coumestrol\"\n",
    "    ],\n",
    "    \"NR-PPAR-gamma\": [\n",
    "        \"Rosiglitazone\", \"Pioglitazone\", \"Troglitazone\", \"Ciglitazone\",\n",
    "        \"Lobeglitazone\", \"15-deoxy-delta-12,14-prostaglandin J2\",\n",
    "        \"GW1929\", \"Telmisartan\", \"MCC-555\", \"N-TZDpa\"\n",
    "    ],\n",
    "\n",
    "    # ---- Stress Response ----\n",
    "    \"SR-ARE\": [\n",
    "        \"Sulforaphane\", \"tert-Butylhydroquinone\", \"Diethyl maleate\",\n",
    "        \"Menadione\", \"Dimethyl fumarate\", \"Bardoxolone methyl\",\n",
    "        \"Curcumin\", \"Resveratrol\", \"p-Benzoquinone\", \"Oltipraz\", \"Caffeic acid phenethyl ester\"\n",
    "    ],\n",
    "    \"SR-ATAD5\": [  # replication stress / fork stalling\n",
    "        \"Hydroxyurea\", \"Aphidicolin\", \"Camptothecin\", \"Etoposide\",\n",
    "        \"Gemcitabine\", \"Cytarabine\", \"Mitomycin C\", \"Cladribine\",\n",
    "        \"Topotecan\", \"Irinotecan\"\n",
    "    ],\n",
    "    \"SR-HSE\": [  # heat shock response inducers (Hsp90 inhibitors, proteotoxic stress)\n",
    "        \"Geldanamycin\", \"17-AAG\", \"Radicicol\", \"Celastrol\",\n",
    "        \"Withaferin A\", \"MG-132\", \"Novobiocin\",\n",
    "        \"Tanespimycin\", \"Luminespib (NVP-AUY922)\", \"2-Deoxy-D-glucose\"\n",
    "    ],\n",
    "    \"SR-MMP\": [  # MMP inhibitors (hydroxamates etc.)\n",
    "        \"Batimastat\", \"Marimastat\", \"Ilomastat (GM6001)\", \"Prinomastat\",\n",
    "        \"CGS 27023A\", \"Tetracycline\", \"Doxycycline\",\n",
    "        \"Tanomastat (BAY 12-9566)\", \"Ro 28-2653\", \"EDTA-hydroxamate analog\"\n",
    "    ],\n",
    "    \"SR-p53\": [  # p53 stabilization/activation (DNA damage, MDM2 inhibition)\n",
    "        \"Nutlin-3a\", \"Doxorubicin\", \"Etoposide\", \"Camptothecin\",\n",
    "        \"Actinomycin D\", \"Mitoxantrone\", \"Cisplatin\",\n",
    "        \"5-Fluorouracil\", \"Bleomycin\", \"Neocarzinostatin\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Quick check\n",
    "for k, v in LABEL_TO_NAMES.items():\n",
    "    print(f\"{k:12s} {len(v):2d} names\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93b61ea",
   "metadata": {},
   "source": [
    "### 2b: esolve names â†’ canonical SMILES (PubChem), save JSON + CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20a7bf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving names via PubChem PUG REST and validating with RDKit...\n",
      "\n",
      "NR-AR:\n",
      "  resolved+kept: 12\n",
      "\n",
      "NR-AR-LBD:\n",
      "  resolved+kept: 10\n",
      "\n",
      "NR-AhR:\n",
      "  resolved+kept: 11\n",
      "\n",
      "NR-Aromatase:\n",
      "  resolved+kept: 10\n",
      "\n",
      "NR-ER:\n",
      "  resolved+kept: 11\n",
      "\n",
      "NR-ER-LBD:\n",
      "  resolved+kept: 10\n",
      "\n",
      "NR-PPAR-gamma:\n",
      "  !! PubChem miss: N-TZDpa\n",
      "  resolved+kept: 9\n",
      "\n",
      "SR-ARE:\n",
      "  resolved+kept: 11\n",
      "\n",
      "SR-ATAD5:\n",
      "  resolved+kept: 10\n",
      "\n",
      "SR-HSE:\n",
      "  resolved+kept: 9\n",
      "\n",
      "SR-MMP:\n",
      "  !! PubChem miss: Ilomastat (GM6001)\n",
      "  !! PubChem miss: Tanomastat (BAY 12-9566)\n",
      "  !! PubChem miss: EDTA-hydroxamate analog\n",
      "  resolved+kept: 6\n",
      "\n",
      "SR-p53:\n",
      "  resolved+kept: 9\n",
      "\n",
      "Saved JSON â†’ D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\implementation\\v2\\seed_smiles_hard.json\n",
      "Per-label CSVs â†’ D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\implementation\\v2\\actives_balanced\n",
      "\n",
      "=== Seed counts (balanced) ===\n",
      "        label  n  valid\n",
      "        NR-AR 12     12\n",
      "    NR-AR-LBD 10     10\n",
      "       NR-AhR 11     11\n",
      " NR-Aromatase 10     10\n",
      "        NR-ER 11     11\n",
      "    NR-ER-LBD 10     10\n",
      "NR-PPAR-gamma  9      9\n",
      "       SR-ARE 11     11\n",
      "     SR-ATAD5 10     10\n",
      "       SR-HSE  9      9\n",
      "       SR-MMP  6      6\n",
      "       SR-p53  9      9\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2b: resolve names â†’ Canonical SMILES (PubChem), validate, save, quick test ===\n",
    "import json, time, re, random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "import ssl\n",
    "\n",
    "# Folders\n",
    "ROOT    = Path(\"implementation\")\n",
    "V2_DIR  = ROOT / \"v2\"\n",
    "OUT_JSON = V2_DIR / \"seed_smiles_hard.json\"\n",
    "OUT_DIR  = V2_DIR / \"actives_balanced\"\n",
    "DIAG_DIR = V2_DIR / \"diagnostics\"\n",
    "for d in [V2_DIR, OUT_DIR, DIAG_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- PubChem helpers (PUG REST) ----------\n",
    "def _fetch(url: str, timeout: float = 20.0) -> str:\n",
    "    # permissive SSL for local notebooks; keep it simple\n",
    "    ctx = ssl.create_default_context()\n",
    "    with urllib.request.urlopen(url, timeout=timeout, context=ctx) as r:\n",
    "        return r.read().decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "def pubchem_name_to_cids(name: str, max_hits: int = 3) -> List[int]:\n",
    "    q = urllib.parse.quote(name)\n",
    "    url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/name/{q}/cids/TXT\"\n",
    "    try:\n",
    "        txt = _fetch(url)\n",
    "        cids = [int(x) for x in txt.strip().split() if x.strip().isdigit()]\n",
    "        return cids[:max_hits]\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def pubchem_cids_to_smiles(cids: List[int]) -> List[str]:\n",
    "    if not cids:\n",
    "        return []\n",
    "    ids = \",\".join(str(i) for i in cids)\n",
    "    url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{ids}/property/CanonicalSMILES/TXT\"\n",
    "    try:\n",
    "        txt = _fetch(url)\n",
    "        smi = [x.strip() for x in txt.splitlines() if x.strip()]\n",
    "        return smi\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def resolve_names_to_smiles(names: List[str], per_name_max: int = 1, sleep: float = 0.15) -> List[str]:\n",
    "    out = []\n",
    "    for nm in names:\n",
    "        cids = pubchem_name_to_cids(nm, max_hits=per_name_max)\n",
    "        smi  = pubchem_cids_to_smiles(cids)\n",
    "        if not smi:\n",
    "            print(f\"  !! PubChem miss: {nm}\")\n",
    "        else:\n",
    "            out.extend(smi[:per_name_max])\n",
    "        time.sleep(sleep)\n",
    "    # dedupe preserve order\n",
    "    seen, uniq = set(), []\n",
    "    for s in out:\n",
    "        if s not in seen:\n",
    "            seen.add(s); uniq.append(s)\n",
    "    return uniq\n",
    "\n",
    "# ---------- RDKit validation / filtering ----------\n",
    "def is_valid_smiles(s: str) -> bool:\n",
    "    return Chem.MolFromSmiles(s) is not None\n",
    "\n",
    "def organic_single_component(s: str) -> bool:\n",
    "    if \".\" in s:\n",
    "        return False\n",
    "    m = Chem.MolFromSmiles(s)\n",
    "    if m is None:\n",
    "        return False\n",
    "    metals = {3,4,11,12,13,19,20,30,31,37,38,47,55,56}\n",
    "    return all(a.GetAtomicNum() == 0 or a.GetAtomicNum() in {1,5,6,7,8,9,14,15,16,17,34,35,53}\n",
    "               or a.GetAtomicNum() not in metals\n",
    "               for a in m.GetAtoms())\n",
    "\n",
    "def sanitize_smiles_list(l: List[str], cap: int = 15) -> List[str]:\n",
    "    # valid, organic, unique, small salts removed, cap length\n",
    "    cleaned = []\n",
    "    seen = set()\n",
    "    for s in l:\n",
    "        if not is_valid_smiles(s): continue\n",
    "        if not organic_single_component(s): continue\n",
    "        if s in seen: continue\n",
    "        seen.add(s); cleaned.append(s)\n",
    "    random.shuffle(cleaned)\n",
    "    return cleaned[:cap]\n",
    "\n",
    "# ---------- Run resolution for all labels ----------\n",
    "from pprint import pprint\n",
    "all_label_to_smiles: Dict[str, List[str]] = {}\n",
    "\n",
    "print(\"Resolving names via PubChem PUG REST and validating with RDKit...\")\n",
    "for label, names in LABEL_TO_NAMES.items():\n",
    "    print(f\"\\n{label}:\")\n",
    "    smi = resolve_names_to_smiles(names, per_name_max=1)\n",
    "    smi = sanitize_smiles_list(smi, cap=15)   # keep up to 15 per label (balanced)\n",
    "    print(f\"  resolved+kept: {len(smi)}\")\n",
    "    all_label_to_smiles[label] = smi\n",
    "\n",
    "# ---------- Save master JSON + per-label CSVs ----------\n",
    "with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_label_to_smiles, f, indent=2)\n",
    "print(f\"\\nSaved JSON â†’ {OUT_JSON.resolve()}\")\n",
    "\n",
    "for label, smi in all_label_to_smiles.items():\n",
    "    pd.DataFrame({\"smiles\": smi}).to_csv(OUT_DIR / f\"{label}.csv\", index=False)\n",
    "print(f\"Per-label CSVs â†’ {OUT_DIR.resolve()}\")\n",
    "\n",
    "# ---------- Quick test report ----------\n",
    "rows = []\n",
    "for label, smi in all_label_to_smiles.items():\n",
    "    valid = sum(1 for s in smi if is_valid_smiles(s))\n",
    "    rows.append({\"label\": label, \"n\": len(smi), \"valid\": valid})\n",
    "df = pd.DataFrame(rows).sort_values(\"label\")\n",
    "df.to_csv(DIAG_DIR / \"seed_counts.csv\", index=False)\n",
    "print(\"\\n=== Seed counts (balanced) ===\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a38c72",
   "metadata": {},
   "source": [
    "### 2c: sanity check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c4890dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Seeds in actives_balanced ===\n",
      "        label  n  n_valid  n_unique              file note\n",
      "        NR-AR 12       12        12         NR-AR.csv     \n",
      "    NR-AR-LBD 10       10        10     NR-AR-LBD.csv     \n",
      "       NR-AhR 11       11        11        NR-AhR.csv     \n",
      " NR-Aromatase 10       10        10  NR-Aromatase.csv     \n",
      "        NR-ER 11       11        11         NR-ER.csv     \n",
      "    NR-ER-LBD 10       10        10     NR-ER-LBD.csv     \n",
      "NR-PPAR-gamma  9        9         9 NR-PPAR-gamma.csv     \n",
      "       SR-ARE 11       11        11        SR-ARE.csv     \n",
      "     SR-ATAD5 10       10        10      SR-ATAD5.csv     \n",
      "       SR-HSE  9        9         9        SR-HSE.csv     \n",
      "       SR-MMP  6        6         6        SR-MMP.csv     \n",
      "       SR-p53  9        9         9        SR-p53.csv     \n",
      "\n",
      "Labels needing top-up (<10 unique): ['NR-PPAR-gamma', 'SR-HSE', 'SR-MMP', 'SR-p53']\n",
      "\n",
      "NR-PPAR-gamma preview: ['CN(CCOC1=CC=C(C=C1)CC(C(=O)O)NC2=CC=CC=C2C(=O)C3=CC=CC=C3)C4=CC=CC=N4', 'CN(CCOC1=CC=C(C=C1)CC2C(=O)NC(=O)S2)C3=CC(=NC=N3)OC4=CC=C(C=C4)OC', 'CCCCCC=CC=C1C(C=CC1=O)CC=CCCCC(=O)O', 'CC1=C(C2=C(CCC(O2)(C)COC3=CC=C(C=C3)CC4C(=O)NC(=O)S4)C(=C1O)C)C', 'CN(CCOC1=CC=C(C=C1)CC2C(=O)NC(=O)S2)C3=CC=CC=N3']\n",
      "\n",
      "SR-HSE preview: ['CC1CC(C(C(C=C(C(C(C=CC=C(C(=O)NC2=CC(=O)C(=C(C1)C2=O)NCC=C)C)OC)OC(=O)N)C)C)O)OC', 'CC1=C(C=CC2=C1OC(=O)C(=C2O)NC(=O)C3=CC(=C(C=C3)O)CC=C(C)C)OC4C(C(C(C(O4)(C)C)OC)OC(=O)N)O', 'C(C=O)C(C(C(CO)O)O)O', 'CC1CC(C(C(C=C(C(C(C=CC=C(C(=O)NC2=CC(=O)C(=C(C1)C2=O)OC)C)OC)OC(=O)N)C)C)O)OC', 'CC1=C(C(=O)OC(C1)C(C)C2CCC3C2(CCC4C3CC5C6(C4(C(=O)C=CC6O)C)O5)C)CO']\n",
      "\n",
      "SR-MMP preview: ['CC1C2C(C3C(C(=O)C(=C(C3(C(=O)C2=C(C4=C1C=CC=C4O)O)O)O)C(=O)N)N(C)C)O', 'CC(C)CC(C(C(=O)NO)O)C(=O)NC(C(=O)NC)C(C)(C)C', 'CC(C)CC(C(CSC1=CC=CS1)C(=O)NO)C(=O)NC(CC2=CC=CC=C2)C(=O)NC', 'CC1(C(N(CCS1)S(=O)(=O)C2=CC=C(C=C2)OC3=CC=NC=C3)C(=O)NO)C', 'CC1(C2CC3C(C(=O)C(=C(C3(C(=O)C2=C(C4=C1C=CC=C4O)O)O)O)C(=O)N)N(C)C)O']\n",
      "\n",
      "SR-p53 preview: ['CC(C)OC1=C(C=CC(=C1)OC)C2=NC(C(N2C(=O)N3CCNC(=O)C3)C4=CC=C(C=C4)Cl)C5=CC=C(C=C5)Cl', 'CC1C(C(=O)NC(C(=O)N2CCCC2C(=O)N(CC(=O)N(C(C(=O)O1)C(C)C)C)C)C(C)C)NC(=O)C3=C4C(=C(C=C3)C)OC5=C(C(=O)C(=C(C5=N4)C(=O)NC6C(OC(=O)C(N(C(=O)CN(C(=O)C7CCCN7C(=O)C(NC6=O)C(C)C)C)C)C(C)C)C)N)C', 'C1=CC(=C2C(=C1NCCNCCO)C(=O)C3=C(C=CC(=C3C2=O)O)O)NCCNCCO', 'CC1OCC2C(O1)C(C(C(O2)OC3C4COC(=O)C4C(C5=CC6=C(C=C35)OCO6)C7=CC(=C(C(=C7)OC)O)OC)O)O', 'CC1C(C(C(C(O1)OC2C3CC#CC4C(O4)(C#CC3=CC2OC(=O)C5=C(C=CC6=C5C=C(C=C6C)OC)O)C7COC(=O)O7)NC)O)O']\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2c: sanity/diagnostics of per-label CSV seeds ===\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "ROOT    = Path(\"implementation\")\n",
    "OUT_DIR = ROOT / \"v2\" / \"actives_balanced\"\n",
    "\n",
    "assert OUT_DIR.exists(), f\"Missing {OUT_DIR}\"\n",
    "\n",
    "rows = []\n",
    "bad = []\n",
    "for p in sorted(OUT_DIR.glob(\"*.csv\")):\n",
    "    label = p.stem\n",
    "    try:\n",
    "        df = pd.read_csv(p)\n",
    "    except Exception as e:\n",
    "        rows.append({\"label\": label, \"n\": 0, \"n_valid\": 0, \"n_unique\": 0, \"file\": str(p.name), \"note\": f\"read_error:{e}\"})\n",
    "        continue\n",
    "    if \"smiles\" not in df.columns:\n",
    "        rows.append({\"label\": label, \"n\": len(df), \"n_valid\": 0, \"n_unique\": 0, \"file\": str(p.name), \"note\": \"no_smiles_col\"})\n",
    "        continue\n",
    "\n",
    "    smi = [str(x).strip() for x in df[\"smiles\"].tolist()]\n",
    "    valid = [s for s in smi if s and Chem.MolFromSmiles(s) is not None]\n",
    "    uniq = list(dict.fromkeys(valid))  # de-dupe preserve order\n",
    "\n",
    "    rows.append({\n",
    "        \"label\": label,\n",
    "        \"n\": len(smi),\n",
    "        \"n_valid\": len(valid),\n",
    "        \"n_unique\": len(uniq),\n",
    "        \"file\": p.name,\n",
    "        \"note\": \"\" if len(valid)==len(smi) else \"had_invalid_or_empty\"\n",
    "    })\n",
    "\n",
    "diag = pd.DataFrame(rows).sort_values(\"label\")\n",
    "print(\"=== Seeds in actives_balanced ===\")\n",
    "print(diag.to_string(index=False))\n",
    "\n",
    "need_topup = diag[diag[\"n_unique\"] < 10][\"label\"].tolist()\n",
    "print(\"\\nLabels needing top-up (<10 unique):\", need_topup if need_topup else \"None\")\n",
    "\n",
    "# Optional: peek at first few SMILES for any short label\n",
    "for lab in need_topup:\n",
    "    df = pd.read_csv(OUT_DIR / f\"{lab}.csv\")\n",
    "    print(f\"\\n{lab} preview:\", df[\"smiles\"].head(5).tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ce9e65",
   "metadata": {},
   "source": [
    "## 3: CAV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3630a44",
   "metadata": {},
   "source": [
    "### 3a: augment (PubChem similarity â†’ background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e22f6ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growing background per label (PubChem 20 per seed @ Tanimotoâ‰¥0.75 + RDKit small expansions + concept top-ups)â€¦\n",
      "NR-AR: seeds=12 -> augmented=33\n",
      "NR-AR-LBD: seeds=10 -> augmented=27\n",
      "NR-AhR: seeds=11 -> augmented=36\n",
      "NR-Aromatase: seeds=10 -> augmented=26\n",
      "NR-ER: seeds=11 -> augmented=35\n",
      "NR-ER-LBD: seeds=10 -> augmented=32\n",
      "NR-PPAR-gamma: seeds=9 -> augmented=31\n",
      "SR-ARE: seeds=11 -> augmented=30\n",
      "SR-ATAD5: seeds=10 -> augmented=29\n",
      "SR-HSE: seeds=9 -> augmented=24\n",
      "SR-MMP: seeds=6 -> augmented=22\n",
      "SR-p53: seeds=9 -> augmented=32\n",
      "\n",
      "=== Augmentation v2 done ===\n",
      "Total unique background molecules: 279\n",
      "Saved â†’ D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\implementation\\v2\\cav\\background_smiles_augmented.csv\n"
     ]
    }
   ],
   "source": [
    "# === Cell 3a-augment-v2: Grow background aggressively (PubChem + RDKit + concept top-ups) ===\n",
    "import json, time, random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import requests\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, rdMolDescriptors\n",
    "\n",
    "ROOT    = Path(\"implementation\")\n",
    "V2_DIR  = ROOT / \"v2\"\n",
    "CAV_DIR = V2_DIR / \"cav\"\n",
    "CAV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED_JSON     = V2_DIR / \"seed_smiles_hard.json\"          # your curated seeds\n",
    "OUT_BG_AUGCSV = CAV_DIR / \"background_smiles_augmented.csv\"\n",
    "\n",
    "SMARTS_PATH   = V2_DIR / \"smarts_lib\" / \"smarts_rules_final.json\"\n",
    "assert SMARTS_PATH.exists(), f\"Missing {SMARTS_PATH}\"\n",
    "rules_all: Dict[str, List[Dict]] = json.load(open(SMARTS_PATH, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "PUBCHEM_BASE = \"https://pubchem.ncbi.nlm.nih.gov/rest/pug\"\n",
    "MAX_ANALOGUES_PER_SEED = 20      # was 10\n",
    "SIM_THRESHOLD = 75               # was 85\n",
    "REQ_TIMEOUT   = 20\n",
    "SLEEP_BETWEEN = 0.20\n",
    "\n",
    "assert SEED_JSON.exists(), f\"Missing seeds file: {SEED_JSON}\"\n",
    "seed = json.load(open(SEED_JSON, \"r\"))\n",
    "\n",
    "def rd_valid(s: str) -> bool:\n",
    "    try:\n",
    "        return Chem.MolFromSmiles(s) is not None\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# --- RDKit light enumeration: tautomers + stereoisomers ---\n",
    "def rdkit_expand_small(smi: str, max_new: int = 6) -> List[str]:\n",
    "    out = set()\n",
    "    m = Chem.MolFromSmiles(smi)\n",
    "    if not m:\n",
    "        return []\n",
    "    try:\n",
    "        # 1) enumerate simple tautomers (very small set using Kekulize trick)\n",
    "        # (We keep it light: generate 3 kekule variants if possible)\n",
    "        out.add(Chem.MolToSmiles(m, isomericSmiles=True))\n",
    "        try:\n",
    "            Chem.Kekulize(m, clearAromaticFlags=True)\n",
    "            out.add(Chem.MolToSmiles(m, isomericSmiles=True))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # 2) stereoisomers (up to a small cap)\n",
    "        opts = AllChem.EnumerateStereoisomersOptions(tryEmbedding=False, maxIsomers=8)\n",
    "        isos = list(AllChem.EnumerateStereoisomers(m, options=opts))\n",
    "        for iso in isos[:max_new]:\n",
    "            out.add(Chem.MolToSmiles(iso, isomericSmiles=True))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return [x for x in out if rd_valid(x)][:max_new]\n",
    "\n",
    "# --- PubChem Similarity ---\n",
    "def pubchem_similar_cids(smiles: str, max_records: int = 20, threshold: int = 75) -> List[int]:\n",
    "    url = (\n",
    "        f\"{PUBCHEM_BASE}/compound/smiles/{requests.utils.quote(smiles, safe='')}\"\n",
    "        f\"/similarity/cids/JSON?Threshold={int(threshold)}&MaxRecords={int(max_records)}\"\n",
    "    )\n",
    "    try:\n",
    "        r = requests.get(url, timeout=REQ_TIMEOUT)\n",
    "        if r.status_code != 200:\n",
    "            return []\n",
    "        data = r.json()\n",
    "        cids = data.get(\"IdentifierList\", {}).get(\"CID\", [])\n",
    "        return cids if isinstance(cids, list) else []\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def pubchem_cids_to_smiles(cids: List[int]) -> List[str]:\n",
    "    out = []\n",
    "    if not cids:\n",
    "        return out\n",
    "    BATCH = 100\n",
    "    for i in range(0, len(cids), BATCH):\n",
    "        batch = cids[i:i+BATCH]\n",
    "        url = f\"{PUBCHEM_BASE}/compound/cid/{','.join(map(str,batch))}/property/IsomericSMILES/JSON\"\n",
    "        try:\n",
    "            r = requests.get(url, timeout=REQ_TIMEOUT)\n",
    "            if r.status_code != 200:\n",
    "                continue\n",
    "            data = r.json()\n",
    "            props = data.get(\"PropertyTable\", {}).get(\"Properties\", [])\n",
    "            for p in props:\n",
    "                smi = p.get(\"IsomericSMILES\", \"\")\n",
    "                if smi and rd_valid(smi):\n",
    "                    out.append(smi)\n",
    "        except Exception:\n",
    "            continue\n",
    "        time.sleep(SLEEP_BETWEEN)\n",
    "    return out\n",
    "\n",
    "# --- Targeted top-ups for sparse concepts (only added to labels that include the concept) ---\n",
    "concept_topups = {\n",
    "    \"Quinone\":         [\"O=C1C=CC(=O)C=CC1=O\", \"O=C1C=CC(=O)C=C1O\", \"O=C1C=CC(=O)C(O)=C1O\"],  # p-BQ, semiquinone-like\n",
    "    \"CarboxylicAcid\":  [\"OC(=O)C\", \"OC(=O)c1ccccc1\", \"OC(=O)CC\", \"OC(=O)C=C\", \"OC(=O)C1=CC=CC=C1\"],\n",
    "    \"Imide\":           [\"O=C1NC(=O)C=CC1=O\", \"O=C1NC(=O)CCC1=O\"],                            # maleimide, succinimide\n",
    "    \"AllylHalide\":     [\"C=CCCl\", \"C=CCBr\", \"C=CCI\"],\n",
    "    \"Pyridine\":        [\"n1ccccc1\", \"n1cccc(C)c1\", \"n1ccccn1\"],                               # pyridine, 4-methyl, diazine-like\n",
    "}\n",
    "\n",
    "# helper: which concepts each label has (from SMARTS library)\n",
    "label_to_concepts = {lab: sorted({r[\"name\"] for r in rules}) for lab, rules in rules_all.items()}\n",
    "\n",
    "# --- Build augmented background ---\n",
    "label_to_aug = {}\n",
    "print(\"Growing background per label (PubChem 20 per seed @ Tanimotoâ‰¥0.75 + RDKit small expansions + concept top-ups)â€¦\")\n",
    "\n",
    "for label, smiles_list in seed.items():\n",
    "    expanded = set()\n",
    "    # keep seeds\n",
    "    for s in smiles_list:\n",
    "        if rd_valid(s):\n",
    "            expanded.add(s)\n",
    "\n",
    "    # RDKit local small expansions\n",
    "    for s in list(expanded):\n",
    "        for x in rdkit_expand_small(s, max_new=6):\n",
    "            expanded.add(x)\n",
    "\n",
    "    # PubChem similarity (heavier)\n",
    "    for s in smiles_list:\n",
    "        cids = pubchem_similar_cids(s, max_records=MAX_ANALOGUES_PER_SEED, threshold=SIM_THRESHOLD)\n",
    "        time.sleep(SLEEP_BETWEEN)\n",
    "        if cids:\n",
    "            for smi in pubchem_cids_to_smiles(cids):\n",
    "                expanded.add(smi)\n",
    "\n",
    "    # concept-targeted top-ups (only if label contains that concept in its SMARTS)\n",
    "    concepts = set(label_to_concepts.get(label, []))\n",
    "    for cname, smi_list in concept_topups.items():\n",
    "        if cname in concepts:\n",
    "            for s in smi_list:\n",
    "                if rd_valid(s):\n",
    "                    expanded.add(s)\n",
    "\n",
    "    label_to_aug[label] = sorted(expanded)\n",
    "    print(f\"{label}: seeds={len(smiles_list)} -> augmented={len(label_to_aug[label])}\")\n",
    "\n",
    "# merge + dedupe across labels, keep first label as origin\n",
    "bg_smiles, bg_origin, seen = [], [], set()\n",
    "for lab, smi_list in label_to_aug.items():\n",
    "    for s in smi_list:\n",
    "        if s not in seen:\n",
    "            seen.add(s)\n",
    "            bg_smiles.append(s)\n",
    "            bg_origin.append(lab)\n",
    "\n",
    "bg_df = pd.DataFrame({\"smiles\": bg_smiles, \"origin_label\": bg_origin})\n",
    "bg_df.to_csv(OUT_BG_AUGCSV, index=False)\n",
    "\n",
    "print(\"\\n=== Augmentation v2 done ===\")\n",
    "print(f\"Total unique background molecules: {len(bg_df)}\")\n",
    "print(f\"Saved â†’ {OUT_BG_AUGCSV.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b04d67c",
   "metadata": {},
   "source": [
    "### 3a-boost concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c01a029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background molecules: 279 -> 294 (+15) added targeted seeds.\n",
      "\n",
      "SMARTS counts per label (selected concepts):\n",
      " NR-AhR      Quinone= 3   Imide= 0\n",
      " SR-ARE      Quinone= 3   Imide= 0\n",
      " SR-ATAD5    Quinone= 0   Imide= 3\n",
      " SR-HSE      Quinone= 3   Imide= 0\n",
      " SR-p53      Quinone= 0   Imide= 3\n",
      "\n",
      "Patched SMARTS file â†’ D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\implementation\\v2\\smarts_lib\\smarts_rules_final.json\n",
      "Patched background  â†’ D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\implementation\\v2\\cav\\background_smiles_augmented.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:22:45] Explicit valence for atom # 8 N, 4, is greater than permitted\n"
     ]
    }
   ],
   "source": [
    "# === Cell 3a-boost-concepts: add targeted seeds + broaden SMARTS for sparse concepts ===\n",
    "import json, collections\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "ROOT    = Path(\"implementation\")\n",
    "V2_DIR  = ROOT / \"v2\"\n",
    "CAV_DIR = V2_DIR / \"cav\"\n",
    "BG_AUG  = CAV_DIR / \"background_smiles_augmented.csv\"\n",
    "SMARTS  = V2_DIR / \"smarts_lib\" / \"smarts_rules_final.json\"\n",
    "\n",
    "assert BG_AUG.exists(), f\"Missing background: {BG_AUG}. Run 3a-augment-v2 first.\"\n",
    "assert SMARTS.exists(), f\"Missing SMARTS lib: {SMARTS}.\"\n",
    "\n",
    "# --- Load current background ---\n",
    "bg = pd.read_csv(BG_AUG)\n",
    "bg[\"smiles\"] = bg[\"smiles\"].astype(str)\n",
    "bg[\"origin_label\"] = bg[\"origin_label\"].astype(str)\n",
    "\n",
    "def valid(s): \n",
    "    try: return Chem.MolFromSmiles(s) is not None\n",
    "    except Exception: return False\n",
    "\n",
    "# === 1) Targeted extra seeds for sparse concepts ===\n",
    "# We add them to the labels where they matter:\n",
    "extra_seeds = {\n",
    "    # Quinone family\n",
    "    \"NR-AhR\":  [\"O=C1C=CC(=O)C=CC1=O\",  # p-BQ\n",
    "                \"O=C1C=CC(=O)c2ccccc21\", # 1,4-naphthoquinone\n",
    "                \"CC(=O)C1=CC(=O)C(=O)C=C1C\", # menadione-like\n",
    "                \"O=C1C(=O)C2=CC=CC=C2C=C1O\"], # lawsone-like\n",
    "    \"SR-ARE\":  [\"O=C1C=CC(=O)C=CC1=O\",\n",
    "                \"O=C1C=CC(=O)c2ccccc21\",\n",
    "                \"O=C1C(=O)C2=CC=CC=C2C=C1O\",\n",
    "                \"CC1=CC(=O)C(=O)C=C1C\"],     # duroquinone-like\n",
    "    \"SR-HSE\":  [\"O=C1C=CC(=O)C=CC1=O\",\n",
    "                \"O=C1C=CC(=O)c2ccccc21\",\n",
    "                \"O=C1C(=O)C2=CC=CC=C2C=C1O\"],\n",
    "\n",
    "    # Imide family\n",
    "    \"SR-ATAD5\": [\"O=C1NC(=O)CCC1=O\",   # succinimide variant\n",
    "                 \"O=C1NC(=O)C=CC1=O\", # maleimide\n",
    "                 \"O=C1NC(=O)CCCN1=O\", # glutarimide-like\n",
    "                 \"O=C1NC(=O)c2ccccc21\"], # phthalimide\n",
    "    \"SR-p53\":  [\"O=C1NC(=O)C=CC1=O\",  # maleimide\n",
    "                \"O=C1NC(=O)CCC1=O\",  # succinimide\n",
    "                \"O=C1NC(=O)c2ccccc21\", # phthalimide\n",
    "                \"CN1C(=O)C=CC(=O)N1\"], # N-methyl imide\n",
    "}\n",
    "\n",
    "# Append to background (dedup)\n",
    "before_n = len(bg)\n",
    "seen = set(zip(bg[\"smiles\"], bg[\"origin_label\"]))\n",
    "\n",
    "rows = []\n",
    "for lab, smi_list in extra_seeds.items():\n",
    "    for s in smi_list:\n",
    "        if valid(s):\n",
    "            key = (s, lab)\n",
    "            if key not in seen:\n",
    "                rows.append({\"smiles\": s, \"origin_label\": lab})\n",
    "                seen.add(key)\n",
    "\n",
    "if rows:\n",
    "    bg = pd.concat([bg, pd.DataFrame(rows)], ignore_index=True).drop_duplicates([\"smiles\",\"origin_label\"])\n",
    "    bg.to_csv(BG_AUG, index=False)\n",
    "\n",
    "print(f\"Background molecules: {before_n} -> {len(bg)} (+{len(rows)}) added targeted seeds.\")\n",
    "\n",
    "# === 2) Broaden SMARTS for Quinone and Imide ===\n",
    "rules_all = json.load(open(SMARTS, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "# New patterns (kept reasonably specific)\n",
    "new_smarts_by_name = {\n",
    "    \"Quinone\": [\n",
    "        \"O=C1C=CC(=O)C=CC1=O\",        # p-benzoquinone\n",
    "        \"O=C1C(=O)c2ccccc21\",         # 1,2-naphthoquinone-ish (ortho-like fused)\n",
    "        \"O=C1C=CC(=O)c2ccccc21\",      # 1,4-naphthoquinone\n",
    "    ],\n",
    "    \"Imide\": [\n",
    "        \"O=C1NC(=O)C=CC1=O\",          # maleimide\n",
    "        \"O=C1NC(=O)CCC1=O\",           # succinimide\n",
    "        \"[CX3](=O)N[CX3](=O)\",        # generic imide core (acyclic too)\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Apply only to labels that currently include that concept\n",
    "def append_unique_rule(label: str, name: str, smarts: str, source: str = \"boost\"):\n",
    "    arr = rules_all.get(label, [])\n",
    "    # skip if exact smarts already present for same name\n",
    "    for r in arr:\n",
    "        if r.get(\"name\")==name and r.get(\"smarts\")==smarts:\n",
    "            return\n",
    "    arr.append({\"name\": name, \"smarts\": smarts, \"source\": source})\n",
    "    rules_all[label] = arr\n",
    "\n",
    "# Identify labels affected (those with low counts you reported)\n",
    "labels_qu = [\"NR-AhR\", \"SR-ARE\", \"SR-HSE\"]\n",
    "labels_im = [\"SR-ATAD5\", \"SR-p53\"]\n",
    "\n",
    "for lab in labels_qu:\n",
    "    for s in new_smarts_by_name[\"Quinone\"]:\n",
    "        append_unique_rule(lab, \"Quinone\", s, source=\"boost\")\n",
    "\n",
    "for lab in labels_im:\n",
    "    for s in new_smarts_by_name[\"Imide\"]:\n",
    "        append_unique_rule(lab, \"Imide\", s, source=\"boost\")\n",
    "\n",
    "# Save back\n",
    "with open(SMARTS, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(rules_all, f, indent=2)\n",
    "\n",
    "# Print short diff summary\n",
    "def count_by_label_name(rules):\n",
    "    cnt = collections.defaultdict(lambda: collections.Counter())\n",
    "    for lab, arr in rules.items():\n",
    "        for r in arr:\n",
    "            cnt[lab][r[\"name\"]] += 1\n",
    "    return cnt\n",
    "\n",
    "cnt = count_by_label_name(rules_all)\n",
    "print(\"\\nSMARTS counts per label (selected concepts):\")\n",
    "for lab in sorted(set(labels_qu + labels_im)):\n",
    "    c = cnt[lab]\n",
    "    print(f\" {lab:10s}  Quinone={c['Quinone']:2d}   Imide={c['Imide']:2d}\")\n",
    "print(f\"\\nPatched SMARTS file â†’ {SMARTS.resolve()}\")\n",
    "print(f\"Patched background  â†’ {BG_AUG.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546795cc",
   "metadata": {},
   "source": [
    "### 3a-embed (re-run masks + embeddings, prefer augmented CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc1fab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using augmented background: implementation\\v2\\cav\\background_smiles_augmented.csv\n",
      "Dropping 5 concepts with 0 positives in background.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339920e064d64f5b9bea83b89c60dede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding background:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cell 3a-embed-relaxed Summary ===\n",
      "Background size:  294\n",
      "Embedding dim:    768\n",
      "Concepts kept:    56 (dropped 5 zero-hit concepts)\n",
      "Saved: background_embeddings.npy, background_index.parquet, concept_index.csv, concept_masks.json\n",
      "\n",
      "âš ï¸ Concepts with <3 positives in background (n=4). Proceeding anyway, but interpret cautiously:\n",
      "                 concept_id    label  name            smarts  pos_count\n",
      "SR-ATAD5__Imide__f8009a7abc SR-ATAD5 Imide O=C1NC(=O)C=CC1=O          2\n",
      "SR-ATAD5__Imide__eea0051af6 SR-ATAD5 Imide  O=C1NC(=O)CCC1=O          2\n",
      "  SR-p53__Imide__4c44271489   SR-p53 Imide O=C1NC(=O)C=CC1=O          2\n",
      "  SR-p53__Imide__bec1aaceeb   SR-p53 Imide  O=C1NC(=O)CCC1=O          2\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# === Cell 3a-embed-relaxed: Rebuild masks + embeddings with augmented background; relax low-positive bar ===\n",
    "import os, json, time, hashlib, random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from rdkit import Chem\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "ROOT          = Path(\"implementation\")\n",
    "MODELS_ROOT   = ROOT / \"models\" / \"chemberta_v2\"\n",
    "MODEL_DIR     = MODELS_ROOT / \"v2_best\"\n",
    "V2_DIR        = ROOT / \"v2\"\n",
    "ACT_DIR       = V2_DIR / \"actives_balanced\"\n",
    "\n",
    "SMARTS_PATH   = V2_DIR / \"smarts_lib\" / \"smarts_rules_final.json\"\n",
    "AUG_BG_CSV    = V2_DIR / \"cav\" / \"background_smiles_augmented.csv\"\n",
    "\n",
    "CAV_DIR       = V2_DIR / \"cav\"\n",
    "CAV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE    = 64\n",
    "MAX_LEN       = 256\n",
    "SEED          = 42\n",
    "DEVICE        = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# model\n",
    "assert MODEL_DIR.exists(), f\"Missing model_dir: {MODEL_DIR}\"\n",
    "tok = AutoTokenizer.from_pretrained(str(MODEL_DIR))\n",
    "cfg = AutoConfig.from_pretrained(str(MODEL_DIR))\n",
    "mdl = AutoModelForSequenceClassification.from_pretrained(str(MODEL_DIR), config=cfg).to(DEVICE).eval()\n",
    "if hasattr(mdl.config, \"use_cache\"): mdl.config.use_cache = False\n",
    "id2label = mdl.config.id2label\n",
    "label_cols = [id2label[i] for i in range(len(id2label))]\n",
    "\n",
    "# SMARTS\n",
    "assert SMARTS_PATH.exists(), f\"Missing {SMARTS_PATH}\"\n",
    "rules_all: Dict[str, List[Dict]] = json.load(open(SMARTS_PATH, \"r\", encoding=\"utf-8\"))\n",
    "rules_all = {lab: rules for lab, rules in rules_all.items() if lab in set(label_cols)}\n",
    "\n",
    "# background source (augmented is preferred)\n",
    "if AUG_BG_CSV.exists():\n",
    "    print(\"Using augmented background:\", AUG_BG_CSV)\n",
    "    bg_df = pd.read_csv(AUG_BG_CSV)\n",
    "else:\n",
    "    raise FileNotFoundError(\"Augmented background not found. Run 3a-augment-v2 first.\")\n",
    "\n",
    "# Clean/validate\n",
    "bg_smiles_raw = bg_df[\"smiles\"].astype(str).tolist()\n",
    "bg_origin_raw = bg_df[\"origin_label\"].astype(str).tolist()\n",
    "bg_smiles, bg_origin = [], []\n",
    "for s, lab in zip(bg_smiles_raw, bg_origin_raw):\n",
    "    if Chem.MolFromSmiles(s):\n",
    "        bg_smiles.append(s); bg_origin.append(lab)\n",
    "bg_df = pd.DataFrame({\"smiles\": bg_smiles, \"origin_label\": bg_origin})\n",
    "bg_df.to_csv(CAV_DIR / \"background_smiles.csv\", index=False)\n",
    "\n",
    "# Concept masks\n",
    "concept_index_rows = []\n",
    "concept_masks: Dict[str, List[int]] = {}\n",
    "\n",
    "def concept_id(label: str, name: str, smarts: str) -> str:\n",
    "    key = f\"{label}|||{name}|||{smarts}\"\n",
    "    return f\"{label}__{name}__{hashlib.sha1(key.encode('utf-8')).hexdigest()[:10]}\"\n",
    "\n",
    "bg_mols = [Chem.MolFromSmiles(s) for s in bg_smiles]\n",
    "for lab, rules in rules_all.items():\n",
    "    for r in rules:\n",
    "        name = r.get(\"name\", \"Concept\")\n",
    "        s    = r.get(\"smarts\", \"\")\n",
    "        mm = Chem.MolFromSmarts(s)\n",
    "        if not mm:\n",
    "            continue\n",
    "        hits = [i for i, m in enumerate(bg_mols) if m.HasSubstructMatch(mm)]\n",
    "        cid = concept_id(lab, name, s)\n",
    "        concept_masks[cid] = hits\n",
    "        concept_index_rows.append({\"concept_id\": cid, \"label\": lab, \"name\": name, \"smarts\": s, \"pos_count\": len(hits)})\n",
    "\n",
    "concept_index = pd.DataFrame(concept_index_rows).sort_values([\"label\",\"pos_count\"], ascending=[True, False])\n",
    "\n",
    "# Drop ONLY zero-hit concepts (keep â‰¥1)\n",
    "zero = concept_index[concept_index[\"pos_count\"] == 0]\n",
    "if not zero.empty:\n",
    "    print(f\"Dropping {len(zero)} concepts with 0 positives in background.\")\n",
    "    drop_ids = set(zero[\"concept_id\"].tolist())\n",
    "    concept_index = concept_index[~concept_index[\"concept_id\"].isin(drop_ids)]\n",
    "    for cid in list(concept_masks.keys()):\n",
    "        if cid in drop_ids:\n",
    "            del concept_masks[cid]\n",
    "\n",
    "# Save masks/index\n",
    "concept_index_path = CAV_DIR / \"concept_index.csv\"\n",
    "concept_index.to_csv(concept_index_path, index=False)\n",
    "with open(CAV_DIR / \"concept_masks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(concept_masks, f)\n",
    "\n",
    "# Embeddings\n",
    "def cls_embed(smiles_list: List[str], batch_size: int = 64, max_len: int = 256) -> np.ndarray:\n",
    "    if not smiles_list:\n",
    "        return np.zeros((0, 768), dtype=np.float32)\n",
    "    vecs = []\n",
    "    for i in tqdm(range(0, len(smiles_list), batch_size), desc=\"Embedding background\"):\n",
    "        chunk = smiles_list[i:i+batch_size]\n",
    "        enc = tok(chunk, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_len).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            out = mdl(**enc, output_hidden_states=True)\n",
    "            last = out.hidden_states[-1]\n",
    "            cls  = last[:, 0, :]\n",
    "        vecs.append(cls.detach().cpu().numpy())\n",
    "    return np.concatenate(vecs, axis=0)\n",
    "\n",
    "emb = cls_embed(bg_smiles, batch_size=BATCH_SIZE, max_len=MAX_LEN).astype(np.float32)\n",
    "np.save(CAV_DIR / \"background_embeddings.npy\", emb)\n",
    "bg_df.to_parquet(CAV_DIR / \"background_index.parquet\", index=False)\n",
    "\n",
    "print(\"\\n=== Cell 3a-embed-relaxed Summary ===\")\n",
    "print(f\"Background size:  {len(bg_smiles)}\")\n",
    "print(f\"Embedding dim:    {emb.shape[1] if emb.size else 0}\")\n",
    "print(f\"Concepts kept:    {len(concept_index)} (dropped {len(zero)} zero-hit concepts)\")\n",
    "print(f\"Saved: background_embeddings.npy, background_index.parquet, concept_index.csv, concept_masks.json\")\n",
    "\n",
    "# Report low-but-nonzero hits (for awareness only)\n",
    "low = concept_index[concept_index[\"pos_count\"] < 3]\n",
    "if not low.empty:\n",
    "    print(f\"\\nâš ï¸ Concepts with <3 positives in background (n={len(low)}). Proceeding anyway, but interpret cautiously:\")\n",
    "    print(low.head(15).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9a6477",
   "metadata": {},
   "source": [
    "### 3b: tcav fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad3ce5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9cf47cf015d45daac490f2d32a9979c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring background:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Cell 3b: TCAV with per-label eval sets and coverage filtering ===\n",
    "import json, math, random, time, hashlib\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "# -----------------------\n",
    "# Paths & config\n",
    "# -----------------------\n",
    "ROOT          = Path(\"implementation\")\n",
    "V2_DIR        = ROOT / \"v2\"\n",
    "CAV_DIR       = V2_DIR / \"cav\"\n",
    "\n",
    "MODEL_DIR     = ROOT / \"models\" / \"chemberta_v2\" / \"v2_best\"\n",
    "SMARTS_PATH   = V2_DIR / \"smarts_lib\" / \"smarts_rules_final.json\"  # <- from your 3a\n",
    "BG_EMB_NPY    = CAV_DIR / \"background_embeddings.npy\"\n",
    "BG_INDEX_PARQ = CAV_DIR / \"background_index.parquet\"\n",
    "MASKS_JSON    = CAV_DIR / \"concept_masks.json\"\n",
    "\n",
    "OUT_CSV       = CAV_DIR / \"tcav_summary_recomp_v2concepts_k10.csv\"\n",
    "OUT_JSON      = CAV_DIR / \"tcav_summary_recomp_v2concepts_k10.json\"\n",
    "\n",
    "DEVICE        = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SEED          = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# --- TCAV settings ---\n",
    "N_NULL          = 50           # number of random CAVs per concept\n",
    "MIN_POS         = 3            # drop concept if fewer than this many positives in background\n",
    "MAX_COVERAGE    = 0.85         # drop concept if matches >85% of background (too generic)\n",
    "NEG_PER_POS     = 1.5          # negatives ~1.5x positives (clipped)\n",
    "EVAL_TOP_K      = 80           # per-label eval set size = top-K by model prob (clips if smaller)\n",
    "BATCH_GRAD      = 64\n",
    "MAX_LEN         = 256\n",
    "\n",
    "# -----------------------\n",
    "# Load artifacts\n",
    "# -----------------------\n",
    "assert MODEL_DIR.exists(), f\"Missing model dir: {MODEL_DIR}\"\n",
    "tok = AutoTokenizer.from_pretrained(str(MODEL_DIR))\n",
    "cfg = AutoConfig.from_pretrained(str(MODEL_DIR))\n",
    "mdl = AutoModelForSequenceClassification.from_pretrained(str(MODEL_DIR), config=cfg).to(DEVICE).eval()\n",
    "if hasattr(mdl.config, \"use_cache\"): mdl.config.use_cache = False\n",
    "\n",
    "id2label   = mdl.config.id2label\n",
    "label_cols = [id2label[i] for i in range(len(id2label))]\n",
    "\n",
    "assert BG_EMB_NPY.exists(), \"Run 3a first (embeddings).\"\n",
    "assert BG_INDEX_PARQ.exists(), \"Run 3a first (index).\"\n",
    "assert MASKS_JSON.exists(), \"Run 3a first (concept masks).\"\n",
    "\n",
    "bg_emb   = np.load(BG_EMB_NPY)                    # [N, H]\n",
    "bg_index = pd.read_parquet(BG_INDEX_PARQ)         # columns: smiles, origin_label\n",
    "with open(MASKS_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    mask_map: Dict[str, List[int]] = json.load(f)\n",
    "\n",
    "N, H = bg_emb.shape\n",
    "bg_smiles = bg_index[\"smiles\"].astype(str).tolist()\n",
    "assert len(bg_smiles) == N, \"Index and embeddings out of sync.\"\n",
    "\n",
    "# -----------------------\n",
    "# Helpers\n",
    "# -----------------------\n",
    "def _normalize(v: np.ndarray) -> np.ndarray:\n",
    "    n = np.linalg.norm(v) + 1e-12\n",
    "    return v / n\n",
    "\n",
    "def make_cav(pos_idx: List[int], neg_idx: List[int]) -> np.ndarray:\n",
    "    pos = bg_emb[pos_idx].mean(axis=0)\n",
    "    neg = bg_emb[neg_idx].mean(axis=0)\n",
    "    return _normalize(pos - neg).astype(np.float32)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs_all(smiles: List[str], batch: int = 256, max_len: int = MAX_LEN) -> np.ndarray:\n",
    "    \"\"\"Return [N, L] probabilities for all labels.\"\"\"\n",
    "    outs = []\n",
    "    for i in tqdm(range(0, len(smiles), batch), desc=\"Scoring background\"):\n",
    "        chunk = smiles[i:i+batch]\n",
    "        enc = tok(chunk, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_len).to(DEVICE)\n",
    "        logits = mdl(**enc).logits\n",
    "        probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "        outs.append(probs)\n",
    "    return np.concatenate(outs, axis=0)\n",
    "\n",
    "def grads_wrt_cls(smiles_batch: List[str], label_idx: int, max_len: int = MAX_LEN) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Gradient of logit[label_idx] w.r.t. CLS (last hidden state). Returns [B, H].\n",
    "    \"\"\"\n",
    "    enc = tok(\n",
    "        smiles_batch,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_len\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    mdl.zero_grad(set_to_none=True)  # <-- fix here\n",
    "    out = mdl(**enc, output_hidden_states=True)   # forward\n",
    "    last = out.hidden_states[-1]                  # [B, T, H]\n",
    "    last.retain_grad()                            # track grads\n",
    "\n",
    "    logits = out.logits                           # [B, L]\n",
    "    target = logits[:, label_idx].sum()           # scalar target\n",
    "    target.backward()                             # backprop\n",
    "\n",
    "    g = last.grad[:, 0, :].detach().cpu().numpy() # [B, H] CLS grads\n",
    "    mdl.zero_grad(set_to_none=True)               # clean up\n",
    "    return g\n",
    "\n",
    "\n",
    "def tcav_for_label(eval_smiles: List[str], cav_vec: np.ndarray, label_idx: int) -> Tuple[float, np.ndarray]:\n",
    "    \"\"\"Return (tcav_score, directional_derivatives).\"\"\"\n",
    "    dds = []\n",
    "    for i in range(0, len(eval_smiles), BATCH_GRAD):\n",
    "        chunk = eval_smiles[i:i+BATCH_GRAD]\n",
    "        g = grads_wrt_cls(chunk, label_idx)                 # [B, H]\n",
    "        dd = (g @ cav_vec.reshape(-1, 1)).squeeze(1)        # dot(grad, cav)\n",
    "        dds.append(dd)\n",
    "    dds = np.concatenate(dds, axis=0) if dds else np.zeros((0,), dtype=np.float32)\n",
    "    score = float((dds > 0).mean()) if dds.size else np.nan\n",
    "    return score, dds\n",
    "\n",
    "def binom_pval(k, n, p0=0.5):\n",
    "    # two-sided binomial using normal approximation with continuity correction (good for n>=30)\n",
    "    if n == 0: return 1.0\n",
    "    prop = k / n\n",
    "    if n < 30:\n",
    "        # fallback: exact (scipy would be ideal; approximate here)\n",
    "        # simple conservative: p = 2 * min(BinomCDF(k), 1-BinomCDF(k-1)) â†’ we approximate with normal anyway\n",
    "        z = (prop - p0) / math.sqrt(p0*(1-p0)/n)\n",
    "        return float(2*min(0.5*(1+math.erf(-abs(z)/math.sqrt(2))), 0.999999))\n",
    "    z = (prop - p0) / math.sqrt(p0*(1-p0)/n)\n",
    "    return float(2*min(0.5*(1+math.erf(-abs(z)/math.sqrt(2))), 0.999999))\n",
    "\n",
    "# -----------------------\n",
    "# Build per-label eval sets (top-K by model prob)\n",
    "# -----------------------\n",
    "probs_bg = predict_probs_all(bg_smiles)        # [N, L]\n",
    "label_to_eval_idx: Dict[str, List[int]] = {}\n",
    "for li, lb in enumerate(label_cols):\n",
    "    order = np.argsort(-probs_bg[:, li])       # descending\n",
    "    keep = order[:min(EVAL_TOP_K, len(order))]\n",
    "    label_to_eval_idx[lb] = keep.tolist()\n",
    "\n",
    "print(\"\\nPer-label eval set sizes (top-K by prob):\")\n",
    "for lb in label_cols:\n",
    "    print(f\" - {lb}: {len(label_to_eval_idx[lb])}\")\n",
    "\n",
    "# -----------------------\n",
    "# Iterate concepts â†’ build CAV â†’ per-label TCAV + nulls\n",
    "# -----------------------\n",
    "rows = []\n",
    "num_kept = 0\n",
    "num_dropped_low = 0\n",
    "num_dropped_cov = 0\n",
    "\n",
    "for cid, pos_idx in tqdm(mask_map.items(), desc=\"Concepts\"):\n",
    "    # parse meta from concept_id: label__name__hash\n",
    "    try:\n",
    "        c_label, c_name, _ = cid.split(\"__\", 2)\n",
    "    except Exception:\n",
    "        c_label, c_name = \"?\", cid\n",
    "\n",
    "    pos_idx = sorted(set(int(i) for i in pos_idx if 0 <= int(i) < N))\n",
    "    n_pos = len(pos_idx)\n",
    "    coverage = n_pos / max(N, 1)\n",
    "    if n_pos < MIN_POS:\n",
    "        num_dropped_low += 1\n",
    "        continue\n",
    "    if coverage > MAX_COVERAGE:\n",
    "        num_dropped_cov += 1\n",
    "        continue\n",
    "\n",
    "    # negatives = background indices not in pos\n",
    "    neg_pool = np.setdiff1d(np.arange(N), np.asarray(pos_idx, dtype=int))\n",
    "    if neg_pool.size == 0:\n",
    "        num_dropped_low += 1\n",
    "        continue\n",
    "    n_neg = int(min(len(pos_idx)*NEG_PER_POS, neg_pool.size))\n",
    "    rng = np.random.default_rng(SEED)\n",
    "    neg_idx = rng.choice(neg_pool, size=n_neg, replace=False).tolist()\n",
    "\n",
    "    cav_vec = make_cav(pos_idx, neg_idx)   # [H]\n",
    "    num_kept += 1\n",
    "\n",
    "    # --- per-label TCAV ---\n",
    "    for li, lb in enumerate(label_cols):\n",
    "        eval_idx = label_to_eval_idx[lb]\n",
    "        eval_smiles = [bg_smiles[i] for i in eval_idx]\n",
    "        score, dds = tcav_for_label(eval_smiles, cav_vec, li)\n",
    "\n",
    "        # nulls: random CAVs with same pos size\n",
    "        null_scores = []\n",
    "        for _ in range(N_NULL):\n",
    "            # sample random positives and negatives of same size\n",
    "            r_pos = rng.choice(np.arange(N), size=len(pos_idx), replace=False)\n",
    "            r_neg_pool = np.setdiff1d(np.arange(N), r_pos)\n",
    "            if r_neg_pool.size == 0: continue\n",
    "            r_neg = rng.choice(r_neg_pool, size=min(n_neg, r_neg_pool.size), replace=False)\n",
    "            r_cav = make_cav(r_pos.tolist(), r_neg.tolist())\n",
    "            s, _ = tcav_for_label(eval_smiles, r_cav, li)\n",
    "            if not np.isnan(s):\n",
    "                null_scores.append(s)\n",
    "        null_scores = np.asarray(null_scores, float)\n",
    "        if null_scores.size == 0:\n",
    "            p_val = binom_pval(int(round(score * len(eval_smiles))), len(eval_smiles), p0=0.5)\n",
    "        else:\n",
    "            # one-sided: P(null >= observed); two-sided can be 2*min(...)\n",
    "            p_val = float(max(1.0 / (len(null_scores)+1), (null_scores >= score).mean()))\n",
    "\n",
    "        rows.append({\n",
    "            \"label\": lb,                 # prediction label (logit index)\n",
    "            \"concept\": c_name,           # concept name\n",
    "            \"concept_label\": c_label,    # the label namespace the concept came from\n",
    "            \"tcav_mean\": float(score),\n",
    "            \"p_value\": float(p_val),\n",
    "            \"n_eval\": int(len(eval_smiles)),\n",
    "            \"n_pos\": int(n_pos),\n",
    "            \"coverage\": float(coverage),\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df = df.sort_values([\"label\",\"tcav_mean\",\"p_value\"], ascending=[True, False, True])\n",
    "\n",
    "# --- save\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json.loads(df.to_json(orient=\"records\")), f)\n",
    "\n",
    "print(\"\\n=== 3b done ===\")\n",
    "print(f\"Concepts kept: {num_kept}  |  dropped low-pos: {num_dropped_low}  |  dropped high-coverage: {num_dropped_cov}\")\n",
    "print(f\"Rows written: {len(df)}\")\n",
    "print(f\"Saved: {OUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baca2189",
   "metadata": {},
   "source": [
    "### 3b: tcav report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b531f37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Per-label TCAV summary ===\n",
      "        label  total  drivers  counters  tcav_min  tcav_max\n",
      "        NR-AR     56       28         0       0.0       1.0\n",
      "    NR-AR-LBD     56       39         0       0.0       1.0\n",
      "       NR-AhR     56       31         0       0.0       1.0\n",
      " NR-Aromatase     56       34         0       0.0       1.0\n",
      "        NR-ER     56       33         0       0.0       1.0\n",
      "    NR-ER-LBD     56       29         0       0.0       1.0\n",
      "NR-PPAR-gamma     56       38         0       0.0       1.0\n",
      "       SR-ARE     56       31         0       0.0       1.0\n",
      "     SR-ATAD5     56       35         0       0.0       1.0\n",
      "       SR-HSE     56       28         0       0.0       1.0\n",
      "       SR-MMP     56       31         0       0.0       1.0\n",
      "       SR-p53     56       35         0       0.0       1.0\n",
      "\n",
      "=== Top concepts per label (driversâ†‘ and countersâ†“) ===\n",
      "        label       concept  tcav_mean  p_value  q_value  n_pos    kind\n",
      "        NR-AR         Ester        1.0 0.000074 0.002060     68  driver\n",
      "        NR-AR  AromaticRing        1.0 0.000060 0.002060    208  driver\n",
      "        NR-AR      Pyridine        1.0 0.000664 0.005918      6  driver\n",
      "        NR-AR         Nitro        0.0 0.995583 0.999870     12 counter\n",
      "        NR-AR       Quinone        0.0 0.994199 0.999870      5 counter\n",
      "    NR-AR-LBD TertiaryAmine        1.0 0.000006 0.000317     26  driver\n",
      "    NR-AR-LBD       Aniline        1.0 0.000086 0.001479     42  driver\n",
      "    NR-AR-LBD        Phenol        1.0 0.000102 0.001479    110  driver\n",
      "    NR-AR-LBD         Nitro        0.0 0.993948 0.997305     12 counter\n",
      "    NR-AR-LBD       Quinone        0.0 0.992522 0.997305      5 counter\n",
      "       NR-AhR      Pyridine        1.0 0.000102 0.002852      6  driver\n",
      "       NR-AhR        Phenol        1.0 0.000100 0.002852    110  driver\n",
      "       NR-AhR  AromaticRing        1.0 0.000187 0.003488    208  driver\n",
      "       NR-AhR         Ester        0.0 0.961949 0.999302     68 counter\n",
      "       NR-AhR       Quinone        0.0 0.986172 0.999302      3 counter\n",
      " NR-Aromatase    ArylHalide        1.0 0.000002 0.000114     21  driver\n",
      " NR-Aromatase  AromaticRing        1.0 0.000235 0.004051    208  driver\n",
      " NR-Aromatase         Ester        1.0 0.000289 0.004051     68  driver\n",
      " NR-Aromatase       Quinone        0.0 0.941762 0.999899      5 counter\n",
      " NR-Aromatase       Quinone        0.0 0.969286 0.999899      3 counter\n",
      "        NR-ER        Phenol        1.0 0.000595 0.008340    110  driver\n",
      "        NR-ER        Phenol        1.0 0.000679 0.008340    110  driver\n",
      "        NR-ER  AromaticRing        1.0 0.000745 0.008340    208  driver\n",
      "        NR-ER       Aniline        0.0 0.986928 0.999075     42 counter\n",
      "        NR-ER         Nitro        0.0 0.997439 0.999075     12 counter\n",
      "    NR-ER-LBD TertiaryAmine        1.0 0.000082 0.004588     26  driver\n",
      "    NR-ER-LBD        Phenol        1.0 0.000780 0.011137    110  driver\n",
      "    NR-ER-LBD  AromaticRing        1.0 0.000665 0.011137    208  driver\n",
      "    NR-ER-LBD         Nitro        0.0 0.970415 0.999869     12 counter\n",
      "    NR-ER-LBD       Quinone        0.0 0.997460 0.999869      5 counter\n",
      "NR-PPAR-gamma         Imide        1.0 0.000010 0.000555     33  driver\n",
      "NR-PPAR-gamma    ArylHalide        1.0 0.000101 0.001890     21  driver\n",
      "NR-PPAR-gamma  AromaticRing        1.0 0.000076 0.001890    208  driver\n",
      "NR-PPAR-gamma         Nitro        0.0 0.997911 0.999282     12 counter\n",
      "NR-PPAR-gamma   AllylHalide        0.0 0.999282 0.999282      4 counter\n",
      "       SR-ARE         Nitro        1.0 0.000021 0.001162     12  driver\n",
      "       SR-ARE    ArylHalide        1.0 0.000124 0.003471     21  driver\n",
      "       SR-ARE        Phenol        1.0 0.000553 0.006519    110  driver\n",
      "       SR-ARE       Quinone        0.0 0.977967 0.999989      5 counter\n",
      "       SR-ARE       Quinone        0.0 0.982019 0.999989      3 counter\n",
      "     SR-ATAD5    ArylHalide        1.0 0.000683 0.009561     21  driver\n",
      "     SR-ATAD5        Phenol        1.0 0.000661 0.009561    110  driver\n",
      "     SR-ATAD5  AromaticRing        1.0 0.000648 0.009561    208  driver\n",
      "     SR-ATAD5         Ester        0.0 0.959360 0.999906     68 counter\n",
      "     SR-ATAD5         Nitro        0.0 0.998184 0.999906     12 counter\n",
      "       SR-HSE  AromaticRing        1.0 0.000103 0.005760    208  driver\n",
      "       SR-HSE        Phenol        1.0 0.000579 0.008609    110  driver\n",
      "       SR-HSE         Ester        1.0 0.000413 0.008609     68  driver\n",
      "       SR-HSE       Quinone        0.0 0.992522 0.999996      5 counter\n",
      "       SR-HSE       Quinone        0.0 0.962504 0.999996      3 counter\n",
      "       SR-MMP    ArylHalide        1.0 0.000101 0.005670     21  driver\n",
      "       SR-MMP       Aniline        1.0 0.000220 0.006148     42  driver\n",
      "       SR-MMP        Phenol        1.0 0.000559 0.009384    110  driver\n",
      "       SR-MMP       Quinone        0.0 0.916075 0.999899      5 counter\n",
      "       SR-MMP       Quinone        0.0 0.997354 0.999899      3 counter\n",
      "       SR-p53        Phenol        1.0 0.000004 0.000239    110  driver\n",
      "       SR-p53 TertiaryAmine        1.0 0.000120 0.003367     26  driver\n",
      "       SR-p53       Aniline        1.0 0.000661 0.003709     42  driver\n",
      "       SR-p53         Nitro        0.0 0.986146 0.999398     12 counter\n",
      "       SR-p53       Quinone        0.0 0.993189 0.999398      5 counter\n",
      "\n",
      "âš ï¸  Concepts with very low positive coverage in background (n_pos < 3):\n",
      "        label concept  tcav_mean  p_value  q_value  n_pos\n",
      "        NR-AR   Imide   0.000000 0.999124 0.999870      2\n",
      "        NR-AR   Imide   0.000000 0.999870 0.999870      2\n",
      "        NR-AR   Imide   0.000000 0.992074 0.999870      2\n",
      "        NR-AR   Imide   0.000000 0.961442 0.999870      2\n",
      "    NR-AR-LBD   Imide   0.000000 0.996085 0.997305      2\n",
      "    NR-AR-LBD   Imide   0.000000 0.997305 0.997305      2\n",
      "    NR-AR-LBD   Imide   0.000000 0.993830 0.997305      2\n",
      "    NR-AR-LBD   Imide   0.000000 0.992430 0.997305      2\n",
      "       NR-AhR   Imide   0.125850 0.982472 0.999302      2\n",
      "       NR-AhR   Imide   0.000000 0.997637 0.999302      2\n",
      "       NR-AhR   Imide   0.051020 0.901152 0.999302      2\n",
      "       NR-AhR   Imide   0.000000 0.959688 0.999302      2\n",
      " NR-Aromatase   Imide   0.000000 0.979847 0.999899      2\n",
      " NR-Aromatase   Imide   0.000000 0.973405 0.999899      2\n",
      " NR-Aromatase   Imide   0.000000 0.999278 0.999899      2\n",
      " NR-Aromatase   Imide   0.000000 0.983349 0.999899      2\n",
      "        NR-ER   Imide   0.000000 0.997634 0.999075      2\n",
      "        NR-ER   Imide   0.000000 0.992951 0.999075      2\n",
      "        NR-ER   Imide   0.000000 0.995425 0.999075      2\n",
      "        NR-ER   Imide   0.000000 0.997309 0.999075      2\n",
      "    NR-ER-LBD   Imide   0.000000 0.997480 0.999869      2\n",
      "    NR-ER-LBD   Imide   0.000000 0.999869 0.999869      2\n",
      "    NR-ER-LBD   Imide   0.000000 0.976013 0.999869      2\n",
      "    NR-ER-LBD   Imide   0.000000 0.992256 0.999869      2\n",
      "NR-PPAR-gamma   Imide   0.000000 0.995821 0.999282      2\n",
      "NR-PPAR-gamma   Imide   0.000000 0.992620 0.999282      2\n",
      "NR-PPAR-gamma   Imide   0.000000 0.992515 0.999282      2\n",
      "NR-PPAR-gamma   Imide   0.000000 0.964371 0.999282      2\n",
      "       SR-ARE   Imide   0.000000 0.999313 0.999989      2\n",
      "       SR-ARE   Imide   0.000000 0.999989 0.999989      2\n",
      "       SR-ARE   Imide   0.000000 0.997245 0.999989      2\n",
      "       SR-ARE   Imide   0.000000 0.997069 0.999989      2\n",
      "     SR-ATAD5   Imide   0.000000 0.992620 0.999906      2\n",
      "     SR-ATAD5   Imide   0.000000 0.999578 0.999906      2\n",
      "     SR-ATAD5   Imide   0.034014 0.996770 0.999906      2\n",
      "     SR-ATAD5   Imide   0.000000 0.999602 0.999906      2\n",
      "       SR-HSE   Imide   0.000000 0.987960 0.999996      2\n",
      "       SR-HSE   Imide   0.000000 0.985616 0.999996      2\n",
      "       SR-HSE   Imide   0.000000 0.999771 0.999996      2\n",
      "       SR-HSE   Imide   0.000000 0.999338 0.999996      2\n",
      "       SR-MMP   Imide   0.000000 0.994276 0.999899      2\n",
      "       SR-MMP   Imide   0.000000 0.998157 0.999899      2\n",
      "       SR-MMP   Imide   0.000000 0.968168 0.999899      2\n",
      "       SR-MMP   Imide   0.000000 0.979650 0.999899      2\n",
      "       SR-p53   Imide   0.000000 0.994307 0.999398      2\n",
      "       SR-p53   Imide   0.000000 0.992510 0.999398      2\n",
      "       SR-p53   Imide   0.000000 0.998587 0.999398      2\n",
      "       SR-p53   Imide   0.000000 0.992289 0.999398      2\n",
      "\n",
      "Files saved:\n",
      " - implementation\\v2\\cav\\tcav_summary_recomp_v2concepts_k10.csv\n",
      " - implementation\\v2\\cav\\tcav_summary_recomp_v2concepts_k10.json\n",
      " - implementation\\v2\\cav\\tcav_per_label_summary.csv            (per-label counts and ranges)\n",
      " - implementation\\v2\\cav\\tcav_significant.csv             (only significant drivers/counters)\n",
      " - implementation\\v2\\cav\\tcav_low_support.csv           (low-support concepts, if any)\n",
      "\n",
      "=== Quick sanity ===\n",
      "Total rows: 672  |  Unique labels: 12  |  Concepts: 15\n",
      "Significant drivers (tcavâ‰¥0.6, qâ‰¤0.05): 392\n",
      "Significant counters (tcavâ‰¤0.4, qâ‰¤0.05): 0\n"
     ]
    }
   ],
   "source": [
    "# === Cell 3c-tcav-report: summarize TCAV results and write clean outputs ===\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ROOT        = Path(\"implementation\")\n",
    "V2_DIR      = ROOT / \"v2\"\n",
    "CAV_DIR     = V2_DIR / \"cav\"\n",
    "TCAV_SUM_CSV  = CAV_DIR / \"tcav_summary_recomp_v2concepts_k10.csv\"\n",
    "TCAV_SUM_JSON = CAV_DIR / \"tcav_summary_recomp_v2concepts_k10.json\"\n",
    "\n",
    "assert TCAV_SUM_CSV.exists(), \"Run 3b-tcav-fit first.\"\n",
    "df = pd.read_csv(TCAV_SUM_CSV)\n",
    "\n",
    "# --- sanity: required cols ---\n",
    "required = {\"label\",\"concept\",\"tcav_mean\",\"p_value\"}\n",
    "missing = required - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"TCAV summary missing columns: {missing}\")\n",
    "\n",
    "# --- add q-values (BH per label) ---\n",
    "def bh_fdr(p):\n",
    "    p = np.asarray(p, float)\n",
    "    if p.size == 0:\n",
    "        return p\n",
    "    order = np.argsort(p)\n",
    "    ranks = np.arange(1, p.size+1)\n",
    "    q_sorted = (p[order] * p.size / ranks).clip(0, 1)\n",
    "    q_sorted = np.minimum.accumulate(q_sorted[::-1])[::-1]\n",
    "    out = np.empty_like(p)\n",
    "    out[order] = q_sorted\n",
    "    return out\n",
    "\n",
    "df[\"q_value\"] = np.nan\n",
    "for lb, sub in df.groupby(\"label\"):\n",
    "    idx = sub.index\n",
    "    df.loc[idx, \"q_value\"] = bh_fdr(sub[\"p_value\"].values)\n",
    "\n",
    "# --- optional: keep support columns if present ---\n",
    "if \"n_pos\" not in df.columns:\n",
    "    df[\"n_pos\"] = np.nan  # will be NaN if not provided by 3b\n",
    "\n",
    "# --- save back canonical files ---\n",
    "df.to_csv(TCAV_SUM_CSV, index=False)\n",
    "with open(TCAV_SUM_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json.loads(df.to_json(orient=\"records\")), f)\n",
    "\n",
    "# --- significance gates (tweak if you like) ---\n",
    "MIN_TCAV = 0.60     # keep drivers with >= 0.60\n",
    "MAX_Q    = 0.05     # BH-FDR <= 0.05\n",
    "NEG_GATE = 0.40     # keep counters with <= 0.40 (and sig)\n",
    "\n",
    "df[\"is_driver\"]  = (df[\"tcav_mean\"] >= MIN_TCAV) & (df[\"q_value\"] <= MAX_Q)\n",
    "df[\"is_counter\"] = (df[\"tcav_mean\"] <= NEG_GATE) & (df[\"q_value\"] <= MAX_Q)\n",
    "\n",
    "# --- per-label summary table ---\n",
    "summ = (df.groupby(\"label\")\n",
    "          .agg(total=(\"concept\",\"count\"),\n",
    "               drivers=(\"is_driver\",\"sum\"),\n",
    "               counters=(\"is_counter\",\"sum\"),\n",
    "               tcav_min=(\"tcav_mean\",\"min\"),\n",
    "               tcav_max=(\"tcav_mean\",\"max\"))\n",
    "          .reset_index()\n",
    "          .sort_values(\"label\"))\n",
    "\n",
    "print(\"=== Per-label TCAV summary ===\")\n",
    "print(summ.to_string(index=False))\n",
    "\n",
    "# --- top drivers & counters per label (head) ---\n",
    "tops = []\n",
    "for lb, sub in df.groupby(\"label\"):\n",
    "    top_pos = (sub.sort_values([\"tcav_mean\",\"q_value\"], ascending=[False, True])\n",
    "                   .head(3)[[\"label\",\"concept\",\"tcav_mean\",\"p_value\",\"q_value\",\"n_pos\"]])\n",
    "    top_neg = (sub.sort_values([\"tcav_mean\",\"q_value\"], ascending=[True, True])\n",
    "                   .head(2)[[\"label\",\"concept\",\"tcav_mean\",\"p_value\",\"q_value\",\"n_pos\"]])\n",
    "    tops.append(pd.concat([top_pos.assign(kind=\"driver\"),\n",
    "                           top_neg.assign(kind=\"counter\")], ignore_index=True))\n",
    "tops = pd.concat(tops, ignore_index=True)\n",
    "\n",
    "print(\"\\n=== Top concepts per label (driversâ†‘ and countersâ†“) ===\")\n",
    "print(tops.to_string(index=False))\n",
    "\n",
    "# --- low-support warnings (if n_pos available) ---\n",
    "low_support = df[(df[\"n_pos\"].notna()) & (df[\"n_pos\"] < 3)].copy()\n",
    "if not low_support.empty:\n",
    "    print(\"\\nâš ï¸  Concepts with very low positive coverage in background (n_pos < 3):\")\n",
    "    low_view = low_support.sort_values([\"label\",\"n_pos\",\"q_value\"])[\n",
    "        [\"label\",\"concept\",\"tcav_mean\",\"p_value\",\"q_value\",\"n_pos\"]\n",
    "    ]\n",
    "    print(low_view.to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo low-support concepts flagged (n_pos >= 3 or not provided).\")\n",
    "\n",
    "# --- write helper artifacts ---\n",
    "sig = df[(df[\"q_value\"] <= MAX_Q) & ((df[\"tcav_mean\"] >= MIN_TCAV) | (df[\"tcav_mean\"] <= NEG_GATE))].copy()\n",
    "sig_path = CAV_DIR / \"tcav_significant.csv\"\n",
    "sig.to_csv(sig_path, index=False)\n",
    "\n",
    "flags_path = CAV_DIR / \"tcav_low_support.csv\"\n",
    "low_support.to_csv(flags_path, index=False)\n",
    "\n",
    "summ_path = CAV_DIR / \"tcav_per_label_summary.csv\"\n",
    "summ.to_csv(summ_path, index=False)\n",
    "\n",
    "print(\"\\nFiles saved:\")\n",
    "print(f\" - {TCAV_SUM_CSV}\")\n",
    "print(f\" - {TCAV_SUM_JSON}\")\n",
    "print(f\" - {summ_path}            (per-label counts and ranges)\")\n",
    "print(f\" - {sig_path}             (only significant drivers/counters)\")\n",
    "print(f\" - {flags_path}           (low-support concepts, if any)\")\n",
    "\n",
    "# --- quick sanity numbers for your notebook record ---\n",
    "print(\"\\n=== Quick sanity ===\")\n",
    "print(f\"Total rows: {len(df)}  |  Unique labels: {df['label'].nunique()}  |  Concepts: {df['concept'].nunique()}\")\n",
    "print(f\"Significant drivers (tcavâ‰¥{MIN_TCAV}, qâ‰¤{MAX_Q}): {int(df['is_driver'].sum())}\")\n",
    "print(f\"Significant counters (tcavâ‰¤{NEG_GATE}, qâ‰¤{MAX_Q}): {int(df['is_counter'].sum())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98668c5a",
   "metadata": {},
   "source": [
    "## 4: discarding cav and using concept centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcdc457",
   "metadata": {},
   "source": [
    "### A: Build concept centroids (fast, one-time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c82cfba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Centroid build complete ===\n",
      "Background N:        294\n",
      "Concepts total:      56\n",
      "Valid centroids:     56\n",
      "Centroids dim:       (56, 768)\n",
      "Saved index CSV:     implementation\\v2\\cav\\concept_centroids_index.csv\n",
      "Saved centroids NPY: implementation\\v2\\cav\\concept_centroids.npy\n",
      "Saved centroids JSON:implementation\\v2\\cav\\concept_centroids.json\n"
     ]
    }
   ],
   "source": [
    "# === Cell A: Build concept centroids from background embeddings (FAST) ===\n",
    "import json, math\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ROOT       = Path(\"implementation\")\n",
    "V2_DIR     = ROOT / \"v2\"\n",
    "CAV_DIR    = V2_DIR / \"cav\"\n",
    "LIB_DIR    = V2_DIR / \"smarts_lib\"    # where you saved the curated SMARTS JSON\n",
    "LIB_JSON   = LIB_DIR / \"smarts_rules_final.json\"\n",
    "\n",
    "# produced by 3a:\n",
    "EMB_NPY    = CAV_DIR / \"background_embeddings.npy\"\n",
    "IDX_PARQ   = CAV_DIR / \"background_index.parquet\"\n",
    "MASKS_JSON = CAV_DIR / \"concept_masks.json\"\n",
    "\n",
    "# outputs here:\n",
    "CENTROIDS_JSON = CAV_DIR / \"concept_centroids.json\"\n",
    "CENTROIDS_NPY  = CAV_DIR / \"concept_centroids.npy\"   # dense array aligned to index\n",
    "INDEX_CSV      = CAV_DIR / \"concept_centroids_index.csv\"\n",
    "\n",
    "assert EMB_NPY.exists(), f\"Missing embeddings: {EMB_NPY}\"\n",
    "assert IDX_PARQ.exists(), f\"Missing background index: {IDX_PARQ}\"\n",
    "assert MASKS_JSON.exists(), f\"Missing concept masks: {MASKS_JSON}\"\n",
    "assert LIB_JSON.exists(), f\"Missing curated SMARTS library: {LIB_JSON}\"\n",
    "\n",
    "# Load background\n",
    "bg_emb = np.load(EMB_NPY)             # [N_bg, H]\n",
    "bg_ix  = pd.read_parquet(IDX_PARQ)    # ['smiles','origin_label']\n",
    "assert len(bg_emb) == len(bg_ix), \"Embeddings and index length mismatch.\"\n",
    "\n",
    "# Load masks (concept_id -> list[int]) and rules (for human-readable fields)\n",
    "concept_masks: Dict[str, List[int]] = json.load(open(MASKS_JSON, \"r\", encoding=\"utf-8\"))\n",
    "rules_all = json.load(open(LIB_JSON, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "# Build a mapping concept_id -> {label,name,smarts}\n",
    "# concept_id format made in 3a: f\"{label}__{name}__{sha10}\"\n",
    "cid_meta = {}\n",
    "for lab, rules in rules_all.items():\n",
    "    for r in rules:\n",
    "        # reconstruct the id like 3a did\n",
    "        name  = r[\"name\"]\n",
    "        smarts= r[\"smarts\"]\n",
    "        key   = f\"{lab}|||{name}|||{smarts}\"\n",
    "        import hashlib\n",
    "        h     = hashlib.sha1(key.encode(\"utf-8\")).hexdigest()[:10]\n",
    "        cid   = f\"{lab}__{name}__{h}\"\n",
    "        cid_meta[cid] = {\"label\": lab, \"name\": name, \"smarts\": smarts}\n",
    "\n",
    "# Compute centroids\n",
    "centroids = []\n",
    "rows = []\n",
    "H = bg_emb.shape[1]\n",
    "for cid, idxs in concept_masks.items():\n",
    "    idxs = [i for i in idxs if 0 <= i < len(bg_emb)]\n",
    "    n = len(idxs)\n",
    "    if n == 0:\n",
    "        # leave a zero vector; we'll mark as invalid\n",
    "        vec = np.zeros((H,), dtype=np.float32)\n",
    "        valid = False\n",
    "    else:\n",
    "        vec = bg_emb[idxs].mean(axis=0).astype(np.float32)\n",
    "        # L2-normalize for cosine usage later\n",
    "        norm = np.linalg.norm(vec) + 1e-12\n",
    "        vec = (vec / norm).astype(np.float32)\n",
    "        valid = True\n",
    "    meta = cid_meta.get(cid, {\"label\":\"_unknown\",\"name\":\"_unknown\",\"smarts\":\"_unknown\"})\n",
    "    rows.append({\n",
    "        \"concept_id\": cid,\n",
    "        \"label\": meta[\"label\"],\n",
    "        \"name\": meta[\"name\"],\n",
    "        \"smarts\": meta[\"smarts\"],\n",
    "        \"n_pos\": n,\n",
    "        \"valid\": bool(valid),\n",
    "    })\n",
    "    centroids.append(vec)\n",
    "\n",
    "centroids = np.vstack(centroids) if centroids else np.zeros((0, H), dtype=np.float32)\n",
    "df_index = pd.DataFrame(rows)\n",
    "df_index.to_csv(INDEX_CSV, index=False)\n",
    "np.save(CENTROIDS_NPY, centroids)\n",
    "\n",
    "# Also dump a json with small floats for portability\n",
    "pack = []\n",
    "for i, r in df_index.iterrows():\n",
    "    vec = centroids[i].tolist()\n",
    "    pack.append({\n",
    "        \"concept_id\": r[\"concept_id\"],\n",
    "        \"label\": r[\"label\"],\n",
    "        \"name\": r[\"name\"],\n",
    "        \"smarts\": r[\"smarts\"],\n",
    "        \"n_pos\": int(r[\"n_pos\"]),\n",
    "        \"valid\": bool(r[\"valid\"]),\n",
    "        \"centroid\": vec,\n",
    "    })\n",
    "with open(CENTROIDS_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(pack, f)\n",
    "\n",
    "print(\"=== Centroid build complete ===\")\n",
    "print(f\"Background N:        {len(bg_emb)}\")\n",
    "print(f\"Concepts total:      {len(df_index)}\")\n",
    "print(f\"Valid centroids:     {int(df_index['valid'].sum())}\")\n",
    "print(f\"Centroids dim:       {centroids.shape}\")\n",
    "print(f\"Saved index CSV:     {INDEX_CSV}\")\n",
    "print(f\"Saved centroids NPY: {CENTROIDS_NPY}\")\n",
    "print(f\"Saved centroids JSON:{CENTROIDS_JSON}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7920ad",
   "metadata": {},
   "source": [
    "### Score concepts for molecules & print mechanistic report (super fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dacaadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Mechanistic summary for `CCOc1ccc2nc(S(N)(=O)=O)sc2c1`\n",
      "\n",
      "**NR-AR** â€” top concepts:\n",
      "- Pyridine: cosine=0.273 â€” heteroaromatic ring providing hydrogen bond acceptor capabilities â€” relevant to NR-AR pathway/context.\n",
      "- Aniline: cosine=0.229 â€” aromatic amine potentially linked to metabolic liabilities â€” relevant to NR-AR pathway/context.\n",
      "- TertiaryAmine: cosine=0.194 â€” basic amine promoting cationic binding and membrane permeability â€” relevant to NR-AR pathway/context.\n",
      "\n",
      "**NR-AR-LBD** â€” top concepts:\n",
      "- Aniline: cosine=0.229 â€” aromatic amine potentially linked to metabolic liabilities â€” relevant to NR-AR-LBD pathway/context.\n",
      "- TertiaryAmine: cosine=0.194 â€” basic amine promoting cationic binding and membrane permeability â€” relevant to NR-AR-LBD pathway/context.\n",
      "- Phenol: cosine=0.207 â€” phenolic OH capable of hydrogen bonding and metabolic conjugation â€” relevant to NR-AR-LBD pathway/context.\n",
      "\n",
      "**NR-AhR** â€” top concepts:\n",
      "- Quinone: cosine=0.305 â€” redox-active scaffold often associated with ROS generation â€” relevant to NR-AhR pathway/context.\n",
      "- Quinone: cosine=0.299 â€” redox-active scaffold often associated with ROS generation â€” relevant to NR-AhR pathway/context.\n",
      "- Nitro: cosine=0.186 â€” nitro functionality linked to bioactivation and potential DNA/protein adducts â€” relevant to NR-AhR pathway/context.\n",
      "\n",
      "**NR-Aromatase** â€” top concepts:\n",
      "- Aniline: cosine=0.229 â€” aromatic amine potentially linked to metabolic liabilities â€” relevant to NR-Aromatase pathway/context.\n",
      "- Ester: cosine=0.194 â€” polar carbonyl/alkoxy modulating permeability and metabolism â€” relevant to NR-Aromatase pathway/context.\n",
      "- Phenol: cosine=0.207 â€” phenolic OH capable of hydrogen bonding and metabolic conjugation â€” relevant to NR-Aromatase pathway/context.\n",
      "\n",
      "**NR-ER** â€” top concepts:\n",
      "- Pyridine: cosine=0.273 â€” heteroaromatic ring providing hydrogen bond acceptor capabilities â€” relevant to NR-ER pathway/context.\n",
      "- Aniline: cosine=0.229 â€” aromatic amine potentially linked to metabolic liabilities â€” relevant to NR-ER pathway/context.\n",
      "- Ester: cosine=0.194 â€” polar carbonyl/alkoxy modulating permeability and metabolism â€” relevant to NR-ER pathway/context.\n",
      "\n",
      "**NR-ER-LBD** â€” top concepts:\n",
      "- Pyridine: cosine=0.273 â€” heteroaromatic ring providing hydrogen bond acceptor capabilities â€” relevant to NR-ER-LBD pathway/context.\n",
      "- Ester: cosine=0.194 â€” polar carbonyl/alkoxy modulating permeability and metabolism â€” relevant to NR-ER-LBD pathway/context.\n",
      "- Phenol: cosine=0.207 â€” phenolic OH capable of hydrogen bonding and metabolic conjugation â€” relevant to NR-ER-LBD pathway/context.\n",
      "\n",
      "**NR-PPAR-gamma** â€” top concepts:\n",
      "- TertiaryAmine: cosine=0.194 â€” basic amine promoting cationic binding and membrane permeability â€” relevant to NR-PPAR-gamma pathway/context.\n",
      "- Ester: cosine=0.194 â€” polar carbonyl/alkoxy modulating permeability and metabolism â€” relevant to NR-PPAR-gamma pathway/context.\n",
      "- AromaticRing: cosine=0.240 â€” planar Ï€-system enabling hydrophobic/Ï€â€“Ï€ interactions â€” relevant to NR-PPAR-gamma pathway/context.\n",
      "\n",
      "**SR-ARE** â€” top concepts:\n",
      "- MichaelAcceptor: cosine=0.244 â€” Î±,Î²-unsaturated system acting as a soft electrophile (Michael acceptor) â€” relevant to SR-ARE pathway/context.\n",
      "- Hydroquinone: cosine=0.217 â€” Hydroquinone motif characteristic for SR-ARE.\n",
      "- AllylHalide: cosine=0.277 â€” AllylHalide motif characteristic for SR-ARE.\n",
      "\n",
      "**SR-ATAD5** â€” top concepts:\n",
      "- Urea: cosine=0.278 â€” bifunctional H-bond donor/acceptor motif â€” relevant to SR-ATAD5 pathway/context.\n",
      "- Imide: cosine=0.331 â€” dicarbonyl motif influencing polarity and reactivity â€” relevant to SR-ATAD5 pathway/context.\n",
      "\n",
      "**SR-HSE** â€” top concepts:\n",
      "- Quinone: cosine=0.305 â€” redox-active scaffold often associated with ROS generation â€” relevant to SR-HSE pathway/context.\n",
      "- Quinone: cosine=0.299 â€” redox-active scaffold often associated with ROS generation â€” relevant to SR-HSE pathway/context.\n",
      "- AromaticRing: cosine=0.240 â€” planar Ï€-system enabling hydrophobic/Ï€â€“Ï€ interactions â€” relevant to SR-HSE pathway/context.\n",
      "\n",
      "**SR-MMP** â€” top concepts:\n",
      "- Hydroxamate: cosine=0.296 â€” Hydroxamate motif characteristic for SR-MMP.\n",
      "- AromaticRing: cosine=0.240 â€” planar Ï€-system enabling hydrophobic/Ï€â€“Ï€ interactions â€” relevant to SR-MMP pathway/context.\n",
      "\n",
      "**SR-p53** â€” top concepts:\n",
      "- Imide: cosine=0.331 â€” dicarbonyl motif influencing polarity and reactivity â€” relevant to SR-p53 pathway/context.\n",
      "- AllylHalide: cosine=0.277 â€” AllylHalide motif characteristic for SR-p53.\n",
      "- Nitro: cosine=0.186 â€” nitro functionality linked to bioactivation and potential DNA/protein adducts â€” relevant to SR-p53 pathway/context.\n",
      "\n",
      "(Scoring = cosine similarity to concept centroids, penalized for cross-label genericity.)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Cell B: Concept centroid scoring + mechanistic report (FAST, no gradients) ===\n",
    "import os, json, math\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "ROOT          = Path(\"implementation\")\n",
    "MODELS_ROOT   = ROOT / \"models\" / \"chemberta_v2\"\n",
    "MODEL_DIR     = MODELS_ROOT / \"v2_best\"\n",
    "\n",
    "V2_DIR        = ROOT / \"v2\"\n",
    "CAV_DIR       = V2_DIR / \"cav\"\n",
    "CENTROIDS_NPY = CAV_DIR / \"concept_centroids.npy\"\n",
    "INDEX_CSV     = CAV_DIR / \"concept_centroids_index.csv\"\n",
    "\n",
    "# Optional: richer text for concept names\n",
    "CK_PATH       = ROOT / \"concept_Knowledge\" / \"concept_knowledge_auto_v2.json\"  # your existing explanations\n",
    "ck = {}\n",
    "if CK_PATH.exists():\n",
    "    ck = json.load(open(CK_PATH, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "# Load model/tokenizer once\n",
    "tok = AutoTokenizer.from_pretrained(str(MODEL_DIR))\n",
    "cfg = AutoConfig.from_pretrained(str(MODEL_DIR))\n",
    "mdl = AutoModelForSequenceClassification.from_pretrained(str(MODEL_DIR), config=cfg).eval()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "mdl.to(device)\n",
    "if hasattr(mdl.config, \"use_cache\"):\n",
    "    mdl.config.use_cache = False\n",
    "\n",
    "id2label = mdl.config.id2label\n",
    "label_cols = [id2label[i] for i in range(len(id2label))]\n",
    "\n",
    "# Load centroids\n",
    "centroids = np.load(CENTROIDS_NPY)  # [C, H] L2-normalized\n",
    "df_idx    = pd.read_csv(INDEX_CSV)  # concept_id, label, name, smarts, n_pos, valid\n",
    "\n",
    "# Precompute groupings\n",
    "by_label = {\n",
    "    lab: df_idx[df_idx[\"label\"] == lab].reset_index(drop=True)\n",
    "    for lab in sorted(df_idx[\"label\"].unique())\n",
    "}\n",
    "\n",
    "def embed_smiles(smiles: List[str], max_len=256, batch=64) -> np.ndarray:\n",
    "    \"\"\"CLS embeddings, L2-normalized for cosine.\"\"\"\n",
    "    allv = []\n",
    "    for i in range(0, len(smiles), batch):\n",
    "        chunk = smiles[i:i+batch]\n",
    "        enc = tok(chunk, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_len).to(device)\n",
    "        with torch.no_grad():\n",
    "            out = mdl(**enc, output_hidden_states=True)\n",
    "            last = out.hidden_states[-1]    # [B, T, H]\n",
    "            cls  = last[:, 0, :]            # [B, H]\n",
    "        v = cls.detach().cpu().numpy()\n",
    "        # L2 normalize\n",
    "        v = v / (np.linalg.norm(v, axis=1, keepdims=True) + 1e-12)\n",
    "        allv.append(v.astype(np.float32))\n",
    "    return np.vstack(allv) if allv else np.zeros((0, cfg.hidden_size), dtype=np.float32)\n",
    "\n",
    "def concept_scores_for(smiles: str) -> pd.DataFrame:\n",
    "    \"\"\"Return per-label concept cosine scores for a single SMILES.\"\"\"\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    if m is None:\n",
    "        raise ValueError(\"Invalid SMILES\")\n",
    "    v = embed_smiles([smiles])[0]  # [H], already L2-normalized\n",
    "    # cosine similarity with all centroids\n",
    "    sims = (centroids @ v)  # [C]\n",
    "    out = df_idx.copy()\n",
    "    out[\"cosine\"] = sims\n",
    "    return out\n",
    "\n",
    "def explanation_text(label: str, concept_name: str) -> str:\n",
    "    items = {d[\"name\"]: d.get(\"explanation\",\"\") for d in ck.get(label, [])} if ck else {}\n",
    "    if concept_name in items and items[concept_name]:\n",
    "        return items[concept_name]\n",
    "    # generic fallback: short\n",
    "    return f\"{concept_name} motif characteristic for {label}.\"\n",
    "\n",
    "def report_for(smiles: str, top_k_per_label: int = 3, min_diversity: int = 2) -> str:\n",
    "    \"\"\"\n",
    "    Build a compact mechanistic report using centroid cosine scores.\n",
    "    - Picks top_k concepts per label with n_pos>=3 and valid==True.\n",
    "    - Promotes diversity by down-weighting very generic concepts across many labels.\n",
    "    \"\"\"\n",
    "    df = concept_scores_for(smiles)\n",
    "    # simple diversity penalty for widely shared concepts\n",
    "    share = df.groupby(\"smarts\").size().to_dict()\n",
    "    df[\"genericity_pen\"] = df[\"smarts\"].map(lambda s: 1.0 / math.sqrt(max(1, share.get(s,1))))\n",
    "    df[\"score\"] = df[\"cosine\"] * df[\"genericity_pen\"]\n",
    "\n",
    "    # Filter low-support concepts (n_pos<3)\n",
    "    df = df[(df[\"valid\"] == True) & (df[\"n_pos\"] >= 3)].copy()\n",
    "\n",
    "    # Assemble by label\n",
    "    lines = [f\"### Mechanistic summary for `{smiles}`\"]\n",
    "    for lab in label_cols:\n",
    "        sub = df[df[\"label\"] == lab].sort_values(\"score\", ascending=False)\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        keep = sub.head(top_k_per_label)\n",
    "        lines.append(f\"\\n**{lab}** â€” top concepts:\")\n",
    "        for _, r in keep.iterrows():\n",
    "            name = r[\"name\"]\n",
    "            sc   = r[\"cosine\"]\n",
    "            txt  = explanation_text(lab, name)\n",
    "            lines.append(f\"- {name}: cosine={sc:.3f} â€” {txt}\")\n",
    "    lines.append(\"\\n(Scoring = cosine similarity to concept centroids, penalized for cross-label genericity.)\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# ---------- DEMO ----------\n",
    "# Put a test SMILES here (or loop over a small list):\n",
    "test_smiles = [\n",
    "    \"CCOc1ccc2nc(S(N)(=O)=O)sc2c1\",    # phenol\n",
    "\n",
    "]\n",
    "for s in test_smiles:\n",
    "    try:\n",
    "        print(report_for(s))\n",
    "        print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"{s}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bcf5b6",
   "metadata": {},
   "source": [
    "# New Attempt 31st Aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247f5bc2",
   "metadata": {},
   "source": [
    "### what threshold to go with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f53eaa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded on: cuda:0\n",
      "ðŸ“Š Threshold set comparison (NaNs handled):\n",
      "implementation/models/chemberta_v2/metadata/v1TH.json: F1=0.462, BalancedAcc=0.693\n",
      "implementation/models/chemberta_v2/metadata/thresholds.json: F1=0.194, BalancedAcc=0.559\n",
      "implementation/models/chemberta_v2/metadata/thresholds_v3.json: F1=0.350, BalancedAcc=0.650\n"
     ]
    }
   ],
   "source": [
    "# Cell X: Compare threshold sets\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# === paths to your 3 threshold files ===\n",
    "threshold_files = [\n",
    "    \"implementation/models/chemberta_v2/metadata/v1TH.json\",\n",
    "    \"implementation/models/chemberta_v2/metadata/thresholds.json\",\n",
    "    \"implementation/models/chemberta_v2/metadata/thresholds_v3.json\"\n",
    "]\n",
    "\n",
    "# === Load validation data (adjust path as needed) ===\n",
    "val_data = pd.read_csv(\"implementation/data/tox21.csv\")\n",
    "labels = [c for c in val_data.columns if c not in [\"mol_id\", \"smiles\"]]\n",
    "\n",
    "# === Load model + tokenizer ===\n",
    "MODEL_DIR = \"implementation/models/chemberta_v2/v2_best\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
    "model.eval()\n",
    "if torch.cuda.is_available():\n",
    "    model.to(\"cuda\")\n",
    "print(\"âœ… Model loaded on:\", next(model.parameters()).device)\n",
    "\n",
    "# === Dataset class ===\n",
    "class SmilesDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=128):\n",
    "        self.smiles = df[\"smiles\"].tolist()\n",
    "        self.labels = df[labels].values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.smiles[idx],\n",
    "            truncation=True, padding=\"max_length\", max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {k: v.squeeze(0) for k, v in enc.items()}, self.labels[idx]\n",
    "\n",
    "# === Collect predictions ===\n",
    "ds = SmilesDataset(val_data, tokenizer)\n",
    "dl = DataLoader(ds, batch_size=32)\n",
    "\n",
    "all_logits, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in dl:\n",
    "        inputs, labels_batch = batch\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        logits = model(**inputs).logits.cpu().numpy()\n",
    "        all_logits.append(logits)\n",
    "        all_labels.append(labels_batch)\n",
    "\n",
    "all_logits = np.vstack(all_logits)\n",
    "all_labels = np.vstack(all_labels)\n",
    "probs = torch.sigmoid(torch.tensor(all_logits)).numpy()\n",
    "\n",
    "# === Evaluate each threshold set ===\n",
    "results = {}\n",
    "\n",
    "for tf in threshold_files:\n",
    "    with open(tf, \"r\") as f:\n",
    "        th = json.load(f)\n",
    "    \n",
    "    preds = np.zeros_like(probs, dtype=int)\n",
    "    for i, lbl in enumerate(labels):\n",
    "        preds[:, i] = (probs[:, i] >= th[lbl]).astype(int)\n",
    "\n",
    "    # === Handle NaNs in true labels ===\n",
    "    mask = ~np.isnan(all_labels)\n",
    "    y_true = all_labels[mask].astype(int)\n",
    "    y_pred = preds[mask]\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    results[tf] = {\"macro_f1\": f1, \"balanced_acc\": bal_acc}\n",
    "\n",
    "print(\"ðŸ“Š Threshold set comparison (NaNs handled):\")\n",
    "for tf, r in results.items():\n",
    "    print(f\"{tf}: F1={r['macro_f1']:.3f}, BalancedAcc={r['balanced_acc']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6386629",
   "metadata": {},
   "source": [
    "## 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e0fc8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ensured directories under implementation/v3\n",
      "âœ… Model loaded on: cuda\n",
      "âœ… Loaded thresholds from implementation/models/chemberta_v2/metadata/v1TH.json and copied to implementation/v3\\metadata\\thresholds_v1TH.json\n",
      "âœ… Found 12 labels: ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER'] ...\n",
      "âœ… Model head matches dataset label count.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup & paths (TCAV v3)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# -----------------------------\n",
    "# Paths (adjust only if needed)\n",
    "# -----------------------------\n",
    "BASE_DIR = \"implementation/v3\"\n",
    "MODEL_DIR = \"implementation/models/chemberta_v2/v2_best\"\n",
    "THRESH_FILE = \"implementation/models/chemberta_v2/metadata/v1TH.json\"\n",
    "DATA_CSV = \"implementation/data/tox21.csv\"   # used to pull label names\n",
    "\n",
    "# Create v3 folders\n",
    "for sub in [\"embeddings\", \"cav/nulls\", \"stats\", \"reports\", \"metadata\"]:\n",
    "    os.makedirs(os.path.join(BASE_DIR, sub), exist_ok=True)\n",
    "\n",
    "print(f\"âœ… Ensured directories under {BASE_DIR}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Reproducibility\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# -----------------------------\n",
    "# Load model & tokenizer\n",
    "# -----------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"âœ… Model loaded on:\", device)\n",
    "\n",
    "# -----------------------------\n",
    "# Load thresholds (v1TH) and persist a copy into v3/metadata for provenance\n",
    "# -----------------------------\n",
    "with open(THRESH_FILE, \"r\") as f:\n",
    "    thresholds = json.load(f)\n",
    "\n",
    "v3_thresh_path = os.path.join(BASE_DIR, \"metadata\", \"thresholds_v1TH.json\")\n",
    "with open(v3_thresh_path, \"w\") as f:\n",
    "    json.dump(thresholds, f, indent=2)\n",
    "print(f\"âœ… Loaded thresholds from {THRESH_FILE} and copied to {v3_thresh_path}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Load dataset just to get label list (no heavy compute)\n",
    "# -----------------------------\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "labels = [c for c in df.columns if c not in [\"mol_id\", \"smiles\"]]\n",
    "num_labels = len(labels)\n",
    "print(f\"âœ… Found {num_labels} labels: {labels[:5]}{' ...' if num_labels>5 else ''}\")\n",
    "\n",
    "# Quick sanity: model head size should match number of labels\n",
    "model_out = model.config.num_labels\n",
    "assert model_out == num_labels, f\"Model has {model_out} outputs but dataset has {num_labels} labels.\"\n",
    "print(\"âœ… Model head matches dataset label count.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb447572",
   "metadata": {},
   "source": [
    "## 2: Load concepts/SMARTS + coverage filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80abda32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 16 unique concepts from implementation/v2/smarts_lib/smarts_rules_final.json\n",
      "â„¹ï¸ Coverage sample: 2000 SMILES, 2000 valid molecules.\n",
      "âœ… Wrote coverage table to: implementation/v3\\metadata\\concept_coverage_v3.csv\n",
      "âœ… Retained 9/16 concepts in prevalence range [2%, 80%].\n",
      "   Example: [{'name': 'AromaticRing', 'smarts': 'c1ccccc1', 'coverage': 0.5555}, {'name': 'Ester', 'smarts': 'C(=O)O', 'coverage': 0.3205}, {'name': 'Phenol', 'smarts': 'c1ccc(cc1)O', 'coverage': 0.2055}, {'name': 'Aniline', 'smarts': 'Nc1ccccc1', 'coverage': 0.18}, {'name': 'TertiaryAmine', 'smarts': 'N(C)(C)C', 'coverage': 0.177}]\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load concepts/SMARTS + coverage filtering (from smarts_rules_final.json)\n",
    "\n",
    "import os, json\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "# Reuse from Cell 1: BASE_DIR, DATA_CSV, df\n",
    "\n",
    "CONCEPTS_SRC_JSON = \"implementation/v2/smarts_lib/smarts_rules_final.json\"\n",
    "CONCEPTS_OUT_JSON = os.path.join(BASE_DIR, \"metadata\", \"concepts_v3.json\")\n",
    "COVERAGE_CSV      = os.path.join(BASE_DIR, \"metadata\", \"concept_coverage_v3.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load concepts from smarts_rules_final.json\n",
    "# -----------------------------\n",
    "with open(CONCEPTS_SRC_JSON, \"r\") as f:\n",
    "    smarts_rules = json.load(f)\n",
    "\n",
    "# Flatten: {concept_name: smarts} across all labels\n",
    "concepts = {}\n",
    "for lbl, rules in smarts_rules.items():\n",
    "    if isinstance(rules, list):\n",
    "        for r in rules:\n",
    "            n, s = r.get(\"name\"), r.get(\"smarts\")\n",
    "            if n and s:\n",
    "                concepts[n] = s\n",
    "print(f\"âœ… Loaded {len(concepts)} unique concepts from {CONCEPTS_SRC_JSON}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Coverage estimation on a sample\n",
    "# -----------------------------\n",
    "N_SAMPLE = min(2000, len(df))\n",
    "sample_df = df.sample(n=N_SAMPLE, random_state=42).reset_index(drop=True)\n",
    "\n",
    "def smiles_to_mol(smi):\n",
    "    try:\n",
    "        return Chem.MolFromSmiles(smi)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "sample_mols = [smiles_to_mol(s) for s in sample_df[\"smiles\"].tolist()]\n",
    "valid_mols = [m for m in sample_mols if m is not None]\n",
    "valid_count = len(valid_mols)\n",
    "print(f\"â„¹ï¸ Coverage sample: {N_SAMPLE} SMILES, {valid_count} valid molecules.\")\n",
    "\n",
    "compiled = {}\n",
    "for name, sm in concepts.items():\n",
    "    q = Chem.MolFromSmarts(sm)\n",
    "    if q is not None:\n",
    "        compiled[name] = q\n",
    "    else:\n",
    "        print(f\"âš ï¸ Dropped invalid SMARTS for concept: {name}\")\n",
    "\n",
    "coverage_records = []\n",
    "for name, q in compiled.items():\n",
    "    hits = sum(1 for m in valid_mols if m.HasSubstructMatch(q))\n",
    "    cov = hits / max(1, valid_count)\n",
    "    coverage_records.append({\"name\": name, \"smarts\": Chem.MolToSmarts(q), \"coverage\": cov})\n",
    "\n",
    "cov_df = pd.DataFrame(coverage_records).sort_values(\"coverage\", ascending=False)\n",
    "cov_df.to_csv(COVERAGE_CSV, index=False)\n",
    "print(f\"âœ… Wrote coverage table to: {COVERAGE_CSV}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Filter concepts by prevalence\n",
    "# -----------------------------\n",
    "MIN_COV = 0.02   # 2%\n",
    "MAX_COV = 0.80   # 80%\n",
    "filtered = cov_df[(cov_df[\"coverage\"] >= MIN_COV) & (cov_df[\"coverage\"] <= MAX_COV)].copy()\n",
    "\n",
    "if len(filtered) == 0:\n",
    "    raise RuntimeError(\"âŒ No concepts survived filtering. Relax MIN_COV/MAX_COV if needed.\")\n",
    "\n",
    "filtered_concepts = [\n",
    "    {\"name\": r[\"name\"], \"smarts\": r[\"smarts\"], \"coverage\": float(r[\"coverage\"])}\n",
    "    for _, r in filtered.iterrows()\n",
    "]\n",
    "\n",
    "with open(CONCEPTS_OUT_JSON, \"w\") as f:\n",
    "    json.dump(filtered_concepts, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Retained {len(filtered_concepts)}/{len(compiled)} concepts in prevalence range \"\n",
    "      f\"[{int(MIN_COV*100)}%, {int(MAX_COV*100)}%].\")\n",
    "print(\"   Example:\", filtered_concepts[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40aba0d",
   "metadata": {},
   "source": [
    "## 3: Cache CLS embeddings + probabilities for the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ce63dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved:\n",
      "  â€¢ CLS embeddings -> implementation/v3\\embeddings\\cls_embeddings.npy (7831, 768)\n",
      "  â€¢ Probabilities  -> implementation/v3\\embeddings\\probs.npy (7831, 12)\n",
      "  â€¢ IDs            -> implementation/v3\\embeddings\\ids.csv (7831, 2)\n",
      "ðŸ”Ž Embedding dim: 768 | labels: 12\n",
      "ðŸ”Ž Prob range: min=0.0252, max=0.9842\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Cache CLS embeddings + probabilities for the whole dataset\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Reuse from Cell 1: BASE_DIR, df, labels, tokenizer, model, device\n",
    "EMB_DIR = os.path.join(BASE_DIR, \"embeddings\")\n",
    "os.makedirs(EMB_DIR, exist_ok=True)\n",
    "\n",
    "# ---- Dataset & Loader ----\n",
    "class SmilesDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=128):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.smiles = self.df[\"smiles\"].tolist()\n",
    "        # keep labels if present; we won't drop NaNs\n",
    "        self.y = self.df[labels].values if set(labels).issubset(self.df.columns) else None\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        smi = self.smiles[idx]\n",
    "        enc = self.tokenizer(\n",
    "            smi,\n",
    "            truncation=True, padding=\"max_length\", max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        return item, idx\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "dl = DataLoader(SmilesDataset(df, tokenizer), batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# ---- Forward pass to get CLS + logits ----\n",
    "all_cls = []\n",
    "all_probs = []\n",
    "\n",
    "model.config.output_hidden_states = True  # ensure hidden states are returned\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dl:\n",
    "        inputs, idxs = batch\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        out = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "        # CLS from last hidden layer: shape (B, hidden)\n",
    "        last_hidden = out.hidden_states[-1]              # (B, L, H)\n",
    "        cls = last_hidden[:, 0, :].detach().cpu().numpy()\n",
    "        all_cls.append(cls)\n",
    "\n",
    "        logits = out.logits.detach().cpu()\n",
    "        probs = torch.sigmoid(logits).numpy()\n",
    "        all_probs.append(probs)\n",
    "\n",
    "all_cls = np.vstack(all_cls)           # (N, H)\n",
    "all_probs = np.vstack(all_probs)       # (N, num_labels)\n",
    "\n",
    "# ---- Save artifacts ----\n",
    "emb_path = os.path.join(EMB_DIR, \"cls_embeddings.npy\")\n",
    "probs_path = os.path.join(EMB_DIR, \"probs.npy\")\n",
    "index_path = os.path.join(EMB_DIR, \"ids.csv\")\n",
    "\n",
    "np.save(emb_path, all_cls)\n",
    "np.save(probs_path, all_probs)\n",
    "\n",
    "ids_df = df[[\"mol_id\", \"smiles\"]].copy()\n",
    "ids_df.to_csv(index_path, index=False)\n",
    "\n",
    "print(\"âœ… Saved:\")\n",
    "print(\"  â€¢ CLS embeddings ->\", emb_path, all_cls.shape)\n",
    "print(\"  â€¢ Probabilities  ->\", probs_path, all_probs.shape)\n",
    "print(\"  â€¢ IDs            ->\", index_path, ids_df.shape)\n",
    "\n",
    "# quick sanity checks\n",
    "print(\"ðŸ”Ž Embedding dim:\", all_cls.shape[1], \"| labels:\", len(labels))\n",
    "print(\"ðŸ”Ž Prob range: min={:.4f}, max={:.4f}\".format(all_probs.min(), all_probs.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7b4d8f",
   "metadata": {},
   "source": [
    "## 4: Building near threshold evaluation cohorts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274919fe",
   "metadata": {},
   "source": [
    "### 4a: initial cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa872197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved per-label near-threshold cohorts:\n",
      "  â€¢ summary CSV -> implementation/v3\\stats\\near_threshold_selection_v3.csv\n",
      "  â€¢ summary JSON -> implementation/v3\\stats\\near_threshold_selection_v3.json\n",
      "  â€¢ eval ids (*.npy) in -> implementation/v3\\embeddings\n",
      "\n",
      "ðŸ”Ž Selection preview:\n",
      "        label  selected_delta  n_eval  pos_rate  score\n",
      "        NR-AR            0.04     241    0.4606 0.1577\n",
      "    NR-AR-LBD            0.03     208    0.4327 0.2692\n",
      "       NR-AhR            0.03     397    0.4332 0.2670\n",
      " NR-Aromatase            0.03    1434    0.9735 2.6865\n",
      "        NR-ER            0.03     472    0.4873 0.0508\n",
      "    NR-ER-LBD            0.07     786    0.5064 0.0254\n",
      "NR-PPAR-gamma            0.03     962    0.9782 2.1152\n",
      "       SR-ARE            0.05     705    0.4979 0.0085\n",
      "     SR-ATAD5            0.04     502    0.5120 0.0478\n",
      "       SR-HSE            0.05     377    1.0000 2.0000\n",
      "       SR-MMP            0.06     561    0.5009 0.0036\n",
      "       SR-p53            0.03    2204    0.5540 1.9710\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Build near-threshold evaluation cohorts (configurable + auto-selection)\n",
    "\n",
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Reuse from earlier cells:\n",
    "# BASE_DIR, labels, v3_thresh_path\n",
    "EMB_DIR = os.path.join(BASE_DIR, \"embeddings\")\n",
    "STATS_DIR = os.path.join(BASE_DIR, \"stats\")\n",
    "os.makedirs(STATS_DIR, exist_ok=True)\n",
    "\n",
    "# Load cached probs + ids\n",
    "probs = np.load(os.path.join(EMB_DIR, \"probs.npy\"))          # (N, L)\n",
    "ids_df = pd.read_csv(os.path.join(EMB_DIR, \"ids.csv\"))       # (N, 2): mol_id, smiles\n",
    "with open(v3_thresh_path, \"r\") as f:\n",
    "    thresholds = json.load(f)\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "# Candidate deltas to try automatically. You can change or extend this list.\n",
    "DELTA_GRID = [0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.10, 0.12, 0.15]\n",
    "\n",
    "# Desired cohort properties:\n",
    "MIN_N = 200      # minimum samples in near-threshold cohort\n",
    "MAX_N = 800      # maximum samples we'll accept (to keep gradients efficient)\n",
    "TARGET_POS_RATE = 0.5   # we want ~50/50 above/below threshold for balance\n",
    "\n",
    "# Scoring weights (tweak if needed)\n",
    "W_SIZE = 1.0     # weight for size penalty (outside [MIN_N, MAX_N])\n",
    "W_BAL  = 2.0     # weight for imbalance penalty |pos_rate - 0.5|\n",
    "\n",
    "# -----------------------------\n",
    "# Helper: score a candidate cohort\n",
    "# -----------------------------\n",
    "def cohort_score(n, pos_rate):\n",
    "    # size penalty: zero if within [MIN_N, MAX_N], else proportional distance\n",
    "    if n < MIN_N:\n",
    "        size_pen = (MIN_N - n) / MIN_N\n",
    "    elif n > MAX_N:\n",
    "        size_pen = (n - MAX_N) / MAX_N\n",
    "    else:\n",
    "        size_pen = 0.0\n",
    "    bal_pen = abs(pos_rate - TARGET_POS_RATE) / TARGET_POS_RATE  # 0 at 0.5, 1 at 0 or 1\n",
    "    return W_SIZE * size_pen + W_BAL * bal_pen\n",
    "\n",
    "# -----------------------------\n",
    "# Auto-select Î´ per label\n",
    "# -----------------------------\n",
    "N, L = probs.shape\n",
    "assert L == len(labels)\n",
    "\n",
    "selection_summary = []\n",
    "selected_deltas = {}\n",
    "eval_id_paths = {}\n",
    "\n",
    "for i, lbl in enumerate(labels):\n",
    "    thr = float(thresholds[lbl])\n",
    "\n",
    "    best = None  # tuple(score, delta, idxs, n, pos_rate)\n",
    "    for delta in DELTA_GRID:\n",
    "        near = np.where(np.abs(probs[:, i] - thr) <= delta)[0]\n",
    "        if near.size == 0:\n",
    "            continue\n",
    "        n = near.size\n",
    "        pos_rate = float(np.mean(probs[near, i] >= thr))\n",
    "        score = cohort_score(n, pos_rate)\n",
    "\n",
    "        cand = (score, delta, near, n, pos_rate)\n",
    "        if (best is None) or (score < best[0]):\n",
    "            best = cand\n",
    "\n",
    "    if best is None:\n",
    "        # If nothing found (very unlikely), fall back to the loosest delta and accept whatever we get\n",
    "        delta = max(DELTA_GRID)\n",
    "        near = np.where(np.abs(probs[:, i] - thr) <= delta)[0]\n",
    "        n = near.size\n",
    "        pos_rate = float(np.mean(probs[near, i] >= thr))\n",
    "        score = cohort_score(n, pos_rate)\n",
    "        best = (score, delta, near, n, pos_rate)\n",
    "\n",
    "    score, delta, near, n, pos_rate = best\n",
    "\n",
    "    # Save indices for this label\n",
    "    out_path = os.path.join(EMB_DIR, f\"eval_ids_{lbl.replace('/', '-')}.npy\")\n",
    "    np.save(out_path, near)\n",
    "    eval_id_paths[lbl] = out_path\n",
    "    selected_deltas[lbl] = delta\n",
    "\n",
    "    selection_summary.append({\n",
    "        \"label\": lbl,\n",
    "        \"selected_delta\": delta,\n",
    "        \"n_eval\": int(n),\n",
    "        \"pos_rate\": round(pos_rate, 4),\n",
    "        \"score\": round(score, 4),\n",
    "        \"threshold\": thr\n",
    "    })\n",
    "\n",
    "# Save summary CSV + JSON\n",
    "summary_df = pd.DataFrame(selection_summary).sort_values([\"label\"])\n",
    "summary_csv = os.path.join(STATS_DIR, \"near_threshold_selection_v3.csv\")\n",
    "summary_json = os.path.join(STATS_DIR, \"near_threshold_selection_v3.json\")\n",
    "summary_df.to_csv(summary_csv, index=False)\n",
    "with open(summary_json, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"selected_deltas\": selected_deltas,\n",
    "        \"eval_id_paths\": eval_id_paths,\n",
    "        \"summary\": selection_summary,\n",
    "        \"config\": {\n",
    "            \"DELTA_GRID\": DELTA_GRID,\n",
    "            \"MIN_N\": MIN_N, \"MAX_N\": MAX_N,\n",
    "            \"TARGET_POS_RATE\": TARGET_POS_RATE,\n",
    "            \"W_SIZE\": W_SIZE, \"W_BAL\": W_BAL\n",
    "        }\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"âœ… Saved per-label near-threshold cohorts:\")\n",
    "print(\"  â€¢ summary CSV ->\", summary_csv)\n",
    "print(\"  â€¢ summary JSON ->\", summary_json)\n",
    "print(\"  â€¢ eval ids (*.npy) in ->\", EMB_DIR)\n",
    "\n",
    "# Quick preview\n",
    "display_cols = [\"label\", \"selected_delta\", \"n_eval\", \"pos_rate\", \"score\"]\n",
    "print(\"\\nðŸ”Ž Selection preview:\")\n",
    "print(summary_df[display_cols].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a12d311",
   "metadata": {},
   "source": [
    "### 4b: Balance & cap near-threshold cohorts (per label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7d931b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved balanced per-label cohorts:\n",
      "  â€¢ CSV  -> implementation/v3\\stats\\near_threshold_balanced_v3.csv\n",
      "  â€¢ JSON -> implementation/v3\\stats\\near_threshold_balanced_v3.json\n",
      "  â€¢ IDs  -> implementation/v3/embeddings/eval_ids_balanced_*.npy\n",
      "\n",
      "ðŸ”Ž Preview:\n",
      "        label  delta_start  delta_final  n_pos_used  n_neg_used  n_total_used\n",
      "        NR-AR         0.04         0.06         149         149           298\n",
      "    NR-AR-LBD         0.03         0.05         152         152           304\n",
      "       NR-AhR         0.03         0.03         172         172           344\n",
      " NR-Aromatase         0.03         0.25          38          38            76\n",
      "        NR-ER         0.03         0.03         230         230           460\n",
      "    NR-ER-LBD         0.07         0.07         388         388           776\n",
      "NR-PPAR-gamma         0.03         0.25          21          21            42\n",
      "       SR-ARE         0.05         0.05         351         351           702\n",
      "     SR-ATAD5         0.04         0.04         245         245           490\n",
      "       SR-HSE         0.05         0.25        4265           0          4265\n",
      "       SR-MMP         0.06         0.06         280         280           560\n",
      "       SR-p53         0.03         0.03         400         400           800\n"
     ]
    }
   ],
   "source": [
    "# Cell 4b: Create balanced, capped near-threshold cohorts\n",
    "\n",
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "EMB_DIR   = os.path.join(BASE_DIR, \"embeddings\")\n",
    "STATS_DIR = os.path.join(BASE_DIR, \"stats\")\n",
    "\n",
    "# Load cached\n",
    "probs   = np.load(os.path.join(EMB_DIR, \"probs.npy\"))        # (N, L)\n",
    "ids_df  = pd.read_csv(os.path.join(EMB_DIR, \"ids.csv\"))      # mol_id, smiles\n",
    "with open(v3_thresh_path, \"r\") as f:\n",
    "    thresholds = json.load(f)\n",
    "\n",
    "# Load our previous selections (deltas & initial near sets)\n",
    "sel_json = os.path.join(STATS_DIR, \"near_threshold_selection_v3.json\")\n",
    "with open(sel_json, \"r\") as f:\n",
    "    sel = json.load(f)\n",
    "\n",
    "selected_deltas = sel[\"selected_deltas\"]  # dict label -> delta\n",
    "\n",
    "# Config for balancing\n",
    "MIN_TOTAL   = 300         # desired minimum total per label\n",
    "MAX_TOTAL   = 800         # hard cap per label\n",
    "MIN_SIDE    = 120         # desired minimum per side (pos/neg)\n",
    "DELTA_STEP  = 0.01        # how much to widen per iteration\n",
    "DELTA_MAX   = 0.25        # safety cap on widening\n",
    "\n",
    "balanced_rows = []\n",
    "balanced_paths = {}\n",
    "\n",
    "for i, lbl in enumerate(labels):\n",
    "    thr   = float(thresholds[lbl])\n",
    "    delta = float(selected_deltas.get(lbl, 0.05))\n",
    "\n",
    "    # Start from the selected delta; expand until both sides have enough\n",
    "    cur_delta = delta\n",
    "    for _ in range(100):  # iteration cap\n",
    "        near_idx = np.where(np.abs(probs[:, i] - thr) <= cur_delta)[0]\n",
    "        if near_idx.size == 0 and cur_delta < DELTA_MAX:\n",
    "            cur_delta += DELTA_STEP\n",
    "            continue\n",
    "\n",
    "        pos_idx = near_idx[probs[near_idx, i] >= thr]\n",
    "        neg_idx = near_idx[probs[near_idx, i] <  thr]\n",
    "\n",
    "        have_both_sides = (len(pos_idx) >= MIN_SIDE) and (len(neg_idx) >= MIN_SIDE)\n",
    "        total_ok = (len(near_idx) >= MIN_TOTAL)\n",
    "\n",
    "        if have_both_sides and total_ok:\n",
    "            break\n",
    "        # Widen window if we don't meet criteria and we can increase delta\n",
    "        if cur_delta < DELTA_MAX:\n",
    "            cur_delta += DELTA_STEP\n",
    "            continue\n",
    "        else:\n",
    "            # Can't widen further; proceed with what we have\n",
    "            break\n",
    "\n",
    "    # Now sample 50/50 from each side\n",
    "    # Target total is the min of what's available and MAX_TOTAL (even number)\n",
    "    avail_pos = len(pos_idx)\n",
    "    avail_neg = len(neg_idx)\n",
    "    total_avail = avail_pos + avail_neg\n",
    "    target_total = min(MAX_TOTAL, total_avail)\n",
    "    target_side = target_total // 2\n",
    "\n",
    "    # If one side is the bottleneck, match the other side to it\n",
    "    target_side = min(target_side, avail_pos, avail_neg)\n",
    "\n",
    "    if target_side == 0:\n",
    "        # If still no negatives or positives, fallback to taking whatever we have (unbalanced),\n",
    "        # but keep a log so you can review later.\n",
    "        chosen = near_idx\n",
    "        used_pos = avail_pos\n",
    "        used_neg = avail_neg\n",
    "    else:\n",
    "        rng = np.random.default_rng(42)\n",
    "        pos_take = rng.choice(pos_idx, size=target_side, replace=False) if avail_pos > target_side else pos_idx\n",
    "        neg_take = rng.choice(neg_idx, size=target_side, replace=False) if avail_neg > target_side else neg_idx\n",
    "        chosen = np.concatenate([pos_take, neg_take])\n",
    "        rng.shuffle(chosen)\n",
    "        used_pos = len(pos_take)\n",
    "        used_neg = len(neg_take)\n",
    "\n",
    "    out_path = os.path.join(EMB_DIR, f\"eval_ids_balanced_{lbl.replace('/', '-')}.npy\")\n",
    "    np.save(out_path, chosen)\n",
    "    balanced_paths[lbl] = out_path\n",
    "\n",
    "    balanced_rows.append({\n",
    "        \"label\": lbl,\n",
    "        \"delta_start\": delta,\n",
    "        \"delta_final\": round(cur_delta, 3),\n",
    "        \"n_pos_avail\": avail_pos,\n",
    "        \"n_neg_avail\": avail_neg,\n",
    "        \"n_pos_used\": int(used_pos),\n",
    "        \"n_neg_used\": int(used_neg),\n",
    "        \"n_total_used\": int(len(chosen)),\n",
    "        \"thr\": thr\n",
    "    })\n",
    "\n",
    "# Save summary\n",
    "bal_df = pd.DataFrame(balanced_rows).sort_values(\"label\")\n",
    "bal_csv = os.path.join(STATS_DIR, \"near_threshold_balanced_v3.csv\")\n",
    "bal_json = os.path.join(STATS_DIR, \"near_threshold_balanced_v3.json\")\n",
    "bal_df.to_csv(bal_csv, index=False)\n",
    "with open(bal_json, \"w\") as f:\n",
    "    json.dump({\"balanced_paths\": balanced_paths, \"cohorts\": balanced_rows}, f, indent=2)\n",
    "\n",
    "print(\"âœ… Saved balanced per-label cohorts:\")\n",
    "print(\"  â€¢ CSV  ->\", bal_csv)\n",
    "print(\"  â€¢ JSON ->\", bal_json)\n",
    "print(\"  â€¢ IDs  -> implementation/v3/embeddings/eval_ids_balanced_*.npy\")\n",
    "\n",
    "print(\"\\nðŸ”Ž Preview:\")\n",
    "print(bal_df[[\"label\",\"delta_start\",\"delta_final\",\"n_pos_used\",\"n_neg_used\",\"n_total_used\"]].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1481cd0",
   "metadata": {},
   "source": [
    "## 5: Train CAVs (real + nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bbac2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Trained 9 concepts Ã— 10 runs each + 50 nulls per label.\n",
      "ðŸ“Š Saved CAV training summary -> implementation/v3\\stats\\cav_training_summary_v3.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept</th>\n",
       "      <th>n_pos</th>\n",
       "      <th>n_neg</th>\n",
       "      <th>k_runs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>4397</td>\n",
       "      <td>2000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ester</td>\n",
       "      <td>2407</td>\n",
       "      <td>2000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phenol</td>\n",
       "      <td>1695</td>\n",
       "      <td>2000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aniline</td>\n",
       "      <td>1366</td>\n",
       "      <td>2000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TertiaryAmine</td>\n",
       "      <td>1395</td>\n",
       "      <td>2000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         concept  n_pos  n_neg  k_runs\n",
       "0   AromaticRing   4397   2000      10\n",
       "1          Ester   2407   2000      10\n",
       "2         Phenol   1695   2000      10\n",
       "3        Aniline   1366   2000      10\n",
       "4  TertiaryAmine   1395   2000      10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 5: Train CAVs (real + label-conditioned nulls)\n",
    "\n",
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Reuse: BASE_DIR, labels\n",
    "EMB_DIR   = os.path.join(BASE_DIR, \"embeddings\")\n",
    "CAV_REAL  = os.path.join(BASE_DIR, \"cav\", \"real\")\n",
    "CAV_NULL  = os.path.join(BASE_DIR, \"cav\", \"nulls\")\n",
    "os.makedirs(CAV_REAL, exist_ok=True)\n",
    "os.makedirs(CAV_NULL, exist_ok=True)\n",
    "\n",
    "# Load embeddings and IDs\n",
    "emb = np.load(os.path.join(EMB_DIR, \"cls_embeddings.npy\"))   # (N, H)\n",
    "ids = pd.read_csv(os.path.join(EMB_DIR, \"ids.csv\"))\n",
    "with open(os.path.join(BASE_DIR, \"metadata\", \"concepts_v3.json\"), \"r\") as f:\n",
    "    concepts = json.load(f)\n",
    "with open(os.path.join(BASE_DIR, \"stats\", \"near_threshold_balanced_v3.json\"), \"r\") as f:\n",
    "    balanced_info = json.load(f)\n",
    "\n",
    "# Config\n",
    "K_RUNS = 10       # number of repeats per concept\n",
    "N_NULL = 50       # null CAVs per concept Ã— label\n",
    "MAX_NEG = 2000    # cap background negatives\n",
    "SEED = 42\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "# Build quick concept matcher\n",
    "from rdkit import Chem\n",
    "\n",
    "compiled = {c[\"name\"]: Chem.MolFromSmarts(c[\"smarts\"]) for c in concepts}\n",
    "mol_cache = [Chem.MolFromSmiles(s) for s in ids[\"smiles\"].tolist()]\n",
    "\n",
    "def mol_has_concept(m, q):\n",
    "    if m is None or q is None: return False\n",
    "    return m.HasSubstructMatch(q)\n",
    "\n",
    "# Metadata collection\n",
    "cav_records = []\n",
    "\n",
    "for ci, concept in enumerate(concepts):\n",
    "    cname, smarts = concept[\"name\"], concept[\"smarts\"]\n",
    "    q = compiled[cname]\n",
    "    if q is None:\n",
    "        print(f\"âš ï¸ Skipping invalid SMARTS for {cname}\")\n",
    "        continue\n",
    "\n",
    "    # positive IDs = all molecules matching concept\n",
    "    pos_idx = [i for i, m in enumerate(mol_cache) if mol_has_concept(m, q)]\n",
    "    if len(pos_idx) < 20:\n",
    "        print(f\"âš ï¸ Skipping {cname} (too few positives: {len(pos_idx)})\")\n",
    "        continue\n",
    "\n",
    "    # background negatives = all non-matching\n",
    "    neg_idx = [i for i in range(len(mol_cache)) if i not in pos_idx]\n",
    "    if len(neg_idx) > MAX_NEG:\n",
    "        neg_idx = rng.choice(neg_idx, size=MAX_NEG, replace=False).tolist()\n",
    "\n",
    "    X_pos = emb[pos_idx]\n",
    "    X_neg = emb[neg_idx]\n",
    "    y_pos = np.ones(len(X_pos))\n",
    "    y_neg = np.zeros(len(X_neg))\n",
    "\n",
    "    # Train K real CAVs\n",
    "    for k in range(K_RUNS):\n",
    "        # resample negatives to match positives\n",
    "        Xn, yn = resample(X_neg, y_neg, n_samples=len(X_pos), random_state=SEED + k)\n",
    "        X_train = np.vstack([X_pos, Xn])\n",
    "        y_train = np.concatenate([y_pos, yn])\n",
    "\n",
    "        clf = LogisticRegression(\n",
    "            solver=\"liblinear\",\n",
    "            random_state=SEED + k,\n",
    "            max_iter=200\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        w = clf.coef_.ravel().astype(np.float32)\n",
    "        w = w / (np.linalg.norm(w) + 1e-8)\n",
    "\n",
    "        out_path = os.path.join(CAV_REAL, f\"{cname}_run{k}.npy\")\n",
    "        np.save(out_path, w)\n",
    "\n",
    "    cav_records.append({\n",
    "        \"concept\": cname,\n",
    "        \"n_pos\": len(pos_idx),\n",
    "        \"n_neg\": len(neg_idx),\n",
    "        \"k_runs\": K_RUNS\n",
    "    })\n",
    "\n",
    "    # Label-conditioned nulls\n",
    "    for lbl in labels:\n",
    "        bal = next((r for r in balanced_info[\"cohorts\"] if r[\"label\"] == lbl), None)\n",
    "        unstable = False\n",
    "        if bal and bal[\"n_total_used\"] < 100:  # mark unstable if too tiny\n",
    "            unstable = True\n",
    "\n",
    "        for n in range(N_NULL):\n",
    "            take_size = min(len(pos_idx), len(neg_idx))\n",
    "            rand_pos = rng.choice(neg_idx, size=take_size, replace=True)  # allow replacement if needed\n",
    "            rand_neg = [i for i in neg_idx if i not in rand_pos]\n",
    "            if len(rand_neg) > MAX_NEG:\n",
    "                rand_neg = rng.choice(rand_neg, size=MAX_NEG, replace=False).tolist()\n",
    "\n",
    "            X_pos_null = emb[rand_pos]\n",
    "            y_pos_null = np.ones(len(X_pos_null))\n",
    "            X_neg_null = emb[rand_neg]\n",
    "            y_neg_null = np.zeros(len(X_neg_null))\n",
    "\n",
    "            X_train = np.vstack([X_pos_null, X_neg_null])\n",
    "            y_train = np.concatenate([y_pos_null, y_neg_null])\n",
    "\n",
    "            clf = LogisticRegression(\n",
    "                solver=\"liblinear\",\n",
    "                random_state=SEED + n,\n",
    "                max_iter=200\n",
    "            )\n",
    "            clf.fit(X_train, y_train)\n",
    "            w = clf.coef_.ravel().astype(np.float32)\n",
    "            w = w / (np.linalg.norm(w) + 1e-8)\n",
    "\n",
    "            out_path = os.path.join(CAV_NULL, f\"{cname}_{lbl}_null{n}.npy\")\n",
    "            np.save(out_path, w)\n",
    "\n",
    "print(f\"âœ… Trained {len(cav_records)} concepts Ã— {K_RUNS} runs each + {N_NULL} nulls per label.\")\n",
    "cav_df = pd.DataFrame(cav_records)\n",
    "cav_csv = os.path.join(BASE_DIR, \"stats\", \"cav_training_summary_v3.csv\")\n",
    "cav_df.to_csv(cav_csv, index=False)\n",
    "print(\"ðŸ“Š Saved CAV training summary ->\", cav_csv)\n",
    "display(cav_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b71bf91",
   "metadata": {},
   "source": [
    "### sanity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef5a7222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Real CAV runs per concept:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept</th>\n",
       "      <th>K_runs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aniline</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ArylHalide</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ester</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MichaelAcceptor</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nitro</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phenol</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TertiaryAmine</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Urea</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           concept  K_runs\n",
       "3          Aniline      10\n",
       "0     AromaticRing      10\n",
       "5       ArylHalide      10\n",
       "1            Ester      10\n",
       "6  MichaelAcceptor      10\n",
       "7            Nitro      10\n",
       "2           Phenol      10\n",
       "4    TertiaryAmine      10\n",
       "8             Urea      10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Null CAVs per (concept Ã— label):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept</th>\n",
       "      <th>label</th>\n",
       "      <th>N_null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aniline</td>\n",
       "      <td>NR-AR</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Aniline</td>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Aniline</td>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Aniline</td>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Aniline</td>\n",
       "      <td>NR-ER</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Aniline</td>\n",
       "      <td>NR-ER-LBD</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Aniline</td>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Aniline</td>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Aniline</td>\n",
       "      <td>SR-ATAD5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Aniline</td>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Aniline</td>\n",
       "      <td>SR-MMP</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Aniline</td>\n",
       "      <td>SR-p53</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>NR-AR</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>NR-ER</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>NR-ER-LBD</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>SR-ATAD5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>SR-MMP</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>SR-p53</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         concept          label  N_null\n",
       "0        Aniline          NR-AR      50\n",
       "14       Aniline      NR-AR-LBD      50\n",
       "79       Aniline         NR-AhR      50\n",
       "78       Aniline   NR-Aromatase      50\n",
       "77       Aniline          NR-ER      50\n",
       "76       Aniline      NR-ER-LBD      50\n",
       "75       Aniline  NR-PPAR-gamma      50\n",
       "74       Aniline         SR-ARE      50\n",
       "73       Aniline       SR-ATAD5      50\n",
       "72       Aniline         SR-HSE      50\n",
       "71       Aniline         SR-MMP      50\n",
       "70       Aniline         SR-p53      50\n",
       "69  AromaticRing          NR-AR      50\n",
       "68  AromaticRing      NR-AR-LBD      50\n",
       "67  AromaticRing         NR-AhR      50\n",
       "66  AromaticRing   NR-Aromatase      50\n",
       "65  AromaticRing          NR-ER      50\n",
       "64  AromaticRing      NR-ER-LBD      50\n",
       "63  AromaticRing  NR-PPAR-gamma      50\n",
       "62  AromaticRing         SR-ARE      50\n",
       "61  AromaticRing       SR-ATAD5      50\n",
       "60  AromaticRing         SR-HSE      50\n",
       "59  AromaticRing         SR-MMP      50\n",
       "58  AromaticRing         SR-p53      50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Null counts pivot (first few concepts):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>NR-AR</th>\n",
       "      <th>NR-AR-LBD</th>\n",
       "      <th>NR-AhR</th>\n",
       "      <th>NR-Aromatase</th>\n",
       "      <th>NR-ER</th>\n",
       "      <th>NR-ER-LBD</th>\n",
       "      <th>NR-PPAR-gamma</th>\n",
       "      <th>SR-ARE</th>\n",
       "      <th>SR-ATAD5</th>\n",
       "      <th>SR-HSE</th>\n",
       "      <th>SR-MMP</th>\n",
       "      <th>SR-p53</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concept</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AromaticRing</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ester</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phenol</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aniline</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TertiaryAmine</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ArylHalide</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MichaelAcceptor</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nitro</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urea</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label            NR-AR  NR-AR-LBD  NR-AhR  NR-Aromatase  NR-ER  NR-ER-LBD  \\\n",
       "concept                                                                     \n",
       "AromaticRing        50         50      50            50     50         50   \n",
       "Ester               50         50      50            50     50         50   \n",
       "Phenol              50         50      50            50     50         50   \n",
       "Aniline             50         50      50            50     50         50   \n",
       "TertiaryAmine       50         50      50            50     50         50   \n",
       "ArylHalide          50         50      50            50     50         50   \n",
       "MichaelAcceptor     50         50      50            50     50         50   \n",
       "Nitro               50         50      50            50     50         50   \n",
       "Urea                50         50      50            50     50         50   \n",
       "\n",
       "label            NR-PPAR-gamma  SR-ARE  SR-ATAD5  SR-HSE  SR-MMP  SR-p53  \n",
       "concept                                                                   \n",
       "AromaticRing                50      50        50      50      50      50  \n",
       "Ester                       50      50        50      50      50      50  \n",
       "Phenol                      50      50        50      50      50      50  \n",
       "Aniline                     50      50        50      50      50      50  \n",
       "TertiaryAmine               50      50        50      50      50      50  \n",
       "ArylHalide                  50      50        50      50      50      50  \n",
       "MichaelAcceptor             50      50        50      50      50      50  \n",
       "Nitro                       50      50        50      50      50      50  \n",
       "Urea                        50      50        50      50      50      50  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 5-check: summarize trained CAV files (run AFTER Cell 5 finishes)\n",
    "\n",
    "import os, re, json\n",
    "import pandas as pd\n",
    "\n",
    "BASE_DIR = \"implementation/v3\"\n",
    "CAV_REAL = os.path.join(BASE_DIR, \"cav\", \"real\")\n",
    "CAV_NULL = os.path.join(BASE_DIR, \"cav\", \"nulls\")\n",
    "STATS_DIR = os.path.join(BASE_DIR, \"stats\")\n",
    "\n",
    "# Load labels & concepts (for neat tables)\n",
    "labels = pd.read_csv(os.path.join(BASE_DIR, \"embeddings\", \"ids.csv\"), nrows=1)  # to ensure path exists\n",
    "with open(os.path.join(BASE_DIR, \"metadata\", \"concepts_v3.json\"), \"r\") as f:\n",
    "    concepts_v3 = [c[\"name\"] for c in json.load(f)]\n",
    "with open(os.path.join(STATS_DIR, \"near_threshold_balanced_v3.json\"), \"r\") as f:\n",
    "    bal = json.load(f)\n",
    "labels_v3 = [row[\"label\"] for row in bal[\"cohorts\"]]\n",
    "\n",
    "# --- Real CAVs ---\n",
    "real_counts = {}\n",
    "for fn in os.listdir(CAV_REAL):\n",
    "    if not fn.endswith(\".npy\") or \"_run\" not in fn: \n",
    "        continue\n",
    "    cname = fn.split(\"_run\")[0]\n",
    "    real_counts[cname] = real_counts.get(cname, 0) + 1\n",
    "\n",
    "real_df = pd.DataFrame(\n",
    "    [{\"concept\": c, \"K_runs\": real_counts.get(c, 0)} for c in concepts_v3]\n",
    ").sort_values(\"concept\")\n",
    "print(\"ðŸ“¦ Real CAV runs per concept:\")\n",
    "display(real_df)\n",
    "\n",
    "# --- Null CAVs ---\n",
    "pat = re.compile(r\"(.+)_([^_]+)_null(\\d+)\\.npy$\")  # concept_label_nullN.npy\n",
    "null_rows = []\n",
    "for fn in os.listdir(CAV_NULL):\n",
    "    m = pat.match(fn)\n",
    "    if not m:\n",
    "        continue\n",
    "    cname, lbl, n = m.groups()\n",
    "    null_rows.append((cname, lbl))\n",
    "\n",
    "if null_rows:\n",
    "    null_df = (\n",
    "        pd.DataFrame(null_rows, columns=[\"concept\", \"label\"])\n",
    "        .value_counts()\n",
    "        .reset_index(name=\"N_null\")\n",
    "        .sort_values([\"concept\", \"label\"])\n",
    "    )\n",
    "else:\n",
    "    null_df = pd.DataFrame(columns=[\"concept\",\"label\",\"N_null\"])\n",
    "\n",
    "print(\"ðŸ“¦ Null CAVs per (concept Ã— label):\")\n",
    "display(null_df.head(24))\n",
    "\n",
    "# Quick gaps report: concepts with 0 real runs, or (concept,label) with 0 nulls\n",
    "missing_real = real_df[real_df[\"K_runs\"] == 0][\"concept\"].tolist()\n",
    "if missing_real:\n",
    "    print(\"âš ï¸ Concepts with NO real CAV runs:\", missing_real)\n",
    "\n",
    "# (optional) pivot to see per-label null counts quickly\n",
    "if not null_df.empty:\n",
    "    pivot = null_df.pivot(index=\"concept\", columns=\"label\", values=\"N_null\").fillna(0).astype(int)\n",
    "    print(\"ðŸ“Š Null counts pivot (first few concepts):\")\n",
    "    display(pivot.loc[concepts_v3].reindex(columns=labels_v3).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef7cc72",
   "metadata": {},
   "source": [
    "## 6: Compute TCAV (with null testing + BH-FDR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff0f19df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels to process: ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53']\n",
      "\n",
      "[NR-AR] computing bottleneck grads for 298 molecules at layer -5 â€¦\n",
      "  NR-AR: processed 5/9 conceptsâ€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_22632\\2960430008.py:172: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  res_df = pd.concat([res_df, tmp], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… NR-AR: saved 9 rows (significant=0) in 3.0s\n",
      "\n",
      "[NR-AR-LBD] computing bottleneck grads for 304 molecules at layer -5 â€¦\n",
      "  NR-AR-LBD: processed 5/9 conceptsâ€¦\n",
      "âœ… NR-AR-LBD: saved 9 rows (significant=0) in 2.6s\n",
      "\n",
      "[NR-AhR] computing bottleneck grads for 344 molecules at layer -5 â€¦\n",
      "  NR-AhR: processed 5/9 conceptsâ€¦\n",
      "âœ… NR-AhR: saved 9 rows (significant=0) in 2.4s\n",
      "\n",
      "[NR-Aromatase] computing bottleneck grads for 76 molecules at layer -5 â€¦\n",
      "  NR-Aromatase: processed 5/9 conceptsâ€¦\n",
      "âœ… NR-Aromatase: saved 9 rows (significant=0) in 2.0s\n",
      "\n",
      "[NR-ER] computing bottleneck grads for 460 molecules at layer -5 â€¦\n",
      "  NR-ER: processed 5/9 conceptsâ€¦\n",
      "âœ… NR-ER: saved 9 rows (significant=0) in 2.6s\n",
      "\n",
      "[NR-ER-LBD] computing bottleneck grads for 776 molecules at layer -5 â€¦\n",
      "  NR-ER-LBD: processed 5/9 conceptsâ€¦\n",
      "âœ… NR-ER-LBD: saved 9 rows (significant=0) in 3.0s\n",
      "\n",
      "[NR-PPAR-gamma] computing bottleneck grads for 42 molecules at layer -5 â€¦\n",
      "  NR-PPAR-gamma: processed 5/9 conceptsâ€¦\n",
      "âœ… NR-PPAR-gamma: saved 9 rows (significant=1) in 2.0s\n",
      "\n",
      "[SR-ARE] computing bottleneck grads for 702 molecules at layer -5 â€¦\n",
      "  SR-ARE: processed 5/9 conceptsâ€¦\n",
      "âœ… SR-ARE: saved 9 rows (significant=0) in 3.0s\n",
      "\n",
      "[SR-ATAD5] computing bottleneck grads for 490 molecules at layer -5 â€¦\n",
      "  SR-ATAD5: processed 5/9 conceptsâ€¦\n",
      "âœ… SR-ATAD5: saved 9 rows (significant=0) in 2.6s\n",
      "\n",
      "[SR-HSE] computing bottleneck grads for 4265 molecules at layer -5 â€¦\n",
      "  SR-HSE: processed 5/9 conceptsâ€¦\n",
      "âœ… SR-HSE: saved 9 rows (significant=0) in 6.0s\n",
      "\n",
      "[SR-MMP] computing bottleneck grads for 560 molecules at layer -5 â€¦\n",
      "  SR-MMP: processed 5/9 conceptsâ€¦\n",
      "âœ… SR-MMP: saved 9 rows (significant=0) in 2.6s\n",
      "\n",
      "[SR-p53] computing bottleneck grads for 800 molecules at layer -5 â€¦\n",
      "  SR-p53: processed 5/9 conceptsâ€¦\n",
      "âœ… SR-p53: saved 9 rows (significant=0) in 2.1s\n",
      "\n",
      "Done. Results at:\n",
      " â€¢ implementation/v3\\stats\\tcav_summary_v3.csv\n",
      " â€¢ implementation/v3\\stats\\tcav_summary_v3.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: TCAV scoring (proper bottleneck + incremental save + progress)\n",
    "\n",
    "import os, json, math, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Reuse from earlier cells\n",
    "BASE_DIR  = \"implementation/v3\"\n",
    "EMB_DIR   = os.path.join(BASE_DIR, \"embeddings\")\n",
    "CAV_REAL  = os.path.join(BASE_DIR, \"cav\", \"real\")\n",
    "CAV_NULL  = os.path.join(BASE_DIR, \"cav\", \"nulls\")\n",
    "STATS_DIR = os.path.join(BASE_DIR, \"stats\")\n",
    "META_DIR  = os.path.join(BASE_DIR, \"metadata\")\n",
    "\n",
    "os.makedirs(STATS_DIR, exist_ok=True)\n",
    "\n",
    "# ---- Config ----\n",
    "BOTTLENECK_LAYER = -5     # non-final layer; try -6/-4 later if you want\n",
    "BATCH_SIZE = 32\n",
    "RESULT_CSV  = os.path.join(STATS_DIR, \"tcav_summary_v3.csv\")\n",
    "RESULT_JSON = os.path.join(STATS_DIR, \"tcav_summary_v3.json\")\n",
    "\n",
    "# Load cohorts & metadata\n",
    "with open(os.path.join(STATS_DIR, \"near_threshold_balanced_v3.json\"), \"r\") as f:\n",
    "    bal = json.load(f)\n",
    "with open(os.path.join(META_DIR, \"thresholds_v1TH.json\"), \"r\") as f:\n",
    "    thresholds = json.load(f)\n",
    "with open(os.path.join(META_DIR, \"concepts_v3.json\"), \"r\") as f:\n",
    "    concepts = json.load(f)\n",
    "\n",
    "ids_df  = pd.read_csv(os.path.join(EMB_DIR, \"ids.csv\"))\n",
    "labels = [r[\"label\"] for r in bal[\"cohorts\"]]\n",
    "concept_names = [c[\"name\"] for c in concepts]\n",
    "\n",
    "# Build eval index map\n",
    "eval_ids_map = {}\n",
    "for row in bal[\"cohorts\"]:\n",
    "    lbl = row[\"label\"]\n",
    "    pth = os.path.join(EMB_DIR, f\"eval_ids_balanced_{lbl.replace('/', '-')}.npy\")\n",
    "    if os.path.exists(pth):\n",
    "        eval_ids_map[lbl] = np.load(pth)\n",
    "\n",
    "# Helpers to load CAVs\n",
    "def load_cav_runs(concept):\n",
    "    runs = []\n",
    "    k = 0\n",
    "    while True:\n",
    "        path = os.path.join(CAV_REAL, f\"{concept}_run{k}.npy\")\n",
    "        if os.path.exists(path):\n",
    "            runs.append(np.load(path))\n",
    "            k += 1\n",
    "        else:\n",
    "            break\n",
    "    return np.array(runs) if runs else None\n",
    "\n",
    "def load_nulls(concept, label):\n",
    "    nulls = []\n",
    "    n = 0\n",
    "    while True:\n",
    "        path = os.path.join(CAV_NULL, f\"{concept}_{label}_null{n}.npy\")\n",
    "        if os.path.exists(path):\n",
    "            nulls.append(np.load(path))\n",
    "            n += 1\n",
    "        else:\n",
    "            break\n",
    "    return np.array(nulls) if nulls else None\n",
    "\n",
    "# Gradients of target logit wrt CLS at chosen bottleneck layer\n",
    "def bottleneck_cls_grads(smiles_list, label_idx, batch_size=BATCH_SIZE, layer_offset=BOTTLENECK_LAYER):\n",
    "    grads = []\n",
    "    model.eval()\n",
    "    with torch.enable_grad():\n",
    "        for i in range(0, len(smiles_list), batch_size):\n",
    "            smi = smiles_list[i:i+batch_size]\n",
    "            enc = tokenizer(\n",
    "                smi, truncation=True, padding=True, max_length=128, return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "\n",
    "            out = model(**enc, output_hidden_states=True, return_dict=True)\n",
    "            h = out.hidden_states[layer_offset]      # (B, L, H) â€” non-final layer\n",
    "            h.requires_grad_(True)\n",
    "\n",
    "            logits = out.logits                      # (B, num_labels)\n",
    "            target = logits[:, label_idx].sum()\n",
    "            g_all = torch.autograd.grad(\n",
    "                outputs=target, inputs=h, retain_graph=False, create_graph=False, allow_unused=True\n",
    "            )[0]\n",
    "            if g_all is None:\n",
    "                g_all = torch.zeros_like(h)\n",
    "\n",
    "            g_cls = g_all[:, 0, :].detach().cpu().numpy()   # CLS grads: (B, H)\n",
    "            grads.append(g_cls)\n",
    "\n",
    "            # free\n",
    "            del out, h, logits, target, g_all\n",
    "            torch.cuda.empty_cache()\n",
    "    return np.vstack(grads) if grads else np.zeros((0,))\n",
    "\n",
    "# Resume/append support\n",
    "if os.path.exists(RESULT_CSV):\n",
    "    res_df = pd.read_csv(RESULT_CSV)\n",
    "else:\n",
    "    res_df = pd.DataFrame(columns=[\n",
    "        \"label\",\"concept\",\"K_runs\",\"N_eval\",\"tcav_mean\",\"ci95_lo\",\"ci95_hi\",\"p_emp_null\",\"n_null\",\"q_value\"\n",
    "    ])\n",
    "\n",
    "labels_to_do = [lbl for lbl in labels if lbl in eval_ids_map]\n",
    "print(f\"Labels to process: {labels_to_do}\")\n",
    "\n",
    "for li, lbl in enumerate(labels_to_do):\n",
    "    t0 = time.time()\n",
    "    eval_idx = eval_ids_map[lbl]\n",
    "    if len(eval_idx) == 0:\n",
    "        print(f\"â­ï¸  {lbl}: empty eval idx, skip.\")\n",
    "        continue\n",
    "\n",
    "    smiles_eval = ids_df.iloc[eval_idx][\"smiles\"].tolist()\n",
    "    print(f\"\\n[{lbl}] computing bottleneck grads for {len(smiles_eval)} molecules at layer {BOTTLENECK_LAYER} â€¦\")\n",
    "    grads_bn = bottleneck_cls_grads(smiles_eval, label_idx=li, layer_offset=BOTTLENECK_LAYER)\n",
    "    if grads_bn.shape[0] == 0:\n",
    "        print(f\"âš ï¸  {lbl}: got zero grads; skipping.\")\n",
    "        continue\n",
    "\n",
    "    label_rows = []\n",
    "    for c in concept_names:\n",
    "        real = load_cav_runs(c)\n",
    "        if real is None or real.shape[0] == 0:\n",
    "            continue\n",
    "        real = real / (np.linalg.norm(real, axis=1, keepdims=True) + 1e-8)   # normalize\n",
    "        proj_real = grads_bn @ real.T                      # (N_eval, K)\n",
    "        run_fracs = (proj_real > 0).mean(axis=0)           # (K,)\n",
    "        tcav_mean = float(run_fracs.mean())\n",
    "        K = int(real.shape[0])\n",
    "        sd = float(run_fracs.std(ddof=1)) if K > 1 else 0.0\n",
    "        lo = max(0.0, tcav_mean - 1.96 * sd / max(1, np.sqrt(K)))\n",
    "        hi = min(1.0, tcav_mean + 1.96 * sd / max(1, np.sqrt(K)))\n",
    "\n",
    "        null = load_nulls(c, lbl)\n",
    "        if null is not None and null.shape[0] > 0:\n",
    "            null = null / (np.linalg.norm(null, axis=1, keepdims=True) + 1e-8)\n",
    "            proj_null = grads_bn @ null.T                  # (N_eval, N_null)\n",
    "            run_fracs_null = (proj_null > 0).mean(axis=0)\n",
    "            p_emp = float((run_fracs_null >= tcav_mean).mean())\n",
    "            n_null = int(null.shape[0])\n",
    "        else:\n",
    "            p_emp, n_null = np.nan, 0\n",
    "\n",
    "        label_rows.append({\n",
    "            \"label\": lbl, \"concept\": c, \"K_runs\": K, \"N_eval\": int(grads_bn.shape[0]),\n",
    "            \"tcav_mean\": round(tcav_mean, 4),\n",
    "            \"ci95_lo\": round(lo, 4), \"ci95_hi\": round(hi, 4),\n",
    "            \"p_emp_null\": p_emp, \"n_null\": n_null\n",
    "        })\n",
    "\n",
    "        if len(label_rows) % 5 == 0:\n",
    "            print(f\"  {lbl}: processed {len(label_rows)}/{len(concept_names)} conceptsâ€¦\")\n",
    "\n",
    "    if label_rows:\n",
    "        tmp = pd.DataFrame(label_rows)\n",
    "\n",
    "        # BH-FDR within label\n",
    "        mask = ~tmp[\"p_emp_null\"].isna().values\n",
    "        if mask.sum() > 0:\n",
    "            tmp.loc[mask, \"q_value\"] = multipletests(tmp.loc[mask, \"p_emp_null\"], alpha=0.05, method=\"fdr_bh\")[1]\n",
    "        else:\n",
    "            tmp[\"q_value\"] = np.nan\n",
    "\n",
    "        # replace existing rows for this label and save incrementally\n",
    "        res_df = res_df[res_df[\"label\"] != lbl]\n",
    "        res_df = pd.concat([res_df, tmp], ignore_index=True)\n",
    "\n",
    "        res_df.to_csv(RESULT_CSV, index=False)\n",
    "        with open(RESULT_JSON, \"w\") as f:\n",
    "            json.dump(json.loads(res_df.to_json(orient=\"records\")), f, indent=2)\n",
    "\n",
    "        took = time.time() - t0\n",
    "        sig_ct = int((tmp[\"q_value\"] <= 0.05).sum()) if \"q_value\" in tmp else 0\n",
    "        print(f\"âœ… {lbl}: saved {len(tmp)} rows (significant={sig_ct}) in {took:.1f}s\")\n",
    "    else:\n",
    "        print(f\"â„¹ï¸ {lbl}: no concepts available (did Cell 5 finish for all concepts?)\")\n",
    "\n",
    "print(\"\\nDone. Results at:\")\n",
    "print(\" â€¢\", RESULT_CSV)\n",
    "print(\" â€¢\", RESULT_JSON)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d565190",
   "metadata": {},
   "source": [
    "### 6a: Sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41ea277a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded TCAV rows: 108 across 12 labels\n",
      "   Fraction tcav_mean â‰¥ 0.95: 0.009 | â‰¤ 0.05: 0.000\n",
      "ðŸ“Š Saved:\n",
      "  â€¢ per-label overview -> implementation/v3\\stats\\tcav_sanity_overview_v3.csv\n",
      "  â€¢ top-3 significant concepts per label -> implementation/v3\\stats\\tcav_sanity_tops_v3.csv\n",
      "\n",
      "ðŸ”Ž Per-label overview (first rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n_concepts</th>\n",
       "      <th>n_sig</th>\n",
       "      <th>med_tcav</th>\n",
       "      <th>sd_tcav</th>\n",
       "      <th>n_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-AR</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3483</td>\n",
       "      <td>0.121891</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3362</td>\n",
       "      <td>0.228725</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3398</td>\n",
       "      <td>0.164853</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4355</td>\n",
       "      <td>0.166156</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3096</td>\n",
       "      <td>0.244682</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NR-ER-LBD</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3459</td>\n",
       "      <td>0.215535</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3167</td>\n",
       "      <td>0.262449</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3006</td>\n",
       "      <td>0.159449</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SR-ATAD5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3763</td>\n",
       "      <td>0.178849</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2614</td>\n",
       "      <td>0.108237</td>\n",
       "      <td>4265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SR-MMP</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3836</td>\n",
       "      <td>0.160372</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SR-p53</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4315</td>\n",
       "      <td>0.235365</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label  n_concepts  n_sig  med_tcav   sd_tcav  n_eval\n",
       "0           NR-AR           9      0    0.3483  0.121891     298\n",
       "1       NR-AR-LBD           9      0    0.3362  0.228725     304\n",
       "2          NR-AhR           9      0    0.3398  0.164853     344\n",
       "3    NR-Aromatase           9      0    0.4355  0.166156      76\n",
       "4           NR-ER           9      0    0.3096  0.244682     460\n",
       "5       NR-ER-LBD           9      0    0.3459  0.215535     776\n",
       "6   NR-PPAR-gamma           9      1    0.3167  0.262449      42\n",
       "7          SR-ARE           9      0    0.3006  0.159449     702\n",
       "8        SR-ATAD5           9      0    0.3763  0.178849     490\n",
       "9          SR-HSE           9      0    0.2614  0.108237    4265\n",
       "10         SR-MMP           9      0    0.3836  0.160372     560\n",
       "11         SR-p53           9      0    0.4315  0.235365     800"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”Ž Top-3 significant concepts per label:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>concept</th>\n",
       "      <th>tcav_mean</th>\n",
       "      <th>ci95_lo</th>\n",
       "      <th>ci95_hi</th>\n",
       "      <th>p_emp_null</th>\n",
       "      <th>q_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label       concept  tcav_mean  ci95_lo  ci95_hi  p_emp_null  \\\n",
       "54  NR-PPAR-gamma  AromaticRing     0.9524   0.9524   0.9524         0.0   \n",
       "\n",
       "    q_value  \n",
       "54      0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sanity-A: Overview of TCAV results (no heavy compute)\n",
    "\n",
    "import os, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "BASE_DIR  = \"implementation/v3\"\n",
    "STATS_DIR = os.path.join(BASE_DIR, \"stats\")\n",
    "META_DIR  = os.path.join(BASE_DIR, \"metadata\")\n",
    "\n",
    "tcav_path = os.path.join(STATS_DIR, \"tcav_summary_v3.csv\")\n",
    "assert os.path.exists(tcav_path), f\"Missing {tcav_path} â€” run Cell 6 first.\"\n",
    "\n",
    "df = pd.read_csv(tcav_path)\n",
    "\n",
    "# basic checks\n",
    "n_rows = len(df)\n",
    "n_labels = df[\"label\"].nunique()\n",
    "near_ones = (df[\"tcav_mean\"] >= 0.95).mean()\n",
    "near_zeros = (df[\"tcav_mean\"] <= 0.05).mean()\n",
    "\n",
    "print(f\"âœ… Loaded TCAV rows: {n_rows} across {n_labels} labels\")\n",
    "print(f\"   Fraction tcav_mean â‰¥ 0.95: {near_ones:.3f} | â‰¤ 0.05: {near_zeros:.3f}\")\n",
    "\n",
    "# per-label summary\n",
    "df[\"significant\"] = df[\"q_value\"] <= 0.05\n",
    "summ = (df.groupby(\"label\")\n",
    "          .agg(n_concepts=(\"concept\",\"nunique\"),\n",
    "               n_sig=(\"significant\",\"sum\"),\n",
    "               med_tcav=(\"tcav_mean\",\"median\"),\n",
    "               sd_tcav=(\"tcav_mean\",\"std\"),\n",
    "               n_eval=(\"N_eval\",\"max\"))\n",
    "          .reset_index()\n",
    "          .sort_values(\"label\"))\n",
    "\n",
    "# top-3 significant concepts per label\n",
    "tops = (df[df[\"significant\"]]\n",
    "        .sort_values([\"label\",\"tcav_mean\"], ascending=[True, False])\n",
    "        .groupby(\"label\")\n",
    "        .head(3)\n",
    "        [[\"label\",\"concept\",\"tcav_mean\",\"ci95_lo\",\"ci95_hi\",\"p_emp_null\",\"q_value\"]])\n",
    "\n",
    "overview_csv = os.path.join(STATS_DIR, \"tcav_sanity_overview_v3.csv\")\n",
    "tops_csv     = os.path.join(STATS_DIR, \"tcav_sanity_tops_v3.csv\")\n",
    "summ.to_csv(overview_csv, index=False)\n",
    "tops.to_csv(tops_csv, index=False)\n",
    "\n",
    "print(\"ðŸ“Š Saved:\")\n",
    "print(\"  â€¢ per-label overview ->\", overview_csv)\n",
    "print(\"  â€¢ top-3 significant concepts per label ->\", tops_csv)\n",
    "\n",
    "print(\"\\nðŸ”Ž Per-label overview (first rows):\")\n",
    "display(summ.head(12))\n",
    "print(\"\\nðŸ”Ž Top-3 significant concepts per label:\")\n",
    "display(tops.head(36))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d776a00",
   "metadata": {},
   "source": [
    "### 6c: sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc675816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”— Overall corr(tcav_mean, coverage) = 0.238\n",
      "ðŸ“Š Saved per-label correlations -> implementation/v3\\stats\\tcav_coverage_correlation_v3.csv\n",
      "\n",
      "ðŸ”Ž Per-label corr(tcav_mean, coverage):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_22632\\1317116566.py:26: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g[[\"tcav_mean\",\"coverage\"]].corr().iloc[0,1])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>0.740791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>0.702739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>0.408444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NR-ER-LBD</td>\n",
       "      <td>0.349046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-AR</td>\n",
       "      <td>0.337817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SR-p53</td>\n",
       "      <td>0.301017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>0.177967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>0.142335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SR-MMP</td>\n",
       "      <td>0.124390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SR-ATAD5</td>\n",
       "      <td>0.049663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>-0.300663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>-0.516011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label      corr\n",
       "4           NR-ER  0.740791\n",
       "6   NR-PPAR-gamma  0.702739\n",
       "2          NR-AhR  0.408444\n",
       "5       NR-ER-LBD  0.349046\n",
       "0           NR-AR  0.337817\n",
       "11         SR-p53  0.301017\n",
       "3    NR-Aromatase  0.177967\n",
       "7          SR-ARE  0.142335\n",
       "10         SR-MMP  0.124390\n",
       "8        SR-ATAD5  0.049663\n",
       "1       NR-AR-LBD -0.300663\n",
       "9          SR-HSE -0.516011"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sanity-B: Is TCAV just reflecting prevalence? (coverage correlation)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "BASE_DIR  = \"implementation/v3\"\n",
    "STATS_DIR = os.path.join(BASE_DIR, \"stats\")\n",
    "META_DIR  = os.path.join(BASE_DIR, \"metadata\")\n",
    "\n",
    "tcav_path = os.path.join(STATS_DIR, \"tcav_summary_v3.csv\")\n",
    "cov_path  = os.path.join(META_DIR, \"concept_coverage_v3.csv\")\n",
    "assert os.path.exists(tcav_path) and os.path.exists(cov_path)\n",
    "\n",
    "tcav = pd.read_csv(tcav_path)\n",
    "cov  = pd.read_csv(cov_path).rename(columns={\"name\":\"concept\"})\n",
    "\n",
    "merged = tcav.merge(cov[[\"concept\",\"coverage\"]], on=\"concept\", how=\"left\")\n",
    "\n",
    "# overall Pearson correlation\n",
    "overall_corr = merged[[\"tcav_mean\",\"coverage\"]].corr().iloc[0,1]\n",
    "print(f\"ðŸ”— Overall corr(tcav_mean, coverage) = {overall_corr:.3f}\")\n",
    "\n",
    "# per-label correlations\n",
    "per_label = (merged.groupby(\"label\")\n",
    "             .apply(lambda g: g[[\"tcav_mean\",\"coverage\"]].corr().iloc[0,1])\n",
    "             .reset_index().rename(columns={0:\"corr\"}))\n",
    "\n",
    "per_label_csv = os.path.join(STATS_DIR, \"tcav_coverage_correlation_v3.csv\")\n",
    "per_label.to_csv(per_label_csv, index=False)\n",
    "print(\"ðŸ“Š Saved per-label correlations ->\", per_label_csv)\n",
    "\n",
    "print(\"\\nðŸ”Ž Per-label corr(tcav_mean, coverage):\")\n",
    "display(per_label.sort_values(\"corr\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a1afc4",
   "metadata": {},
   "source": [
    "### 6d: sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "104cb8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Saved presence sanity -> implementation/v3\\stats\\tcav_presence_check_v3.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>concept</th>\n",
       "      <th>tcav_mean</th>\n",
       "      <th>q_value</th>\n",
       "      <th>present_rate</th>\n",
       "      <th>n_checked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label       concept  tcav_mean  q_value  present_rate  n_checked\n",
       "0  NR-PPAR-gamma  AromaticRing     0.9524      0.0        0.6429         42"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sanity-C: Presence check â€” do top concepts actually exist in near-threshold molecules?\n",
    "\n",
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "BASE_DIR  = \"implementation/v3\"\n",
    "EMB_DIR   = os.path.join(BASE_DIR, \"embeddings\")\n",
    "STATS_DIR = os.path.join(BASE_DIR, \"stats\")\n",
    "META_DIR  = os.path.join(BASE_DIR, \"metadata\")\n",
    "\n",
    "tcav_path = os.path.join(STATS_DIR, \"tcav_summary_v3.csv\")\n",
    "concepts_path = os.path.join(META_DIR, \"concepts_v3.json\")\n",
    "ids_path  = os.path.join(EMB_DIR, \"ids.csv\")\n",
    "\n",
    "tcav = pd.read_csv(tcav_path)\n",
    "with open(concepts_path, \"r\") as f:\n",
    "    concepts = {c[\"name\"]: c[\"smarts\"] for c in json.load(f)}\n",
    "ids_df = pd.read_csv(ids_path)\n",
    "\n",
    "# pick top-3 significant per label\n",
    "tops = (tcav[tcav[\"q_value\"] <= 0.05]\n",
    "        .sort_values([\"label\",\"tcav_mean\"], ascending=[True, False])\n",
    "        .groupby(\"label\")\n",
    "        .head(3)\n",
    "        [[\"label\",\"concept\",\"tcav_mean\",\"q_value\"]]\n",
    "        .reset_index(drop=True))\n",
    "\n",
    "def compile(smarts):\n",
    "    try:\n",
    "        return Chem.MolFromSmarts(smarts)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "compiled = {c: compile(s) for c, s in concepts.items()}\n",
    "\n",
    "rows = []\n",
    "MAX_CHECK = 200  # cap per label for speed\n",
    "\n",
    "for lbl in tops[\"label\"].unique():\n",
    "    eval_ids_path = os.path.join(EMB_DIR, f\"eval_ids_balanced_{lbl.replace('/', '-')}.npy\")\n",
    "    if not os.path.exists(eval_ids_path):\n",
    "        continue\n",
    "    eval_idx = np.load(eval_ids_path)\n",
    "    # subsample for speed\n",
    "    if len(eval_idx) > MAX_CHECK:\n",
    "        rng = np.random.default_rng(42)\n",
    "        eval_idx = rng.choice(eval_idx, size=MAX_CHECK, replace=False)\n",
    "    smiles = ids_df.iloc[eval_idx][\"smiles\"].tolist()\n",
    "    mols = [Chem.MolFromSmiles(s) for s in smiles]\n",
    "\n",
    "    sub = tops[tops[\"label\"] == lbl]\n",
    "    for _, r in sub.iterrows():\n",
    "        c = r[\"concept\"]\n",
    "        q = compiled.get(c, None)\n",
    "        if q is None:\n",
    "            present_rate = np.nan\n",
    "            n = 0\n",
    "        else:\n",
    "            hits = sum(1 for m in mols if m is not None and m.HasSubstructMatch(q))\n",
    "            present_rate = hits / max(1, len(mols))\n",
    "            n = len(mols)\n",
    "        rows.append({\n",
    "            \"label\": lbl, \"concept\": c, \"tcav_mean\": r[\"tcav_mean\"], \"q_value\": r[\"q_value\"],\n",
    "            \"present_rate\": round(present_rate, 4), \"n_checked\": n\n",
    "        })\n",
    "\n",
    "presence_df = pd.DataFrame(rows).sort_values([\"label\",\"tcav_mean\"], ascending=[True, False])\n",
    "presence_csv = os.path.join(STATS_DIR, \"tcav_presence_check_v3.csv\")\n",
    "presence_df.to_csv(presence_csv, index=False)\n",
    "\n",
    "print(\"ðŸ“Š Saved presence sanity ->\", presence_csv)\n",
    "display(presence_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acaa8e7",
   "metadata": {},
   "source": [
    "## 7: Faithfulness tests (Null FPR + SMARTS ablation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4eb326c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… (A) Null FPR saved -> implementation/v3\\reports\\faithfulness_null_fpr_v3.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>null_fpr_at_q0.05</th>\n",
       "      <th>n_null_tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-AR</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NR-ER-LBD</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SR-ATAD5</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SR-MMP</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SR-p53</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label  null_fpr_at_q0.05  n_null_tests\n",
       "0           NR-AR             0.0200           450\n",
       "1       NR-AR-LBD             0.0200           450\n",
       "2          NR-AhR             0.0178           450\n",
       "3    NR-Aromatase             0.0156           450\n",
       "4           NR-ER             0.0200           450\n",
       "5       NR-ER-LBD             0.0200           450\n",
       "6   NR-PPAR-gamma             0.0133           450\n",
       "7          SR-ARE             0.0200           450\n",
       "8        SR-ATAD5             0.0200           450\n",
       "9          SR-HSE             0.0200           450\n",
       "10         SR-MMP             0.0200           450\n",
       "11         SR-p53             0.0200           450"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… (B) SMARTS ablation saved -> implementation/v3\\reports\\faithfulness_ablation_v3.csv\n",
      "\n",
      "ðŸ”Ž Null FPR (qâ‰¤0.05) per label:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>null_fpr_at_q0.05</th>\n",
       "      <th>n_null_tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-AR</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NR-ER-LBD</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SR-ATAD5</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SR-MMP</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SR-p53</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label  null_fpr_at_q0.05  n_null_tests\n",
       "0           NR-AR             0.0200           450\n",
       "1       NR-AR-LBD             0.0200           450\n",
       "2          NR-AhR             0.0178           450\n",
       "3    NR-Aromatase             0.0156           450\n",
       "4           NR-ER             0.0200           450\n",
       "5       NR-ER-LBD             0.0200           450\n",
       "6   NR-PPAR-gamma             0.0133           450\n",
       "7          SR-ARE             0.0200           450\n",
       "8        SR-ATAD5             0.0200           450\n",
       "9          SR-HSE             0.0200           450\n",
       "10         SR-MMP             0.0200           450\n",
       "11         SR-p53             0.0200           450"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”Ž Ablation Î”p summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>concept</th>\n",
       "      <th>n_pairs</th>\n",
       "      <th>mean_delta_p</th>\n",
       "      <th>ci95_lo</th>\n",
       "      <th>ci95_hi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>AromaticRing</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.0382</td>\n",
       "      <td>-0.0767</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label       concept  n_pairs  mean_delta_p  ci95_lo  ci95_hi\n",
       "0  NR-PPAR-gamma  AromaticRing       26       -0.0382  -0.0767   0.0003"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 7: Faithfulness tests â€” (A) Null FPR via holdout-null; (B) SMARTS ablation Î”p\n",
    "\n",
    "import os, json, time, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from rdkit import Chem\n",
    "\n",
    "# Reuse from earlier cells:\n",
    "BASE_DIR  = \"implementation/v3\"\n",
    "EMB_DIR   = os.path.join(BASE_DIR, \"embeddings\")\n",
    "CAV_NULL  = os.path.join(BASE_DIR, \"cav\", \"nulls\")\n",
    "STATS_DIR = os.path.join(BASE_DIR, \"stats\")\n",
    "META_DIR  = os.path.join(BASE_DIR, \"metadata\")\n",
    "REPORTS_DIR = os.path.join(BASE_DIR, \"reports\")\n",
    "os.makedirs(REPORTS_DIR, exist_ok=True)\n",
    "\n",
    "# ---- Config (match Cell 6) ----\n",
    "BOTTLENECK_LAYER = -5      # same bottleneck as Cell 6\n",
    "BATCH_SIZE = 32\n",
    "TOP_K_CONCEPTS = 2         # ablation: top-K significant concepts per label\n",
    "MAX_MOLS_PER_LABEL = 100   # ablation: cap molecules per label to keep it quick\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "# ---- Load essentials ----\n",
    "tcav_csv = os.path.join(STATS_DIR, \"tcav_summary_v3.csv\")\n",
    "assert os.path.exists(tcav_csv), \"Missing tcav_summary_v3.csv â€“ run Cell 6 first.\"\n",
    "tcav = pd.read_csv(tcav_csv)\n",
    "\n",
    "ids_df  = pd.read_csv(os.path.join(EMB_DIR, \"ids.csv\"))\n",
    "with open(os.path.join(META_DIR, \"concepts_v3.json\"), \"r\") as f:\n",
    "    concepts_j = json.load(f)\n",
    "CONCEPT_SMARTS = {c[\"name\"]: c[\"smarts\"] for c in concepts_j}\n",
    "concept_names  = list(CONCEPT_SMARTS.keys())\n",
    "\n",
    "with open(os.path.join(STATS_DIR, \"near_threshold_balanced_v3.json\"), \"r\") as f:\n",
    "    bal = json.load(f)\n",
    "labels = [row[\"label\"] for row in bal[\"cohorts\"]]\n",
    "\n",
    "# Build eval index map\n",
    "eval_ids_map = {}\n",
    "for row in bal[\"cohorts\"]:\n",
    "    lbl = row[\"label\"]\n",
    "    pth = os.path.join(EMB_DIR, f\"eval_ids_balanced_{lbl.replace('/', '-')}.npy\")\n",
    "    if os.path.exists(pth):\n",
    "        eval_ids_map[lbl] = np.load(pth)\n",
    "\n",
    "# Helpers to load null cavs\n",
    "def load_nulls(concept, label):\n",
    "    nulls = []\n",
    "    n = 0\n",
    "    while True:\n",
    "        path = os.path.join(CAV_NULL, f\"{concept}_{label}_null{n}.npy\")\n",
    "        if os.path.exists(path):\n",
    "            nulls.append(np.load(path))\n",
    "            n += 1\n",
    "        else:\n",
    "            break\n",
    "    return np.array(nulls) if nulls else None\n",
    "\n",
    "# Gradients of target logit w.r.t CLS at chosen bottleneck layer (same as Cell 6)\n",
    "def bottleneck_cls_grads(smiles_list, label_idx, batch_size=BATCH_SIZE, layer_offset=BOTTLENECK_LAYER):\n",
    "    grads = []\n",
    "    model.eval()\n",
    "    with torch.enable_grad():\n",
    "        for i in range(0, len(smiles_list), batch_size):\n",
    "            smi = smiles_list[i:i+batch_size]\n",
    "            enc = tokenizer(\n",
    "                smi, truncation=True, padding=True, max_length=128, return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "\n",
    "            out = model(**enc, output_hidden_states=True, return_dict=True)\n",
    "            h = out.hidden_states[layer_offset]      # (B, L, H)\n",
    "            h.requires_grad_(True)\n",
    "\n",
    "            logits = out.logits                      # (B, num_labels)\n",
    "            target = logits[:, label_idx].sum()\n",
    "            g_all = torch.autograd.grad(\n",
    "                outputs=target, inputs=h, retain_graph=False, create_graph=False, allow_unused=True\n",
    "            )[0]\n",
    "            if g_all is None:\n",
    "                g_all = torch.zeros_like(h)\n",
    "\n",
    "            g_cls = g_all[:, 0, :].detach().cpu().numpy()\n",
    "            grads.append(g_cls)\n",
    "\n",
    "            del out, h, logits, target, g_all\n",
    "            torch.cuda.empty_cache()\n",
    "    return np.vstack(grads) if grads else np.zeros((0,))\n",
    "\n",
    "# ==============================\n",
    "# (A) Null FPR via holdout-null\n",
    "# ==============================\n",
    "fpr_rows = []\n",
    "for li, lbl in enumerate(labels):\n",
    "    if lbl not in eval_ids_map: \n",
    "        continue\n",
    "    eval_idx = eval_ids_map[lbl]\n",
    "    if len(eval_idx) == 0:\n",
    "        continue\n",
    "\n",
    "    smiles_eval = ids_df.iloc[eval_idx][\"smiles\"].tolist()\n",
    "    grads_bn = bottleneck_cls_grads(smiles_eval, label_idx=li, layer_offset=BOTTLENECK_LAYER)\n",
    "    if grads_bn.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    # For each concept, compute tcav for each null vector vs the remaining nulls\n",
    "    pvals = []\n",
    "    for c in concept_names:\n",
    "        null = load_nulls(c, lbl)\n",
    "        if null is None or null.shape[0] < 5:\n",
    "            continue\n",
    "        # normalize\n",
    "        null = null / (np.linalg.norm(null, axis=1, keepdims=True) + 1e-8)  # (N_null, H)\n",
    "        # projections (N_eval, N_null)\n",
    "        proj = grads_bn @ null.T\n",
    "        run_fracs = (proj > 0).mean(axis=0)  # (N_null,)\n",
    "\n",
    "        # holdout p for each null_i against others\n",
    "        for i in range(len(run_fracs)):\n",
    "            x = run_fracs[i]\n",
    "            others = np.delete(run_fracs, i)\n",
    "            p_emp = float((others >= x).mean())\n",
    "            pvals.append(p_emp)\n",
    "\n",
    "    if len(pvals) == 0:\n",
    "        continue\n",
    "\n",
    "    # BH-FDR across all nulls of this label\n",
    "    pvals = np.array(pvals, dtype=float)\n",
    "    qvals = multipletests(pvals, alpha=0.05, method=\"fdr_bh\")[1]\n",
    "    fpr = float((qvals <= 0.05).mean())  # fraction of nulls deemed \"significant\"\n",
    "    fpr_rows.append({\"label\": lbl, \"null_fpr_at_q0.05\": round(fpr, 4), \"n_null_tests\": int(len(pvals))})\n",
    "\n",
    "fpr_df = pd.DataFrame(fpr_rows).sort_values(\"label\")\n",
    "fpr_csv = os.path.join(REPORTS_DIR, \"faithfulness_null_fpr_v3.csv\")\n",
    "fpr_df.to_csv(fpr_csv, index=False)\n",
    "print(\"âœ… (A) Null FPR saved ->\", fpr_csv)\n",
    "display(fpr_df)\n",
    "\n",
    "# =================================\n",
    "# (B) SMARTS ablation Î”p per label\n",
    "# =================================\n",
    "# choose top-K significant concepts per label (from TCAV)\n",
    "tops = (tcav[tcav[\"q_value\"] <= 0.05]\n",
    "        .sort_values([\"label\",\"tcav_mean\"], ascending=[True, False])\n",
    "        .groupby(\"label\")\n",
    "        .head(TOP_K_CONCEPTS)\n",
    "        [[\"label\",\"concept\",\"tcav_mean\",\"q_value\"]]\n",
    "        .reset_index(drop=True))\n",
    "\n",
    "def replace_smarts_with_dummy(smi, smarts):\n",
    "    \"\"\"Replace all occurrences of SMARTS with a dummy atom '*'.\n",
    "       Return ablated largest-fragment SMILES or None if failure.\"\"\"\n",
    "    m = Chem.MolFromSmiles(smi)\n",
    "    q = Chem.MolFromSmarts(smarts)\n",
    "    if m is None or q is None:\n",
    "        return None\n",
    "    try:\n",
    "        reps = Chem.ReplaceSubstructs(m, q, Chem.MolFromSmiles(\"*\"), replaceAll=True)\n",
    "        if not reps: \n",
    "            return None\n",
    "        rep = reps[0]\n",
    "        # Split to fragments; keep largest by atom count\n",
    "        frags = Chem.GetMolFrags(rep, asMols=True)\n",
    "        if not frags:\n",
    "            return None\n",
    "        frag = max(frags, key=lambda x: x.GetNumAtoms())\n",
    "        Chem.SanitizeMol(frag)\n",
    "        return Chem.MolToSmiles(frag, canonical=True)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# quick prob function\n",
    "def probs_for(smiles_list, label_idx):\n",
    "    ps = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(smiles_list), BATCH_SIZE):\n",
    "            batch = smiles_list[i:i+BATCH_SIZE]\n",
    "            enc = tokenizer(\n",
    "                batch, truncation=True, padding=True, max_length=128, return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "            logits = model(**enc).logits\n",
    "            p = torch.sigmoid(logits)[:, label_idx].detach().cpu().numpy()\n",
    "            ps.append(p)\n",
    "    return np.concatenate(ps) if ps else np.array([])\n",
    "\n",
    "abl_rows = []\n",
    "\n",
    "for li, lbl in enumerate(labels):\n",
    "    if lbl not in eval_ids_map:\n",
    "        continue\n",
    "    eval_idx = eval_ids_map[lbl]\n",
    "    if len(eval_idx) == 0:\n",
    "        continue\n",
    "\n",
    "    # pick molecules from near-threshold set\n",
    "    mols = ids_df.iloc[eval_idx][[\"mol_id\",\"smiles\"]].copy()\n",
    "    if len(mols) > MAX_MOLS_PER_LABEL:\n",
    "        sel_idx = rng.choice(mols.index.values, size=MAX_MOLS_PER_LABEL, replace=False)\n",
    "        mols = mols.loc[sel_idx].reset_index(drop=True)\n",
    "\n",
    "    # top concepts for this label\n",
    "    sub = tops[tops[\"label\"] == lbl]\n",
    "    if sub.empty:\n",
    "        continue\n",
    "\n",
    "    for _, row in sub.iterrows():\n",
    "        concept = row[\"concept\"]\n",
    "        smarts  = CONCEPT_SMARTS.get(concept, None)\n",
    "        if not smarts:\n",
    "            continue\n",
    "\n",
    "        # find which selected molecules actually contain the concept\n",
    "        q = Chem.MolFromSmarts(smarts)\n",
    "        present_mask = []\n",
    "        for smi in mols[\"smiles\"].tolist():\n",
    "            m = Chem.MolFromSmiles(smi)\n",
    "            present_mask.append(bool(m and q and m.HasSubstructMatch(q)))\n",
    "        present_mask = np.array(present_mask, dtype=bool)\n",
    "\n",
    "        if present_mask.sum() == 0:\n",
    "            # nothing to ablate for this concept/label subset\n",
    "            continue\n",
    "\n",
    "        smi_present = mols.loc[present_mask, \"smiles\"].tolist()\n",
    "        # make ablated smiles\n",
    "        smi_abl = []\n",
    "        for s in smi_present:\n",
    "            s2 = replace_smarts_with_dummy(s, smarts)\n",
    "            smi_abl.append(s2)\n",
    "        # filter out failed ablations\n",
    "        keep = [i for i, s2 in enumerate(smi_abl) if isinstance(s2, str) and len(s2) > 0]\n",
    "        if len(keep) == 0:\n",
    "            continue\n",
    "\n",
    "        smi_present = [smi_present[i] for i in keep]\n",
    "        smi_abl = [smi_abl[i] for i in keep]\n",
    "\n",
    "        # probs before/after\n",
    "        p_before = probs_for(smi_present, label_idx=li)\n",
    "        p_after  = probs_for(smi_abl,     label_idx=li)\n",
    "        if len(p_before) == 0 or len(p_after) == 0:\n",
    "            continue\n",
    "\n",
    "        delta = p_before - p_after\n",
    "        mean_dp = float(delta.mean())\n",
    "        sd_dp = float(delta.std(ddof=1)) if len(delta) > 1 else 0.0\n",
    "        ci_lo = mean_dp - 1.96 * sd_dp / max(1, math.sqrt(len(delta)))\n",
    "        ci_hi = mean_dp + 1.96 * sd_dp / max(1, math.sqrt(len(delta)))\n",
    "\n",
    "        abl_rows.append({\n",
    "            \"label\": lbl, \"concept\": concept,\n",
    "            \"n_pairs\": int(len(delta)),\n",
    "            \"mean_delta_p\": round(mean_dp, 4),\n",
    "            \"ci95_lo\": round(ci_lo, 4), \"ci95_hi\": round(ci_hi, 4)\n",
    "        })\n",
    "\n",
    "abl_df = pd.DataFrame(abl_rows).sort_values([\"label\",\"mean_delta_p\"], ascending=[True, False])\n",
    "abl_csv = os.path.join(REPORTS_DIR, \"faithfulness_ablation_v3.csv\")\n",
    "abl_df.to_csv(abl_csv, index=False)\n",
    "print(\"âœ… (B) SMARTS ablation saved ->\", abl_csv)\n",
    "\n",
    "print(\"\\nðŸ”Ž Null FPR (qâ‰¤0.05) per label:\")\n",
    "display(fpr_df)\n",
    "\n",
    "print(\"\\nðŸ”Ž Ablation Î”p summary:\")\n",
    "display(abl_df.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ae98f9",
   "metadata": {},
   "source": [
    "## 8: Test A, Single-molecule SMARTS ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7330f6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”® Model predictions (utils model) â€” sorted by probability:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "      <th>threshold</th>\n",
       "      <th>predicted_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.370</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.392</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SR-MMP</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.470</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>0.103093</td>\n",
       "      <td>0.540</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SR-p53</td>\n",
       "      <td>0.061069</td>\n",
       "      <td>0.050</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NR-AR</td>\n",
       "      <td>0.038674</td>\n",
       "      <td>0.620</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SR-ATAD5</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.280</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.460</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.050</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NR-ER-LBD</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>0.425</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.050</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label      prob  threshold  predicted_positive\n",
       "0          NR-AhR  0.180328      0.370               False\n",
       "1          SR-ARE  0.137931      0.392               False\n",
       "2          SR-MMP  0.119048      0.470               False\n",
       "3           NR-ER  0.103093      0.540               False\n",
       "4          SR-p53  0.061069      0.050                True\n",
       "5           NR-AR  0.038674      0.620               False\n",
       "6        SR-ATAD5  0.038462      0.280               False\n",
       "7       NR-AR-LBD  0.016000      0.460               False\n",
       "8   NR-PPAR-gamma  0.010000      0.050               False\n",
       "9          SR-HSE  0.008333      0.050               False\n",
       "10      NR-ER-LBD  0.006920      0.425               False\n",
       "11   NR-Aromatase  0.004673      0.050               False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§ª Mechanistic reports (presence-gated, utils model):\n",
      "\n",
      "ðŸ” SR-p53 â€” Report\n",
      "   Presence-gated; contributions=(tcavâˆ’0.5)Ã—(1âˆ’q), boosted if present in this molecule.\n",
      "   â€¢ ArylHalide (â†‘), tcav=0.89, q=0.36, contrib=0.251, final=0.251\n",
      "     â†³ halogenated aryl increasing lipophilicity and metabolic stability\n",
      "   â€¢ AromaticRing (â†‘), tcav=0.80, q=0.45, contrib=0.163, final=0.163\n",
      "     â†³ planar Ï€-system enabling hydrophobic/Ï€â€“Ï€ interactions\n",
      "   â€¢ MichaelAcceptor (â†“), tcav=0.21, q=0.82, contrib=-0.052, final=-0.052\n",
      "     â†³ Î±,Î²-unsaturated system acting as a soft electrophile (Michael acceptor)\n",
      "   â€¢ Ester (â†“), tcav=0.31, q=0.82, contrib=-0.033, final=-0.033\n",
      "     â†³ polar carbonyl/alkoxy modulating permeability and metabolism\n",
      "   â€¢ Nitro (â†“), tcav=0.32, q=0.82, contrib=-0.033, final=-0.033\n",
      "     â†³ nitro functionality linked to bioactivation and potential DNA/protein adducts\n",
      "   â€¢ Urea (â†‘), tcav=0.66, q=0.82, contrib=0.030, final=0.030\n",
      "     â†³ bifunctional H-bond donor/acceptor motif\n",
      "\n",
      "ðŸ’¾ Saved JSON: implementation/v3\\reports\\mechanistic_report_utils_v3_20250901-101421.json\n"
     ]
    }
   ],
   "source": [
    "# Test A (utils-integrated): Predict + presence-gated TCAV v3 mechanistic report\n",
    "# for a SINGLE SMILES, with warnings for problematic endpoints.\n",
    "\n",
    "import os, json, time, numpy as np, pandas as pd\n",
    "from importlib import reload\n",
    "from rdkit import Chem\n",
    "\n",
    "import utils as U\n",
    "U = reload(U)  # ensure we pick up your latest utils.py edits\n",
    "\n",
    "# ---- Inputs ----\n",
    "TEST_SMILES = \"CCOc1ccc2nc(S(N)(=O)=O)sc2c1\"   # your example\n",
    "BASE_DIR    = \"implementation/v3\"\n",
    "STATS_DIR   = os.path.join(BASE_DIR, \"stats\")\n",
    "META_DIR    = os.path.join(BASE_DIR, \"metadata\")\n",
    "TCAV_CSV    = os.path.join(STATS_DIR, \"tcav_summary_v3.csv\")\n",
    "BAL_JSON    = os.path.join(STATS_DIR, \"near_threshold_balanced_v3.json\")\n",
    "REPORT_DIR  = os.path.join(BASE_DIR, \"reports\"); os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "\n",
    "# ---- Predictions via utils model (calibrated) ----\n",
    "probs_dict = U.predict_probs(TEST_SMILES)                 # {label: prob}\n",
    "labels     = U.label_cols                                 # label order from utils model\n",
    "thr        = U.thresholds                                 # v1TH.json from utils metadata\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"label\": labels,\n",
    "    \"prob\": [probs_dict[l] for l in labels],\n",
    "    \"threshold\": [thr.get(l, 0.5) for l in labels]\n",
    "}).sort_values(\"prob\", ascending=False).reset_index(drop=True)\n",
    "pred_df[\"predicted_positive\"] = pred_df[\"prob\"] >= pred_df[\"threshold\"]\n",
    "\n",
    "print(\"ðŸ”® Model predictions (utils model) â€” sorted by probability:\")\n",
    "display(pred_df)\n",
    "\n",
    "# ---- Detect â€œproblematicâ€ endpoints based on your balanced cohorts ----\n",
    "problem_labels = set()\n",
    "if os.path.exists(BAL_JSON):\n",
    "    with open(BAL_JSON, \"r\") as f:\n",
    "        bal = json.load(f)\n",
    "    for row in bal[\"cohorts\"]:\n",
    "        if (row.get(\"n_total_used\", 0) < 100) or (row.get(\"n_pos_used\", 0) == 0) or (row.get(\"n_neg_used\", 0) == 0):\n",
    "            problem_labels.add(row[\"label\"])\n",
    "\n",
    "# ---- Load TCAV v3 summary for explanations ----\n",
    "tcav = pd.read_csv(TCAV_CSV)  # expects columns incl. label, concept, tcav_mean, q_value\n",
    "\n",
    "# Presence gating using utils' SMARTS map\n",
    "def present_count(smiles, concept):\n",
    "    is_present, count = U._concept_present_in_smiles(smiles, concept)  # uses utils.CONCEPT_TO_SMARTS\n",
    "    return bool(is_present), int(count)\n",
    "\n",
    "def mechanistic_report_v3(smiles, label, top_k=6):\n",
    "    sub = tcav[tcav[\"label\"] == label].copy()\n",
    "    if sub.empty:\n",
    "        return {\"label\": label, \"items\": [], \"note\": \"No TCAV rows for this label.\", \"warning\": None}\n",
    "\n",
    "    # presence gate + contribution score = (tcav_mean - 0.5) * (1 - q)\n",
    "    sub[\"q_value\"] = sub[\"q_value\"].fillna(1.0).clip(0, 1)\n",
    "    sub[\"contrib\"] = (sub[\"tcav_mean\"] - 0.5) * (1.0 - sub[\"q_value\"])\n",
    "    pres, pres_cnt = [], []\n",
    "    for c in sub[\"concept\"].astype(str):\n",
    "        p, n = present_count(smiles, c)\n",
    "        pres.append(p); pres_cnt.append(n)\n",
    "    sub[\"present\"] = pres\n",
    "    sub[\"present_count\"] = pres_cnt\n",
    "    # slight boost if present in this molecule (like utils does)\n",
    "    sub[\"final_score\"] = sub[\"contrib\"] * (1.0 + 0.5 * sub[\"present\"].astype(float))\n",
    "\n",
    "    # top by |final_score|\n",
    "    sub = sub.sort_values(\"final_score\", key=lambda s: s.abs(), ascending=False).head(top_k)\n",
    "\n",
    "    items = []\n",
    "    for _, r in sub.iterrows():\n",
    "        items.append({\n",
    "            \"concept\": r[\"concept\"],\n",
    "            \"direction\": \"â†‘\" if r[\"final_score\"] >= 0 else \"â†“\",\n",
    "            \"tcav_mean\": float(r[\"tcav_mean\"]),\n",
    "            \"q_value\": (None if pd.isna(r[\"q_value\"]) else float(r[\"q_value\"])),\n",
    "            \"contrib\": float(r[\"contrib\"]),\n",
    "            \"final_score\": float(r[\"final_score\"]),\n",
    "            \"present\": bool(r[\"present\"]),\n",
    "            \"present_count\": int(r[\"present_count\"]),\n",
    "            \"explanation\": U.CONCEPT_KNOWLEDGE.get(label, {}).get(str(r[\"concept\"]), \"\")\n",
    "        })\n",
    "\n",
    "    note = \"Presence-gated; contributions=(tcavâˆ’0.5)Ã—(1âˆ’q), boosted if present in this molecule.\"\n",
    "    warn = \"âš ï¸ Unreliable endpoint â€” cohort was tiny or one-sided. Interpret cautiously.\" if label in problem_labels else None\n",
    "    return {\"label\": label, \"items\": items, \"note\": note, \"warning\": warn}\n",
    "\n",
    "# Build reports for predicted positives (or top-1 label if none positive)\n",
    "pos_labels = pred_df.loc[pred_df[\"predicted_positive\"], \"label\"].tolist()\n",
    "if not pos_labels:\n",
    "    pos_labels = [pred_df.iloc[0][\"label\"]]\n",
    "\n",
    "reports = []\n",
    "for lbl in pos_labels:\n",
    "    rep = mechanistic_report_v3(TEST_SMILES, lbl, top_k=6)\n",
    "    reports.append(rep)\n",
    "\n",
    "# Pretty print + save\n",
    "ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "out_json = os.path.join(REPORT_DIR, f\"mechanistic_report_utils_v3_{ts}.json\")\n",
    "with open(out_json, \"w\") as f:\n",
    "    json.dump({\"smiles\": TEST_SMILES,\n",
    "               \"predictions\": pred_df.to_dict(orient=\"records\"),\n",
    "               \"problem_labels\": sorted(list(problem_labels)),\n",
    "               \"reports\": reports}, f, indent=2)\n",
    "\n",
    "print(\"\\nðŸ§ª Mechanistic reports (presence-gated, utils model):\")\n",
    "for rep in reports:\n",
    "    warn = f\"  {rep['warning']}\" if rep[\"warning\"] else \"\"\n",
    "    print(f\"\\nðŸ” {rep['label']} â€” Report{warn}\")\n",
    "    print(\"   \" + rep[\"note\"])\n",
    "    if not rep[\"items\"]:\n",
    "        print(\"   (no matched concepts)\")\n",
    "    for it in rep[\"items\"]:\n",
    "        qtxt = \"q=NA\" if it[\"q_value\"] is None else f\"q={it['q_value']:.3g}\"\n",
    "        pres = \" â€¢ present\" + (f\"Ã—{it['present_count']}\" if it[\"present_count\"] > 1 else \"\") if it[\"present\"] else \"\"\n",
    "        print(f\"   â€¢ {it['concept']} ({it['direction']}), tcav={it['tcav_mean']:.2f}, {qtxt}, contrib={it['contrib']:.3f}, final={it['final_score']:.3f}{pres}\")\n",
    "        if it[\"explanation\"]:\n",
    "            print(f\"     â†³ {it['explanation']}\")\n",
    "\n",
    "print(f\"\\nðŸ’¾ Saved JSON: {out_json}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b411ba53",
   "metadata": {},
   "source": [
    "### 9: Test B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c17e59d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SR-p53] Baseline p = 0.2266 (threshold=0.050)\n",
      "  â€¢ ArylHalide: Î”p = 0.0000 (before 0.2266 â†’ after 0.2266)\n",
      "  â€¢ AromaticRing: ablation failed (no match or invalid transform).\n",
      "  â€¢ MichaelAcceptor: Î”p = 0.0000 (before 0.2266 â†’ after 0.2266)\n",
      "\n",
      "ðŸ’¾ Saved ablation CSV: implementation/v3\\reports\\single_ablation_20250901-101511.csv\n"
     ]
    }
   ],
   "source": [
    "# Test B: Single-molecule SMARTS ablation (Î”p = p_before âˆ’ p_after) on top concepts from Test A\n",
    "\n",
    "import os, json, math, numpy as np\n",
    "from rdkit import Chem\n",
    "\n",
    "# Reuse model/tokenizer, labels, thresholds, reports, concepts_map, label_to_idx from Test A\n",
    "\n",
    "def replace_smarts_with_dummy(smi, smarts):\n",
    "    m = Chem.MolFromSmiles(smi)\n",
    "    q = Chem.MolFromSmarts(smarts)\n",
    "    if m is None or q is None:\n",
    "        return None\n",
    "    try:\n",
    "        reps = Chem.ReplaceSubstructs(m, q, Chem.MolFromSmiles(\"*\"), replaceAll=True)\n",
    "        if not reps:\n",
    "            return None\n",
    "        rep = reps[0]\n",
    "        frags = Chem.GetMolFrags(rep, asMols=True)\n",
    "        if not frags:\n",
    "            return None\n",
    "        frag = max(frags, key=lambda x: x.GetNumAtoms())\n",
    "        Chem.SanitizeMol(frag)\n",
    "        return Chem.MolToSmiles(frag, canonical=True)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def prob_for_label(smiles, label):\n",
    "    idx = label_to_idx[label]\n",
    "    with torch.no_grad():\n",
    "        enc = tokenizer(smiles, truncation=True, padding=True, max_length=128, return_tensors=\"pt\").to(device)\n",
    "        p = torch.sigmoid(model(**enc).logits)[0, idx].item()\n",
    "    return float(p)\n",
    "\n",
    "ABLATE_TOP_K = 3\n",
    "rows = []\n",
    "\n",
    "for rep in reports:\n",
    "    lbl = rep[\"label\"]\n",
    "    # Take top-K by |contrib|\n",
    "    top_items = sorted(rep[\"items\"], key=lambda x: -abs(x[\"contrib\"]))[:ABLATE_TOP_K]\n",
    "    if not top_items:\n",
    "        print(f\"\\n[{lbl}] No present concepts to ablate.\")\n",
    "        continue\n",
    "\n",
    "    p0 = prob_for_label(TEST_SMILES, lbl)\n",
    "    print(f\"\\n[{lbl}] Baseline p = {p0:.4f} (threshold={float(thresholds[lbl]):.3f})\")\n",
    "\n",
    "    for it in top_items:\n",
    "        c = it[\"concept\"]; smarts = concepts_map.get(c, None)\n",
    "        if not smarts:\n",
    "            continue\n",
    "        s2 = replace_smarts_with_dummy(TEST_SMILES, smarts)\n",
    "        if not s2:\n",
    "            print(f\"  â€¢ {c}: ablation failed (no match or invalid transform).\")\n",
    "            continue\n",
    "        p1 = prob_for_label(s2, lbl)\n",
    "        dp = p0 - p1\n",
    "        rows.append({\"label\": lbl, \"concept\": c, \"smiles_original\": TEST_SMILES, \"smiles_ablated\": s2, \"p_before\": p0, \"p_after\": p1, \"delta_p\": dp})\n",
    "        warn = \"  âš ï¸ Unreliable endpoint â€” interpret cautiously.\" if lbl in problem_labels else \"\"\n",
    "        print(f\"  â€¢ {c}: Î”p = {dp:.4f} (before {p0:.4f} â†’ after {p1:.4f}){warn}\")\n",
    "\n",
    "# Save ablation summary\n",
    "abl_csv = os.path.join(REPORT_DIR, f\"single_ablation_{time.strftime('%Y%m%d-%H%M%S')}.csv\")\n",
    "pd.DataFrame(rows).to_csv(abl_csv, index=False)\n",
    "print(f\"\\nðŸ’¾ Saved ablation CSV: {abl_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a369e32",
   "metadata": {},
   "source": [
    "## 10: model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84d4290",
   "metadata": {},
   "source": [
    "### 10a) (current thresholds from utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99fee2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Using dataset: implementation/data/tox21.csv\n",
      "  â€¦ 64/7831\n",
      "  â€¦ 1344/7831\n",
      "  â€¦ 2624/7831\n",
      "  â€¦ 3904/7831\n",
      "  â€¦ 5184/7831\n",
      "  â€¦ 6464/7831\n",
      "  â€¦ 7744/7831\n",
      "âœ… Saved probabilities to: implementation/v3\\eval\\probs_eval.npy  shape=(7831, 12)\n",
      "âœ… Saved:\n",
      "  â€¢ implementation/v3\\eval\\model_eval_current_v3_per_label.csv\n",
      "  â€¢ implementation/v3\\eval\\model_eval_current_v3_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>macro_balanced_acc</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_f1</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.396351</td>\n",
       "      <td>0.715657</td>\n",
       "      <td>0.25936</td>\n",
       "      <td>0.502218</td>\n",
       "      <td>0.342067</td>\n",
       "      <td>7831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   macro_f1  macro_balanced_acc  micro_precision  micro_recall  micro_f1  \\\n",
       "0  0.396351            0.715657          0.25936      0.502218  0.342067   \n",
       "\n",
       "   n_samples  \n",
       "0       7831  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>support_pos</th>\n",
       "      <th>support_neg</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>balanced_acc</th>\n",
       "      <th>auroc</th>\n",
       "      <th>auprc</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-AR</td>\n",
       "      <td>309</td>\n",
       "      <td>6956</td>\n",
       "      <td>0.868056</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>0.551876</td>\n",
       "      <td>0.700900</td>\n",
       "      <td>0.868603</td>\n",
       "      <td>0.501744</td>\n",
       "      <td>0.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>237</td>\n",
       "      <td>6521</td>\n",
       "      <td>0.839695</td>\n",
       "      <td>0.464135</td>\n",
       "      <td>0.597826</td>\n",
       "      <td>0.730457</td>\n",
       "      <td>0.927694</td>\n",
       "      <td>0.610455</td>\n",
       "      <td>0.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>768</td>\n",
       "      <td>5781</td>\n",
       "      <td>0.604052</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.500381</td>\n",
       "      <td>0.694946</td>\n",
       "      <td>0.882649</td>\n",
       "      <td>0.515410</td>\n",
       "      <td>0.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>300</td>\n",
       "      <td>5521</td>\n",
       "      <td>0.215398</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.342033</td>\n",
       "      <td>0.832859</td>\n",
       "      <td>0.892115</td>\n",
       "      <td>0.303615</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>793</td>\n",
       "      <td>5400</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.095839</td>\n",
       "      <td>0.173121</td>\n",
       "      <td>0.547086</td>\n",
       "      <td>0.765610</td>\n",
       "      <td>0.408084</td>\n",
       "      <td>0.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NR-ER-LBD</td>\n",
       "      <td>350</td>\n",
       "      <td>6605</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.415584</td>\n",
       "      <td>0.654171</td>\n",
       "      <td>0.878737</td>\n",
       "      <td>0.417478</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>186</td>\n",
       "      <td>6264</td>\n",
       "      <td>0.161504</td>\n",
       "      <td>0.784946</td>\n",
       "      <td>0.267890</td>\n",
       "      <td>0.831969</td>\n",
       "      <td>0.903980</td>\n",
       "      <td>0.340509</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>942</td>\n",
       "      <td>4890</td>\n",
       "      <td>0.553223</td>\n",
       "      <td>0.391720</td>\n",
       "      <td>0.458670</td>\n",
       "      <td>0.665390</td>\n",
       "      <td>0.817924</td>\n",
       "      <td>0.444717</td>\n",
       "      <td>0.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SR-ATAD5</td>\n",
       "      <td>264</td>\n",
       "      <td>6808</td>\n",
       "      <td>0.540373</td>\n",
       "      <td>0.329545</td>\n",
       "      <td>0.409412</td>\n",
       "      <td>0.659338</td>\n",
       "      <td>0.912567</td>\n",
       "      <td>0.378591</td>\n",
       "      <td>0.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>372</td>\n",
       "      <td>6095</td>\n",
       "      <td>0.110537</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.197346</td>\n",
       "      <td>0.733919</td>\n",
       "      <td>0.850402</td>\n",
       "      <td>0.343798</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SR-MMP</td>\n",
       "      <td>918</td>\n",
       "      <td>4892</td>\n",
       "      <td>0.601420</td>\n",
       "      <td>0.645969</td>\n",
       "      <td>0.622899</td>\n",
       "      <td>0.782817</td>\n",
       "      <td>0.895066</td>\n",
       "      <td>0.606246</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SR-p53</td>\n",
       "      <td>423</td>\n",
       "      <td>6351</td>\n",
       "      <td>0.123671</td>\n",
       "      <td>0.962175</td>\n",
       "      <td>0.219171</td>\n",
       "      <td>0.754037</td>\n",
       "      <td>0.877619</td>\n",
       "      <td>0.316979</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label  support_pos  support_neg  precision    recall        f1  \\\n",
       "0           NR-AR          309         6956   0.868056  0.404531  0.551876   \n",
       "1       NR-AR-LBD          237         6521   0.839695  0.464135  0.597826   \n",
       "2          NR-AhR          768         5781   0.604052  0.427083  0.500381   \n",
       "3    NR-Aromatase          300         5521   0.215398  0.830000  0.342033   \n",
       "4           NR-ER          793         5400   0.894118  0.095839  0.173121   \n",
       "5       NR-ER-LBD          350         6605   0.592593  0.320000  0.415584   \n",
       "6   NR-PPAR-gamma          186         6264   0.161504  0.784946  0.267890   \n",
       "7          SR-ARE          942         4890   0.553223  0.391720  0.458670   \n",
       "8        SR-ATAD5          264         6808   0.540373  0.329545  0.409412   \n",
       "9          SR-HSE          372         6095   0.110537  0.919355  0.197346   \n",
       "10         SR-MMP          918         4892   0.601420  0.645969  0.622899   \n",
       "11         SR-p53          423         6351   0.123671  0.962175  0.219171   \n",
       "\n",
       "    balanced_acc     auroc     auprc  threshold  \n",
       "0       0.700900  0.868603  0.501744      0.620  \n",
       "1       0.730457  0.927694  0.610455      0.460  \n",
       "2       0.694946  0.882649  0.515410      0.370  \n",
       "3       0.832859  0.892115  0.303615      0.050  \n",
       "4       0.547086  0.765610  0.408084      0.540  \n",
       "5       0.654171  0.878737  0.417478      0.425  \n",
       "6       0.831969  0.903980  0.340509      0.050  \n",
       "7       0.665390  0.817924  0.444717      0.392  \n",
       "8       0.659338  0.912567  0.378591      0.280  \n",
       "9       0.733919  0.850402  0.343798      0.050  \n",
       "10      0.782817  0.895066  0.606246      0.470  \n",
       "11      0.754037  0.877619  0.316979      0.050  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 10A (batched): Model evaluation with current thresholds from utils\n",
    "# Saves everything under implementation\\v3\\eval\n",
    "\n",
    "import os, json, math, numpy as np, pandas as pd, torch\n",
    "from importlib import reload\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, balanced_accuracy_score,\n",
    "    roc_auc_score, average_precision_score\n",
    ")\n",
    "\n",
    "import utils as U\n",
    "U = reload(U)\n",
    "\n",
    "BASE_DIR  = \"implementation/v3\"\n",
    "EVAL_DIR  = os.path.join(BASE_DIR, \"eval\")\n",
    "os.makedirs(EVAL_DIR, exist_ok=True)\n",
    "\n",
    "# Pick a split (val/test preferred if present)\n",
    "CANDIDATES = [\n",
    "    \"implementation/data/tox21_val.csv\",\n",
    "    \"implementation/data/tox21_test.csv\",\n",
    "    \"implementation/data/tox21.csv\",\n",
    "]\n",
    "for p in CANDIDATES:\n",
    "    if os.path.exists(p):\n",
    "        DATA_CSV = p\n",
    "        break\n",
    "print(\"ðŸ“„ Using dataset:\", DATA_CSV)\n",
    "\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "labels = [l for l in U.label_cols if l in df.columns]\n",
    "assert len(labels) > 0, \"No matching labels between utils.label_cols and dataset.\"\n",
    "smiles_all = df[\"smiles\"].astype(str).tolist()\n",
    "\n",
    "# ---- Batched probabilities (GPU-safe) ----\n",
    "def probs_matrix_stream(smiles_list, batch_size=64, max_len=128):\n",
    "    rows = []\n",
    "    for i in range(0, len(smiles_list), batch_size):\n",
    "        chunk = smiles_list[i:i+batch_size]\n",
    "        dicts = U.predict_probs_batch(chunk, max_len=max_len)  # -> list of {label: prob}\n",
    "        # convert to row-major using utils.label order\n",
    "        for d in dicts:\n",
    "            rows.append([d[lbl] for lbl in U.label_cols])\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        if (i // batch_size) % 20 == 0:\n",
    "            print(f\"  â€¦ {min(i+batch_size, len(smiles_list))}/{len(smiles_list)}\")\n",
    "    return np.array(rows, dtype=np.float32)\n",
    "\n",
    "PROBS_NPY = os.path.join(EVAL_DIR, \"probs_eval.npy\")\n",
    "META_JSON = os.path.join(EVAL_DIR, \"probs_eval_meta.json\")\n",
    "\n",
    "if os.path.exists(PROBS_NPY):\n",
    "    probs_mat = np.load(PROBS_NPY)\n",
    "    with open(META_JSON, \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "    if probs_mat.shape[0] != len(df):\n",
    "        print(\"âš ï¸ Cached probs length mismatch; recomputing.\")\n",
    "        probs_mat = probs_matrix_stream(smiles_all, batch_size=64, max_len=128)\n",
    "else:\n",
    "    probs_mat = probs_matrix_stream(smiles_all, batch_size=64, max_len=128)\n",
    "\n",
    "# Reorder columns to match the labels present in df (usually already aligned)\n",
    "idx_map = [U.label_cols.index(l) for l in labels]\n",
    "probs_mat = probs_mat[:, idx_map]\n",
    "\n",
    "# Save for reuse\n",
    "np.save(PROBS_NPY, probs_mat)\n",
    "with open(META_JSON, \"w\") as f:\n",
    "    json.dump({\"dataset\": DATA_CSV, \"n\": len(df), \"labels\": labels}, f, indent=2)\n",
    "print(f\"âœ… Saved probabilities to: {PROBS_NPY}  shape={probs_mat.shape}\")\n",
    "\n",
    "# ---- Metrics with current thresholds ----\n",
    "thr = {l: U.thresholds.get(l, 0.5) for l in labels}\n",
    "\n",
    "per_label_rows = []\n",
    "y_true_all, y_pred_all = [], []\n",
    "\n",
    "for j, lbl in enumerate(labels):\n",
    "    y = df[lbl].values\n",
    "    mask = ~pd.isna(y)\n",
    "    y = y[mask].astype(int)\n",
    "    p = probs_mat[mask, j]\n",
    "    yhat = (p >= float(thr[lbl])).astype(int)\n",
    "\n",
    "    prec = precision_score(y, yhat, zero_division=0)\n",
    "    rec  = recall_score(y, yhat, zero_division=0)\n",
    "    f1   = f1_score(y, yhat, zero_division=0)\n",
    "    bal  = balanced_accuracy_score(y, yhat)\n",
    "\n",
    "    # AUROC/AUPRC only if both classes present\n",
    "    try:\n",
    "        if len(np.unique(y)) == 2:\n",
    "            auroc = roc_auc_score(y, p)\n",
    "            auprc = average_precision_score(y, p)\n",
    "        else:\n",
    "            auroc = np.nan; auprc = np.nan\n",
    "    except Exception:\n",
    "        auroc = np.nan; auprc = np.nan\n",
    "\n",
    "    pos = int((y == 1).sum()); neg = int((y == 0).sum())\n",
    "    per_label_rows.append({\n",
    "        \"label\": lbl, \"support_pos\": pos, \"support_neg\": neg,\n",
    "        \"precision\": prec, \"recall\": rec, \"f1\": f1,\n",
    "        \"balanced_acc\": bal, \"auroc\": auroc, \"auprc\": auprc,\n",
    "        \"threshold\": float(thr[lbl])\n",
    "    })\n",
    "\n",
    "    y_true_all.append(y); y_pred_all.append(yhat)\n",
    "\n",
    "y_true_all = np.concatenate(y_true_all)\n",
    "y_pred_all = np.concatenate(y_pred_all)\n",
    "\n",
    "macro_f1   = np.nanmean([r[\"f1\"] for r in per_label_rows])\n",
    "macro_bal  = np.nanmean([r[\"balanced_acc\"] for r in per_label_rows])\n",
    "micro_prec = precision_score(y_true_all, y_pred_all, zero_division=0)\n",
    "micro_rec  = recall_score(y_true_all, y_pred_all, zero_division=0)\n",
    "micro_f1   = f1_score(y_true_all, y_pred_all, zero_division=0)\n",
    "\n",
    "per_label_df = pd.DataFrame(per_label_rows).sort_values(\"label\")\n",
    "summary = pd.DataFrame([{\n",
    "    \"macro_f1\": macro_f1, \"macro_balanced_acc\": macro_bal,\n",
    "    \"micro_precision\": micro_prec, \"micro_recall\": micro_rec, \"micro_f1\": micro_f1,\n",
    "    \"n_samples\": len(df)\n",
    "}])\n",
    "\n",
    "per_label_csv = os.path.join(EVAL_DIR, \"model_eval_current_v3_per_label.csv\")\n",
    "summary_csv   = os.path.join(EVAL_DIR, \"model_eval_current_v3_summary.csv\")\n",
    "per_label_df.to_csv(per_label_csv, index=False)\n",
    "summary.to_csv(summary_csv, index=False)\n",
    "\n",
    "print(\"âœ… Saved:\")\n",
    "print(\"  â€¢\", per_label_csv)\n",
    "print(\"  â€¢\", summary_csv)\n",
    "display(summary)\n",
    "display(per_label_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de05195f",
   "metadata": {},
   "source": [
    "### 10b) Threshold tuning (per label; F1- or Balanced-Acc-optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a3e1313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Threshold tuning (primary = f1 )\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>support_pos</th>\n",
       "      <th>support_neg</th>\n",
       "      <th>primary_metric</th>\n",
       "      <th>thr_current</th>\n",
       "      <th>thr_tuned</th>\n",
       "      <th>prec_current</th>\n",
       "      <th>rec_current</th>\n",
       "      <th>f1_current</th>\n",
       "      <th>bal_current</th>\n",
       "      <th>prec_tuned</th>\n",
       "      <th>rec_tuned</th>\n",
       "      <th>f1_tuned</th>\n",
       "      <th>bal_tuned</th>\n",
       "      <th>delta_f1</th>\n",
       "      <th>delta_bal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-AR</td>\n",
       "      <td>309</td>\n",
       "      <td>6956</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.868056</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>0.551876</td>\n",
       "      <td>0.700900</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.433657</td>\n",
       "      <td>0.569002</td>\n",
       "      <td>0.714816</td>\n",
       "      <td>0.017126</td>\n",
       "      <td>0.013916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>237</td>\n",
       "      <td>6521</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.839695</td>\n",
       "      <td>0.464135</td>\n",
       "      <td>0.597826</td>\n",
       "      <td>0.730457</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.601156</td>\n",
       "      <td>0.819453</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>0.088996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>768</td>\n",
       "      <td>5781</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.604052</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.500381</td>\n",
       "      <td>0.694946</td>\n",
       "      <td>0.523409</td>\n",
       "      <td>0.567708</td>\n",
       "      <td>0.544660</td>\n",
       "      <td>0.749518</td>\n",
       "      <td>0.044278</td>\n",
       "      <td>0.054571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>300</td>\n",
       "      <td>5521</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.215398</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.342033</td>\n",
       "      <td>0.832859</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>0.377510</td>\n",
       "      <td>0.647248</td>\n",
       "      <td>0.035477</td>\n",
       "      <td>-0.185611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>793</td>\n",
       "      <td>5400</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.095839</td>\n",
       "      <td>0.173121</td>\n",
       "      <td>0.547086</td>\n",
       "      <td>0.492455</td>\n",
       "      <td>0.452711</td>\n",
       "      <td>0.471748</td>\n",
       "      <td>0.692096</td>\n",
       "      <td>0.298627</td>\n",
       "      <td>0.145010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NR-ER-LBD</td>\n",
       "      <td>350</td>\n",
       "      <td>6605</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.415584</td>\n",
       "      <td>0.654171</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.411429</td>\n",
       "      <td>0.445820</td>\n",
       "      <td>0.694208</td>\n",
       "      <td>0.030236</td>\n",
       "      <td>0.040037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>186</td>\n",
       "      <td>6264</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.161504</td>\n",
       "      <td>0.784946</td>\n",
       "      <td>0.267890</td>\n",
       "      <td>0.831969</td>\n",
       "      <td>0.341991</td>\n",
       "      <td>0.424731</td>\n",
       "      <td>0.378897</td>\n",
       "      <td>0.700233</td>\n",
       "      <td>0.111007</td>\n",
       "      <td>-0.131736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>942</td>\n",
       "      <td>4890</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.553223</td>\n",
       "      <td>0.391720</td>\n",
       "      <td>0.458670</td>\n",
       "      <td>0.665390</td>\n",
       "      <td>0.375334</td>\n",
       "      <td>0.746285</td>\n",
       "      <td>0.499467</td>\n",
       "      <td>0.753510</td>\n",
       "      <td>0.040797</td>\n",
       "      <td>0.088121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SR-ATAD5</td>\n",
       "      <td>264</td>\n",
       "      <td>6808</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.540373</td>\n",
       "      <td>0.329545</td>\n",
       "      <td>0.409412</td>\n",
       "      <td>0.659338</td>\n",
       "      <td>0.412338</td>\n",
       "      <td>0.481061</td>\n",
       "      <td>0.444056</td>\n",
       "      <td>0.727237</td>\n",
       "      <td>0.034644</td>\n",
       "      <td>0.067899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>372</td>\n",
       "      <td>6095</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.110537</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.197346</td>\n",
       "      <td>0.733919</td>\n",
       "      <td>0.453674</td>\n",
       "      <td>0.381720</td>\n",
       "      <td>0.414599</td>\n",
       "      <td>0.676832</td>\n",
       "      <td>0.217253</td>\n",
       "      <td>-0.057086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SR-MMP</td>\n",
       "      <td>918</td>\n",
       "      <td>4892</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.601420</td>\n",
       "      <td>0.645969</td>\n",
       "      <td>0.622899</td>\n",
       "      <td>0.782817</td>\n",
       "      <td>0.602216</td>\n",
       "      <td>0.651416</td>\n",
       "      <td>0.625850</td>\n",
       "      <td>0.785336</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.002519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SR-p53</td>\n",
       "      <td>423</td>\n",
       "      <td>6351</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.123671</td>\n",
       "      <td>0.962175</td>\n",
       "      <td>0.219171</td>\n",
       "      <td>0.754037</td>\n",
       "      <td>0.335714</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.418522</td>\n",
       "      <td>0.741169</td>\n",
       "      <td>0.199351</td>\n",
       "      <td>-0.012867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label  support_pos  support_neg primary_metric  thr_current  \\\n",
       "0           NR-AR          309         6956             f1        0.620   \n",
       "1       NR-AR-LBD          237         6521             f1        0.460   \n",
       "2          NR-AhR          768         5781             f1        0.370   \n",
       "3    NR-Aromatase          300         5521             f1        0.050   \n",
       "4           NR-ER          793         5400             f1        0.540   \n",
       "5       NR-ER-LBD          350         6605             f1        0.425   \n",
       "6   NR-PPAR-gamma          186         6264             f1        0.050   \n",
       "7          SR-ARE          942         4890             f1        0.392   \n",
       "8        SR-ATAD5          264         6808             f1        0.280   \n",
       "9          SR-HSE          372         6095             f1        0.050   \n",
       "10         SR-MMP          918         4892             f1        0.470   \n",
       "11         SR-p53          423         6351             f1        0.050   \n",
       "\n",
       "    thr_tuned  prec_current  rec_current  f1_current  bal_current  prec_tuned  \\\n",
       "0        0.45      0.868056     0.404531    0.551876     0.700900    0.827160   \n",
       "1        0.14      0.839695     0.464135    0.597826     0.730457    0.553191   \n",
       "2        0.21      0.604052     0.427083    0.500381     0.694946    0.523409   \n",
       "3        0.15      0.215398     0.830000    0.342033     0.832859    0.474747   \n",
       "4        0.25      0.894118     0.095839    0.173121     0.547086    0.492455   \n",
       "5        0.24      0.592593     0.320000    0.415584     0.654171    0.486486   \n",
       "6        0.24      0.161504     0.784946    0.267890     0.831969    0.341991   \n",
       "7        0.28      0.553223     0.391720    0.458670     0.665390    0.375334   \n",
       "8        0.18      0.540373     0.329545    0.409412     0.659338    0.412338   \n",
       "9        0.15      0.110537     0.919355    0.197346     0.733919    0.453674   \n",
       "10       0.26      0.601420     0.645969    0.622899     0.782817    0.602216   \n",
       "11       0.15      0.123671     0.962175    0.219171     0.754037    0.335714   \n",
       "\n",
       "    rec_tuned  f1_tuned  bal_tuned  delta_f1  delta_bal  \n",
       "0    0.433657  0.569002   0.714816  0.017126   0.013916  \n",
       "1    0.658228  0.601156   0.819453  0.003330   0.088996  \n",
       "2    0.567708  0.544660   0.749518  0.044278   0.054571  \n",
       "3    0.313333  0.377510   0.647248  0.035477  -0.185611  \n",
       "4    0.452711  0.471748   0.692096  0.298627   0.145010  \n",
       "5    0.411429  0.445820   0.694208  0.030236   0.040037  \n",
       "6    0.424731  0.378897   0.700233  0.111007  -0.131736  \n",
       "7    0.746285  0.499467   0.753510  0.040797   0.088121  \n",
       "8    0.481061  0.444056   0.727237  0.034644   0.067899  \n",
       "9    0.381720  0.414599   0.676832  0.217253  -0.057086  \n",
       "10   0.651416  0.625850   0.785336  0.002951   0.002519  \n",
       "11   0.555556  0.418522   0.741169  0.199351  -0.012867  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved tuned thresholds -> implementation/v3\\eval\\thresholds_tuned_v3.json\n",
      "âœ… Saved comparison -> implementation/v3\\eval\\thresholds_tuning_comparison_v3.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 10B: Per-label threshold tuning using cached probabilities; saves tuned JSON under eval/\n",
    "\n",
    "import os, json, numpy as np, pandas as pd\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, precision_score, recall_score\n",
    "from importlib import reload\n",
    "import utils as U\n",
    "U = reload(U)\n",
    "\n",
    "BASE_DIR   = \"implementation/v3\"\n",
    "EVAL_DIR   = os.path.join(BASE_DIR, \"eval\")\n",
    "os.makedirs(EVAL_DIR, exist_ok=True)\n",
    "\n",
    "# Load dataset + cached probs from 10A\n",
    "with open(os.path.join(EVAL_DIR, \"probs_eval_meta.json\"), \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "DATA_CSV = meta[\"dataset\"]\n",
    "labels   = meta[\"labels\"]\n",
    "df       = pd.read_csv(DATA_CSV)\n",
    "probs_mat = np.load(os.path.join(EVAL_DIR, \"probs_eval.npy\"))\n",
    "\n",
    "current_thr = {l: U.thresholds.get(l, 0.5) for l in labels}\n",
    "\n",
    "# Config\n",
    "METRIC_PRIMARY = \"f1\"   # or \"balanced_acc\"\n",
    "THR_GRID = np.round(np.linspace(0.05, 0.95, 91), 3)  # 0.05..0.95 step 0.01\n",
    "MIN_POS = 10  # fallback to balanced_acc when positives/negatives are scarce\n",
    "\n",
    "rows = []\n",
    "tuned_thr = {}\n",
    "\n",
    "for j, lbl in enumerate(labels):\n",
    "    y_full = df[lbl].values\n",
    "    mask = ~pd.isna(y_full)\n",
    "    y = y_full[mask].astype(int)\n",
    "    p = probs_mat[mask, j]\n",
    "\n",
    "    pos = int((y == 1).sum())\n",
    "    neg = int((y == 0).sum())\n",
    "    use_bal = (pos < MIN_POS or neg < MIN_POS)\n",
    "    primary = \"balanced_acc\" if use_bal else METRIC_PRIMARY\n",
    "\n",
    "    best_score = -1.0\n",
    "    best_thr = current_thr[lbl]\n",
    "    best_prec = best_rec = best_f1 = best_bal = 0.0\n",
    "\n",
    "    for t in THR_GRID:\n",
    "        yhat = (p >= t).astype(int)\n",
    "        prec = precision_score(y, yhat, zero_division=0)\n",
    "        rec  = recall_score(y, yhat, zero_division=0)\n",
    "        f1   = f1_score(y, yhat, zero_division=0)\n",
    "        bal  = balanced_accuracy_score(y, yhat)\n",
    "\n",
    "        score = f1 if primary == \"f1\" else bal\n",
    "        # tie-break: prefer closer to current threshold to avoid wild swings\n",
    "        if (score > best_score) or (np.isclose(score, best_score) and abs(t - current_thr[lbl]) < abs(best_thr - current_thr[lbl])):\n",
    "            best_score, best_thr = score, float(t)\n",
    "            best_prec, best_rec, best_f1, best_bal = prec, rec, f1, bal\n",
    "\n",
    "    tuned_thr[lbl] = best_thr\n",
    "\n",
    "    # current metrics\n",
    "    yhat_cur = (p >= current_thr[lbl]).astype(int)\n",
    "    cur_prec = precision_score(y, yhat_cur, zero_division=0)\n",
    "    cur_rec  = recall_score(y, yhat_cur, zero_division=0)\n",
    "    cur_f1   = f1_score(y, yhat_cur, zero_division=0)\n",
    "    cur_bal  = balanced_accuracy_score(y, yhat_cur)\n",
    "\n",
    "    rows.append({\n",
    "        \"label\": lbl, \"support_pos\": pos, \"support_neg\": neg,\n",
    "        \"primary_metric\": primary,\n",
    "        \"thr_current\": float(current_thr[lbl]), \"thr_tuned\": float(best_thr),\n",
    "        \"prec_current\": cur_prec, \"rec_current\": cur_rec, \"f1_current\": cur_f1, \"bal_current\": cur_bal,\n",
    "        \"prec_tuned\": best_prec, \"rec_tuned\": best_rec, \"f1_tuned\": best_f1, \"bal_tuned\": best_bal,\n",
    "        \"delta_f1\": best_f1 - cur_f1, \"delta_bal\": best_bal - cur_bal\n",
    "    })\n",
    "\n",
    "tune_df = pd.DataFrame(rows).sort_values(\"label\")\n",
    "print(\"ðŸ”§ Threshold tuning (primary =\", METRIC_PRIMARY, \")\")\n",
    "display(tune_df)\n",
    "\n",
    "# Save new thresholds JSON and comparison table\n",
    "tuned_json = os.path.join(EVAL_DIR, \"thresholds_tuned_v3.json\")\n",
    "with open(tuned_json, \"w\") as f:\n",
    "    json.dump(tuned_thr, f, indent=2)\n",
    "print(\"âœ… Saved tuned thresholds ->\", tuned_json)\n",
    "\n",
    "cmp_csv = os.path.join(EVAL_DIR, \"thresholds_tuning_comparison_v3.csv\")\n",
    "tune_df.to_csv(cmp_csv, index=False)\n",
    "print(\"âœ… Saved comparison ->\", cmp_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f707ea29",
   "metadata": {},
   "source": [
    "### 10c) Re-evaluate metrics using tuned thresholds    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2868054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Current thresholds â€” summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>macro_balanced_acc</th>\n",
       "      <th>micro_f1</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.396351</td>\n",
       "      <td>0.715657</td>\n",
       "      <td>0.342067</td>\n",
       "      <td>7831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   macro_f1  macro_balanced_acc  micro_f1  n_samples\n",
       "0  0.396351            0.715657  0.342067       7831"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Tuned thresholds â€” summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>macro_balanced_acc</th>\n",
       "      <th>micro_f1</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.482607</td>\n",
       "      <td>0.725138</td>\n",
       "      <td>0.501878</td>\n",
       "      <td>7831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   macro_f1  macro_balanced_acc  micro_f1  n_samples\n",
       "0  0.482607            0.725138  0.501878       7831"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î” (tuned - current):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>macro_balanced_acc</th>\n",
       "      <th>micro_f1</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>delta</th>\n",
       "      <td>0.086256</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>0.159811</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       macro_f1  macro_balanced_acc  micro_f1  n_samples\n",
       "delta  0.086256            0.009481  0.159811        0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Re-saved eval CSVs with tuned comparison under: implementation/v3\\eval\n"
     ]
    }
   ],
   "source": [
    "# Cell 10C (optional): Re-evaluate metrics using tuned thresholds; saves under eval/\n",
    "\n",
    "import os, json, numpy as np, pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    ")\n",
    "from importlib import reload\n",
    "import utils as U\n",
    "U = reload(U)\n",
    "\n",
    "BASE_DIR  = \"implementation/v3\"\n",
    "EVAL_DIR  = os.path.join(BASE_DIR, \"eval\")\n",
    "\n",
    "# Load meta + cached probs + data\n",
    "with open(os.path.join(EVAL_DIR, \"probs_eval_meta.json\"), \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "DATA_CSV = meta[\"dataset\"]\n",
    "labels   = meta[\"labels\"]\n",
    "df       = pd.read_csv(DATA_CSV)\n",
    "probs_mat = np.load(os.path.join(EVAL_DIR, \"probs_eval.npy\"))\n",
    "\n",
    "# Threshold maps\n",
    "with open(os.path.join(EVAL_DIR, \"thresholds_tuned_v3.json\"), \"r\") as f:\n",
    "    tuned_thr = json.load(f)\n",
    "curr_thr = {l: U.thresholds.get(l, 0.5) for l in labels}\n",
    "\n",
    "def eval_with_thresholds(thr_map):\n",
    "    rows = []\n",
    "    y_true_all, y_pred_all = [], []\n",
    "    for j, lbl in enumerate(labels):\n",
    "        y_full = df[lbl].values\n",
    "        mask = ~pd.isna(y_full)\n",
    "        y = y_full[mask].astype(int)\n",
    "        p = probs_mat[mask, j]\n",
    "        yhat = (p >= float(thr_map[lbl])).astype(int)\n",
    "\n",
    "        prec = precision_score(y, yhat, zero_division=0)\n",
    "        rec  = recall_score(y, yhat, zero_division=0)\n",
    "        f1   = f1_score(y, yhat, zero_division=0)\n",
    "        bal  = balanced_accuracy_score(y, yhat)\n",
    "\n",
    "        rows.append({\"label\": lbl, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"balanced_acc\": bal, \"threshold\": float(thr_map[lbl])})\n",
    "        y_true_all.append(y); y_pred_all.append(yhat)\n",
    "\n",
    "    y_true_all = np.concatenate(y_true_all)\n",
    "    y_pred_all = np.concatenate(y_pred_all)\n",
    "    macro_f1  = np.nanmean([r[\"f1\"] for r in rows])\n",
    "    macro_bal = np.nanmean([r[\"balanced_acc\"] for r in rows])\n",
    "    micro_f1  = f1_score(y_true_all, y_pred_all, zero_division=0)\n",
    "    return pd.DataFrame(rows).sort_values(\"label\"), pd.DataFrame([{\n",
    "        \"macro_f1\": macro_f1, \"macro_balanced_acc\": macro_bal, \"micro_f1\": micro_f1, \"n_samples\": len(df)\n",
    "    }])\n",
    "\n",
    "per_label_cur, summary_cur = eval_with_thresholds(curr_thr)\n",
    "per_label_new, summary_new = eval_with_thresholds(tuned_thr)\n",
    "\n",
    "print(\"ðŸ“Š Current thresholds â€” summary:\")\n",
    "display(summary_cur)\n",
    "print(\"ðŸ“Š Tuned thresholds â€” summary:\")\n",
    "display(summary_new)\n",
    "\n",
    "delta = (summary_new.iloc[0] - summary_cur.iloc[0]).to_frame(name=\"delta\").T\n",
    "print(\"Î” (tuned - current):\")\n",
    "display(delta)\n",
    "\n",
    "# Save\n",
    "per_label_cur.to_csv(os.path.join(EVAL_DIR, \"model_eval_current_v3_per_label.csv\"), index=False)\n",
    "summary_cur.to_csv(os.path.join(EVAL_DIR, \"model_eval_current_v3_summary.csv\"), index=False)\n",
    "per_label_new.to_csv(os.path.join(EVAL_DIR, \"model_eval_tuned_v3_per_label.csv\"), index=False)\n",
    "summary_new.to_csv(os.path.join(EVAL_DIR, \"model_eval_tuned_v3_summary.csv\"), index=False)\n",
    "print(\"âœ… Re-saved eval CSVs with tuned comparison under:\", EVAL_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78337f6c",
   "metadata": {},
   "source": [
    "### 10d) pick per label  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f9fc504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: implementation/v3\\eval\\thresholds_selected_v3.json\n",
      "ðŸ“Š Table: implementation/v3\\eval\\thresholds_selected_v3_table.csv\n",
      "Selection: tuned=11 | kept_current=1\n",
      "\n",
      "No F1 regressions > 0.01 avoided.\n"
     ]
    }
   ],
   "source": [
    "# Cell 10D: Pick per-label thresholds conservatively (use tuned only if it helps)\n",
    "\n",
    "import os, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "BASE_DIR = \"implementation/v3\"\n",
    "EVAL_DIR = os.path.join(BASE_DIR, \"eval\")\n",
    "os.makedirs(EVAL_DIR, exist_ok=True)\n",
    "\n",
    "# Inputs from 10B\n",
    "cmp_csv = os.path.join(EVAL_DIR, \"thresholds_tuning_comparison_v3.csv\")\n",
    "assert os.path.exists(cmp_csv), \"Run 10B first to create thresholds_tuning_comparison_v3.csv\"\n",
    "\n",
    "cmp_df = pd.read_csv(cmp_csv)\n",
    "\n",
    "# Decision rule:\n",
    "# - Prefer tuned if it improves F1 by > 0.01\n",
    "# - If Î”F1 ~ 0 (|Î”| <= 0.005), prefer tuned if it improves balanced_acc by > 0.01\n",
    "# - Else keep current\n",
    "F1_MIN_IMPROVE  = 0.01\n",
    "F1_TIE_MARGIN   = 0.005\n",
    "BAL_MIN_IMPROVE = 0.01\n",
    "\n",
    "choices = []\n",
    "selected = {}\n",
    "\n",
    "for _, r in cmp_df.iterrows():\n",
    "    lbl = r[\"label\"]\n",
    "    df1 = float(r[\"delta_f1\"])\n",
    "    dba = float(r[\"delta_bal\"])\n",
    "    use_tuned = False\n",
    "\n",
    "    if df1 > F1_MIN_IMPROVE:\n",
    "        use_tuned = True\n",
    "    elif abs(df1) <= F1_TIE_MARGIN and dba > BAL_MIN_IMPROVE:\n",
    "        use_tuned = True\n",
    "\n",
    "    choice = \"tuned\" if use_tuned else \"current\"\n",
    "    thr = float(r[\"thr_tuned\"] if use_tuned else r[\"thr_current\"])\n",
    "    selected[lbl] = thr\n",
    "\n",
    "    choices.append({\n",
    "        \"label\": lbl,\n",
    "        \"choice\": choice,\n",
    "        \"thr_selected\": thr,\n",
    "        \"thr_current\": float(r[\"thr_current\"]),\n",
    "        \"thr_tuned\": float(r[\"thr_tuned\"]),\n",
    "        \"delta_f1\": df1,\n",
    "        \"delta_bal\": dba,\n",
    "        \"primary_metric\": r.get(\"primary_metric\", \"f1\"),\n",
    "        \"support_pos\": int(r.get(\"support_pos\", 0)),\n",
    "        \"support_neg\": int(r.get(\"support_neg\", 0))\n",
    "    })\n",
    "\n",
    "sel_df = pd.DataFrame(choices).sort_values(\"label\")\n",
    "\n",
    "# Save outputs\n",
    "sel_json = os.path.join(EVAL_DIR, \"thresholds_selected_v3.json\")\n",
    "sel_csv  = os.path.join(EVAL_DIR, \"thresholds_selected_v3_table.csv\")\n",
    "with open(sel_json, \"w\") as f:\n",
    "    json.dump(selected, f, indent=2)\n",
    "sel_df.to_csv(sel_csv, index=False)\n",
    "\n",
    "# Quick summary\n",
    "n_tuned   = int((sel_df[\"choice\"] == \"tuned\").sum())\n",
    "n_current = int((sel_df[\"choice\"] == \"current\").sum())\n",
    "print(f\"âœ… Saved: {sel_json}\")\n",
    "print(f\"ðŸ“Š Table: {sel_csv}\")\n",
    "print(f\"Selection: tuned={n_tuned} | kept_current={n_current}\")\n",
    "\n",
    "# Show worst regressions (if any)\n",
    "reg = sel_df[(sel_df[\"choice\"] == \"current\") & (sel_df[\"delta_f1\"] < -0.01)].copy()\n",
    "if len(reg):\n",
    "    print(\"\\nâš ï¸ Labels where tuned F1 would regress by > 0.01 (kept current):\")\n",
    "    display(reg[[\"label\",\"delta_f1\",\"delta_bal\",\"thr_current\",\"thr_tuned\"]].sort_values(\"delta_f1\"))\n",
    "else:\n",
    "    print(\"\\nNo F1 regressions > 0.01 avoided.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lord",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
