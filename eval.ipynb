{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa39e6c0",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a4de19",
   "metadata": {},
   "source": [
    "## Class imbalance Bar chart (Fig 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd2604c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"v8/data/tox21.csv\")\n",
    "\n",
    "# Select first 12 columns (labels)\n",
    "label_cols = df.columns[:12]\n",
    "\n",
    "# Count positives (1s) for each class\n",
    "counts = df[label_cols].apply(pd.Series.value_counts).loc[1].fillna(0).astype(int)\n",
    "\n",
    "# Generate light-to-dark blue colors\n",
    "colors = plt.cm.Blues(np.linspace(0.4, 0.8, len(counts)))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12,6))\n",
    "bars = plt.bar(counts.index, counts.values, color=colors)\n",
    "\n",
    "# Style\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=10)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.xlabel(\"Class Name\", fontsize=12)\n",
    "plt.title(\"Counts of Positive Samples per Class\", fontsize=14, weight=\"bold\")\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + max(counts.values)*0.01,\n",
    "             f\"{yval}\", ha='center', va='bottom', fontsize=9, color=\"black\")\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea3eb9e",
   "metadata": {},
   "source": [
    "## How SMILES representations were handled (Fig 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaf3a607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABW0AAAKyCAYAAACuWPzHAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAq0tJREFUeJzs3QeYVOX5P+4XpChFBeyAWLFiwxKxYu+VICJSRMBoikaNMSaxRGNL1Gg0oigo2LDHEnvBHnvvLfaCjaLU+V/P+/vO/HeXIiDLzO7e93UNy5w5M/OeM2V3PvOc521UKBQKCQAAAACAitC43AMAAAAAAOD/J7QFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAK0qTcAwAAAAAqT6FQSBMnTiz3MIB6okWLFqlRo0blHkadIbQFAAAAZhCBbatWrco9DKCeGD9+fGrZsmW5h1FnaI8AAAAAAFBBVNoCAAAAs/XZZ5+pkAPm2oQJE9LSSy9d7mHUSUJbAAAAYLYisBXaAiw42iMAAAAAAFQQoS0AAAAAQAUR2gIAAAAAVBChLQAAAABABRHaAgAAAABUEKEtAAAAAEAFEdoCAAAAAFQQoS0AAAAAQAUR2gIAAAAAVBChLQAAAABABRHaAgAAAABUEKEtAAAAAEAFEdoCAAAAAFQQoS0AAAAAQAVpUu4BAAAAAIT//e9/6csvvyz3MKDeW2KJJdLyyy9f7mEwG0JbAAAAoCIC2zXWWCNNnDix3EOBeq9Fixbp1VdfFdxWMKEtAAAAUHZRYRuB7ahRo3J4C9SOCGv79OmTX3NC28oltAUAAAAqRgS2G2ywQbmHAVBWJiIDAAAAAKggQlsAAACAeqh///5pr732SnXNI488kpo0aZLWW2+9cg8FykZoCwAAAMACMXny5Nle/s0336S+ffumbbfddoGNCSqR0BYAAACgATrrrLNSly5dUsuWLVPHjh3ToYcemsaPH58vmzBhQlp00UXTddddV+06N910U15/3Lhx+fwHH3yQevbsmRZffPHUtm3btOeee6b33ntvhmrfU045JS233HJptdVWm+2YDjnkkNS7d++06aab1so2Q11hIrJ5UCgU8oyWQP3UokWL1KhRo9TQea+r2zyP6w6vtbrNa63u8Fqr+7zeYP5r3LhxOvfcc9OKK66Y3nnnnRza/u53v0sXXHBBDmZ79eqVhg8fnnr06FG6TvF869at05QpU9KOO+6YA9aHHnootzQ4+eST00477ZReeOGF1KxZs3yde++9NwfAd99992zHE7cd4xg1alS+HWjIhLbzIP7Ya9WqVbmHAdSS+GY5/kBp6LzX1W2ex3WH11rd5rVWd3it1X1ebzD/HX744aX/r7DCCjkojUrXCG3DwQcfnLp165Y++eSTtOyyy6bPP/883X777emee+7Jl19zzTVp+vTpadiwYaUvVSJ4jarbBx54IO2www55Wbx2Y51iiDszb775Zvr9739fCn+hodMeAQAAAKABivA1ese2b98+V84eeOCBaezYsaUjEzbeeOO01lprpcsuuyyfjwrYTp06pS233DKff/7559Nbb72VrxtfjMUpWiT88MMP6e233y7dT7RgmF1gO23atNwS4cQTT0ydO3eu9e2GusBXFz/RZ5995tteqAeiX9PSSy9d7mFULO91dYPncd3ntVY3eK3VfV5rdYfXG9Se6Du72267pV/84he532yErQ8//HAaOHBgniwsWpIUq23PP//8XAUbVbQDBgwoVdVGBXzXrl3TFVdcMcPtL7nkkqX//9h7bvTHfeqpp9Kzzz6bfvnLX+ZlUcEbrW2i6vauu+5K22yzzXzeA1DZhLY/Ubzx+IMPqO+818GC4bUGC4bXGkBKTz/9dA5G//73v+fetmH06NEzrNenT5/c5zZ6377yyiupX79+pcs22GCD3CJhqaWWyj1r51Vc98UXX6y2LFo03HfffXkitOi5Cw2N0BYAAACgnvr222/Tc889V21Zu3bt0iqrrJInEjvvvPPS7rvvnh555JF04YUXznD9Nm3apH322ScdffTRuUdthw4dSpcdcMAB6cwzz0x77rlnOumkk/Jl77//frrhhhty0Ft13dmJ0HjttdeutiyC4IUXXniG5dBQ6GkLAAAAUE/FhGDrr79+tVP0jl133XXTWWedlU4//fQcjEaLg1NPPXWmt1FsmXDQQQdVWx4tFMaMGZOWX375HOyuscYaed3oaftTKm+BlBoVokEIc91XqTjzrBlMoX7wup6RfVL3eMzqJo9b3eMxq5s8bnWTx61h7f9nnnkm90eNw/bjsHsqx8iRI9MRRxyRPv7449lOKEbdsCBfa97H5532CAAAAADMYOLEiemTTz5Jp512WhoyZIjAFhYg7REAAAAAmMEZZ5yRVl999bTMMsukY489ttzDgQZFaAsAAADADE444YQ8Wdm9995bOsQdWDC0RwAAAAAqxquvvlruIUC95jVWNwhtAQAAgLJbYoklUosWLVKfPn3KPRSo9+K1Fq85KpfQFgAAACi75ZdfPlcAfvnll+UeCtR7EdjGa47KJbQFAAAAKkKESIIkABORAQAAAABUFJW2AAAAQEX43//+pz1CDS+//HL629/+lt544430ww8/pCuvvDKtttpq5R4WNXz88cdp9913T8cff3zaY489UqXTHqHyCW0BAACAighs11hjjTRx4sRyD6Wi9e7du9xDYDZOPPHEfKoLE5FFD2nBbeUS2gIAAABlFxW2EdiOGjUqh7fz2+23317t/K233pqeeOKJ9Je//KXa8k022SS1a9cuVYJ333039ejRI/3xj39Me++9d2pIFas77rhj2nzzzWe4PKqMV1555VRp6lKlbYS1ffr0ya85oW3lEtoCAAAAFSMC2w022GC+327N2/z0009zaBuB6OxEkBxVieUwfvz4/HPdddedb/tkwoQJqWXLlvPltmpjDG3bts0/t9tuu3TUUUeluqI47hVWWGG+PFaV8DhRXiYiAwAAAEgpbb311mnttddOTz/9dNpyyy1zWPuHP/whX3bzzTenXXfdNS233HKpefPmudozqnSnTZs209t45ZVXUvfu3fNttG/fPp1xxhkz3N95552X1lprrbxOmzZt0oYbbph71ob+/funrbbaKv//5z//eWrUqFG+7aL77rsvbbHFFjnYW3zxxdOee+6ZKyirWm+99fL1YizRViHuo1i9GuHibrvtlh544IF8v4ssskjq0qVLPh9uuOGGfH7hhRdOXbt2Tc8+++wM43/ttddyJXAElrFe3M6///3vauuMGDEij+HBBx9Mhx56aFpqqaVShw4dZrithx9+OG222WZp/fXXz+djf5199tmzfbyK2xDX3XjjjfMYVlpppXT55ZfPsO4333yTjjjiiHydePxiDH379q3WQ/nzzz9PAwcOTEsvvXS+rQjLL7vsspneVjw+iy22WN73/fr1y8tmZn7uIxoWlbYAAAAA/2fs2LFp5513Tr169cqHkEeAVwzWWrVqlX7729/mnxGa/vnPf07fffddOvPMM6vdxtdff5122mmntM8++6SePXum6667Lh1zzDE5BI3bDhdffHH69a9/nQO93/zmN3mSsRdeeCFX/0bAOmTIkBz2/vWvf83rbbTRRqWx3HPPPfl2IqA84YQT0vfff58D4Ag9n3nmmRxMVhWh76qrrppvq1AolJa/9dZbpfuKbY0Jz+IQ/wsvvDCH1REghlNPPTVvx+uvv54aN25cmiAt7i/G+Pvf/z6Hx6NHj0577bVXuv7662do5xC3teSSS+bbnTRp0gz7Pa7/y1/+MremiNYIEUhHFXSMN8LVoghJmzRpUm0bYh9G2Brh6aWXXpoD1QiaIxAvVizH7UWofdBBB+VK2AhrIzz98MMP86RcsQ8jFI/bi3GsuOKK6dprr823FYFsPEYhxhMBeQTFhxxySK4Mv/HGG/N91zSv+yieV1FpSwNXYK6NHz8+3uHyKf4P1H1e1zOyT+oej1nd5HGrezxmdZPHrW7yuDWs/f/000/n+4qfC8Jhhx2W76+qrbbaKi+78MILZ1h/4sSJMywbMmRIoUWLFoUffvhhhtu4/PLLS8smTZpUWGaZZQr77rtvadmee+5ZWGuttWY7xvvvvz/f1rXXXltt+XrrrVdYaqmlCmPHji0te/755wuNGzcu9O3bt7Rs3XXXzdfff//9Z7jtTp065ctWWmmlvA0dOnQo7LbbbnnZIossUnj11VcLrVu3zvc9dOjQvDzGc+ONN+b1Yzu7dOlSePPNNws///nPC4sttlihTZs2+bTCCiuU7mezzTbL1437W3bZZatdNjPvvvtu6Xk3s9Njjz02wzaMGTOmtOzzzz8vNG/evHDkkUeWlv35z3/O691www0z3N/06dPzz3POOSevM2rUqNJlkydPLmy66aaFVq1aFb777ru87KabbsrrnXHGGaX1pk6dWthiiy3y8uHDh5eWb7vttnkfVX1+xP1169atsOqqq5aWxXXiuptvvnm+rfr0WvM+Pu+0RwAAAAD4P3Ho/IABA2ZYHu0DisaNG5crNaN6M3rexiHwVUUlblSuFjVr1iwfvv/OO+9UqxiNKs8nn3xyrsb3ySefpOeeey5XgBb7qIZ11lknbb/99jNMuBaiInRmonJ32LBhuSI02gBEJW3YZptt0uqrr56rjYcPH54nZwsx/jgf1bhjxoxJ++67b24Z0bRp01y1GpO7xWH97733Xp5EraqoNr377rvzOnMiqpSjnUO0NIjrFU9rrrlmtfXifDwORVGpGpOVVd3XUdUarQ5mNplbtCUIsd+WWWaZtP/++5cui+2KKueo1I3WBcX1otL3F7/4RWm9hRZaKP3qV7+qdrtfffVVrsaOCuXi8yVOUckdlcRvvvlm+uijj6pdZ9CgQfm2IAhtqVPiTXfw4MH5l0ex508cihCHIdx///2l9eJQkHjjjcMqZnbYRYjDGWKdOMUvlJq9ZOLwlaK4PJbFIRKzU1xvdqf4pVwUh7/EISxxmEscjhF/BMTMjXEYzemnn/4T9xYAAABzK8LFCFlrimAzQr/oY7rooovmcLAYzH777bfV1o3gshgGFsXn12ibUBTtEiLcjTA3Whccdthh6ZFHHvnR8b3//vv5ZwSTNcXn4wgGax5aH4f6z0z0j42+u/EZOoLaaJ8QOnbsmH8efPDB6c477yx9rv7f//6XQ8toIxBtAqI1wxtvvJH78Eb/3WgF8OKLL+Z1//Of/1S7r+j/G+0Kii0LZmXTTTfNP6PlQAS2Z511Vp6UrHiKfV9VfIauqea+fvvtt3Of4R/br/E4FNs/VN2nxcuLP5dddtn82FVV8/GINguxj/70pz/l50rV0/HHH1/qoTsnjxMNk5621BlPPfVU/iUQ33RFP5t4o4+eM/Ht1F133ZVat26df9kURYPv+GYrvu2L/j1VffbZZ/kXTawTwen8Ft9uVu25U1Xxm9CpU6embbfdNj366KNpl112yX2E4k0/vo3873//m3sGxS9xAAAAFpyqFbVF0dM0Po9GYHjSSSflScji82T0j43PbdOnT6+2/qyqJav2k40wMCpbo/L0jjvuyNWgF1xwQe5neuKJJ9b6NoUINuNzaVQKR2/e+JwaitsTgXJ89o6xhZigrVOnTrlqNcSkWrEPaobcEfLWLKCqGbbOSvR8jUngoor3nHPOSausskq16tea5mRfl0NxHx511FG5snZmYtvm5HGiYRLaUmfEL6047CQOAyn+gqjq008/rXY+fonGN2Rx6EbN0LY4k2Qc0hGNxee3zp07VzsUZmZi5tEIbA8//PCZzohZc3sAAAAojwceeCAf1n7DDTfkQLGoZguAuRUTU+233375NHny5NwS4JRTTknHHntsDoVnJkLTUGxlUFWEr3EUZ9zuj4mANlozxOH/cZ9RYBSTa8WEXlVD6Ki2jfC0WEwVR6DG5+0wbdq0HNxeccUVM9x+VJTOi2KVb7RkiM/+Uc07u9B2TsR4X3rppdmuE/s1JoKLba9abVtsfVHc7/Hz3nvvzS0Tqlbb1nw8YpK4EIVnUSEMc0t7BOqMqKiNdgczC2xD9J6pKfoQRRXuxx9/XG15BLnRd2eppZZK5dyeEN9qzun2AAAAsOAVqzmrVm9GyBqVsfMqQuCqolo1+rPGfUyZMmWW14tD89dbb73cgzYqgIsilIzPv3Ek55yISti4r7///e/pZz/7WS4+qvnZOURBUrH3ahy1Gu0J47N0tEiIoDLaI8T5qBotnqKFRJx+qghQZ9XycG5E1e7zzz+fWy7UVHxMY79F8dQ111xTLdiOloYRzkaldXG9WP6vf/2rtF6E17FeVcV9NHTo0NyHuKYvvvjiJ28X9ZtKW+qM+GYsfiHEN5vx7eOciF8ucahK/DKLbyrD448/nl599dV02mmn5V9otSFaLkQfoZqiWXk0mw/FbyZHjRqVg1uHQQAAAFSmbt265T6pEVhGZWr0qx05cuRPOgR/hx12yMU60Qc2JgSLz6n//Oc/c4FRtP+bnTPPPDPtvPPOuf9rVMZG68AIDSMojcrUmqLPbIy/KAqiogI0xh/Xi6NQo5/uhRdeOMN143ox70ocLRrBbvTrDeeff34ee7RV6NKlS64WjvAybif6ucZRssV150TcXvSnLVavxlGxUfka+yk+NxfFZ+li39s5dfTRR+d5a+Io3IMOOih17dq11E4xtjmKw2L+nAhYY4K3aAMRfX7jOrE9UWlcfExiX8V2//73v8/z2kTQHjlFzb7GxW3afPPN8/6JScai+jaC78ceeyzPdxNBMsyK0JY6449//GOeKTK+IYvm4PHGFxN4xTdXxcbgMzscI95QY3KxYmh76aWX5l+M8e1YbYW2l1xyST7VFL2AiodkxERoG2ywQf4WL/oXxfZEv6D4Y6DYuxcAAIDyi5Azes8eeeSR+bNpBJlRJBQFOLPqV/pjhgwZktsKxERbcah9BJwRCMft/5g43D4+R8aEVtEDNz4/xufImNB6ZpNZxSRjVUXQG5W98Vk6rhOfl6PtQ8ytMrP5WXr27JlD2/gMXhRhZYSbEV7ecsstOUgOMWl4fK6d0x62VatqYxwxAXmIuV5CBKtxKorgfG5D2wiCH3rooby/oto2CruiEjYev2KwHIVU0QYjticujzA6JheLI3UjyC2K1gkxnmh1GGFyBPh77LFHrliOid2qin0ULSWi3WPkElFdHfcb68XjBrPTqFDuzsx1UMzCWPzmJ95Y56RXDPNHfDsYb4QxC2XVWRa32GKL/AZY7BkT34jFYxQB6W233ZZ222233JsnQtIIbOOX4xlnnJF78cQ3X9GHKK4T4nairUJ8q9ejR4+8LL49i198MZtnfPM5K8X1IpCN264pxhSHnRTF8+cf//hHbrQe21Z8OcabePziPuCAA+bj3mN2vK5nZJ/UPR6zusnjVvd4zOomj1vd5HFrWPs/JrSKCsgIAuOzG5UjqoqPOOKI3D6h5qRj1D0L8rXmfXzeqbSlTolDCiJUDe+//3568MEH07Bhw/I3ZhGUxhtOzV8gcRhH9PyJb8fiG7v4tixC2doU39TNSaPxeOM67rjj8inGFd8k3nTTTemiiy7K325GkByHXQAAAMCCFpOBRz/WaC8YxU8CW1hwTERGnRUzNkawGcFtBJtRVVs8fKJmw/hYL6pZo0l8VLrOqp1COcWhIxH0RiVvVP/GoSERNAMAAEA5xBGqq6++ej5itdhyEFgwhLbUedE/ZpNNNsn/L85oWVM0Gh83blyehCz+X+mKLRRmtT0AAABQ22JSsylTpqR77723dIg7sGAIbakzYhKyqVOnzrA8ZsksTigWTb5nJma4jN6x0XQ8ZrSsBDGTZhxmMjPRImF22wPMu2ijEhMvxISG0U8pJhyIGWgPPPDA/D4DzB9ea1D77r///vy3bceOHVPz5s1T27Zt8+S2Z599dvrhhx/KPTwA4CfQ05Y6I5qex0yLMStj9LaNGSk/+OCDdOWVV6Y33ngjt0CI5bMSs3D+VDHr48knnzzD8iZNmuQZJotiPDGL5MxEC4Q4tOSee+5Jf/jDH9IOO+yQ2zvEsm+//TbPVhkzUUYf3t/+9rc/eczA/xMtR4466qj8QTZeszGDbryfxEy70e86Ji2M1+1JJ52U/vSnP5V7uFBnea1B7YtChpggN+ZBiC9Fdt5557TKKqvkvyWjmCH+hrzwwgvz6y2WQ13z6quvlnsIUK95jdUNQlvqjLPOOivdfPPN6eGHH07XX399+uabb9Jiiy2W1llnnXTMMcek/v371/oYnnjiiXyqKSobqoa2UUE0qyqiWB4BbY8ePdKkSZNyeBu9dj///PP84TYmH4uA+uijj87rAfPHH//4xxwirbfeeum6667LFX81q/ajp3R8OQTMO681qH3RVzIC24022ijdeOONqX379qXLpk2blr8UiVNMyBszhMfcCVAXLLHEErk4p0+fPuUeCtR78VqL1xyVq1GhUCiUexB1zYQJE0q9XMaPH5+/3Qbqtvr8uo6qt6h0+/rrr/OXAb169cpfEDSkffLWW2/lCRQWX3zx9PLLL6ell156luvGlynxRUxdVJ8es4akPj1uXmtUsvryuMURXTGpbrzOXnnllVm+zg444IB8RFpUtEeAW1fVl8et3CZOnJiP7mvWrFkO/ffcc888N0gl7v///e9/6csvv0z12WWXXZYLkuLLzcaN565rZbT8i/6yUczE/NWvX7+0wQYbpN/85jepIYjAdvnll6/1+/E+/hNEaMvcGT9+fATd+RT/B+q++vy6/uCDD0rbFqfOnTsXRo4cWZgyZUqD2SfHHXdc3o4//OEPhfqsPj1mDUl9ety81qhk9eVxi9dXbMPvf//72a736quv5vXat29fqMvqy+NWbv/973+r/T243nrrFW688cbC9OnTZ3s9+3/++/bbbwtt27YtXHrppdWWf//994WzzjqrsPHGGxcWXXTRQvPmzQurrrpq4bDDDiu8/vrrpfX69etXaNmyZaGSHH/88dWeX40aNSoss8wyhV133bXw2GOPVVv33XffrbZuzdOpp55aWnerrbaqdtnCCy9c6NKlS+Hss88uTJs2La8zu9uqerr//vt/dDtuuOGGQosWLQqffPJJLeylhsv7yLzTHgGggYkKnZgI6C9/+UuuvpnTytu67JFHHsk/o+IYqD1ea1D7Hn300fxz2223ne16UfW+3HLLpY8++ijPAxGTlUHVSZH33nvv3MomKjfntPJ2QajvlbZRAR9Hm8RrNNqXhDgi7le/+lXuM7rFFlukQYMG5UPX33///VyNO3To0FKbvmgvFEfSFa9bCYoTbEcVd4w7xvfZZ5/l9i2xPZdffnlabbXV8joff/xx/rnjjjvmiRNrirZKxW2Lqsw4muCXv/xlPh8tEu+4447cTvDFF1/Mvb3jM01Vt956a95XNZdPmTLlR/dZvE/GxKnxGekXv/hFqu8WVKUt8057hHmgtBvqn/r8uv7www9n+0Gtc+fOMw1v69M+icNIX3vttXwq/sFYH9Wnx6whqU+Pm9calay+PG5z8zr72c9+VpqTYeONN051UX153MrtySefnO1zYFbh7YLe/xHYxnM82jkAtSsC9viioLaDW+/j865+l1YBzOOMzNEHLvox1geTJ0+eo8rbIUOG5P5Y8QEPAKDS3HXXXem0007LVYrMnR8LQYuVt9ErOaoRV1xxxVQOUWEbYx01alQOb+ubqHzfY4890gknnJB23333vCwqRmNS7dj/MZnnnPa0veGGG/Lr4b///W/uEb/bbrulX//612mhhRYqrRsVr1dffXWueI1CjgjOtt5661zVW3WCwrhuVLjGZ4JzzjknvfPOO6lDhw7pd7/7Xdpwww3Tfffdly688MJctb/SSivlgo+oFC6KSuCYHDEm2W7Tpk1peVTGxlEBUTl8yCGHlCptY9ujb2zfvn1nu62DBw/OtzF69Ohqy2NcsQ+i6nbJJZesdtnpp5+e13/66adLy/7973+n2267Lb399ts5NIxt22+//dLPf/7zGe7zwQcfTL/97W/TFVdcUW0b65sIa2PCv3jNqbatXEJbgJkc3hOHLTU08QfytddeWy9D22WWWSZXJMUfyvW5+g/KzWsNFtzrLMKTH3udxTph2WWXTfVBBE8RUFF7IiD7z3/+kw499NCyjiMC25gQqj4GZWGfffZJXbp0yf+//vrr88845H9Otrldu3YxN1E66qij0iabbJKPlouwNILubt26VTusP8LSESNGpAEDBqSuXbumd999N/3zn//M7w3R0qhp06Z5vZig7osvvshhchRyLLbYYulvf/tbOvLII3NYe95555WeE6eeemoOjl9//fXSJGrF95g4uq9t27Y5LI6/BeK+Fl544RzQrrXWWnmduLz4c2ZhYXxxUDz6L0LmH374YYb98u233+aK8C233DK3M6iqGOJWvU4ExmuvvXYuzInbvuWWW3LgHeFttFioKtoxRGj71Vdf1cvnIHWL0Baghvhj4/777y/9UVXXRY+s4447brbrxB9E8cdj/BFWH8VsyQ888ED+Rl6vTag9XmtQ+yKUKb7Otttuu1muF8FuVLS1b9++3vSzPfnkk3OVoErbuffee++lM844Y7brRFgWlZYNoZdnucTrMlStZC5+5iiGuHMigsyoFI2K12IoGQHjJZdcUnr8Hn744TRs2LBcMdq7d+/Sdbt375522mmnXKxRdXmEsNEze9NNN83n11xzzdx3NoLfGHcxYI1K2gh2x4wZk1+PVdX8IimeUzfddFMpsK0qgt841fTYY49VKyKZNm1aqcdx9PONbXzqqafSrrvuOkNgOytRPVt13eiRG/vgrLPOmiG0jffMCLFfeeWVObptqE1CW4CZiD9Aav4RUlfFoVCzCm2j+XwcXhR/3BX7DNVHcchZfJseh20dfvjhMxxGVVV8EIxDzIC557UGtS8OJ47X2cUXX5yrwWb1OjvllFPyz4MOOijVF1FhWJ+2Z0H3tJ1VaBvVhn/4wx/yvvW+XLsidIxKz6p/d3/33Xf5Z+vWrefqtortBopiwq+RI0eWzkcoGxWz0RogqnBjMrAQFbdx/1GkUjW0jZC2GNiGqOIN8SVs1YrY4vJooVDz81JUDUfbhagEjkrbf/3rX2nffffNrU3iC6earQ9qtid46KGH8mRmL730UunLmXHjxs3wPhctJiK8nVNVA9uo0o1Jybbaaqt055135vOxn6qKYLo+T4ZH3fH/atmhjooqgzgsIn6GFVZYIX9grCkqEXr27JmrDOIPkfiFGL+sIsiKQGtmlYknnXRS2mijjfK3g/FNW/wxE79wonfQzObvu/nmm/O3fUsttVReP2brjfXjW70fCwXjkJXYjvgGHBaECGvjD/c4ROroo4+u14FtWGWVVXI4HX987bzzznm7Z1axEN+2x2FhwLzxWoPaF5VscahxhD/RF7I4a3tRHJYcs6ZHSBM9KuMQapiZ+HxzwQUXpLfeeit/gS+wLY9ib9kIJ+dUtByoGWRG0BifY4vefPPNHEhec801ueVFrF88RV/Xzz//vNr1a7YqKAaZNSv1i8ur3ldRtCuIIwC23377/Lk8PofHZ+/ooVvTqquumteteorxxt8Pt99+e+5JG5/FQ4S/EbDG8zUqYaOVQ+yDORWtIOL2YwKsuM3YB/FFRYj7rCk+71edkA/KRaUt9Vr80RqHbsRhIZ06dcrfJMYvh5iYKX4JnH/++blKoeovrOiTFbOmxrL4Bi/63sQv0vimMH55RBAb1yv29InDNaJHUHyrGd9Oxh/R0dPn/fffz99mRjAb3xb+9a9/LeOeoKHPChp/dMQfHw2lsnZWh1RGWHT22WfnD7xRNRC9raKXVwRL0QssPgDHesC881qD2hdfvEbQcOmll+a/baNwIALaqNiLirYIa2J5/O1adbIhGq6qf/eprC1vtXhMehwBbbGytjjZVUxIFtWyc6LqZGOz+ywcBUXrrrtumjBhQjrxxBOrXV4MfeOL1GilEsVMEdDGl0HxHlN8zkRFa0wm1qNHj2rXj8+4US0b21EMPuN9KMYW2/GPf/wjF1VFZW4UOMXtRtuDc889d5ZjjknQqopJz+JzeZyKlcXRiilaQcRzeHa3VRSTj8X4Yz/HtsY2RpFVvD/G3yqxn2bW2zk+N0G5CW2p16KKJwLb/fffP1ezxptzVX//+9+r/fL69NNP8y+T+LAZFbKbb755tfWjZ1B8w1f1W8W4jwhs41C1+IVWbJoejjnmmBwAR5/QqD5yOBflEE3+4zkaf0zF87ShhbVFMVFC/KEWX97Et/XRhytO8YdafNESPbviC5jZ9QcEfpzXGtS++Hsz/u6Mv3GjHUn0roxJuqKKLCZwinAjvqCd036P1H8RWMV7cnweiqIUYW15FAPa+BJznXXWyf+Pz5/xeTGq4+c0tJ0TEaDGF6UxsVaExLP6vRu/t+PzQhQg/fGPf8zFSVHkEVWtIb4AGj58+AyhbYw/AttoNRBjDzHBV4TB8cVs9Ix94YUXckgdoh1DVAPH55L4W2BORNFJ/P1QnLyseL99+vRJQ4cOzUcSzGwys6piTNFqIdpEVF03xjMzUawVRV7xXgrlJrSl3opv484888xcYRtVCDUD2xCHRsS3a0Wxflwv/qCpGdgWVf0FE+vGrJrx5h+/NKoGtsUKx2j8Ht8Qxi/A+OUys3FAbYs/zvl/Ntxww7nqgQXMG681qH3FQ4rhx8RRVzV7oLLgFXvGxkRaxdA2lkXAGcVG0Rpgr732qnadCBCjqjQ+d86NaA8Ywevzzz+fP49WFUFqtEiIz8PRgz4qXOOzaxwdE4FrPFeKoW2EufGlULRiiS9fi71eo5VgiPYLxfaBsW5UqEbIG7cdgWlMbhatDKJwJLYxqnrn1AcffJBD29iWqiJUjqNa40vimtW5s6pKrtriMIpZYowzE0fkhpo9eKEchLbUW7fddluumI3KwjntdxON0yNU7dev31zdR8yyOqv7iENSotr2yiuvzDNhRsNzAAAAGpYIT6NlUFTAVj0KMwLIHXbYIe2zzz658jYO54/K+Wh1cvXVV+fAdG5D2/jcGa0Co7jos88+y+FmtCqK24xJyqJ9QVTPxlji8jjqNCpnI9CNz7gTJ07MtxOVumuttVa67LLL0u9///t00003lbYlRCj81VdflVpvVA2bo+I/jlKNtggR2lYtYHrmmWdKFbo1K4QjyI7Pz9FyMNoZxGfqqiIc3mWXXXIIHEfDRtuJWYn9Gvcb+zX2R4TV0SIxbrNmT/Bw991356Ks9ddff672N9QGoS11WvSLrfqNWdWJvGLGybDeeuvN0W3FISPxS6FLly5zfChZ8T6ip87sxKRn8Usn+hQVQ9vi5GkhmrTPbAI1AAAA6o8Ia//85z+n77//vvS5M1oKREVqVLdG5WpMmB2hZxw1GvOsxLwp8+LCCy/MLQpeeeWVXK0bR4ZGn9k4AjR6w8bn59122y2HmvE5OKpPo93KwIED8/0XHXzwwXlelwhtr7vuurysOFFXhKAxCXe0FYg2BEWxbXFfcb0odoo+sVVdddVV+VRTFFDF5/K4zwhnZzYJeIjJlON2zzvvvNlObhr99WPMceRrtFNYZpllcpgc+7xm+8Ko6o1Crth+E5FRCYS21FsxEUOY08kX5nb9qtcpzqA5K8XbnNnMlAAAADQMERRGC4Io6olwsGrIeeSRR+bT7MRcLXGqKYLLmYWXnTt3zlWlxQrZqiKgjKAyAtXobRtGjx5durwYmEa1bLQkiIm/olI32hYUq2qjgCmC5visO6vP0hGuFkWQO6sgNkSQG73vo8I4jlidlSiGmtnt/POf/8ynqqLKNk41xf1UFX1vY18UJx2Hcvt/r0qoh4q/MKKCtjbWn5swdk7DXQAAAOqv+EwYAWjMpxKB6YIQn1efe+65aqcIXmOy7JhILKpV33nnnTxJWFTn1hQTiEXrhqhujXYDVdsgxNwZ0cc2AtaHHnooT7IWR5X++te/Th9++OFcjTOC7GhvGBOGb7LJJrllQ5wWVPHT6aefnn75y1/m3r1QCYS21FvRKyg8++yzc7R+9O+Jw09ee+21fKjK3NxH9OOZneLlccgJAAAADdcxxxyTP3cWq1trW4So0aO16unEE09M6667bp7MK8LK+Gwbk2ifeuqpM72NYsuEmi0FYgKzMWPG5D6wEeyuscYaed3oizs3R7GGiy66KPfUPeyww3JwWjzNa3uIuRVz0JxxxhkL5L5gTjQqzK4unZmaMGFCbqJd7N8SDcKpPJ9//nkOYaNnTfxCbN68+Y9e57e//W06++yzc7P2wYMH/+j60bC9eB+vv/76TO/jiy++yE3aIxSOnkFVm69TObyuZ2Sf1D0es7rJ41b3eMzqJo9b3eRxa1j7P4pdYj6Qp59++kfnDWHBiircI444In388cc+09YDC/K15n183qm0pd6Kvj1x+EYEpdHEvGoj9aptC+IXT1EcphINyeNnfMs2M3fddVfur1OcSTOC3miUHs3Mp02bVm3dqNg98MAD8xtT9C3yyw0AAIC6YuLEientt99Op512WhoyZIjPtLAAmYiMei0asX/yySdp2LBheRbMXr165b49EeBGH59rr702/9KJ6toQFbO33npr7sez+eabp7322ittueWW+bCO+EbxjjvuyLfzr3/9q3QfJ510Ug5tY6bNJ598Mu2///75EI5Ydvnll+eePjHLZs3DSAAAAKCSRbuAU045JX8uPvbYY8s9HGhQhLbUa9Ej6OKLL0777bdfbnkQh3RE24RoYxCzaEavnJozQ2688cbp5Zdfzs3Yb7nllvTnP/85V8xG5e7PfvazdPPNN6c99tijtH6TJk1y758ePXrkHjwRAEej9LZt26Zu3bqlSy+9NG299dZl2HoAAAD4aYVQcQIWPKEtDcJ2222XT3MqAtfjjz8+n+bU3nvvnU8AAADMu1dffbXcQ4B6zWusbhDaAgAAAGW3xBJLpBYtWqQ+ffqUeyhQ78VrLV5zVC6hLQAAAFB2yy+/fK4A/PLLL8s9FKj3IrCN1xyVS2gLAAAAVIQIkQRJACk1LvcAAAAAAAD4/6m0BQAAACrC//73P+0RYAHQHqHyCW0BAACAighs11hjjTRx4sRyDwUaxERk0UNacFu5hLYAAABA2UWFbQS2o0aNyuEtUDsirO3Tp09+zQltK5fQFgAAAKgYEdhusMEG5R4GQFmZiAwAAACgHurfv3/aa6+9Ul3wySefpN69e6fOnTunxo0bp8MPP7zcQ4KyEtoCAAAAsEBMnjx5pssnTZqUllxyyfTHP/4xrbvuugt8XFBphLYAAAAADdBZZ52VunTpklq2bJk6duyYDj300DR+/Ph82YQJE9Kiiy6arrvuumrXuemmm/L648aNy+c/+OCD1LNnz7T44ountm3bpj333DO99957M1T7nnLKKWm55ZZLq6222kzHssIKK6R//OMfqW/fvmmxxRar1e2GukBoCwAAANAARRuCc889N7388svpsssuS/fdd1/63e9+ly+LYLZXr15p+PDh1a4T53v06JFat26dpkyZknbcccf8/4ceeig98sgjqVWrVmmnnXaqVlF77733ptdffz3dfffd6dZbb13g2wl1kYnIAAAAABqgqn1jo9L15JNPTocccki64IIL8rKDDz44devWLfebXXbZZdPnn3+ebr/99nTPPffky6+55po0ffr0NGzYsNSoUaNSqBtVtw888EDaYYcdSgFwrNOsWbOybCfURSptAQAAABqgCF+33Xbb1L59+1wte+CBB6axY8emiRMn5ss33njjtNZaa+Uq3DBq1KjUqVOntOWWW+bzzz//fHrrrbfydaPCNk7RIuGHH35Ib7/9dul+ogWDwBbmjtAWAAAAoIGJvrO77bZbWmedddL111+fnn766XT++efny6q2Nohq2xEjRpSqaAcMGFCqqo3+t127dk3PPfdctdMbb7yRevfuXbqNqLQF5o72CAAAAAANTIS00drg73//e+5tG0aPHj3Den369Ml9bqP37SuvvJL69etXumyDDTbILRKWWmqpPGkZMP+otAUAAACop7799tsZKmE/+OCDtMoqq+SJxM4777z0zjvvpJEjR6YLL7xwhuu3adMm7bPPPunoo4/OPWo7dOhQuuyAAw5ISyyxRNpzzz3zRGTvvvtu7mX761//On344YdzPdbi+KKC94svvsj/j6AYGiKhLQAAAEA9FSHq+uuvX+104oknpnXXXTedddZZ6fTTT09rr712uuKKK9Kpp54609sYOHBgbplw0EEHVVveokWLNGbMmLT88svnYHeNNdbI60ZP23mpvC2OL6qAr7zyyvz/XXbZZZ63Heoy7REAAAAA6qHoRVvsRzszRxxxRD5VFZOR1fTRRx+ldu3a5YrampZZZpnSRGWzGsOcKhQKc7wu1HdCWwAAAABmMHHixPTJJ5+k0047LQ0ZMiQ1a9as3EOCBkN7BAAAAABmcMYZZ6TVV189V9Mee+yx5R4ONChCWwAAAABmcMIJJ+TJyu69997UqlWrcg8HGhTtEX6iCRMmlHsIwHzgtTx79k/d4HGq+zyGdYPHqe7zGNYdHisAGiqh7U+09NJLl3sIALXOex0sGF5rsGB4rUFle/XVV8s9BKjXvMbqBqEtAAAAUHZLLLFEatGiRerTp0+5hwL1XrzW4jVH5RLazuMTe/z48eUeBlCLr3G819V1nsd1h9da3ea1Vnd4rdV9Xm/13/LLL58rAL/88styDwXqvQhs4zVH5WpUKBQK5R4EAAAAUHk9hYuTT8WXHi1btiz3kIA6xvvIvGv8E64LAAAAAMB8JrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggTco9AAAAAKCyTZgwodxDAOog7x3zTmgLAAAAzNbSSy9d7iEANCjaIwAAAAAAVJBGhUKhUO5BAAAAAJUl4oKJEyeWexiU2eeff55GjRqVhg8fnt59993S8s022yzdeeedZR0bdUuLFi1So0aNyj2MOkNoCwAAAEBJREVjxoxJF154Ybr++uvTlClT8vII3HbYYYd0yCGHpN122y01aaLrJtQWry4AAAAA0ldffZUuv/zyNHTo0PTaa6+Vli+55JJp4MCBadCgQWmllVYq6xihoRDaAgAAADTgqtrHH388V9WOHj06/fDDD6XLunfvnoYMGZL23nvv1KxZs7KOExoaoS0AAABAA/Pdd9/lXrVRVfvCCy+Ulrdp0yb1798/DR48OK2++uplHSM0ZEJbAAAAgAbimWeeyVW1V155ZZowYUJpebdu3XKv2h49eqRFFlmkrGMEhLYAAAAA9VqEs1dffXWuqn3yySdLy1u3bp369u2bWyB06dKlrGMEqhPaAgAAANRDL730Ug5qY3KxaIdQ1LVr11xV26tXr9SqVauyjhGYOaEtAAAAQD0RE4ldd911uQXCI488UlreokWL1Lt371xVu+GGG5Z1jMCPE9oCAAAA1HFvvPFGrqodMWJE+uqrr0rL11577VxV26dPn7TYYouVdYzAnBPaAgAAANRBkydPTjfffHOuqr3vvvtKy5s3b5569uyZw9pNN900NWrUqKzjBOae0BYAAACgDnn33XfTxRdfnC655JL0+eefl5Z37tw5B7UxuVi7du3KOkbgpxHaAgAAAFS4qVOnpttuuy1X1d55552pUCjk5U2bNk177713Dmu33nprVbVQTwhtAQAAACrUhx9+mCtqo7L2o48+Ki1fYYUV8qRiAwYMSEsvvXRZxwjMf0JbAAAAgAoyffr0dNddd+Wq2ltuuSWfD40bN0577LFHrqrdfvvt83mgfhLaAgAAAFSAzz77LF166aW5qjb61ha1b98+DRo0KA0cODB16NChrGMEFgyhLQAAAECZRG/aBx54IFfV3njjjWnKlCl5efSm3WmnnXJV7S677JKaNBHhQEPiFQ8AAACwgI0dOzZddtllaejQoemNN94oLY/+tFFRG5W10bcWaJiEtgAAAAALqKr20UcfzVW11157bZo0aVLpsm222SZX1e65556pWbNmZR0nUH5CWwAAAIBa9O2336ZRo0blsPall14qLW/btm0aMGBAGjx4cOrcuXNZxwhUFqEtAAAAQC146qmnclB71VVXpYkTJ5aWb7755mnIkCGpR48eaeGFFy7rGIHKJLQFAAAAmE/Gjx+fQ9roVfv000+Xli+66KKpb9++Oaxde+21yzpGoPIJbQEAAAB+ohdeeCEHtSNHjkzjxo0rLd9oo41yr9r99tsvtWzZsqxjBOoOoS0AAADAPPj+++/zhGLRAuGxxx4rLY9wtnfv3rmqtmvXrmUdI1A3CW0BAAAA5sJrr72WLrroojRixIj09ddfl5avs846uar2gAMOyO0QAOaV0BYAAADgR0yePDndeOONuar2gQceKC2PicSi9UGEtZtssklq1KhRWccJ1A9CWwAAAIBZeOedd3JV7aWXXpq++OKL0vLVV189B7UHHnhgatu2bVnHCNQ/QlsAAACAKqZOnZpuueWWXFV71113lZY3bdo07bvvvjms3XLLLVXVArVGaAsAAACQUvrggw/SsGHD8unjjz8uLV9ppZXypGL9+/dPSy21VFnHCDQMQlsAAACgwZo2bVq68847c1XtbbfdlqZPn56XL7TQQmnPPffMYe12222XGjduXO6hAg2I0BYAAABocD799NN0ySWXpIsvvji9//77peUdO3ZMgwYNSgMHDkzLLbdcWccINFxCWwAAAKBBiCra+++/P1fV3nTTTbl3bYjetLvsskvuVbvzzjvnKluAchLaAgAAAPXal19+mUaMGJGGDh2a3nrrrdLyZZZZJlfURmVtp06dyjpGgKqEtgAAAEC9UygU0sMPP5yD2muvvTZNnjy5dFn0qI2q2j322CM1bdq0rOMEmBmhLQAAAFBvfPPNN2nkyJG5BcIrr7xSWt6uXbt00EEHpcGDB6dVVlmlrGME+DFCWwAAAKDOV9U++eSTOai9+uqr0/fff1+6bMstt0xDhgxJ++67b2revHlZxwkwp4S2AAAAQJ00bty4dOWVV+YWCM8++2xp+WKLLZb69euXw9o111yzrGMEmBdCWwAAAKBOef7553NV7ahRo9L48eNLyzfZZJPcq7Znz56pRYsWZR0jwE8htAUAAAAq3sSJE9Po0aNzWPvEE0+Ulrdq1SodcMABuap2/fXXL+sYAeYXoS0AAABQsV599dXc/uCyyy7Lk4wVrbvuuukXv/hF6t27d2rdunVZxwgwvwltAQAAgIoyadKkdMMNN+Sq2jFjxpSWL7LIIqlXr165qnbjjTdOjRo1Kus4AWqL0BYAAACoCG+99Va66KKL0vDhw9OXX35ZWr7GGmvkXrUHHnhgatOmTVnHCLAgCG0BAACAspkyZUr697//nVsg3H333aXlzZo1Sz169Mhh7eabb66qFmhQhLYAAADAAve///0vXXzxxWnYsGHp008/LS1feeWVc1Dbv3//tMQSS5R1jADlIrQFAAAAFohp06al//znP7lXbfycPn16Xr7QQgulvfbaK4e122yzTWrcuHG5hwpQVkJbAAAAoFZ9/PHH6ZJLLsmVtR988EFp+fLLL58GDx6cDjrooLTsssuWdYwAlURoCwAAAMx3UUV7zz335F61N998c66yDVFFu+uuu6YhQ4aknXbaKVfZAlCd0BYAAACYb7744os0fPjwHNa+8847peVRSXvwwQfnU1TYAjBrQlsAAADgJykUCmnMmDE5qL3++uvT5MmTS5ftsMMOuVftbrvtlpo2bVrWcQLUFUJbAAAAYJ58/fXX6fLLL88Ti7322mul5UsuuWQaMGBA7le78sorl3WMAHWR0BYAAACYq6raJ554Ige111xzTfrhhx9Kl2211Va5qnbvvfdOzZs3L+s4AeoyoS0AAADwo8aNG5euuOKKHNY+//zzpeWLL7546t+/f66qXWONNco6RoD6QmgLAAAAzNKzzz6bg9oIbCdMmFBavummm6YhQ4aknj17pkUWWaSsYwSob4S2AAAAQDURzkbrgwhrn3zyydLy1q1bpz59+uSwdt111y3rGAHqM6EtAAAAkL388stp6NCheXKxb7/9trR8/fXXT7/4xS/S/vvvn1q1alXWMQI0BEJbAAAAaMBiIrHrr78+V9U+/PDDpeXR8qB37965qnbDDTdMjRo1Kus4ARoSoS0AAAA0QG+++Wauqh0xYkQaO3Zsaflaa62VDjnkkNwGISYZA2DBE9oCAABAAzFlypR0880356rae++9t7S8efPm6ec//3muqt1ss81U1QKUmdAWAAAA6rn33nsvXXzxxemSSy5Jn332WWn5qquumoPafv36pSWWWKKsYwTg/ye0BQAAgHpo6tSp6fbbb89VtXfccUcqFAp5eZMmTdLee++dWyB0795dVS1ABRLaAgAAQD3y0UcfpWHDhuXThx9+WFreqVOnXFU7YMCAtMwyy5R1jADMntAWAAAA6rjp06enu+++O1fV3nLLLWnatGl5eePGjdNuu+2Wq2p32GGHtNBCC5V7qADMAaEtAAAA1FHRn3b48OHpoosuSu+++25p+XLLLZcGDRqUBg4cmDp27FjWMQIw94S2AAAAUIdEb9oHHnggDR06NN1www1pypQpeXn0pt1xxx1zVe2uu+6ae9cCUDd5BwcAAIA64KuvvkqXXXZZDmtff/310vIll1wyV9RGZe1KK61U1jECMH8IbQEAAKCCq2ofe+yx3Kt29OjRadKkSaXLunfvnqtq99prr9SsWbOyjhOA+UtoCwAAABXm22+/TVdccUUOa1988cXS8jZt2qQBAwakwYMHp9VWW62sYwSg9ghtAQAAoEI8/fTTOai98sor08SJE0vLu3Xrlqtqe/TokRZZZJGyjhGA2ie0BQAAgDKaMGFCuuqqq3JYG6FtUevWrVPfvn3TkCFDUpcuXco6RgAWLKEtAAAAlEG0PYhJxUaOHJm+++670vINN9wwB7W9evVKrVq1KusYASgPoS0AAAAsIN9//3267rrrclXto48+WlreokWL1Lt37xzWRmgLQMMmtAUAAIBa9vrrr+eq2ssuuyx99dVXpeXR9iB61R5wwAFpscUWK+sYAagcQlsAAACoBZMnT0433nhjDmvvv//+0vLmzZun/fbbL1fVbrrppqlRo0ZlHScAlUdoCwAAAPPRO++8ky6++OJ06aWXps8//7y0vHPnzrmqtl+/fqlt27ZlHSMAlU1oCwAAAD/R1KlT06233pp71d51112pUCjk5U2bNk377LNPDmu32morVbUAzBGhLQAAAMyjDz/8MA0bNixX1n788cel5SuuuGIaPHhwGjBgQFp66aXLOkYA6h6hLQAAAMyFadOm5WraqKqN6trp06fn5QsttFDafffdc1Xt9ttvnxo3blzuoQJQRwltAQAAYA58+umnuU9tVNW+9957peUdOnRIgwYNSgMHDkzt27cv6xgBqB+EtgAAADALUUV7//33p6FDh6Ybb7wx964N0Zt2p512ylW1u+yyS2rSxMdrAOYfv1UAAACghrFjx6YRI0bksPbNN98sLY/+tFFRG5W1K6ywQlnHCED9JbQFAACAlFKhUEiPPPJIDmqvvfbaNGnSpNJl2267ba6q3WOPPVKzZs3KOk4A6j+hLQAAAA3aN998k0aNGpUnFnv55ZdLy9u1a5f69++fBg8enDp37lzWMQLQsAhtAQAAaJBVtU899VQOaq+66qr0/fffly7bfPPNc1XtvvvumxZeeOGyjhOAhkloCwAAQIMxfvz4dOWVV+aw9tlnny0tX2yxxVLfvn3TkCFD0lprrVXWMQKA0BYAAIB67/nnn8+9aqMNwrhx40rLN9544xzU7rfffqlly5ZlHSMAFAltAQAAqJei5cHo0aNzVe3jjz9eWh7h7AEHHJDD2g022KCsYwSAmRHaAgAAUK+8+uqruar2sssuy5OMFa2zzjq5V20EtosuumhZxwgAsyO0BQAAoM6bNGlSuuGGG3JY++CDD5aWx0Ri0fogwtpNNtkkNWrUqKzjBIA5IbQFAACgznr77bfTRRddlC699NL05ZdflpavvvrqOaiNycXatGlT1jECwNwS2gIAAFCnTJkyJd1yyy25V+3dd99dWt60adPUo0ePHNZuscUWqmoBqLOEtgAAANQJ//vf/9KwYcPy6ZNPPiktX2mllfKkYv37909LLbVUWccIAPOD0BYAAICKNW3atHTHHXfkqtrbb789TZ8+PS9faKGF0p577pmrarfddtvUuHHjcg8VAOYboS0AAAAVJyppL7nkknTxxRfnCtuijh07psGDB6eDDjooLbfccmUdIwDUFqEtAAAAFSGqaO+7775cVXvzzTenqVOn5uXRm3aXXXbJVbU777xzrrIFgPpMaAsAAEBZffnll2n48OFp6NCh6e233y4tX2aZZdLBBx+cT506dSrrGAFgQRLaAgAAsMAVCoX00EMP5ara66+/Pk2ePLl02fbbb58nFttjjz1S06ZNyzpOACgHoS0AAAALzNdff51GjhyZw9pXX321tLxdu3a5T230q11llVXKOkYAKDehLQAAALVeVfvf//43B7VXX311+uGHH0qXbbnllrlX7T777JOaN29e1nECQKUQ2gIAAFArxo0bl6644orcq/a5554rLV988cVTv379clXtmmuuWdYxAkAlEtoCAAAwXz377LM5qI3Advz48aXlm2yySa6q7dmzZ2rRokVZxwgAlUxoCwAAwE82ceLEdM011+QWCNEKoahVq1apT58+eWKx9dZbr6xjBIC6QmgLAADAPHv55ZdzVe3ll1+evv3229LyCGijqrZ3796pdevWZR0jANQ1QlsAAADmyqRJk9L111+fq2ofeuih0vJFFlkk9erVK4e1G220UWrUqFFZxwkAdZXQFgAAgDny5ptvposuuiiNGDEiffnll6XlMZlYBLUHHnhgnmQMAPhphLYAAADM0pQpU9LNN9+cWyDcc889peXNmjVLPXr0yGHt5ptvrqoWAOYjoS0AAAAzeP/999PFF1+cLrnkkvTpp5+Wlq+yyip5UrH+/funJZZYoqxjBID6SmgLAABANm3atHT77bfnXrX/+c9/UqFQyMubNGmS9tprr1xV271799S4ceNyDxUA6jWhLQAAQAP38ccf54raqKz94IMPSss7deqUBg0alA466KC07LLLlnWMANCQCG0BAAAaoOnTp+cetVFV++9//ztX2Yaoot11111zVe2OO+6YFlpooXIPFQAaHKEtAABAA/L555+n4cOHp4suuii98847peVRSRtVtQcffHDq2LFjWccIAA2d0BYAAKCei960Y8aMyVW1119/fZoyZUrpsqimjYnFdtttt9S0adOyjhMA+H+EtgAAAPXUV199lS6//PI0dOjQ9Nprr5WWL7nkkrlPbVTWrrzyymUdIwAwI6EtAABAPauqffzxx3NV7ejRo9MPP/xQumzrrbfOVbV77713at68eVnHCQDMmtAWAACgHvjuu+/SqFGjclXtCy+8UFrepk2b1K9fvxzWrr766mUdIwAwZ4S2AAAAddgzzzyTq2qvvPLKNGHChNLyTTfdNB1yyCHp5z//eVpkkUXKOkYAYO4IbQEAAOqYCGevvvrqXFX75JNPlpa3bt06HXjggbmqdp111inrGAGAeSe0BQAAqCNeeumlHNTG5GLRDqFogw02yFW1+++/f2rVqlVZxwgA/HRCWwAAgAoWE4ldd911uQXCI488UlreokWLHNJGWLvhhhuWdYwAwPwltAUAAKhAb7zxRq6qHTFiRPrqq69Ky9dee+0c1Pbp0ycttthiZR0jAFA7hLYAAAAVYvLkyenmm2/OVbX33XdfaXnz5s1Tz549c6/abt26pUaNGpV1nABA7RLaAgAAlNm7776bLr744nTJJZekzz//vLR81VVXzVW1/fr1S+3atSvrGAGABUdoCwAAUAZTp05Nt912W66qvfPOO1OhUMjLmzRpkvbZZ59cVdu9e3dVtQDQAAltAQAAFqCPPvooDRs2LFfWxv+LVlhhhTR48OA0YMCAtMwyy5R1jABAeQltAQAAatn06dPTXXfdlatqb7311jRt2rS8vHHjxmn33XfPLRB22GGHfB4AQGgLAABQSz777LN06aWX5qra6Ftb1L59+zRo0KA0cODA1KFDh7KOEQCoPEJbAACA+Sh60z7wwAO5qvbGG29MU6ZMycujN+2OO+6Yq2p33XXX3LsWAGBm/JUAAAAwH4wdOzZddtllaejQoemNN94oLV9qqaVyRW1U1q644oplHSMAUDcIbQEAAH5CVe2jjz6ag9rRo0enSZMmlS7bZptt0pAhQ9Jee+2VmjVrVtZxAgB1i9AWAABgLn377bdp1KhRuQXCSy+9VFretm3b1L9//zR48OC02mqrlXWMAEDdJbQFAACYQ0899VQOaq+66qo0ceLE0vLNNtss96rt0aNHWnjhhcs6RgCg7hPaAgAAzMb48ePT1VdfncPap59+urR80UUXTQceeGBugdClS5eyjhEAqF+EtgAAADPxwgsv5F61I0eOTOPGjSst33DDDXNVba9evVLLli3LOkYAoH4S2gIAAPyf77//Pl177bW5qvaxxx4rLY9wtnfv3rmqtmvXrmUdIwBQ/wltAQCABu+1115LF110URoxYkT6+uuvS8uj7cEvfvGLdMABB+R2CAAAC4LQFgAAaJAmT56cbrzxxlxV+8ADD5SWN2/ePO233365BcLPfvaz1KhRo7KOEwBoeIS2AABAg/LOO+/kqtrhw4enzz//vLR8tdVWy0Ft3759U9u2bcs6RgCgYRPaAgAA9d7UqVPTrbfemqtq77zzztLypk2bpn333Tf3qt1qq61U1QIAFUFoCwAA1FsffPBBGjZsWD59/PHHpeUrrrhiDmoHDBiQllpqqbKOEQCgJqEtAABQr0ybNi1X00ZV7W233ZamT5+ely+00EJpjz32yGHt9ttvnxo3blzuoQIAzJTQFgAAqBc+/fTTdOmll+Z+te+//35peYcOHdKgQYPSwIEDU/v27cs6RgCAOSG0BQAA6qyoor3//vtzVe1NN92Ue9eG6E27884754nF4meTJj76AAB1h79cAACAOufLL79MI0aMyFW1b775Zmn50ksvnQ4++OB8WmGFFco6RgCAeSW0BQAA6oRCoZAefvjhNHTo0HTttdemyZMnly7bdtttc1XtnnvumZo2bVrWcQIA/FRCWwAAoKJ98803aeTIkbkFwiuvvFJa3q5duzRgwIA0ePDgtOqqq5Z1jAAA85PQFgAAqMiq2ieffDJX1V511VXp+++/L122xRZb5KraffbZJy288MJlHScAQG0Q2gIAABVj3LhxOaSNqtpnn322tHyxxRZL/fr1y1W1a621VlnHCABQ24S2AABA2T3//PM5qB01alQaP358afnGG2+cq2r322+/1KJFi7KOEQBgQRHaAgAAZTFx4sQ0evTo3ALh8ccfLy1v2bJl6tOnTxoyZEhaf/31yzpGAIByENoCAAAL1KuvvpqD2ssuuyxPMla07rrr5qra3r17p0UXXbSsYwQAKCehLQAAUOsmTZqUbrjhhtwCYcyYMaXlMZFYr169clgbrRAaNWpU1nECAFQCoS0AAFBr3nrrrXTRRRel4cOHpy+//LK0fI011shB7YEHHpjatGlT1jECAFQaoS0AADBfTZkyJd1yyy25qvbuu+8uLW/WrFnad999c1i7xRZbqKoFAJgFoS0AADBf/O9//0sXX3xxuuSSS9Inn3xSWr7yyivnScX69++fllxyybKOEQCgLhDaAgAA82zatGnpP//5T55Y7Pbbb0/Tp0/PyxdaaKG011575bB22223TY0bNy73UAEA6gyhLQAAMNeikjYqaqOyNipsi5Zffvk0aNCgdNBBB6XllluurGMEAKirfN0NAJRV9LT85S9/mRqSBx54IG/3ddddV+v3dcIJJ8xx39BYL9YvGjFiRF723nvvpUoVVZ1rr712OuWUU8o9lAYh9nf0qI2+tB07dkx/+tOfcmAbz5Pddtst3Xrrremdd95Jf/zjH2cb2M7p635unoMrrLBCbr8wP29zXo0dOza1bNkyVx4DAMwLoS0AMNci8JiTU4STdcnWW289y21ZffXVyz08ZuKqq65KH3zwQYML/he0L774Ip155pmpc+fOaYcddkg33HBDbouw7LLL5uA2AtCYeGzXXXfNbREaunbt2qWDDz447xsAgHmhPQIAMNdGjhxZ7fzll1+eq+9qLl9jjTVSXdOhQ4d06qmnzrB8scUWSw3NgQcemHr16pWaN2+eKlUEiTHGhvj41LZCoZAeeuihdOGFF6brr78+TZ48uXTZ9ttvnw455JC0++67p6ZNmzbo5+CsxP4599xz03333Ze22Wabcg8HAKhjhLYAwFzr06dPtfOPP/54Dm1rLq+LIvyrD9sxP0TFZCVXTT777LPp+eefT3//+9/LPZR65euvv85fxMTEYq+++mpp+RJLLJE23njjHJSvueaaM1wv1o22AJtvvnmDeQ7OTnxpFa07oh2D0BYAmFvaIwAAtWLChAnpyCOPzH0vo0putdVWS3/7299y9d6POfnkk/NM8+edd15pWcxOv8UWW+Q+ka1bt86HYb/88svVrhf9LFu1apU++uijPGt9/H/JJZdMRx11VD6Ue373iX3jjTdywBtBb9xPHAod2xeH6++5555p0UUXTcsss8wsQ8UY0x/+8Ie8TmzXHnvska9b0xNPPJF22mmnfD8tWrRIW221VXrkkUdmWO/hhx9OG220UVp44YXTyiuvnEO3mZk0aVI64ogj8phjX8b9fvjhh3PU+zP6hkbv0rivCPDivlZaaaUc8tX0wgsv5LEussgiuYI5Htfhw4fPcJtPPfVU2nHHHXMoGOuuuOKKeRKrH3PTTTelZs2apS233LLa8nHjxqXDDz88jzWee0sttVSuDH3mmWfm236t2Ss4tifOxz77sV7BIZ6jsY1LL710HuNaa62VLr300pn2Ph49enTu2Rv7MMaw7bbbprfeemuG+4nt2WWXXVKbNm3y82mdddZJ//jHP6qt89prr6UePXqktm3b5tvacMMN07///e/8vI3rDxgwIPeijf1XDGxjv0Qbiqi6jS9njj/++NzbtqroaxttE37729+muRGPYQSbxX1wxx13/OhzMMYaz6XYH/G4de/efYb3gqJYHoFp1edgzbHX5ntMPO+ibcScvO8BAFSl0hYAmO8ioIgg8P77708DBw5M6623XrrzzjvT0UcfncOOs88+e5bXjQmM/vrXv+ZgLGagD9F2oV+/fjnYO/3009PEiRPTv/71r1zRF9WWEc4VRXAS622yySY5JL7nnntyaBph2y9+8YsfHXtc/8svv5xheYQ+EeZUtd9+++VqutNOOy3ddtttORCKMCzGHkFRjPWKK67IgU6EfjXDxQjiIpA65phj0ueff57OOeectN1226Xnnnsu31+IQ6t33nnn1LVr1xyWRZgdwWfcfoRoEZyGF198MYdmESBFQDh16tS8foSCNUWvzVGjRqXevXunbt265fuIgGpORWAYwV88tvG4RNgYYVaMMYK3EI9zhGmxfccee2zed8OGDZvhMPfY7uK4f//736fFF188B3TRM/XHPProoznwq3l4fhyWHpO8RZ/bqAiN6s8IXiOE3GCDDWptv86pzz77LP3sZz8rTcYVtx2BYezP7777LgemVcXzK8YXz6Nvv/02nXHGGemAAw7IIWtRhKkRpkeP2d/85jf5i4DY3pgYLM6HCCA322yz1L59+7yv4zGJMDbCx06dOlULRuNxiMd2yJAh1dqcRDgf9x3LL7744lK/2wgn43V/7bXXzvF+iMckHudDDz00h6TRSiAmOIsAOHrCzsqf//zn/FqLgDpOEcbHY1S1fUP49NNP83MwHrPi9l500UWl11ZVtfUeE8+veL+LfR/PVQCAOVYAAPiJDjvssCgjK52/6aab8vmTTz652no9evQoNGrUqPDWW2+VlsV6cf1w5JFHFho3blwYMWJE6fJx48YVFl988cKgQYOq3dann35aWGyxxaot79evX769k046qdq666+/fqFr164/uh1bbbVVvv7MTkOGDCmtd/zxx+dlgwcPLi2bOnVqoUOHDnn7TjvttNLyr7/+urDIIovksRXdf//9+frt27cvfPfdd6Xlo0ePzsv/8Y9/5PPTp08vrLrqqoUdd9wx/79o4sSJhRVXXLGw/fbbl5bttddehYUXXrjw/vvvl5a98sorhYUWWqjaY/Pcc8/l84ceemi1be/du3deHttWNHz48Lzs3XffLS3r1KlTXjZmzJjSss8//7zQvHnz/PgV/epXv8r74tlnny0tGzt2bKFt27bVbvPGG2/M55988snC3Ir9ve+++86wPJ4XxefUzNTGfo3tifOxz2qquV8HDhxYWHbZZQtffvlltfV69eqVxx7jqPo8WWONNQqTJk0qrRfPj1j+4osvlp57Me54bOL5VnNbi7bddttCly5dCj/88EPhmWeeyc/fli1bVnue/+xnP8uvvwkTJsxy//3rX//K6x599NGFb7/9trDBBhvkx/Xll1+e5XVmtk+aNWtW7b3g+eefz8vPO++8WT4H47kW19t1112rbdsf/vCHvF7V19nhhx+elz3xxBOlZXH92MdVb7M232MeffTRvP4111wzx/sGACBojwAAzHe333577kP561//utryaJcQeU1UFVYVy6LiMA7ljgrQqHirWkH4zTffpP333z9XwBZPcftR6RbVvDVFpWVVccjzO++8M0djj4q6uM+ap5rVj8WK1aIYTxxqHtsSFZNVKxajNcTM7r9v3765wrAoqlejUjL2X4iK2zfffDNXxEa1aHHbo/VEHCI/ZsyYfKh3VP5FJXNUTC6//PKl24sKyagIrKp42zUfm5lt36xE9Wrs06KoFK25jXGY+6abbpqrrIuiCjmqNKuK/ROiInTKlClpbsQ+iVYANcVtRhXqxx9/PNPr1cZ+nVPx/IhJvWICr/h/1ed03GZU0tZs4xAtC6INRFFx3xf3d1SCvvvuu/kxLO7PomILh6+++ipXF6+yyir5cYmK46g6jW0u3nZs62OPPZZff9F2YFbi9RWVrtHbtkuXLrlNSLymZ9bndnaiqjyqU4uinUO0FJndazWqWqOi9le/+lW19hQze/7Gcz0qmotV08Xnas3nYG2+xxSfnzOr3gcAmB3tEQCA+e7999/PfTGrBpKheJh1XF5VHHI9fvz4fDhyBCdVRbgWZjWRT4Q8VUWfzghmagYnMbnSnIhDqCNMmhNVg7wQvVHj/qM3a83lEQ7WtOqqq1Y7HyFUhGrFw9SL2141xK4pQr7oUfv999/PcHshwtRiUFvc93GofdWwrLjenKq53TPbx3E/EQ7WFNtXVfRLjUPiTzzxxHwY+dZbb51D0ghUa7ZSmJmZ9QqN9gGxz6KfchyeHofQR0AevXdra7/OqWglEAFhBKZxmploGTG7/V0MAov7++23384/Z3X4fRyaH/s39tWNN944w+XFtgI1Xzez87vf/S63k4j7ji8Aqgaj8/N5VFPxvaPmYxJjrxngx7oRutZU87lem+8xxedn1YAZAGBOCG0BgLKLPptR/fjPf/4z9ezZM1dkFhUnDYqek9Gns6YmTar/ObMgZ5qf2X3N6v7nZSKi4rZHRWPVitWqYiKkCBcXpPm5jRFmRf/Zxx9/PE/YFNWeMUFX9AiNZbF9sxJ9T2cWlMVzKCofI6C866678v6LPqXRPzX62NbGfp1VKFdzcqrifccEdrMKjaPi9Kfu7x9++CFX9EZ/5ejRW/X1EtXE0f82wsuq464ZqM9KbEOMPb5ciNuK121UtNb8wmVBPo9+itp8jyk+P2t+kQMA8GOEtgDAfBeTGsVhzOPGjatWbRsz1xcvryrCoqiOjCrLnXbaKd17772l6xUrQpdaaqk5roCtK4oVflXDqpjkqxjaFbc9Kv1mt+1R9ReTK9W8vfD6669XOx/7PkKqqJCsWnFYc72fKu4ntqWmmS0LEfrFKSZnu/LKK/Mh7FdffXW1FhQ1rb766rktwMxEm4mY4CpOUbka7QDitiO0rY39WqzyjCraqmpWlcdtxnM7wtz59Xwubs9LL72U93tU8EYVbNXq7nisY8zRVuCss876SfcXrUzisYn7iPA5JuSLEDcqyqOquTYV3zviMSlWThcrmGsG+LHunDx2tfkeU3x+Vp3MDQBgTuhpCwDMdxHcRCgVFXhVxeHvUdkXwVlNEVTG4eYx4330+4zD0kP0+Yxw7a9//etMe55GWFNXRVuICLaLouL0k08+Ke2fOLQ/AqWYoT7aR8xq26PyL/bTTTfdlP73v/+VLo99GZWrVRVv+9xzz622/Jxzzpmv2xbjif6oUUFdFH1Vr7jiimrrRdBWs7KyWP36Y5Wu0X4hgsqq68XzLlobVBVhXLTrKK5XG/s1nqNRTRn9cKu64IILqp2P24x2EFEFG2Of1X3PjegrG9t47LHHps6dO+ftisA2etVGm4motI0xx5cil112WX6Ozev9HnfccbmNSTxfIqiN7YmQPW47ejJXreqtDRGqNm3aNJ133nnVnjcze/7G+1BUa//3v/+ttp01n4O1+R7z9NNP5zB7rbXWmufbAAAaJpW2AMB8F6Fr9+7dc8ATh1Cvu+66+TD1m2++OU8YVLOfalFUWsY6EbZEABRhWYQpERIdeOCBuVqyV69euVoxQrTbbrstt1aoGQ7/FBH4xWRoMxNVhfNTtIHYfPPN80RTn332WQ6eoup40KBB+fLoPTts2LActEboE+u1b98+ffTRR3lypNg30VIgRM/SmPwr2gJEdenUqVNzsBXXe+GFF6oFonEYe4SJsa3dunXLlc2zqoCdV9HzNPbj9ttvn6s7o1dwbEv0MY3wtnhYfoSIMZa99947Py8ixL744ovztv1Y1eaee+6Z/vKXv6QHH3ww7bDDDnlZXL9Dhw75+RPPu2hzEFXfTz75ZG65UFv7NURV8GmnnZZ/xqR0EeDGJF01xTpxP9FvNR7rmMAr9klMQBZjjf/PiZjc6o9//GO65JJLqvXBjedV9GeNEDkmx4rnWDj//PPz/yPkjfuNStV43kW4/uGHH6bnn3/+R6tGo6XECSecUG0iuwiHoxVFBKpHHXVUngSutsRrP+7j1FNPzS0e4jkSE7HFRGg1WxDEczBaHkT1/m9+85v8HIwq5KjArfrY1eZ7TExyFu+HetoCAHOtAADwEx122GFR8lZt2bhx4wpHHHFEYbnllis0bdq0sOqqqxbOPPPMwvTp06utF9eL61d18803F5o0aVLYb7/9CtOmTcvL7r///sKOO+5YWGyxxQoLL7xwYeWVVy7079+/8NRTT5Wu169fv0LLli1nGN/xxx8/w/hmZquttsrrzepU8/a++OKLatef1f3H7a611lql87Etcf2rrrqqcOyxxxaWWmqpwiKLLFLYddddC++///4M13/22WcL++yzT6Fdu3aF5s2bFzp16lTo2bNn4d5776223oMPPljo2rVroVmzZoWVVlqpcOGFF85027///vvCr3/963x7Md7dd9+98MEHH+T1Yv2i4cOH52XvvvtuaVncd4xzZtsYp5rj3mKLLfKYO3ToUDj11FML5557br7NTz/9NK/zzDPPFPbff//C8ssvn9eLfbHbbrtVe1xnZ5111ikMHDiwdH7SpEmFo48+urDuuusWWrdunbcv/n/BBRfU+n6dOHFiHks8R+O+47Y+//zzGfZr+Oyzz/LzvmPHjvn1scwyyxS23XbbwkUXXTTD8+Taa68tLZs6dWrh4osvnuG5Ga+X7t2753EWtzv2zXnnnVftft9+++1C37598/3F/bZv3z7v7+uuu26O9nfss1n56quvZvr8nZmZve5DPAbxOprdczDeE0488cTCsssum183W2+9deGll16a4brhhRdeyM/LeM+Ibf3LX/5SuOSSS2a4zdp4j3n11VfzsnvuuWeO9gkAQFWN4p+5j3oBAGDuRaV1TI4VbQnmx6RxUUl52GGH5arIxRdfPC0oUW0aVbgL6k/pqAKOitqoQo6q2KKoGh08eHCevG1mk2hR3ud6VFtHiwSVtgDA3NLTFgCAWlHsS1wUfVYjZI1D9OdHYBtiwrJouRCH/tc3MWFc9M7dZ599cjh7/PHH58A22jvsscceuQd0TCj3hz/8QWBbYeK5Hi04Tj75ZIEtADBP9LQFAKBWxERhMUHVGmuskXunRqXod999l/70pz/Nt/uIAHNmE3rVZdGfdvjw4bn/avSkLYrJ1KIX7cCBA1PHjh3LOkZmr127djOd5A4AYE4JbQEAqBUxSdR1112Xw8eoNoxJniK43XLLLcs9tIoTbRZiQrULL7ww3XDDDWnKlCmly3bcccd0yCGH5Im3mjTx5zsAQEOgpy0AAJTJV199lS6//PIc1r7++uul5UsuuWSuqI3K2pVWWqmsYwQAYMHzVT0AACxAUTPx+OOP56B29OjR6Ycffihd1r179zRkyJC09957p2bNmpV1nAAAlI/QFgAAFoDo5ztq1Kgc1r744oul5W3atEn9+/dPgwcPTquvvnpZxwgAQGUQ2gIAQC16+umn09ChQ9OVV16ZJkyYUFrerVu33Ku2R48eaZFFFinrGAEAqCxCWwAAmM8inL366qtzVe1TTz1VWt66devUt2/f3AKhS5cuZR0jAACVS2gLAADzSbQ9iKrakSNH5nYIRV27ds1Vtb169UqtWrUq6xgBAKh8QlsAAPgJYiKxa6+9Noe1jzzySGl5ixYtUu/evXNV7YYbbljWMQIAULcIbQEAYB688cYbOagdMWJE+uqrr0rL11577VxV26dPn7TYYouVdYwAANRNQlsAAJhDkydPTjfddFMOa++7777S8ubNm6eePXvmsHbTTTdNjRo1Kus4AQCo24S2AADwI95999108cUXp0suuSR9/vnnpeWdO3fOQW1MLtauXbuyjhEAgPpDaAsAQIPy/fffp4MOOihNnTo1XXHFFalZs2YzXS8uv+2229KFF16Y7rzzzlQoFPLypk2bpr333juHtVtvvbWqWgAA5rtGheJfnwAAUM9NmzYt/fznP0833nhjPn/11Ven/fbbr9o6H374YRo2bFg+ffTRR6XlK6ywQp5UbMCAAWnppZde4GMHAKDhENoCANAgxJ+9hx9+eDr33HNLy7p37557006fPj3ddddduar2lltuyedD48aN0x577JGrarfffvt8HgAAapvQFgCABuGss85KRx555AzLI8iNycXee++90rL27dunQYMGpYEDB6YOHTos4JECANDQCW0BAKj3Ro8ePUMbhJqiN+1OO+2Uq2p32WWX1KSJ6R8AACgPoS0AAPXamDFjcmuDyZMnzzKsPeqoo9Khhx6a+9YCAEC5acoFAEC99corr6Rdd911loFtiBqGLl26CGwBAKgYKm0BAKiXxo4dm3vTTpo06UfX7datW3rkkUcWyLgAAODHaNQFUAbxfdnEiRPLPQyAeu2FF16Yo8A2PProo3n9lVdeudbHBVAXtWjRIreTYcHweaF2eB5Tl6i0BSiDCRMmpFatWpV7GAAAMEfGjx+fWrZsWe5hNBg+L9QOz2PqEj1tAQAAAAAqiPYIAGV2/vnnp3XXXbfcw4AG7a677konnXRS+vOf/5x22GGHcg8HGjSvR6gczz//fDrssMPKPYwG77PPPlMd+hOrlpdeeulyDwPmmtAWoMwisN1ss83KPQxo0N577738s3Pnzl6PUGZejwDVRWArtIWGR3sEAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAYIFYYYUV0jnnnFPuYUDFE9oCAAAA1KKxY8emSZMmpbqgf//+qVGjRvnUrFmztMoqq6STTjopTZ06tdxDgwZFaAsAAABQS954443Uvn371KFDh3TGGWek8ePHp0q30047pU8++SS9+eab6cgjj0wnnHBCOvPMM8s9LGhQhLYAAAAAteS1117LVbZffvllOuaYY9KKK65Y8eFt8+bN0zLLLJM6deqUfvGLX6Ttttsu/fvf/05ff/116tu3b2rTpk1q0aJF2nnnnXOwW9X111+f1lprrXwb0Qrh73//e9m2A+oyoS0AAADAAlKXwtuiRRZZJE2ePDm3TnjqqadygPvYY4+lQqGQdtlllzRlypS83tNPP5169uyZevXqlV588cVcofunP/0pjRgxotybAHVOk3IPAAAAAKh806ZNK/cQ6qTp06fPNryNtgPRguCwww5LrVu3TpUkQtl777033Xnnnbmq9qabbkqPPPJI6tatW778iiuuSB07dszLf/7zn6ezzjorbbvttjmoDZ07d06vvPJK3sYIfIE5J7QFAAAAZuvkk0/OVaGzCiCZdxHeHnvssTnojFYD0VKg3G699dbUqlWrXEEbj3nv3r3TPvvsk5dvsskmpfXatWuXVltttfTqq6/m8/Fzzz33rHZbm222WTrnnHNy6L/QQgst8G2Bukp7BAAAAGC23nrrLYFtLZs6dWoaO3ZsqgTdu3dPzz33XA6Rv//++3TZZZelRo0alXtY0KCotAUAAABm65JLLsnVoBEsMnfGjBmTjj766FleHmFosaVA165dUyVo2bJlWmWVVaotW2ONNfLj/8QTT5TaI0TI/Prrr6c111yztE60T6gqzkebBFW2MHeEtgAAAMBsReC2wQYblHsYddKnn346y7A2+sBGWLv22munSrfqqqvm1geDBg1KQ4cOzf13f//736f27duXWiJEb96NNtoo/eUvf0n77bdfnqzsn//8Z7rgggvKPXyoc7RHAAAAAFhAIqzt2bNneuGFF9I111xTJwLbouHDh+dq4N122y1tuummeaKy22+/PTVt2jRfHsH+6NGj09VXX523689//nM66aSTTEIG80ClLQAAAEAtWWaZZepUZe2IESNmeVmbNm3S5ZdfPtvr77vvvvk0K++9995PGh80FEJbAAAAgFqy8cYbpwcffDAttdRSafXVVy/3cIA6QmgLAAAAUIu23HLLcg8BqGP0tAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACiK0BQAAAACoIEJbAAAAAIAKIrQFAAAAAKggQlsAAAAAgAoitAUAAAAAqCBCWwAAAACACtKk3AMAaOi+//77NGHChHIPAxq0SZMmlX56PUJ5eT1CZf2dSvl5L/xp7D/qqkaFQqFQ7kEANMQ/HFq1alXuYQAAwBwZP358atmyZbmH0WD4vFA7PI+pS7RHAAAAAACoICptAcog3nonTpyYPvjggzR27NhyDwf4v0OxmzdvXu5hAF6PUFHatWuXOnbsmFq0aJEaNWpU7uE0uM8LdcWjjz6adthhh/z/Qw89NJ144olpkUUWSZXG85i6RGgLAAAAwE/6sm2XXXZJ9913Xz6/5pprpiuuuCKtt9565R4a1FnaIwAAAAAwz+LoiLvvvjudeeaZqVmzZumVV15JG2+8cTr99NPTtGnTyj08qJNU2gIAAAAwX7zwwgvpgAMOSC+99FI+v8UWW6TLL788rbDCCuUeGtQpKm0BAAAAmC/WWWed9OSTT6Yjjzwy94996KGH8rLLLrss9+oF5oxKWwAAAADmu/vvvz/169cvT8Ac9t133zR06NA8wR0weyptAQAAAJjvunfvntsl9O7dO5+//vrrU5cuXdKdd95Z7qFBxRPaAgAAAFArFl988XTFFVekq666Kv//k08+STvttFP61a9+lSZOnFju4UHF0h4BAAAAgFr34Ycf5nYJ9913Xz6/+uqrp1GjRqWuXbuWe2hQcVTaAgAAAFDrOnTokO6+++509tlnp+bNm6fXXnst/exnP0unnHJKmjp1armHBxVFpS0AAAAAC9RLL72U+vTpk55//vl8vlu3bmnkyJFppZVWKvfQoCKotAUAAABggVp77bXTE088kX73u9+lRo0apUcffTStu+666dJLL03qC0GlLQAAAABlNGbMmNS3b9/0/vvv5/N77bVXuuiii9KSSy5Z7qFB2ai0BYB59Omnn+ZZb+MQrujJ1bFjx7T77rune++9t9xDgwbH6xEqxwcffJAOOuigtNxyy6VmzZqlTp06pd/85jdp7Nix5R4aUKG23HLL3CbhwAMPzOdvuumm1KVLl3T77beXe2hQNiptAWAevPfee2mzzTZLiy++eDrppJPyH5VTpkxJd955Z64KiEkVgAXD6xEqxzvvvJM23XTT1Llz53TyySenFVdcMb388svp6KOPTpMnT06PP/54atu2bbmHCVSwa6+9Nh1yyCHpq6++yufj/3/7299Sy5Ytyz00WKCEtgAwD3bZZZf0wgsvpNdff32GPyC/+eabHB4BC4bXI1SOnXfeOU8u9MYbb6RFFlmkWjX8yiuvnA9//te//lXWMQKV7+OPP04DBgxId911Vz6/6qqrplGjRqWNN9643EODBUZ7BACYS/Gt/x133JEOO+ywmX7jLyCCBcfrESrr9RgV7oceemi1wDYss8wy6YADDkjXXHONCYaAHxXtVf7zn/+kc889Ny288MLpzTffTN26dctH1EydOrXcw4MFQmgLAHPprbfeyh84V1999XIPBRo8r0eoHBGqxOtxjTXWmOnlsfzrr79OX3zxxQIfG1D3NG7cOPerf+aZZ9L666+fpk2blo4//vi0+eab5/cbqO+EtgAwl1QIQeXweoTK43UJzE/xhU/0w/7DH/6Qg9wnnngirbfeerlvvfcb6jOhLQDMpeip1ahRI5MbQQXweoTKscoqq+TX46uvvjrTy2N5mzZt0pJLLrnAxwbUbc2aNUunnHJKGjNmTJ7gcOLEiWnIkCFpjz32SJ999lm5hwe1wkRkADCPE628+OKLJj6CCuD1CJVjxx13TC+//HI+dNlEZEBt+O6779Lhhx+ehg8fns/HF0GXXHJJ2n333cs9NJivhLYAMA/eeeedtNlmm6W2bdvmCRHWWWedPCnC3XffnT+MzqrKCJj/vB6hchQnC4rDmU8++eRcERch7tFHH50mTZqUD3GO1yrAT3XDDTekwYMHp7Fjx+bzgwYNSmeddVZq1apVuYcG84XQFgDm0SeffJIP07r11lvz/+Nb/q5du6Yjjjgibb311uUeHjQoXo9QOd5///08WdAdd9yRvvrqq7TMMsukvfbaKy9r165duYcH1CPxO3/gwIHpP//5Tz4fFf0jR45Mm266abmHBj+Z0BYAAACAOilirQsvvDAdeeSR6fvvv8+TlR133HHpT3/6U2ratGm5hwfzTGgLAAAAQJ0Wve379OmTnnrqqXx+o402ylW3q622WrmHBvOk8bxdDQAAAAAqQ4Szjz76aK6wjWrbJ598Mq2//vq5v716ReoilbYAAAAA1BuPPfZYOvDAA9Pbb7+dz++8887p0ksvzT22oa5QaQsAAABAvRETkT333HPp4IMPzudjorK111473XjjjeUeGswxlbYAAAAA1Ev//ve/c3j7xRdf5PMDBgxI//jHP1Lr1q3LPTSYLaEtAAAAAPXWZ599loPbW2+9NZ9fccUV8yRlm222WbmHBrOkPQIAAAAA9dbSSy+dK26HDh2aWrRokd5999205ZZbpuOOOy5Nnjy53MODmVJpCwAAAECD8Oabb+ZJyp544ol8foMNNkijRo1Ka6yxRrmHBtWotAUAAACgQVh11VXTww8/nE444YS00EILpWeeeSYHt+edd15S10glUWkLAAAAQIPz3//+N/Xp0ydX34YddtghDR8+PC233HLlHhqotAUAAACg4dl4443Ts88+mw455JB8/q677kpdunRJ1113XbmHBiptAQAAAGjYbrvttjRw4MD02Wef5fN9+/ZN5557blpsscXKPTQaKKEtAAAAAA3eF198kQYNGpRuvvnmfL5Tp07p8ssvT1tuuWW5h0YDpD0CAAAAAA3ekksumW688cY0bNiw1LJly/T++++nrbfeOh1zzDFp0qRJ5R4eDYxKWwAAAACo4u23384tEh599NF8ft11101XXHFFWmuttco9NBoIlbYAAAAAUMXKK6+cHnzwwXTyySenJk2apOeffz517do1nXPOOWn69OnlHh4NgEpbAAAAAJiFp556KvXp0ye9/vrr+fy2226bRowYkTp06FDuoVGPqbQFAAAAgFnYcMMN0zPPPJMOO+ywfP7ee+9NXbp0SVdffXW5h0Y9ptIWAAAAAObAHXfckQYMGJA+/fTTfL53797p/PPPT4svvni5h0Y9I7QFAAAAgDn05ZdfpiFDhqQbbrghn+/YsWO67LLLUvfu3cs9NOoR7REAAAAAYA4tscQS6brrrst9bVu3bp0++OCD3Of2qKOOSj/88EO5h0c9odIWAAAAAObBu+++m/r27ZsefvjhfD563Y4aNSqts8465R4adZxKWwAAAACYByuuuGJ64IEH0qmnnpqaNm2aXnzxxbTRRhulv/3tb2n69OnlHh51mEpbAAAAAPiJnn322XTAAQekV199NZ/feuutc6/b5ZdfvtxDow5SaQsAAAAAP9H666+fnn766fSb3/wmn48K3GiTcMUVVyQ1k8wtlbYAAAAAMB/dfffdqX///unjjz/O53v27Jn+9a9/pbZt25Z7aNQRKm0BAAAAYD7afvvtc3/bCGvD6NGjc9XtPffcU+6hUUcIbQEAAABgPouq2quvvjqNHDkyLbrooumjjz7KYe7hhx+evv/++3IPjwqnPQIAAAAA1KL3338/9evXLz344IP5/Jprrpl73a633nrlHhoVSqUtAAAAANSiTp06pXvvvTedeeaZqVmzZumVV15JG2+8cTr99NPTtGnTZlg/aiwfe+yxNH78+LKMl/IT2gIAAABALVtooYXSUUcdlZ588sm09tprpylTpqTf//73qXv37um9996rtu6JJ56YunXrlvbdd98c4NLwaI8AAAAAAAvQDz/8kI477rh01lln5fOtW7dO5513Xurbt2+usN1iiy3S9OnT82W333572nnnncs8YhY0oS0AAAAAlMF9992Xe91++OGH+fyee+6Znn/++WqVt126dEnPPvtsrtSl4RDaAgAAAECZfP311+mwww5LV1111SzXGTFiRA53aTiEtgAAAABQZtHv9u9///tML+vYsWN644030sILL7zAx0V5mIgMAAAAAMros88+S5dffvksL//ggw9yz1saDpW2AAAAAFAmEc3tscce6dZbb53teosvvnh6++23U9u2bRfY2CgflbYAAAAAUCavv/76jwa24ZtvvknHHHPMAhkT5afSFgAAAADKZOrUqenQQw9NY8aMSe+8806aMmXKbNd///330/LLL7/Axkd5CG0BAAAAoEIC3AhlY9KxOL355pv55wsvvJD73jZu3Dj3t11uueXKPVRqmdAWAAAAoIJEVDNx4sRyD4MK8/3336dGjRqlhRdeuNxD4Sdq2bLlj67T5KfeCQAAAADzTwS2rVq1KvcwgFoyJzW0JiIDAAAAAKggKm0BAAAAKlT0MZ2TQ6mB+kVoCwAAAFChIrAV2kLDoz0CAAAAAEAFEdoCAAAAAFQQoS0AAAAAQAUR2gIAAAAAVBChLQAAAABABRHaAgAAAABUEKEtAAAAAEAFEdoCAAAAAFQQoS0AAAAAQAUR2gIAAAAAVBChLQAAAABABRHaAgAAAECZrbDCCql///4L/H5HjBiRGjVqlN57770Fft/MmtAWAAAAAH4k1CyeFl544dS5c+f0y1/+Mn322WeprvjrX/+abrrppnIPgznUqFAoFOZ0ZQAAAABq14QJE1KrVq3y/8ePH59atmxZ7iGlhh7aDhgwIJ100klpxRVXTD/88EN6+OGH08iRI1OnTp3SSy+9lFq0aPGT72fSpEmpcePGqWnTpqk2xHOqR48eeXuqmjZtWpoyZUpq3rx5DqWpDE3KPQAAAAAAqHQ777xz2nDDDfP/Dz744NSuXbt01llnpZtvvjntv//+Mw3f5yZwj9C0HBZaaKF8orJojwAAAAAAc2mbbbbJP999993cizYqWd9+++20yy67pNatW6cDDjigFN4eeeSRqWPHjjmYXW211dLf/va3VPPg95n1tP3mm2/S4YcfXrruKquskk4//fQ0ffr0auvF+X/84x+pS5cuuX3DkksumXbaaaf01FNP5cujgjbGcdlll5XaPBTva1Y9bS+44IK01lpr5ftdbrnl0mGHHZbHU9XWW2+d1l577fTKK6+k7t2754rj9u3bpzPOOGO+7eeGSqUtAAAAAMylCGhDVNyGqVOnph133DFtvvnmOZSNADOC2T322CPdf//9aeDAgWm99dZLd955Zzr66KPTRx99lM4+++xZ3v7EiRPTVlttldcbMmRIWn755dOjjz6ajj322PTJJ5+kc845p7Ru3HaEr1ENHFXAMZaHHnooPf7447k6OFo5xPKNN944DR48OF9n5ZVXnuV9n3DCCenEE09M2223XfrFL36RXn/99fSvf/0rPfnkk+mRRx6p1sLh66+/zgHxPvvsk3r27Jmuu+66dMwxx+QAOcbDvBHaAgAAAMCP+Pbbb9OXX36Ze9pGcBk9bhdZZJG02267pcceeyz3pP35z3+eTj311NJ1onXCfffdl04++eR03HHH5WVRsRrrRWVsTGY2q/A0Wi9EMPzss8+mVVddNS+L8DaqXs8888xS9W4EwhHY/vrXv863WRSXF6t5+/Tpkw455JC00kor5f/PzhdffJG3YYcddkj/+c9/cp/dsPrqq+fxjho1Kvf4Lfr444/T5Zdfng488MBSgBy9fi+55BKh7U+gPQIAAAAA/IioOo22AxGU9urVK7dDuPHGG3M7gKKoSq3q9ttvz/1iI1CtqhioRig6K9dee23aYostUps2bXJYXDzFOGLysDFjxuT1rr/++tze4Pjjj5/hNuZlYrF77rknTZ48ObdlKAa2YdCgQWnRRRdNt912W7X1Yz9UDYKbNWuWK3rfeeedub5v/n8qbQEAAADgR5x//vmpc+fOqUmTJmnppZfOvWmrhpqxvEOHDtWu8/777+fK2OhxW9Uaa6xRunxW3nzzzfTCCy/koHhmPv/88/wzqnHjPtq2bfuTtq/qmENsX1URxkalbs0xxzbXDIcjaI6xM++EtgAAAADwI6J6NPrDzkpM2FU1xP2pYnKx7bffPv3ud7+b6eURIFeCqCSemZoTrTF3hLYAAAAAUAuit2u0Gxg3bly1atvXXnutdPmsRK/b8ePH53YIsxPrxeRmX3311Wyrbee0VUJxTDH5WFTWFkXLhHffffdHx8P8oactAAAAANSCXXbZJfef/ec//1lt+dlnn51D1NlN1NWzZ888wVkEsjV98803aerUqfn/++67b65qPfHEE2db7dqyZct8vR8ToWy0Qjj33HOrXT8mFovJ2HbdddcfvQ1+OpW2AAAAAFALdt9999S9e/d03HHHpffeey+tu+666a677ko333xznugrqmRn5eijj07//ve/02677Zb69++funbtmiZMmJBefPHFdN111+XbW2KJJfLtH3jggTlkjT64O+20U26t8NBDD+XLfvnLX+bbi+tH1e9ZZ52Ve+CuuOKKaZNNNpnhfqOH7rHHHptD4LitPfbYI1fdXnDBBWmjjTaqNukYtUdoCwAAAAC1IHrcRvD65z//OV1zzTVp+PDhaYUVVkhnnnlmOvLII2d73RYtWqQHH3ww/fWvf03XXnttuvzyy9Oiiy6ae9lGoLrYYouV1o3bXWeddXI1bIS9cVn03+3WrVtpnQhrBw8enP74xz+m77//PvXr12+moW044YQTcngbFcJHHHFEbrsQ142xNG3adD7uIWalUUFXYAAAAICKEdWUrVq1yv+PnqZxWDv1X8eOHdOOO+6Yhg0bVu6hUAH0tAUAAACAMpoyZUoaO3ZsbncAQXsEAAAAACiTmGjs6quvzi0Ltt1223IPhwohtAUAAACAMjnttNPSW2+9lU455ZS0/fbbl3s4VAg9bQEAAAAqiJ62gJ62AAAAAAAVRGgLAAAAAFBBhLYAAAAA1EtnnHFGWn311dP06dNTXdS/f/+0wgorpIZm7NixuS3I7bffnhoqoS0AAAAA9c53332XTj/99HTMMcekxo0bl8LAM888M2255ZZpySWXTIsvvnj62c9+lq655poZrv/AAw+kRo0azfT0+OOPz7D+5MmT01//+tccEi+88MJp6aWXTrvuumv68MMPU30UgeoJJ5xQK7fdrl27dPDBB6c//elPqaFqUu4BAAAAAMD8dumll6apU6em/fffv7TsscceS8cdd1zaZZdd0h//+MfUpEmTdP3116devXqlV155JZ144okz3M6vf/3rtNFGG1Vbtsoqq1Q7P2XKlBzQPvroo2nQoEFpnXXWSV9//XV64okn0rfffps6dOiQ6mNoe/7559dacHvIIYekc889N913331pm222SQ2N0BYAAACAemf48OFpjz32yFWvRWuttVZ68803U6dOnUrLDj300LTddtvlqtzf/e53+bD8qrbYYovUo0eP2d7X2WefnR588MH08MMPp4033rgWtqZhiDYWUbG88MILpzXWWCOtvfbaacSIEQ0ytNUeAQAAAIB65d13300vvPBCDmOrWnHFFasFtiHaHey1115p0qRJ6Z133pnp7Y0bNy5X7c4qaPzHP/6R9t577xzYxnoTJ06c6zHfdNNNOaSMwDJ+3njjjXN0vd122y2ttNJKM71s0003TRtuuGG1ZaNGjUpdu3ZNiyyySGrbtm2uMv7ggw9muG5UCUdFcps2bXKQHdXDsZ3FXrtRZRuqto0omjBhQjryyCNTx44dU/PmzdNqq62W/va3v6VCoVDtPuI6v/zlL9MVV1yRA/VY94477ihdvv3226dbbrllhus1BEJbAAAAAOqVaFMQNthggzla/9NPP80/l1hiiRkuGzBgQFp00UVzmNq9e/f01FNPVbs82ip8/PHHOdQcPHhwDjiLIef9998/R/d/1113pX333TeHmKeeemoOkeN+a97XzOy33345pH7yySerLX///fdz790IZYtOOeWU1Ldv37Tqqqums846Kx1++OHp3nvvzT1+v/nmm9J6d999d14W2/ab3/wm/f3vf8/bfuutt+bLhwwZkgPVMHLkyNIpRMAaFc5RfbzTTjvl+4nQ9uijj06//e1vZxh/tD844ogj8nZEKFx14rWuXbvmcb388supodEeAQAAAIB65bXXXitV1v6Yr776Kg0bNiy3QVh22WVLy5s1a5aD1Kg2jTA3AsyoFo31IhRef/3183rRbiFESBmVq0OHDs3nY1KyCC0jTI0Ad3ZisrSYuCzaKyy22GJ52VZbbZV22GGHGSqDa9pzzz1zhWpMpla19+7o0aNzCNyzZ89SiHv88cenk08+Of3hD38orbfPPvvkbbngggvy8mnTpuVQNvbFc889lydrKypWvEYFb+fOnXO426dPn2rj+fe//52D2Lif6B8cDjvssPTzn/88h7JRWbvyyiuX1n/99dfTiy++mNZcc80Ztm2l/6sgjn0f1ccNiUpbAAAAAOqVsWPH5knGWrVqNdv1orXBAQcckKs5zzvvvGqXdevWLV133XXpoIMOypWjv//973PlagShxx57bGm98ePHl1ooRNVqtA6I0z333JNDzjPOOGO2Y/jkk09yONqvX79SYBuiknVmQWZNUQW8884755C2ahuBCHF/9rOfpeWXXz6fv+GGG/L2Roj75Zdflk7LLLNMrrwtVgU/++yzuXI3qnCrBrahaguE2U1QttBCC+UJ3KqKdgkxvv/85z/Vlkc4PavtbNOmTf4Z42xoVNoCAAAA0CD96le/yj1UL7/88rTuuuv+6PqrrLJKrmyNADQqUiOcjN6wYbPNNss9XIsiLN18881LrRpigq2o6q1qySWXzBWwIYLTmqKtwDPPPPOj44rWAtET97HHHsth89tvv52efvrpdM4555TWiYrgCE1ndj+hadOm+WdcN8xrZWtsz3LLLZdat25dbXlMLFa8vKrZVUMX/i+EnpOwuL4R2gIAAABQr7Rr1y5PCBbVrzXDw6ITTzwxtwQ47bTT0oEHHjjHtx3BbASwMdlWVLlGQBmivUFNSy21VK5cDRHeRl/YqqKidX7YfffdU4sWLXK1bYS28bNx48a5JUFRVNlG+BmVrhE21/RjVcm1pRh6z8zXX389y17D9Z3QFgAAAIB6ZfXVVy+FojPrJ3v++eenE044IbcAiH6yc+Odd97Jk5IVQ84uXbrkKtWPPvpohnVjgrKopg1RyRs9YKuK1gTRj7Zqb9yqot/rnIiJz3bbbbd07bXX5om/ojVC9N4tBsoh+shG5WpUtkY/2lkp9pt96aWX0nbbbTfL9WZV/Ro9eKM1RM3AvNhn+Md69M4s1F7j/6p0GxI9bQEAAACoV2KirPDUU0/NcFkEmtFvNXrZRsA5K1988cUMy55//vk80VZMEBaVrCGCyZisLCppi8FkePXVV/Oy6E1b7M8aIWjVU4S/MeHXeuutly677LL07bfflq4fAW9MwDWnokVChMQxqVqMM85XFROORYVtVBhX7X0b4nz0AQ4bbLBBDnajtUL0+q25XtWgONRcJ/ZFtI745z//WW15TNQWQW/0351TTz/9dO7zu9Zaa6WGplGh5qMEAAAAQNnEYffFKs6Y5KoYjjF3ogI2TldeeWVp2X//+99cgRpB4Omnn17q41oUrQVWWmml/P9tttkmH7ofy6LNQQSoF110Ub5O9I6tWv0Zl22yySY5wC1OwHXuuefmFg3RHqF9+/azHWv01d11113zhFwx8Vn0vo2J0Tp06JCfA++9996Pbu8PP/yQxxkmTpyYA9zi+aJoBRGTqMU27bXXXnm8Uc164403psGDB6ejjjoqr3fnnXfmlgtRqTtgwIAcLEcg/fLLL+fLQlT1xqRm0Vpixx13zIFwr169chuGCKQfeOCBNGjQoFxhfNddd6Wbb745VzZHeFsUIe5hhx02Q8BbFI9fBNojR45MDU6EtgAAAABUhvHjx0eBXT7F/5k3Z511VqFVq1aFiRMnlpYNHz68tG9ndorLi/7xj38UNt5440Lbtm0LTZo0KSy77LKFPn36FN58882Z3t/TTz9d2G677QotW7YstG7durDnnnsW3njjjTke7/XXX19YY401Cs2bNy+sueaahRtuuKHQr1+/QqdOneb4Ng444IC8HTGO2d3P5ptvnscZp9VXX71w2GGHFV5//fVq6z388MOF7bffPm9LrLfOOusUzjvvvNLlU6dOLfzqV78qLLnkkoVGjRrl+y0aN25c4Ygjjigst9xyhaZNmxZWXXXVwplnnlmYPn16tfuI68R9z8yrr76aL7/nnnsKDZFKWwAAAIAKotJ2/ohWA1E1e8YZZ6SBAweWezjMpcMPPzyNGTMmt0iYVf/c+kxPWwAAAADqnWiB8Lvf/S6deeaZ+ZB96o6xY8fm3rwnn3xygwxsg0pbAAAAgAqi0hZQaQsAAAAAUEGEtgAAAAAAFURoCwAAAABQQYS2AAAAAAAVRGgLAAAAAFBBhLYAAAAAABVEaAsAAAAAUEGEtgAAAAAAFURoCwAAAABQQYS2AAAAAAAVRGgLAAAAAFBBhLYAAAAAABVEaAsAAAAAUEGalHsAAAAAAMzchAkTyj0EYD5r2bLlj64jtAUAAACoUEsvvXS5hwDMZ4VC4UfXaVSYk7UAAAAAWKAaNWpU7iEAtWBO4liVtgAAAAAVaPz48eUeAlAmKm0BAAAAACpI43IPAAAAAACA/5/QFgAAAACggghtAQAAAAAqiNAWAAAAAKCCCG0BAAAAACqI0BYAAAAAoIIIbQEAAAAAKojQFgAAAACggghtAQAAAAAqiNAWAAAAAKCCCG0BAAAAACqI0BYAAAAAoIIIbQEAAAAAKojQFgAAAACggghtAQAAAAAqiNAWAAAAAKCCCG0BAAAAACqI0BYAAAAAoIIIbQEAAAAAKojQFgAAAACggghtgf+vvTOBtqoqA/AxJ0TFWXFWiAxFEYfAxFQyNS0xZxGclUrLgcwh0JIcgjTLBC3FksQSTQWHMs0EjUzMHNAEy9JynidU1Nv69lr7rnPPO/fe896773EffN9aV3n3nnHv/e/973///79FRERERERERKSJ0GgrIiIiIiIiIiIi0kRotBURERERERERERFpIjTaioiIiIiIiIiIiDQRGm1FREREREREREREmgiNtiIiIiIiIiIiIiJNhEZbERERERERERERkSZCo62IiIiIiIiIiIhIE6HRVkRERERERERERKSJ0GgrIq1i2rRpya677pqsuuqqyTLLLJNsvPHGyciRI5O5c+cmXZ1///vfyXe/+93k2Wef7bB7/OlPf0qWWGKJZPbs2e2+1i9+8YtwrZdffjnpCDbaaKPk+OOPL/99+OGHJ/369UsWNo899liy//77J+utt17SrVu38P8vfelLyW233daibPj9jTfeaHGNQw45JPy+00471awbfufa1Yjn5H1233338nEffvhhcvHFFyf9+/dPVlhhhWSVVVYJ/6Z833///aQjoR6rPWP80O4XZlur1/Y6Ur4bKZMLg3vuuScZOnRosuaaa4Y+GXkYPnx4xft0RHm2BeQp3e5WWmmlZNCgQclNN93UJrmiT0r/ttZaa4XxadasWbm/533SfUBn0hXlcmHQGePOlltuGe5Ti9dffz2UNWXebHLVaLJys/baaydf/vKXk0ceeaTh98rrf/n7hz/8YdKV+Oijj5Jx48Yln/vc55LVV1896Mg777xzMnPmzBbH5sl6z549c6/7y1/+MhkwYEDQZbjuF7/4xWT+/PkNaefNotO1B/pIdKpGs6jqCyLSNVlqYT+AiHQdTjvttOQHP/hBst9++yU///nPkzXWWCP55z//mUyaNCk58MADkwcffDDpyqCkfe973wtGunXWWSdpdvbcc89gnFh55ZU75X5jxoxJ3nnnnWRhQnsbOHBgssUWWyQXXHBBMFRRb7feemtQppnQpFl66aWTG264oWKi8u677wYjUSMV/SuvvDL59Kc/XfFdul6++c1vhmNOP/305LOf/Wx4hr///e/J5MmTk+9///vJsssum3QUvH/aMPyVr3wlGTx4cDJq1Kjydxj6mgmeGcN2Z8j3VlttFeSob9++SVdjwoQJwWg0ZMiQ5Mc//nGy7rrrJv/73/+Sq6++OvnCF76QvPbaa0mzsf3225cNMhjCrrjiimSfffZJZsyYEX5rjVxBr169wvuWSqXkX//6V3LWWWclu+yySzAw0Wd99atfLR87duzY5B//+Ec4PtKjR49kYdAV5VI6vp9qFtJy9eSTTyZnnnlmsuOOO4ZF02oGxkZBf7zhhhsmXQkMqeedd17QNU499dRkySWXTH72s58Fw+3tt98e+ug03/jGN5Jhw4aV/2bBLcs555wTdO4zzjgj2W677cLizJ133hkMxIuKTtdejj766KALN5pFUV8Qka6LRlsRKQRGMZRHlLyzzz67/D1eBUcccURy8803L9TnWxzBaM6ns+jdu3eysMGIA3/4wx+S7t27l7+nDX788cctjscD8Zprrqkw2k6fPj0YSfHwa9SEBW+VbbbZJvc3DLSXX355Mnr06DDxjey1117hbybFHQleOml4dzwSef9mJfvMHQlGu2Yui2o8/PDDyQknnJCMGDGi7HEZOfjgg5u2T8bomi5vDKx48rGQkjXa1pKryHLLLVe+HoYNoj+4zm9+85uwSJLut+gv//Of/zRFfXdFuZSF1091Nlm5wqsYfe9Xv/pV8q1vfatD790VZYDyYtEobcRn4Yw+7Ec/+lELo+0GG2xQ8z2feOKJ4OlJdFt6MXrfffddpHS6PFjMYsH9E5+oHxDMwlZnLm51VX1BRLo2pkcQkULg1ciEEqNtHukQ8vfeey85+eSTw+o0IV2EZOGRkiaGZeEdycRn+eWXTz7zmc8kDzzwQMVxGOIuvPDCsKrNpBYPD0Lj0yHvjz/+eDDOEWrLdVh1xyMzDQaN888/P/n2t78dJu4rrrhieIa33nor/M5z4BEB2267bTlkrVYIajbUjNV3DHG8N8/B73hStmWFn/sRFnfUUUeF9yLUjjIlzD6Sfa6i58F///vfEEJNuB2TDSZj2bLPkg2li/fHw5pJBe/cp0+f5Kqrrmpx7i233BI8ZLkX5f+1r32tTQZTPAdRmtMG20iego/xCs+UF198sfzdlClTgrc4k4LOgPdcsGBBMEzlkTa2LSwuu+yyZJNNNgkyxuQc7988I3jWgI53EJ6SgPEZD8pPfepT4Tp4ajFZzQtlxAsSr0LqkTb1+9//vuK4bNjxnDlzkj322CNZbbXVwjk8K6GoRWWvlnznhTs2sg/rKPCspc3TN+e1oby0HpdccknwYKNv2HvvvZOXXnqp4nc8X7/+9a+Htkodbr311sFLLE1MGcJiCPJOfRA6jWxiEN1tt91CHW+22WahbOqx1FJLhX4BGWmkIe3pp5+ue+xzzz2XHHnkkaGt8gy8D15tHZ2ypKvKZR6tuT5jBQZAyhqPNf5G1hgPMHZhfLnoooty70P6G54JeaRd/uUvf2lxDGMSURgcg9f5d77znRZeiX/+85/D+RzD9dJpddIQTUSZUxaf//zng7dp0RRC9foE9BfGX/QQokVoc1k5Rh5OOeWUYNyjXGOKgrx0P51BXDx56qmnCveR8Nvf/jb8xjEcyzmcW4tseoTY51x33XVBHmhLGEGzeh56DcdRZ+uvv35ohyeeeGKop44Gz9qs1zXf0R7bknILOWYBKhs9VJQi7byaTsdYSJqZONbecccdod9h4Zl5AB8WxOr1RfH69WQ3yhFjOuMT/cOrr74ark+fx+/IAFEX9In10iMUGceiXsoCH+9J3dHO6JMWRX1BRLo2Gm1FpC4Y/O69994wcSli6CJfKIoVBtIbb7wx2XTTTYN3AB4DaZ5//vkQNs7E5Nprrw2KDyGi6ck7IWRcB0UcD0mMDkx03n777fA7ng2Em6PgoXBikMMQwbNmJ97kFMXAi1ETA+7111+fHHPMMeE3JpBcOyrLGIFiXsSiYLBAAcSrkmflnTGecr+2wEQOpZWyoYx4fpTm9p6HcYWJOeH5/EY5oEAyCUobN4tCfaPgU9cooyinlHOEiRYGtc033zwosijmTOQomzQo5vXyS6J8MwEi5JnnrzdpwFDMJGDq1KllZf53v/tdMOY2EgwDyEn6Ez1oMVIz8Wby8etf/7phIeu8+7nnnhveqT3QBihPjG20W+qPiRByV+8cDPSxHvH6xHP4sMMOC5OhGCZ66aWXVpyLfNNm+J32gNECWXnllVeq3i8aBTFEcW08vdJG/3qy11r5bmQf1lF1evfddwdDCgsvReDZ+VAOGHw5n/418sEHHwTPMDx0CcvlWN6bRbBsLksmtlwDwwr1S95G+lIWQ+irkW/qlbQHsa+OIBdRRlhw4l6kdODY1shVNWgLgMGjHtyfhS0WBukXqG/aTDqlQmtZnOSytdfnmGOPPTaMOfxNnRPejJEG+WEh4aSTTgoGp6xxHSNMlDMMMZRLeryiDrlWLC+e4Sc/+Ukw3Kblld85P46PGIxpf2mQAZ4Tww1lgT7BYnERivQJMTqJsRC9hfESeUpDqD1lSFoqDE4//elPg1GorQsK6EjoPW2N7IjG2hgqXqSP5N/0CfzGMRzLO2Gwbi2M9+PHjw/vQJlhRE9fh/di8Z7jeC76OfohPu2B96bs2wL9FQbKvFB66hd9msgD0otlF5k4D50JvSHmK2eMu+++++ret2g7r8ahhx4a+nHaPvWNnCLnzzzzTOhbjjvuuFAP6DP1KCK7QJ+ATCAHRF2gk3IOfR59CjKNnkn/Vqs+io5jRGKgV1C2zBtIBUL5UkZdRV8QkcWIkohIHZ5//nm0/NJpp51W99iHHnooHHvppZdWfL/ddtuVttpqq/Lfhx12WGmJJZYoPfroo+Xv7rrrrnDuzJkzw99PPPFEOObcc8+ter9DDz201KtXr9L8+fPL37344oulFVZYoXTJJZeUv+O6G2+8cenDDz8sf3fFFVeE6z/++OMV97///vsr7nHllVeG71966aWK7/v37x/eI4+PP/64tGDBgtKxxx4b3j37jtl7pHnqqafCMTvssEPF92PGjCl179699Oqrr+Y+V9HzzjzzzNJKK61UeuGFF8rHvPfee6UNNtigdMopp5S/23DDDUvHHXdc+W/edbPNNmtRLulyfvvtt8O9xo4dWy4HrnPwwQdXPNNtt93Wov579+5dGjJkSKkW1N+wYcPCffmsuOKKpaFDh5ZuuummiuPSZXPGGWeUBg8eHL6//PLLS+uuu27po48+CuftuOOONeuG3/fcc8+qzxPPyfvEMojHrbXWWuF73rtv375BnrJtqjVQn/369Qty9corrxQ+L12vlOfqq69eOuiggyqOOf3000vLLLNM6eWXX25RnsjjsssuW1HmTz75ZHivyy67rOI6p556aqlnz56hvOGss84K17nlllvKx8R2O3ny5Nxn5J78Pm3atELv11rZy37fyD6sI+u0W7duLeqtGpTneuutF+Q8Ql0svfTS5bqZNGlSaamllirNmTOn4tyBAweW9t9//wqZWH755Sva7qhRo8J7T5w4sfzdI488Er678cYbK87NysmSSy5Zuuiii9okV7FPor4/+OCDMGbsvPPO4X0ZB7Jk+7AsXOfqq68O5fDOO++U2sKiLJdZWnv9W2+9tXzM9OnTw3cHHnhg+Tvee8011yydeOKJFXXGcXfeeWf5u9dffz30/VEnefPNN8OYT/mkoT0ut9xy5fLiuTiP8yNcl+unx3LafN44ynGUea0xsl6fgHzx91VXXVU+hnLq06dP+D7CuLPPPvuUGgX9W48ePUpHHHFEuV6qkZUrdCTKg/4CuS7aRw4YMKCiDwbaCuc+/PDDVftl/h4/fnyLPict07HtP/PMM+Fv2i5/z5gxo3zMW2+9FXQd6qmt3HzzzUHmaMOt5Zxzzgn92+zZs1vorddee23p7rvvDvoTsrL++uuXdTTYZJNNQpumXUydOjW83/bbbx/qMK275VG0nVfT6SZMmNCiHx80aFDFPbbeeuvS3nvvXfM5isguUD+rrbZa0B8j9Gm0t+y8A11yjTXWKOvy1AttI1JkHENHYDzcbbfdqj57V9AXRGTxQU9bESlMkTDuuFNu1islblSW9o5jBZ8Q2gir0zHEDf74xz8G74msR2YaPFDw4iTENnpiEeaEx+f9999fcSyr6oSrRfAA4fp//etfk0aAJyCr6Hh24kHBh40o5s6d26brsQKfhuclP2q9HZzrnUeZ4UGEh1ksM8qFTUayZVYEvB8ieEfw/rEOeXc83w444IAKbznuRWh3OsQMzxlSGdSC58Qj4tFHHw2eKjvssEN4Hzxs0vli0+BVi6c4XiKEdNMWi+RKaw14n1B26U+63eJBTCgnHr8jR44MHoR4qhAuVyt0Ei8VNk7K+7zwwgvJxIkTwzHUZzbUvQhcB2/DPHnFYyUrG3it4b2CFwtyFyF8EvAuSdcz+UrxLqHsI5Q936c9rPG0i20mCykRaFOEY+IFmXdcI2WvkX1YR9dpa1JrIHPpDe94Vjx8oscTcoRnF2Hu6TrEaynbLxD+mfbw5RxI12v8Ll33gJd/lBH6eDwrCS3Ni0ioJ1cxdQb1jScaobx4ouFdVyTfN/0/4fiUBW2Q6+A1xXsTxVEN5bJt18djtVaboX8nz2a2zZDOI50TlL85L3od4pmLRzfllX0ONohivACOp044P8J1GQsj9M2ELOeNo0Wo1ydEWUrXE2WDfpIGbz/2EsDTkHPqRZUAY0y1dkkIOZ7Y5KTF47neZlZpucJTlGsz9jJmFekjqQ+8XrPlxjFwzz33JK2BPict03nlitcqOkGEd063uWpUKzM+tEdki02piGIqCnn32RQRvYQIoTT0dZQdaanwQiUNCXoAKTki1DdlSKQSZUh6IDw36bOipynHpNt7bCNF2nkt6POzcpotR77Pymke9WQ3rSOhP0b4nfEpr43Rp1Yb24uMY+QLpt2QGqe9dLS+ICICbkQmInXBaEKepiI5AjGeoOhnlUNyYKFsEjIaFbPsLuBx99yY74ywTIyxhC9Vg4ktk+68PHjZ3Xiz1yE3Ku/F5LoREMLF5BElHcWM6zN5JwyrLWSflzKEes9b7zzKjNC7vFQXbdmYIq8eYx3GfLvZCXCkiNKfB+XLh9BRFHjC7TDikr8u2/aYZHIs+e3uuuuusKFeo2FSW2/DJNo9k684iSWUn5ByQswJ7c0jGirrQd0Sdlot53Q1YqqG2EYi8W9CatMwgWRChOEtDfWMfFcL1aee427gGIKyspluM3mGSSZiGKYIy2QSxCSYMmPS22jZa2Qf1pF1Ss7OIn1ypN6zUodMMvP6hfRiV61rpb+vVhZM2tOygnGBSTQpLwjLTRuii8gVfRZhuhihHnrooRCiyiIRG7Xl5b5Ow7jBfTmH52DBj4k97awz6rAry2V7r5/XZqrdM88AT1nENDxxnMHQWe05Yn188pOfrDlmMp5g5Kk2jrZXzngGZCxtUMs+A9DfYcylnWEwpAxol/Rx1RZrMKzF9CC1wHBL+oe0gbOaXHEvcoPyifct0kfyfz7ZcuO9WTzKtuFGlGteO6mlP0by0hfkwUIr4fmkO6rF3/72t7CQMWzYsKqLyWnIe8uCUzq/KX0Ruje/RShvHBIwqAObAtM2IhiJMfIXaee1yOvHi8hpHvVkN/1de/rASJFxLKZ8iak+2kNH6wsiIqDRVkTqguGUXE94QTKZ4e9qoLiwOo4ik96UAe8jFP6s0lILFFbuhydYNWWT+5GrCm+FLOS+TZPNofXmm28GZanaBlERDLuAh1OadG5SroOXE4akdJ7IIt4x1cg+L2UI9Z633nmU2e67756MHTu2xblpT7xGEBVZPEPIL5ulEUozkwJyBOJpOW/evNz74G2L4YSJTNbrZWFB/kXyLmYnL2nI3cenGngC4cWCFxJ50tpaP9XaTHYigqcP+e2YkJK7LU6MOA75xnsqa/gBJqTtAa8ZvJTpWzDO4vGEZxr55+iPGil7jezDOrJO8UzC+MLktagHVS24BgaCuIFVZ4LRhJyFtMOixrF0/xwNu8g+BkTaJ16FyFctaFN4PLLgE3nsscfq3lO5TDrl+pE8b2XKIj2mAR7WbECVJeY35vi8vO3p7xhP6FOqlX174RnoX9hQLG24zd6PsRgDHB+iUCZNmhT+zUZvI0aMyL02m5HWgryhjIUYhGsZbLNy1ZY+EoMV/86+F+9NXt5G9FnZcs1rJ0Xy9NfL80ue1VGjRgVP2HoGW+qKzcPYa4GF2bbC4mN2o7VINPJheE9vOBn1qSLtvLOoJ7uR7EJEug9kgTJ9bvr3toxjzC2gLRvEdba+ICICpkcQkUIQvkq4I2FieRDGB9HTJ278FOHvuGNqUZj0ovSwEUA1CLMi9JFrM8FIf7ITRowC6ZBAvJO4PrvD1lr1ZkdrSBvX+HfaS5RJCEai9MT1rbfearERQWvI7j7L8+I5hkdVe86jzDBMRC+29KfetVsLu/1SfoQaZ+/Fp7VG22oT5xgq17Nnz9zf8XjByIdnbmcTFfosTEaYwFZ75nrgLYLhjvaLoSYuLrQGZAQjRVZe2SSDtszuxtnjCYkmdJHJf5SnGDrJM+XVc3YBpa1gjCLMn3pk0YVJV1HZK+rV0sg+rCPrlEUKyh9P0TzYFKo10C8gp8hkXh12JPTh1C0e0u0F4yWLjHjW16trQuezxkZCwNvD4iSXnSX39JOk0kj/zfvGBbrtttsujHGEGec9RzTSUG5EW3B+hOumvfbwxsNjN28cbQRRlthsKUL/hX5SDRYb2dwOA1GtRb5asGv9QQcdFLwz8chsD0X6SFITsGiRLTfacPoajQJ5w6txxowZ5e9IL1Av5VI9WBijj8XjmcXhWuDhSrooDLu8d5GNe4E0EkQbRF0UMMYiV/wW4W+8eOPCc7avjvpUkXbeWdST3WrwDpRfXh+IE0dM29CWcYz+Er201tyiK+gLIrL4oKetiBSCfFqEkOLpgcEP5R+PJnbWxQMERYxjWOFm0oyRlwkxyhFKL95x6UlKEVDKCEUbPXp0UDaZIJKbFWMEz8HqO6FhKLqEx+N1gJcWxmV2RseThAlsBOMOu1Pjlctz44VFqHoMjeN+TNh4Hzxt+KDkoVzivUPuRTyyMBYRJhcngoDHDM/B99FTh3/zfVu9G/CyYJJAWaOoc2+eIb2a35bzqBsMExi/2BGYCQbeEEz4UXQ5tlFgFMcDEqMpYe14RaPEEsJJPTIRjco3E1NCaWtNsvAOZhJDveKJgkJN6PyECRNC3cZQ3CzkZ8SA0hZoT3kTdt4lbXTCKzwNxhomrchGnz59Quh3zCVM+yMtAu2NXZ3bAu2P98YYXXRymIX744GMAZCJEDJM6gxSSJBqIt3GIxj2KXMWVciNSN5R6pDQXTzA8CxEZjBWY0xn8tjWsgfC3PFyIkccIbuUJ22aOuVv3qGI7FWT7yyN7MM6sk55TjzAjj/++HJ+PvpEvI8Ja8Z40ZpJOu2THbAxOGKkoLwwghBqSpRB2hu1PXBN2lg0rrPgx4dUIYTQp6klV7VgfCCHId6wjCHV4BjKkEgA3pd6xlOuPSwucgkdff0IfSa5jBnv8VxDvvGOpCyA7zBGoqMgC7RhyhDjDTKLhylGXY5nV3g8IVn4YTENA2a2PPFEJU96HEcJW588eXJD3oVxi3RB1C36DGMW+bfpa9LehoxnGOei4QejLs+bzg/aGvD8xJDEddtL0T4SOeR+w4cPDx8Mk0RJ4BHe6AVi6hRjO7oGfRVtYty4cWHhoD057JFjIjnQMWtBOfAMhOfTp8Q8ytFrmnoExn10NNooss1xOEOgYxJ9E6HcGNfQUfmdvpH34lp5kWVpirbzzqCe7FaD+QWRM+PHjw99/qBBg8I4MWXKlBBFkU3Z05pxDDmjHtAjaYucQ7nOmjUrlDkG866gL4jIYsTC3glNRLoW7AS+yy67lFZeeeWws+tGG21UGjlyZGnevHnlY959992w+zM74rLr7hZbbFG6/vrr6+7i/dprr7XYnZldjseNGxd20OV+XJPdpt94443yMXPnzi0dcMABYfdZds/mmdidN71LK9c977zzSieffHJp1VVXDbvyjhgxouI6wA6wvXr1CrvPprtIdv/ddtttw07Um2++eemOO+4o9e/fv2InXspgyJAhpe7du4edgNn9OLuzbbUdadPEXbspB67PTruU9wknnBB2co6kdw5vzXnw3HPPlY466qjS2muvHeqInXT322+/0r333ltzZ+y8nYbTu8hDtlzg9ttvL+8AzYfrsON8endj7scxtZg1a1Z47rizMjtDc78LLrigNH/+/LrPlmbo0KEV98urm7zd7uOHXatr7XLfu3fvcI3333+/dP7555d22mmn0H5poxtssEFp3333LT3wwAOlziZbr3GX9ShjPNvYsWMrdhjPK0/qgjo4+uijw27MfC6++OJSv379QptCzthB+cILLyyfk5WHCPWY3p07/YzslD18+PAgl5Qdu8tTdsh9a2Svmnzn1Xsj+7COht3S99prr9D/8V7rrLNOKK9028qr8xtuuCE8K/1GhP7wpJNOCm2AtkD/sMcee4Qd1NMywc72aarJW94u8GkZoT+lDDkGOYkUkatqdRAZPHhwODbuMp53PLvLH3744aVVVlklfI455pjS9OnT6/bRi6tc5tHW68fxaurUqRXfZ9tXrDPaYN++fcM9BgwYUDFWRa655pryON2jR49w3JgxY0oLFiyokJctt9wyXIfrcd28MYu+gr6kW7du4Znuu+++FrJdb4ys1ifw3SGHHBLKBLlFLxk9enQYryPoPdtss02oA45jJ/opU6aUOoNactWaPhKuu+668BvHcCznpMfqvP43r9/I9jkPPvhgOI7zI4zJ9FfUGX0XOh/yTX13NLE9531oJ5Fp06aVBg0aFPob+mue88gjjyw9++yzLa6JXNOX0wZo07vuumtpzpw5hZ6nSDsvqtNl6yPv3DyKym5e3wf0dWeffXZ5PKIvRC7T0LfQ36UpMo7Fuhg4cGBoL8geOgTtalHWF0Ska7IE/1nYhmMRkY6GlXVW7KuFEjcT5KUjBx9eMUV3rG7PeSIiIrLwYFNFPPvwUJbGgGflpptuGqKuaoXCS8fABqGzZ8+u8DpuNEThEAlVZAM+EZGuiukRREREREREOgHSNTz99NMhRQApEgj5njlzZos8utI6SDNBfmBC1EkJMHHixLCYTboYWbRAbpAZUrCkcwGLiCyKaLQVERERERHpBNikixy58+bNC96gbNhJHsxG5JtdnCH3KTlTMdRC//79Q+78jt5IUTof8mYjL2xYRu5iEZFFGdMjiIiIiIiIiIiIiDQRbd9OU0REREREREREREQajkZbERERERERERERkSZCo62IiIiIiIiIiIhIE6HRVkRERERERERERKSJ0GgrIiIiIiIiIiIi0kRotBURERERERERERFpIjTaioiIiIiIiIiIiDQRGm1FREREREREREREmgiNtiIiIiIiIiIiIiJNhEZbERERERERERERkSZCo62IiIiIiIiIiIhIE6HRVkRERERERERERKSJ0GgrIiIiIiIiIiIi0kRotBURERERERERERFpIjTaioiIiIiIiIiIiDQRGm1FREREREREREREmgiNtiIiIiIiIiIiIiJNhEZbERERERERERERkSZCo62IiIiIiIiIiIhIE6HRVkRERERERERERKSJ0GgrIiIiIiIiIiIi0kRotBURERERERERERFpIjTaioiIiIiIiIiIiDQRGm1FREREREREREREmgiNtiIiIiIiIiIiIiJNhEZbERERERERERERkSZCo62IiIiIiIiIiIhIE6HRVkRERERERERERKSJ0GgrIiIiIiIiIiIikjQP/we9Qn0Q6LKpewAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle, FancyArrowPatch\n",
    "\n",
    "# --- helpers ---\n",
    "def add_box(ax, x, y, w, h, text=\"\", fontsize=12, lw=1.5, fc=\"none\", ec=\"black\"):\n",
    "    rect = Rectangle((x, y), w, h, linewidth=lw, edgecolor=ec, facecolor=fc)\n",
    "    ax.add_patch(rect)\n",
    "    if text:\n",
    "        ax.text(x + w/2, y + h/2, text, ha='center', va='center', fontsize=fontsize)\n",
    "    return rect\n",
    "\n",
    "def add_arrow(ax, x1, y1, x2, y2, lw=1.6):\n",
    "    arr = FancyArrowPatch((x1, y1), (x2, y2), arrowstyle='-|>', \n",
    "                          mutation_scale=15, linewidth=lw, color='black')\n",
    "    ax.add_patch(arr)\n",
    "    return arr\n",
    "\n",
    "# --- canvas ---\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "ax.axis('off')\n",
    "\n",
    "# layout\n",
    "Y_MAIN = 0.75\n",
    "Y_EMB  = 0.30\n",
    "Y_VEC  = 0.10\n",
    "\n",
    "# 1) SMILES\n",
    "smiles = add_box(ax, 0.05, Y_MAIN, 0.18, 0.12, 'SMILES\\n\"CCO\"', fontsize=13)\n",
    "\n",
    "# 2) Tokenisation (C, C, O)\n",
    "tok_x, tok_w, tok_gap = 0.28, 0.08, 0.08   # more gap\n",
    "tokens = [\"C\", \"C\", \"O\"]\n",
    "token_boxes = []\n",
    "for i, t in enumerate(tokens):\n",
    "    token_boxes.append(add_box(ax, tok_x + i*(tok_w+tok_gap), Y_MAIN, \n",
    "                               tok_w, 0.12, t, fontsize=14))\n",
    "\n",
    "# Arrow: SMILES -> first token\n",
    "add_arrow(ax, smiles.get_x()+smiles.get_width(), Y_MAIN+0.06,\n",
    "          token_boxes[0].get_x(), Y_MAIN+0.06)\n",
    "\n",
    "# 3) Transformer encoder (ChemBERTa)\n",
    "enc_x, enc_y, enc_w, enc_h = 0.75, Y_MAIN-0.02, 0.20, 0.18  # much further right\n",
    "enc = add_box(ax, enc_x, enc_y, enc_w, enc_h, \n",
    "              'Transformer Encoder\\n(ChemBERTa)', fontsize=12)\n",
    "\n",
    "# Inner \"layers\"\n",
    "layer_count, margin = 4, 0.02\n",
    "layer_h = (enc_h - 2*margin) / layer_count\n",
    "for i in range(layer_count):\n",
    "    add_box(ax, enc_x + margin, enc_y + margin + i*layer_h,\n",
    "            enc_w - 2*margin, layer_h*0.8,\n",
    "            f'Layer {i+1}', fontsize=10, lw=1.0)\n",
    "\n",
    "# Arrow: last token -> encoder\n",
    "last_tok = token_boxes[-1]\n",
    "add_arrow(ax, last_tok.get_x()+last_tok.get_width(), Y_MAIN+0.06, enc_x, Y_MAIN+0.06)\n",
    "\n",
    "# 4) Embeddings (sequence × hidden)\n",
    "emb_x, emb_y, emb_w, emb_h = 0.25, Y_EMB, 0.50, 0.14  # lower down\n",
    "add_box(ax, emb_x, emb_y, emb_w, emb_h)\n",
    "ax.text(emb_x + emb_w/2, emb_y + emb_h + 0.03,\n",
    "        \"Token Embeddings (sequence × hidden)\", ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "# columns for tokens\n",
    "cols = len(tokens)\n",
    "col_w = emb_w / cols\n",
    "for i, t in enumerate(tokens):\n",
    "    add_box(ax, emb_x + i*col_w, emb_y, col_w, emb_h, lw=1.0)\n",
    "    ax.text(emb_x + i*col_w + col_w/2, emb_y - 0.02, t, ha='center', va='top', fontsize=10)\n",
    "\n",
    "# Arrow: encoder -> embeddings (downward)\n",
    "add_arrow(ax, enc_x + enc_w/2, enc_y, emb_x + emb_w/2, emb_y + emb_h)\n",
    "\n",
    "# 5) Pooling + projection\n",
    "pool_x, pool_y, pool_w, pool_h = 0.82, Y_EMB, 0.06, 0.14\n",
    "add_box(ax, pool_x, pool_y, pool_w, pool_h, 'Pool', fontsize=10)\n",
    "\n",
    "vec_x, vec_y, vec_w, vec_h = 0.82, Y_VEC, 0.20, 0.10\n",
    "add_box(ax, vec_x, vec_y, vec_w, vec_h, 'Projection\\n(256-d vector)', fontsize=12)\n",
    "\n",
    "# Arrows\n",
    "add_arrow(ax, emb_x + emb_w, emb_y + emb_h/2, pool_x, pool_y + pool_h/2)\n",
    "add_arrow(ax, pool_x + pool_w/2, pool_y, vec_x + vec_w/2, vec_y + vec_h)\n",
    "\n",
    "# Caption\n",
    "ax.text(0.5, 0.03,\n",
    "        \"Conceptual pipeline: SMILES → Tokenisation → ChemBERTa → Token embeddings → Pooling → 256-dim projection\",\n",
    "        ha='center', va='bottom', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2ebabf",
   "metadata": {},
   "source": [
    "## RQ1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a223d57",
   "metadata": {},
   "source": [
    "### All the figures and needed Tables in one go saved under \"v7/v7_Eval/RQ1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4dd349e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Split] Using indices: train.npy  | Prepared: train.npz\n",
      "[Aligned] N=6265 L=12  observed=62450  positives=4888\n",
      "\n",
      "[T2] Computing specialist-calibrated probabilities on TEST…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:31:19] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ1\\test\\probs\\test_probs_specialist_calibrated.npy  shape=(6265, 12)\n",
      "\n",
      "[T3] TEST metrics (specialist-calibrated):\n",
      "[AP] macro=0.3527  micro=0.3026\n",
      "[ROC-AUC] macro=0.8078  finite_labels=12/12\n",
      "Saved per-label metrics → D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ1\\test\\C1_metrics\\test_per_label_metrics_specialist.csv\n",
      "PR curves → D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ1\\test\\C1_metrics\\pr_curves  |  ROC curves → D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ1\\test\\C1_metrics\\roc_curves\n",
      "[Bootstrap] 100/1000\n",
      "[Bootstrap] 200/1000\n",
      "[Bootstrap] 300/1000\n",
      "[Bootstrap] 400/1000\n",
      "[Bootstrap] 500/1000\n",
      "[Bootstrap] 600/1000\n",
      "[Bootstrap] 700/1000\n",
      "[Bootstrap] 800/1000\n",
      "[Bootstrap] 900/1000\n",
      "[Bootstrap] 1000/1000\n",
      "\n",
      "[T4] TEST bootstrap:\n",
      "[macro AP] mean=0.3551  95%CI=(0.3356, 0.3741)\n",
      "[micro AP] mean=0.3031  95%CI=(0.2874, 0.3189)\n",
      "\n",
      "[T5] Saved T1_test → D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ1\\test\\T1\\T1_test_specialist.csv and .md\n",
      "[T6] F1 saved → D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ1\\test\\F1\n",
      "[T6] F1b saved → D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ1\\test\\F1b\n",
      "\n",
      "[T7] Computing UNCALIBRATED specialist probabilities …\n",
      "[T7] F2 saved → D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ1\\test\\F2_cal_vs_uncal\n",
      "\n",
      "[T8] Computing BLEND (alpha=0.80) …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:31:40] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[T8] Spec vs Blend aggregates:\n",
      "{'macro_AP': {'specialist': 0.3527, 'blend': 0.378, 'delta': 0.0254}, 'micro_AP': {'specialist': 0.3026, 'blend': 0.3685, 'delta': 0.0658}, 'macro_ROC_AUC': {'specialist': 0.8078, 'blend': 0.8215, 'delta': 0.0138}, 'alpha': 0.8}\n",
      "[T8] F2b saved → D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ1\\test\\F2b_spec_vs_blend\n",
      "[T8] F2c saved → D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ1\\test\\F2c_delta_ap\n",
      "\n",
      "[T9] Operating-point table saved:\n",
      " - Table: D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ1\\test\\T1_op\\T1_op_test_blend.csv\n",
      " - Aggregates (F1 CIs): D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ1\\test\\T1_op\\T1_op_test_aggregates.json\n",
      "\n",
      "[T10] Paired Δ(AP) CIs saved → D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ1\\test\\C2b_bootstrap_delta\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# RQ1 — TEST REPLICATION (no refits). Uses split at v7/data/splits/train.npy.\n",
    "# Outputs under: v7/v7_Eval/RQ1/test/<artifact_group>/\n",
    "# =============================================================================\n",
    "from __future__ import annotations\n",
    "\n",
    "# =========================\n",
    "# T0. Common setup & utils\n",
    "# =========================\n",
    "import json, math, os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from numbers import Number\n",
    "\n",
    "# sklearn optional\n",
    "try:\n",
    "    from sklearn.metrics import (\n",
    "        average_precision_score, roc_auc_score,\n",
    "        precision_recall_curve, roc_curve,\n",
    "        precision_score, recall_score, f1_score\n",
    "    )\n",
    "    _HAVE_SK = True\n",
    "except Exception:\n",
    "    _HAVE_SK = False\n",
    "\n",
    "# --- Path detection ---\n",
    "def detect_v7() -> Path:\n",
    "    cwd = Path(\".\").resolve()\n",
    "    if (cwd/\"data\").exists() and (cwd/\"model\").exists() and cwd.name == \"v7\":\n",
    "        return cwd\n",
    "    if (cwd/\"v7\"/\"data\").exists():\n",
    "        return (cwd/\"v7\").resolve()\n",
    "    return cwd\n",
    "\n",
    "V7   = detect_v7()\n",
    "PREP = V7 / \"data\" / \"prepared\"\n",
    "SPL  = V7 / \"data\" / \"splits\"\n",
    "MOD  = V7 / \"model\"\n",
    "CAL  = MOD / \"calibration\"\n",
    "ENS  = MOD / \"ensembles\"\n",
    "CKPT = MOD / \"checkpoints\" / \"shared\" / \"best.pt\"\n",
    "\n",
    "# Base outdir for TEST artifacts\n",
    "RQ1_BASE = V7 / \"v7_Eval\" / \"RQ1\" / \"test\"\n",
    "RQ1_BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Subfolders (grouped by table/figure/function)\n",
    "DIR_PROBS   = RQ1_BASE / \"probs\"         ; DIR_PROBS.mkdir(exist_ok=True, parents=True)\n",
    "DIR_C1      = RQ1_BASE / \"C1_metrics\"    ; DIR_C1.mkdir(exist_ok=True, parents=True)\n",
    "DIR_BOOT    = RQ1_BASE / \"C2_bootstrap\"  ; DIR_BOOT.mkdir(exist_ok=True, parents=True)\n",
    "DIR_T1      = RQ1_BASE / \"T1\"            ; DIR_T1.mkdir(exist_ok=True, parents=True)\n",
    "DIR_F1      = RQ1_BASE / \"F1\"            ; DIR_F1.mkdir(exist_ok=True, parents=True)\n",
    "DIR_F1b     = RQ1_BASE / \"F1b\"           ; DIR_F1b.mkdir(exist_ok=True, parents=True)\n",
    "DIR_F2      = RQ1_BASE / \"F2_cal_vs_uncal\"; DIR_F2.mkdir(exist_ok=True, parents=True)\n",
    "DIR_F2b     = RQ1_BASE / \"F2b_spec_vs_blend\"; DIR_F2b.mkdir(exist_ok=True, parents=True)\n",
    "DIR_F2c     = RQ1_BASE / \"F2c_delta_ap\"  ; DIR_F2c.mkdir(exist_ok=True, parents=True)\n",
    "DIR_OP      = RQ1_BASE / \"T1_op\"         ; DIR_OP.mkdir(exist_ok=True, parents=True)\n",
    "DIR_BOOT_DEL= RQ1_BASE / \"C2b_bootstrap_delta\"; DIR_BOOT_DEL.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Curves dirs\n",
    "DIR_PR_CAL   = DIR_C1 / \"pr_curves\"       ; DIR_PR_CAL.mkdir(parents=True, exist_ok=True)\n",
    "DIR_ROC_CAL  = DIR_C1 / \"roc_curves\"      ; DIR_ROC_CAL.mkdir(parents=True, exist_ok=True)\n",
    "DIR_PR_UNCAL = DIR_F2 / \"pr_curves_uncal\" ; DIR_PR_UNCAL.mkdir(parents=True, exist_ok=True)\n",
    "DIR_PR_BLEND = DIR_F2b / \"pr_curves_blend\"; DIR_PR_BLEND.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- Model components (same as Phase-5 rig) ----\n",
    "from rdkit import Chem\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ChemBERTaEncoder(nn.Module):\n",
    "    def __init__(self, ckpt_name=\"seyonec/ChemBERTa-zinc-base-v1\", fusion_dim=256, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(ckpt_name)\n",
    "        self.backbone  = AutoModel.from_pretrained(ckpt_name)\n",
    "        self.proj = nn.Sequential(nn.Dropout(dropout_p), nn.Linear(self.backbone.config.hidden_size, fusion_dim))\n",
    "        self.ln = nn.LayerNorm(fusion_dim)\n",
    "    def forward(self, smiles_list: List[str], max_length=256, add_special_tokens=True):\n",
    "        enc = self.tokenizer(list(smiles_list), padding=True, truncation=True,\n",
    "                             max_length=max_length, add_special_tokens=add_special_tokens,\n",
    "                             return_tensors=\"pt\")\n",
    "        input_ids, attention_mask = enc[\"input_ids\"].to(device), enc[\"attention_mask\"].to(device)\n",
    "        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "        toks = self.ln(self.proj(out))\n",
    "        return toks, attention_mask.to(dtype=torch.int32)\n",
    "\n",
    "ATOM_LIST = [\"H\",\"C\",\"N\",\"O\",\"F\",\"P\",\"S\",\"Cl\",\"Br\",\"I\"]\n",
    "def _one_hot(v, choices):\n",
    "    z = [0]*len(choices)\n",
    "    if v in choices: z[choices.index(v)] = 1\n",
    "    return z\n",
    "def _bucket_oh(v, lo, hi):\n",
    "    buckets = list(range(lo, hi+1))\n",
    "    o = [0]*(len(buckets)+1)\n",
    "    idx = v - lo\n",
    "    o[idx if 0 <= idx < len(buckets) else -1] = 1\n",
    "    return o\n",
    "def _atom_feat(atom):\n",
    "    hybs = [Chem.rdchem.HybridizationType.S, Chem.rdchem.HybridizationType.SP,\n",
    "            Chem.rdchem.HybridizationType.SP2, Chem.rdchem.HybridizationType.SP3,\n",
    "            Chem.rdchem.HybridizationType.SP3D, Chem.rdchem.HybridizationType.SP3D2]\n",
    "    chir = [Chem.rdchem.ChiralType.CHI_UNSPECIFIED,\n",
    "            Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CW,\n",
    "            Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CCW,\n",
    "            Chem.rdchem.ChiralType.CHI_OTHER]\n",
    "    sym = atom.GetSymbol()\n",
    "    feat = _one_hot(sym if sym in ATOM_LIST else \"other\", ATOM_LIST+[\"other\"])\n",
    "    feat += _bucket_oh(atom.GetDegree(), 0, 5)\n",
    "    feat += _bucket_oh(atom.GetFormalCharge(), -2, 2)\n",
    "    feat += (_one_hot(atom.GetHybridization(), hybs)+[0])\n",
    "    feat += [int(atom.GetIsAromatic())]\n",
    "    feat += [int(atom.IsInRing())]\n",
    "    feat += _one_hot(atom.GetChiralTag(), chir)\n",
    "    feat += _bucket_oh(atom.GetTotalNumHs(includeNeighbors=True), 0, 4)\n",
    "    feat += _bucket_oh(atom.GetTotalValence(), 0, 5)\n",
    "    feat += [atom.GetMass()/200.0]\n",
    "    return feat\n",
    "def _smiles_to_graph(smi, max_nodes=128):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None or mol.GetNumAtoms() == 0:\n",
    "        return np.zeros((0,0), dtype=np.float32), np.zeros((0,0), dtype=np.float32)\n",
    "    feats = [_atom_feat(mol.GetAtomWithIdx(i)) for i in range(mol.GetNumAtoms())]\n",
    "    x = np.asarray(feats, dtype=np.float32)\n",
    "    Nn = mol.GetNumAtoms()\n",
    "    adj = np.zeros((Nn, Nn), dtype=np.float32)\n",
    "    for b in mol.GetBonds():\n",
    "        i, j = b.GetBeginAtomIdx(), b.GetEndAtomIdx()\n",
    "        adj[i, j] = 1.0; adj[j, i] = 1.0\n",
    "    if Nn > max_nodes:\n",
    "        x = x[:max_nodes]; adj = adj[:max_nodes, :max_nodes]\n",
    "    return x, adj\n",
    "def _collate_graphs(smiles_batch, max_nodes=128):\n",
    "    graphs = [_smiles_to_graph(s) for s in smiles_batch]\n",
    "    Nmax = max([g[0].shape[0] for g in graphs] + [1])\n",
    "    Fnode = graphs[0][0].shape[1] if graphs[0][0].size>0 else 51\n",
    "    B = len(graphs)\n",
    "    X = np.zeros((B, Nmax, Fnode), dtype=np.float32)\n",
    "    A = np.zeros((B, Nmax, Nmax), dtype=np.float32)\n",
    "    M = np.zeros((B, Nmax), dtype=np.int64)\n",
    "    for i, (x, a) in enumerate(graphs):\n",
    "        n = x.shape[0]\n",
    "        if n == 0: continue\n",
    "        X[i, :n, :] = x\n",
    "        A[i, :n, :n] = a\n",
    "        M[i, :n] = 1\n",
    "    return torch.from_numpy(X).to(device), torch.from_numpy(A).to(device), torch.from_numpy(M).to(device)\n",
    "def masked_mean(x: torch.Tensor, mask: torch.Tensor, dim: int) -> torch.Tensor:\n",
    "    mask = mask.to(dtype=x.dtype, device=x.device)\n",
    "    denom = mask.sum(dim=dim, keepdim=True).clamp(min=1.0)\n",
    "    return (x * mask.unsqueeze(-1)).sum(dim=dim) / denom\n",
    "class GINLayer(nn.Module):\n",
    "    def __init__(self, h=256, p=0.1):\n",
    "        super().__init__()\n",
    "        self.eps = nn.Parameter(torch.tensor(0.0))\n",
    "        self.mlp = nn.Sequential(nn.Linear(h, h), nn.GELU(), nn.LayerNorm(h), nn.Dropout(p))\n",
    "    def forward(self, x, adj, mask):\n",
    "        out = (1.0 + self.eps) * x + torch.matmul(adj, x)\n",
    "        out = self.mlp(out)\n",
    "        return out * mask.unsqueeze(-1).to(out.dtype)\n",
    "class GraphGINEncoder(nn.Module):\n",
    "    def __init__(self, node_in_dim=51, hidden_dim=256, n_layers=4, p=0.1):\n",
    "        super().__init__()\n",
    "        self.inp = nn.Sequential(nn.Linear(node_in_dim, hidden_dim), nn.GELU(), nn.Dropout(p))\n",
    "        self.layers = nn.ModuleList([GINLayer(hidden_dim, p) for _ in range(n_layers)])\n",
    "        self.out_ln = nn.LayerNorm(hidden_dim)\n",
    "    def forward(self, smiles_list: List[str], max_nodes=128):\n",
    "        X, A, M = _collate_graphs(smiles_list, max_nodes=max_nodes)\n",
    "        h = self.inp(X)\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, A, M)\n",
    "        return self.out_ln(h), M.to(dtype=torch.int32)\n",
    "class CrossAttentionBlock(nn.Module):\n",
    "    def __init__(self, dim=256, n_heads=4, p=0.1):\n",
    "        super().__init__()\n",
    "        self.mha = nn.MultiheadAttention(dim, n_heads, dropout=p, batch_first=False)\n",
    "        self.ln  = nn.LayerNorm(dim)\n",
    "        self.do  = nn.Dropout(p)\n",
    "    def forward(self, text_tokens, text_mask, graph_nodes, graph_mask):\n",
    "        Q = text_tokens.transpose(0,1)\n",
    "        K = graph_nodes.transpose(0,1)\n",
    "        V = graph_nodes.transpose(0,1)\n",
    "        kpm = (graph_mask == 0)\n",
    "        attn, _ = self.mha(Q, K, V, key_padding_mask=kpm)\n",
    "        attn = attn.transpose(0,1)\n",
    "        return self.ln(text_tokens + self.do(attn))\n",
    "class DescriptorMLP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim=256, hidden=256, p=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden), nn.GELU(), nn.Dropout(p),\n",
    "            nn.Linear(hidden, out_dim), nn.GELU(), nn.Dropout(p)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "class FusionClassifier(nn.Module):\n",
    "    def __init__(self, dim=256, n_labels=12, p=0.1):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim*3, dim*2), nn.GELU(), nn.Dropout(p),\n",
    "            nn.Linear(dim*2, n_labels)\n",
    "        )\n",
    "    def forward(self, fused_vec): return self.mlp(fused_vec)\n",
    "class V7FusionModel(nn.Module):\n",
    "    def __init__(self, text_encoder, graph_encoder, desc_in_dim=208, dim=256, n_labels=12, n_heads=4, p=0.1):\n",
    "        super().__init__()\n",
    "        self.text_encoder=text_encoder\n",
    "        self.graph_encoder=graph_encoder\n",
    "        self.cross=CrossAttentionBlock(dim, n_heads, p)\n",
    "        self.desc_mlp=DescriptorMLP(desc_in_dim, out_dim=dim, hidden=256, p=p)\n",
    "        self.shared_head=FusionClassifier(dim, n_labels, p)\n",
    "    def forward(self, smiles_list, desc_feats):\n",
    "        tt, tm = self.text_encoder(smiles_list, max_length=256)\n",
    "        gn, gm = self.graph_encoder(smiles_list, max_nodes=128)\n",
    "        tta = self.cross(tt.to(device), tm.to(device), gn.to(device), gm.to(device))\n",
    "        de  = self.desc_mlp(desc_feats.to(device))\n",
    "        text_pool  = masked_mean(tta, tm.to(device), 1)\n",
    "        graph_pool = masked_mean(gn.to(device),  gm.to(device), 1)\n",
    "        fused = torch.cat([text_pool, graph_pool, de], dim=-1)\n",
    "        logits_shared = self.shared_head(fused)\n",
    "        return logits_shared, fused\n",
    "class LabelHead(nn.Module):\n",
    "    def __init__(self, in_dim=768, h1=512, h2=256, h3=128, p=0.30):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(nn.Linear(in_dim, h1), nn.GELU(), nn.LayerNorm(h1), nn.Dropout(p))\n",
    "        self.block2 = nn.Sequential(nn.Linear(h1, h2), nn.GELU(), nn.LayerNorm(h2), nn.Dropout(p))\n",
    "        self.block3 = nn.Sequential(nn.Linear(h2, h3), nn.GELU(), nn.LayerNorm(h3), nn.Dropout(p))\n",
    "        self.out    = nn.Linear(h3, 1)\n",
    "        self.short  = nn.Linear(in_dim, h3)\n",
    "    def forward(self, x):\n",
    "        z1 = self.block1(x); z2 = self.block2(z1); z3 = self.block3(z2)\n",
    "        z  = z3 + self.short(x)\n",
    "        return self.out(z).squeeze(-1)\n",
    "\n",
    "def load_best_head(label: str) -> nn.Module:\n",
    "    cands = []\n",
    "    for sd in sorted((ENS / label).glob(\"seed*/\")):\n",
    "        mfile = sd / \"metrics.json\"\n",
    "        if mfile.exists():\n",
    "            try:\n",
    "                ap = float(json.loads(mfile.read_text()).get(\"best_ap\", float(\"nan\")))\n",
    "                cands.append((ap, sd))\n",
    "            except Exception:\n",
    "                pass\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(f\"No trained heads for label {label}\")\n",
    "    cands.sort(key=lambda x: (-1.0 if math.isnan(x[0]) else x[0]), reverse=True)\n",
    "    best_dir = cands[0][1]\n",
    "    ck = torch.load(best_dir / \"best.pt\", map_location=\"cpu\")\n",
    "    cfg = ck.get(\"config\", {\"in_dim\":768,\"h1\":512,\"h2\":256,\"h3\":128,\"dropout\":0.30})\n",
    "    head = LabelHead(in_dim=cfg[\"in_dim\"], h1=cfg[\"h1\"], h2=cfg[\"h2\"], h3=cfg[\"h3\"], p=cfg.get(\"dropout\",0.30)).to(device)\n",
    "    head.load_state_dict(ck[\"model\"], strict=True)\n",
    "    head.eval()\n",
    "    return head\n",
    "\n",
    "# --- Metrics helpers ---\n",
    "def _ap_fallback(yt, ys):\n",
    "    order = np.argsort(-ys); y = yt[order]\n",
    "    tp = np.cumsum(y); fp = np.cumsum(1-y)\n",
    "    Pp = int(tp[-1]) if tp.size else 0\n",
    "    if Pp == 0: return 0.0\n",
    "    prec = tp / np.maximum(tp + fp, 1)\n",
    "    rec  = tp / Pp\n",
    "    ap, last = 0.0, 0.0\n",
    "    for r, p in zip(rec, prec):\n",
    "        if r > last:\n",
    "            ap += p*(r-last); last = r\n",
    "    return float(ap)\n",
    "\n",
    "def ap_masked(y_true, y_score, mask) -> float:\n",
    "    m = mask.astype(bool)\n",
    "    yt, ys = y_true[m], y_score[m]\n",
    "    if yt.size == 0 or yt.sum() == 0:\n",
    "        return 0.0\n",
    "    return float(average_precision_score(yt, ys)) if _HAVE_SK else _ap_fallback(yt, ys)\n",
    "\n",
    "def per_label_ap(Y, P, M) -> np.ndarray:\n",
    "    L = Y.shape[1]\n",
    "    aps = np.zeros(L, dtype=float)\n",
    "    for j in range(L):\n",
    "        aps[j] = ap_masked(Y[:, j], P[:, j], M[:, j])\n",
    "    return aps\n",
    "\n",
    "def micro_ap(Y, P, M) -> float:\n",
    "    m = M.astype(bool)\n",
    "    yt = Y[m]; ys = P[m]\n",
    "    if yt.size == 0 or yt.sum() == 0:\n",
    "        return 0.0\n",
    "    return float(average_precision_score(yt, ys)) if _HAVE_SK else _ap_fallback(yt, ys)\n",
    "\n",
    "def per_label_roc(Y, P, M) -> np.ndarray:\n",
    "    L = Y.shape[1]\n",
    "    aucs = np.full(L, np.nan, dtype=float)\n",
    "    if not _HAVE_SK: return aucs\n",
    "    for j in range(L):\n",
    "        m = M[:, j]\n",
    "        yt, ys = Y[m, j], P[m, j]\n",
    "        if len(np.unique(yt)) < 2:\n",
    "            continue\n",
    "        aucs[j] = float(roc_auc_score(yt, ys))\n",
    "    return aucs\n",
    "\n",
    "def conf_mat_metrics_at_threshold(Y, P, M, th_vec: np.ndarray) -> pd.DataFrame:\n",
    "    # Apply per-label thresholds on observed entries\n",
    "    L = Y.shape[1]\n",
    "    rows = []\n",
    "    for j in range(L):\n",
    "        m = M[:, j]\n",
    "        if m.sum() == 0:\n",
    "            rows.append({\"label\": LABELS[j], \"thr\": float(th_vec[j]), \"accuracy\": np.nan, \"recall\": np.nan,\n",
    "                         \"specificity\": np.nan, \"precision\": np.nan, \"F1\": np.nan, \"TP\":0,\"FP\":0,\"TN\":0,\"FN\":0})\n",
    "            continue\n",
    "        yt = Y[m, j].astype(int)\n",
    "        yp = (P[m, j] >= float(th_vec[j])).astype(int)\n",
    "        TP = int(((yp == 1) & (yt == 1)).sum()); FP = int(((yp == 1) & (yt == 0)).sum())\n",
    "        TN = int(((yp == 0) & (yt == 0)).sum()); FN = int(((yp == 0) & (yt == 1)).sum())\n",
    "        prec = TP / (TP + FP) if (TP + FP) else 0.0\n",
    "        rec  = TP / (TP + FN) if (TP + FN) else 0.0\n",
    "        spe  = TN / (TN + FP) if (TN + FP) else 0.0\n",
    "        acc  = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) else 0.0\n",
    "        f1   = (2*prec*rec)/(prec+rec) if (prec+rec) else 0.0\n",
    "        rows.append({\"label\": LABELS[j], \"thr\": float(th_vec[j]), \"accuracy\": acc, \"recall\": rec,\n",
    "                     \"specificity\": spe, \"precision\": prec, \"F1\": f1, \"TP\":TP,\"FP\":FP,\"TN\":TN,\"FN\":FN})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def _roundish(obj, nd=4):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: _roundish(v, nd) for k, v in obj.items()}\n",
    "    if isinstance(obj, (Number, np.floating)):\n",
    "        return round(float(obj), nd)\n",
    "    return obj\n",
    "\n",
    "# =========================\n",
    "# T1. Load TEST split + align with prepared/* (auto-detect)\n",
    "# =========================\n",
    "SPLIT_FILE = SPL / \"train.npy\"  # per your instruction: treat this as TEST split indices\n",
    "assert SPLIT_FILE.exists(), f\"Missing split file: {SPLIT_FILE}\"\n",
    "\n",
    "# Try to find matching prepared npz by intersecting indices\n",
    "CAND_PREP = [PREP/\"test.npz\", PREP/\"train.npz\", PREP/\"val.npz\"]\n",
    "prep_choice = None\n",
    "VAL_IDX = np.load(SPLIT_FILE)\n",
    "for p in CAND_PREP:\n",
    "    if not p.exists(): continue\n",
    "    z = np.load(p, allow_pickle=True)\n",
    "    if \"indices\" in z:\n",
    "        idx_full = z[\"indices\"]\n",
    "        # Check coverage\n",
    "        present = np.isin(VAL_IDX, idx_full).sum()\n",
    "        if present > 0:\n",
    "            prep_choice = p\n",
    "            z.close()\n",
    "            break\n",
    "    z.close()\n",
    "\n",
    "if prep_choice is None:\n",
    "    # fallback: prefer test.npz if shape matches\n",
    "    for p in CAND_PREP:\n",
    "        if p.exists():\n",
    "            prep_choice = p; break\n",
    "assert prep_choice is not None, \"Could not locate a prepared NPZ to match the given split.\"\n",
    "print(f\"[Split] Using indices: {SPLIT_FILE.name}  | Prepared: {prep_choice.name}\")\n",
    "\n",
    "Z = np.load(prep_choice, allow_pickle=True)\n",
    "mani = json.loads((PREP/\"dataset_manifest.json\").read_text())\n",
    "LABELS: List[str] = mani[\"labels\"]\n",
    "DESC_IN_DIM = int(mani[\"n_features\"])\n",
    "\n",
    "Y_full  = Z[\"Y\"].astype(float)\n",
    "OBS_full= (~Z[\"y_missing_mask\"].astype(bool)) if \"y_missing_mask\" in Z else ~np.isnan(Y_full)\n",
    "SMILES_full = list(Z[\"smiles\"])\n",
    "X_full  = Z[\"X\"].astype(np.float32)\n",
    "\n",
    "if \"indices\" in Z:\n",
    "    idx_full = Z[\"indices\"]\n",
    "    pos = pd.Series(np.arange(len(idx_full)), index=idx_full).reindex(VAL_IDX)\n",
    "    if pos.isna().any():\n",
    "        missing = VAL_IDX[pd.isna(pos.values)]\n",
    "        raise RuntimeError(f\"{len(missing)} split indices not present in {prep_choice.name}.\")\n",
    "    order = pos.astype(int).to_numpy()\n",
    "else:\n",
    "    if len(VAL_IDX) != Y_full.shape[0]:\n",
    "        raise RuntimeError(f\"{prep_choice.name} has no 'indices' and length mismatch with split.\")\n",
    "    order = np.arange(len(VAL_IDX))\n",
    "\n",
    "Y  = np.nan_to_num(Y_full[order], nan=0.0).astype(int)\n",
    "OBS= OBS_full[order].astype(bool)\n",
    "SMI= [SMILES_full[i] for i in order]\n",
    "X  = X_full[order]\n",
    "N, L = Y.shape\n",
    "\n",
    "print(f\"[Aligned] N={N} L={L}  observed={int(OBS.sum())}  positives={int((Y*OBS).sum())}\")\n",
    "\n",
    "# ======================================================\n",
    "# T2. Specialist-CALIBRATED probabilities on TEST split\n",
    "# ======================================================\n",
    "# Build fusion to get fused features; then run best specialist heads; apply temps.json (specialist)\n",
    "text_encoder = ChemBERTaEncoder().to(device)\n",
    "graph_encoder= GraphGINEncoder().to(device)\n",
    "fusion = V7 and V7  # dummy to placate linters\n",
    "\n",
    "# Load shared fusion checkpoint (only needed if you prefer to re-create fused features as in Phase-5)\n",
    "fusion = V7 and V7  # reassign properly below\n",
    "fusion = V7FusionModel(text_encoder, graph_encoder, desc_in_dim=DESC_IN_DIM, n_labels=L).to(device)\n",
    "ckpt = torch.load(CKPT, map_location=\"cpu\")\n",
    "fusion.load_state_dict(ckpt[\"model\"], strict=True)\n",
    "fusion.eval()\n",
    "\n",
    "HEADS: Dict[str, nn.Module] = {lbl: load_best_head(lbl) for lbl in LABELS}\n",
    "temps_spec = json.loads((CAL/\"temps.json\").read_text())  # VAL-fitted\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_fused(smiles: List[str], desc: np.ndarray, batch: int = 32) -> np.ndarray:\n",
    "    out = np.zeros((len(smiles), 768), dtype=np.float32)\n",
    "    off = 0\n",
    "    for i in range(0, len(smiles), batch):\n",
    "        b_smi = smiles[i:i+batch]\n",
    "        b_desc= torch.tensor(desc[i:i+batch], dtype=torch.float32, device=device)\n",
    "        _, fused = fusion(b_smi, b_desc)\n",
    "        out[off:off+len(b_smi)] = fused.detach().cpu().numpy()\n",
    "        off += len(b_smi)\n",
    "    return out\n",
    "\n",
    "@torch.no_grad()\n",
    "def probs_specialist_calibrated(fused: np.ndarray, batch: int = 64) -> np.ndarray:\n",
    "    probs = np.zeros((fused.shape[0], L), dtype=np.float32)\n",
    "    for i in range(0, fused.shape[0], batch):\n",
    "        x = torch.tensor(fused[i:i+batch], dtype=torch.float32, device=device)\n",
    "        cols = []\n",
    "        for lbl in LABELS:\n",
    "            logits = HEADS[lbl](x).detach().cpu().numpy()\n",
    "            Tsp = max(float(temps_spec.get(lbl, 1.0)), 1e-3)\n",
    "            p = 1. / (1. + np.exp(-logits / Tsp))\n",
    "            cols.append(p)\n",
    "        probs[i:i+batch] = np.stack(cols, axis=1).astype(np.float32)\n",
    "    return probs\n",
    "\n",
    "print(\"\\n[T2] Computing specialist-calibrated probabilities on TEST…\")\n",
    "FUSED = compute_fused(SMI, X, batch=32)\n",
    "P_spec_cal = probs_specialist_calibrated(FUSED, batch=64)\n",
    "np.save(DIR_PROBS/\"test_probs_specialist_calibrated.npy\", P_spec_cal)\n",
    "print(f\"[Saved] {DIR_PROBS/'test_probs_specialist_calibrated.npy'}  shape={P_spec_cal.shape}\")\n",
    "\n",
    "# ====================================================================\n",
    "# T3. C1-style metrics & PR/ROC curves (TEST, specialist-calibrated)\n",
    "# ====================================================================\n",
    "AP_per   = per_label_ap(Y, P_spec_cal, OBS)\n",
    "AP_macro = float(np.mean(AP_per)) if len(AP_per) else 0.0\n",
    "AP_micro = micro_ap(Y, P_spec_cal, OBS)\n",
    "ROC_per  = per_label_roc(Y, P_spec_cal, OBS)\n",
    "ROC_macro= float(np.nanmean(ROC_per)) if np.isfinite(ROC_per).any() else float(\"nan\")\n",
    "\n",
    "# Export PR/ROC curve points (+ prevalence baseline for reference)\n",
    "if _HAVE_SK:\n",
    "    for j, lbl in enumerate(LABELS):\n",
    "        m = OBS[:, j]\n",
    "        yt, ys = Y[m, j], P_spec_cal[m, j]\n",
    "        # PR\n",
    "        prec, rec, thr = precision_recall_curve(yt, ys)\n",
    "        df_pr = pd.DataFrame({\"precision\":prec, \"recall\":rec, \"threshold\": np.r_[thr, np.nan]})\n",
    "        df_pr.to_csv(DIR_PR_CAL/f\"{lbl}.csv\", index=False)\n",
    "        # ROC\n",
    "        if len(np.unique(yt)) >= 2:\n",
    "            fpr, tpr, thr2 = roc_curve(yt, ys)\n",
    "            pd.DataFrame({\"fpr\":fpr, \"tpr\":tpr, \"threshold\":thr2}).to_csv(DIR_ROC_CAL/f\"{lbl}.csv\", index=False)\n",
    "\n",
    "# per-label metrics base sheet (fill minimal fields now; op metrics later)\n",
    "df_per = pd.DataFrame({\"label\": LABELS, \"AP\": AP_per, \"ROC_AUC\": ROC_per})\n",
    "df_per.to_csv(DIR_C1/\"test_per_label_metrics_specialist.csv\", index=False)\n",
    "\n",
    "# aggregates\n",
    "agg = {\n",
    "    \"macro_AP\": AP_macro, \"micro_AP\": AP_micro, \"macro_ROC_AUC\": (None if (isinstance(ROC_macro, float) and not np.isfinite(ROC_macro)) else ROC_macro),\n",
    "    \"labels\": LABELS\n",
    "}\n",
    "(DIR_C1/\"test_aggregates_specialist.json\").write_text(json.dumps(agg, indent=2))\n",
    "\n",
    "print(\"\\n[T3] TEST metrics (specialist-calibrated):\")\n",
    "print(f\"[AP] macro={AP_macro:.4f}  micro={AP_micro:.4f}\")\n",
    "print(f\"[ROC-AUC] macro={ROC_macro:.4f}  finite_labels={(np.isfinite(ROC_per)).sum()}/{L}\")\n",
    "print(f\"Saved per-label metrics → {DIR_C1/'test_per_label_metrics_specialist.csv'}\")\n",
    "print(f\"PR curves → {DIR_PR_CAL}  |  ROC curves → {DIR_ROC_CAL}\")\n",
    "\n",
    "# ===================================================\n",
    "# T4. C2-style bootstrap 95% CIs (AP per-label, agg)\n",
    "# ===================================================\n",
    "B = 1000\n",
    "SEED = 1337\n",
    "rng = np.random.default_rng(SEED)\n",
    "idx = np.arange(N)\n",
    "ap_per_all   = np.zeros((B, L), dtype=float)\n",
    "ap_macro_all = np.zeros(B, dtype=float)\n",
    "ap_micro_all = np.zeros(B, dtype=float)\n",
    "npos_all     = np.zeros((B, L), dtype=float)\n",
    "\n",
    "for b in range(B):\n",
    "    bs = rng.choice(idx, size=N, replace=True)\n",
    "    yb, pb, mb = Y[bs], P_spec_cal[bs], OBS[bs]\n",
    "    ap_b = per_label_ap(yb, pb, mb)\n",
    "    ap_per_all[b]   = ap_b\n",
    "    ap_macro_all[b] = float(np.mean(ap_b))\n",
    "    ap_micro_all[b] = micro_ap(yb, pb, mb)\n",
    "    npos_all[b]     = (yb * mb).sum(axis=0)\n",
    "    if (b+1) % max(1, B//10) == 0:\n",
    "        print(f\"[Bootstrap] {b+1}/{B}\")\n",
    "\n",
    "def _ci(x, lo=2.5, hi=97.5):\n",
    "    return float(np.mean(x)), float(np.percentile(x, lo)), float(np.percentile(x, hi))\n",
    "\n",
    "rows = []\n",
    "for j, lbl in enumerate(LABELS):\n",
    "    mean, lo, hi = _ci(ap_per_all[:, j])\n",
    "    rows.append({\"label\": lbl, \"AP_mean\": mean, \"AP_CI_lo\": lo, \"AP_CI_hi\": hi, \"npos_mean\": float(np.mean(npos_all[:, j]))})\n",
    "df_boot = pd.DataFrame(rows).sort_values(\"AP_mean\", ascending=False)\n",
    "df_boot.to_csv(DIR_BOOT/\"test_bootstrap_ap_per_label.csv\", index=False)\n",
    "\n",
    "macro_mean, macro_lo, macro_hi = _ci(ap_macro_all)\n",
    "micro_mean, micro_lo, micro_hi = _ci(ap_micro_all)\n",
    "boot_agg = {\n",
    "    \"B\": int(B), \"seed\": int(SEED),\n",
    "    \"macro_AP\": {\"mean\": macro_mean, \"ci_lo\": macro_lo, \"ci_hi\": macro_hi},\n",
    "    \"micro_AP\": {\"mean\": micro_mean, \"ci_lo\": micro_lo, \"ci_hi\": micro_hi},\n",
    "    \"labels\": LABELS\n",
    "}\n",
    "(DIR_BOOT/\"test_bootstrap_aggregates.json\").write_text(json.dumps(boot_agg, indent=2))\n",
    "print(\"\\n[T4] TEST bootstrap:\")\n",
    "print(f\"[macro AP] mean={macro_mean:.4f}  95%CI=({macro_lo:.4f}, {macro_hi:.4f})\")\n",
    "print(f\"[micro AP] mean={micro_mean:.4f}  95%CI=({micro_lo:.4f}, {micro_hi:.4f})\")\n",
    "\n",
    "# ======================================================\n",
    "# T5. T1 table (TEST, specialist-only, with AP CIs & ROC)\n",
    "# ======================================================\n",
    "df_metrics = pd.read_csv(DIR_C1/\"test_per_label_metrics_specialist.csv\")\n",
    "boot_per   = pd.read_csv(DIR_BOOT/\"test_bootstrap_ap_per_label.csv\")\n",
    "agg_spec   = json.loads((DIR_C1/\"test_aggregates_specialist.json\").read_text())\n",
    "boot_agg   = json.loads((DIR_BOOT/\"test_bootstrap_aggregates.json\").read_text())\n",
    "\n",
    "# Merge + prefer AP_mean in table for CI consistency\n",
    "df_t1 = df_metrics.merge(boot_per[[\"label\",\"AP_mean\",\"AP_CI_lo\",\"AP_CI_hi\"]], on=\"label\", how=\"left\")\n",
    "if \"AP_mean\" in df_t1.columns:\n",
    "    df_t1[\"AP\"] = df_t1[\"AP_mean\"]; df_t1.drop(columns=[\"AP_mean\"], inplace=True)\n",
    "\n",
    "# Round & order\n",
    "cols = [\"label\",\"AP\",\"AP_CI_lo\",\"AP_CI_hi\",\"ROC_AUC\",\"accuracy\",\"recall\",\"specificity\",\"precision\",\"F1\",\"thr\",\"TP\",\"FP\",\"TN\",\"FN\"]\n",
    "df_t1 = df_t1.reindex(columns=[c for c in cols if c in df_t1.columns])\n",
    "for c in [\"AP\",\"AP_CI_lo\",\"AP_CI_hi\",\"ROC_AUC\"]:\n",
    "    if c in df_t1: df_t1[c] = df_t1[c].astype(float).round(4)\n",
    "\n",
    "# Append Macro/Micro rows\n",
    "macro_row = {\n",
    "    \"label\":\"Macro\",\n",
    "    \"AP\": round(float(boot_agg[\"macro_AP\"][\"mean\"]),4),\n",
    "    \"AP_CI_lo\": round(float(boot_agg[\"macro_AP\"][\"ci_lo\"]),4),\n",
    "    \"AP_CI_hi\": round(float(boot_agg[\"macro_AP\"][\"ci_hi\"]),4),\n",
    "    \"ROC_AUC\": round(float(agg_spec.get(\"macro_ROC_AUC\", np.nan)),4) if agg_spec.get(\"macro_ROC_AUC\", None) is not None else np.nan,\n",
    "}\n",
    "micro_row = {\n",
    "    \"label\":\"Micro\",\n",
    "    \"AP\": round(float(boot_agg[\"micro_AP\"][\"mean\"]),4),\n",
    "    \"AP_CI_lo\": round(float(boot_agg[\"micro_AP\"][\"ci_lo\"]),4),\n",
    "    \"AP_CI_hi\": round(float(boot_agg[\"micro_AP\"][\"ci_hi\"]),4),\n",
    "}\n",
    "df_t1_out = pd.concat([df_t1, pd.DataFrame([macro_row]), pd.DataFrame([micro_row])], ignore_index=True)\n",
    "\n",
    "# Save CSV + MD\n",
    "(df_t1_out).to_csv(DIR_T1/\"T1_test_specialist.csv\", index=False)\n",
    "(DIR_T1/\"T1_test_specialist.md\").write_text(df_t1_out[[\"label\",\"AP\",\"AP_CI_lo\",\"AP_CI_hi\",\"ROC_AUC\"]].to_markdown(index=False))\n",
    "print(f\"\\n[T5] Saved T1_test → {DIR_T1/'T1_test_specialist.csv'} and .md\")\n",
    "\n",
    "# =================================================\n",
    "# T6. F1 (macro/micro CIs) + F1b (per-assay CIs)\n",
    "# =================================================\n",
    "# F1\n",
    "means = [boot_agg[\"macro_AP\"][\"mean\"], boot_agg[\"micro_AP\"][\"mean\"]]\n",
    "err_lo = [means[0] - boot_agg[\"macro_AP\"][\"ci_lo\"], means[1] - boot_agg[\"micro_AP\"][\"ci_lo\"]]\n",
    "err_hi = [boot_agg[\"macro_AP\"][\"ci_hi\"] - means[0], boot_agg[\"micro_AP\"][\"ci_hi\"] - means[1]]\n",
    "yerr = np.array([err_lo, err_hi])\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.bar(np.arange(2), means, yerr=yerr, capsize=6)\n",
    "plt.xticks(np.arange(2), [\"Macro AP\",\"Micro AP\"])\n",
    "plt.ylim(0,1.0)\n",
    "plt.ylabel(\"PR-AUC\")\n",
    "plt.title(\"TEST — Macro & Micro PR-AUC (95% CI)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(DIR_F1/\"F1_test_macro_micro_pr_auc_ci.png\", dpi=200)\n",
    "plt.savefig(DIR_F1/\"F1_test_macro_micro_pr_auc_ci.pdf\")\n",
    "plt.close()\n",
    "print(f\"[T6] F1 saved → {DIR_F1}\")\n",
    "\n",
    "# F1b\n",
    "tbl = boot_per.merge(pd.DataFrame({\"label\": LABELS}), on=\"label\", how=\"right\").sort_values(\"AP_mean\", ascending=False).reset_index(drop=True)\n",
    "means = tbl[\"AP_mean\"].to_numpy()\n",
    "err_lo = means - tbl[\"AP_CI_lo\"].to_numpy()\n",
    "err_hi = tbl[\"AP_CI_hi\"].to_numpy() - means\n",
    "yerr = np.vstack([err_lo, err_hi])\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(np.arange(len(tbl)), means, yerr=yerr, capsize=3)\n",
    "plt.xticks(np.arange(len(tbl)), tbl[\"label\"].tolist(), rotation=45, ha=\"right\")\n",
    "plt.ylim(0,1.0)\n",
    "plt.ylabel(\"PR-AUC\")\n",
    "plt.title(\"TEST — Per-assay PR-AUC with 95% Bootstrap CIs\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(DIR_F1b/\"F1b_test_per_assay_ap_ci.png\", dpi=200)\n",
    "plt.savefig(DIR_F1b/\"F1b_test_per_assay_ap_ci.pdf\")\n",
    "plt.close()\n",
    "print(f\"[T6] F1b saved → {DIR_F1b}\")\n",
    "\n",
    "# ============================================================\n",
    "# T7. F2 — PR grid: calibrated specialist vs UNCALIBRATED\n",
    "# ============================================================\n",
    "@torch.no_grad()\n",
    "def probs_specialist_uncalibrated(fused: np.ndarray, batch: int = 64) -> np.ndarray:\n",
    "    probs = np.zeros((fused.shape[0], L), dtype=np.float32)\n",
    "    for i in range(0, fused.shape[0], batch):\n",
    "        x = torch.tensor(fused[i:i+batch], dtype=torch.float32, device=device)\n",
    "        cols = []\n",
    "        for lbl in LABELS:\n",
    "            logits = HEADS[lbl](x).detach().cpu().numpy()\n",
    "            p = 1. / (1. + np.exp(-logits))  # T=1\n",
    "            cols.append(p)\n",
    "        probs[i:i+batch] = np.stack(cols, axis=1).astype(np.float32)\n",
    "    return probs\n",
    "\n",
    "print(\"\\n[T7] Computing UNCALIBRATED specialist probabilities …\")\n",
    "P_spec_uncal = probs_specialist_uncalibrated(FUSED, batch=64)\n",
    "\n",
    "# Export PR curves (uncal)\n",
    "if _HAVE_SK:\n",
    "    for j, lbl in enumerate(LABELS):\n",
    "        m = OBS[:, j]\n",
    "        yt, ys = Y[m, j], P_spec_uncal[m, j]\n",
    "        if yt.sum() == 0: continue\n",
    "        prec, rec, thr = precision_recall_curve(yt, ys)\n",
    "        pd.DataFrame({\"precision\":prec, \"recall\":rec, \"threshold\": np.r_[thr, np.nan]}).to_csv(DIR_PR_UNCAL/f\"{lbl}.csv\", index=False)\n",
    "\n",
    "# Plot grid\n",
    "minority = {\"NR-ER\", \"NR-PPAR-gamma\", \"SR-p53\", \"SR-HSE\"}\n",
    "nrows, ncols = 3, 4\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(14,9), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "for j, lbl in enumerate(LABELS):\n",
    "    ax = axes[j]\n",
    "    m = OBS[:, j]\n",
    "    yt = Y[m, j]\n",
    "    if yt.sum() == 0:\n",
    "        ax.text(0.5,0.5,\"No positives\", ha=\"center\", va=\"center\"); ax.set_title(lbl, fontsize=9); continue\n",
    "    # Calibrated\n",
    "    pc, rc, _ = precision_recall_curve(yt, P_spec_cal[m, j])\n",
    "    ap_c = ap_masked(Y[:, j], P_spec_cal[:, j], OBS[:, j])\n",
    "    # Uncal\n",
    "    pu, ru, _ = precision_recall_curve(yt, P_spec_uncal[m, j])\n",
    "    ap_u = ap_masked(Y[:, j], P_spec_uncal[:, j], OBS[:, j])\n",
    "    prev = yt.mean()  # prevalence baseline\n",
    "    is_min = lbl in minority\n",
    "    lw = 2.5 if is_min else 1.5\n",
    "    ax.plot(rc, pc, label=f\"Cal (AP={ap_c:.3f})\", linewidth=lw)\n",
    "    ax.plot(ru, pu, linestyle=\"--\", label=f\"Uncal (AP={ap_u:.3f})\", linewidth=lw)\n",
    "    ax.hlines(prev, 0, 1, linestyles=\"dotted\")  # random baseline\n",
    "    ax.set_xlim(0,1); ax.set_ylim(0,1); ax.set_title(lbl + (\" ★\" if is_min else \"\"), fontsize=9)\n",
    "    if j % ncols == 0: ax.set_ylabel(\"Precision\")\n",
    "    if j // ncols == nrows-1: ax.set_xlabel(\"Recall\")\n",
    "    if j == 0: ax.legend(fontsize=8, loc=\"lower left\")\n",
    "fig.suptitle(\"TEST — PR Curves: Specialist (calibrated) vs Uncalibrated\\n★ minority assays; dotted line = prevalence baseline\", fontsize=12)\n",
    "plt.tight_layout(rect=[0,0.03,1,0.95])\n",
    "plt.savefig(DIR_F2/\"F2_test_pr_grid_cal_vs_uncal.png\", dpi=200)\n",
    "plt.savefig(DIR_F2/\"F2_test_pr_grid_cal_vs_uncal.pdf\")\n",
    "plt.close()\n",
    "print(f\"[T7] F2 saved → {DIR_F2}\")\n",
    "\n",
    "# ============================================================\n",
    "# T8. Spec (cal) vs BLEND (probs, metrics, F2b, F2c, aggregates)\n",
    "# ============================================================\n",
    "temps_shared = json.loads((CAL/\"temps_shared.json\").read_text()) if (CAL/\"temps_shared.json\").exists() else {}\n",
    "alpha = None\n",
    "for f in [\"thresholds_blend_v2.json\",\"thresholds_blend.json\"]:\n",
    "    p = CAL / f\n",
    "    if p.exists():\n",
    "        blob = json.loads(p.read_text()); alpha = float(blob.get(\"alpha\", 0.8)); break\n",
    "if alpha is None: alpha = 0.8\n",
    "\n",
    "@torch.no_grad()\n",
    "def fused_and_shared_logits(smiles: List[str], desc: np.ndarray, batch: int = 32) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    # reuse fusion object & encoders from earlier\n",
    "    logits_out = np.zeros((len(smiles), L), dtype=np.float32)\n",
    "    fused_out  = np.zeros((len(smiles), 768), dtype=np.float32)\n",
    "    off = 0\n",
    "    for i in range(0, len(smiles), batch):\n",
    "        b_smi = smiles[i:i+batch]\n",
    "        b_desc= torch.tensor(desc[i:i+batch], dtype=torch.float32, device=device)\n",
    "        logits, fused = fusion(b_smi, b_desc)\n",
    "        n = len(b_smi)\n",
    "        logits_out[off:off+n] = logits.detach().cpu().numpy()\n",
    "        fused_out[off:off+n]  = fused.detach().cpu().numpy()\n",
    "        off += n\n",
    "    return fused_out, logits_out\n",
    "\n",
    "@torch.no_grad()\n",
    "def probs_blend(FUSED: np.ndarray, LOGITS_SH: np.ndarray, batch: int = 64) -> np.ndarray:\n",
    "    out = np.zeros((FUSED.shape[0], L), dtype=np.float32)\n",
    "    for i in range(0, FUSED.shape[0], batch):\n",
    "        x = torch.tensor(FUSED[i:i+batch], dtype=torch.float32, device=device)\n",
    "        # specialist (with temps)\n",
    "        spec_cols = []\n",
    "        for lbl in LABELS:\n",
    "            log_spec = HEADS[lbl](x).detach().cpu().numpy()\n",
    "            Tsp = max(float(temps_spec.get(lbl, 1.0)), 1e-3)\n",
    "            psp = 1. / (1. + np.exp(-log_spec / Tsp))\n",
    "            spec_cols.append(psp)\n",
    "        P_spec = np.stack(spec_cols, axis=1).astype(np.float32)\n",
    "        # shared (with temps_shared)\n",
    "        T_sh = np.array([max(float(temps_shared.get(lbl, 1.0)), 1e-3) for lbl in LABELS], dtype=np.float32)\n",
    "        log_sh = LOGITS_SH[i:i+batch]\n",
    "        P_sh = 1. / (1. + np.exp(-(log_sh / T_sh[None, :])))\n",
    "        out[i:i+batch] = alpha * P_spec + (1.0 - alpha) * P_sh\n",
    "    return out\n",
    "\n",
    "print(f\"\\n[T8] Computing BLEND (alpha={alpha:.2f}) …\")\n",
    "FUSED2, LOG_SH = fused_and_shared_logits(SMI, X, batch=32)  # reuse encoders/fusion\n",
    "P_blend = probs_blend(FUSED2, LOG_SH, batch=64)\n",
    "np.save(DIR_PROBS/\"test_probs_blend.npy\", P_blend)\n",
    "\n",
    "# Export PR curves (blend)\n",
    "if _HAVE_SK:\n",
    "    for j, lbl in enumerate(LABELS):\n",
    "        m = OBS[:, j]\n",
    "        yt, ys = Y[m, j], P_blend[m, j]\n",
    "        if yt.sum() == 0: continue\n",
    "        prec, rec, thr = precision_recall_curve(yt, ys)\n",
    "        pd.DataFrame({\"precision\":prec, \"recall\":rec, \"threshold\": np.r_[thr, np.nan]}).to_csv(DIR_PR_BLEND/f\"{lbl}.csv\", index=False)\n",
    "\n",
    "# Metrics & deltas\n",
    "AP_spec = per_label_ap(Y, P_spec_cal, OBS)\n",
    "AP_blnd = per_label_ap(Y, P_blend, OBS)\n",
    "APm_spec, APm_blnd = float(np.mean(AP_spec)), float(np.mean(AP_blnd))\n",
    "APu_spec, APu_blnd = micro_ap(Y, P_spec_cal, OBS), micro_ap(Y, P_blend, OBS)\n",
    "ROC_spec = per_label_roc(Y, P_spec_cal, OBS); ROC_blnd = per_label_roc(Y, P_blend, OBS)\n",
    "ROCm_spec = float(np.nanmean(ROC_spec)) if np.isfinite(ROC_spec).any() else float(\"nan\")\n",
    "ROCm_blnd = float(np.nanmean(ROC_blnd)) if np.isfinite(ROC_blnd).any() else float(\"nan\")\n",
    "\n",
    "df_comp = pd.DataFrame({\n",
    "    \"label\": LABELS,\n",
    "    \"AP_spec\": AP_spec,\n",
    "    \"AP_blend\": AP_blnd,\n",
    "    \"AP_delta\": AP_blnd - AP_spec,\n",
    "    \"ROC_spec\": ROC_spec,\n",
    "    \"ROC_blend\": ROC_blnd,\n",
    "    \"ROC_delta\": ROC_blnd - ROC_spec,\n",
    "}).sort_values(\"AP_delta\", ascending=False)\n",
    "df_comp.to_csv(DIR_F2b/\"test_spec_vs_blend_metrics.csv\", index=False)\n",
    "\n",
    "agg_comp = {\n",
    "    \"macro_AP\": {\"specialist\": APm_spec, \"blend\": APm_blnd, \"delta\": APm_blnd - APm_spec},\n",
    "    \"micro_AP\": {\"specialist\": APu_spec, \"blend\": APu_blnd, \"delta\": APu_blnd - APu_spec},\n",
    "    \"macro_ROC_AUC\": {\n",
    "        \"specialist\": (None if (isinstance(ROCm_spec, float) and not np.isfinite(ROCm_spec)) else ROCm_spec),\n",
    "        \"blend\": (None if (isinstance(ROCm_blnd, float) and not np.isfinite(ROCm_blnd)) else ROCm_blnd),\n",
    "        \"delta\": (None if (not (np.isfinite(ROCm_spec) and np.isfinite(ROCm_blnd))) else (ROCm_blnd - ROCm_spec))\n",
    "    },\n",
    "    \"alpha\": float(alpha),\n",
    "}\n",
    "(DIR_F2b/\"test_spec_vs_blend_aggregates.json\").write_text(json.dumps(agg_comp, indent=2))\n",
    "print(\"\\n[T8] Spec vs Blend aggregates:\")\n",
    "print(_roundish(agg_comp, nd=4))\n",
    "\n",
    "# F2b grid plot (spec-cal vs blend), with prevalence baseline\n",
    "minority = {\"NR-ER\", \"NR-PPAR-gamma\", \"SR-p53\", \"SR-HSE\"}\n",
    "nrows, ncols = 3, 4\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(14,9), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "for j, lbl in enumerate(LABELS):\n",
    "    ax = axes[j]\n",
    "    m = OBS[:, j]\n",
    "    yt = Y[m, j]\n",
    "    if yt.sum() == 0:\n",
    "        ax.text(0.5,0.5,\"No positives\", ha=\"center\", va=\"center\"); ax.set_title(lbl, fontsize=9); continue\n",
    "    pc, rc, _ = precision_recall_curve(yt, P_spec_cal[m, j])\n",
    "    ap_c = ap_masked(Y[:, j], P_spec_cal[:, j], OBS[:, j])\n",
    "    pb, rb, _ = precision_recall_curve(yt, P_blend[m, j])\n",
    "    ap_b = ap_masked(Y[:, j], P_blend[:, j], OBS[:, j])\n",
    "    prev = yt.mean()\n",
    "    is_min = lbl in minority\n",
    "    lw = 2.5 if is_min else 1.5\n",
    "    ax.plot(rc, pc, label=f\"Specialist (AP={ap_c:.3f})\", linewidth=lw)\n",
    "    ax.plot(rb, pb, linestyle=\"--\", label=f\"Blend (AP={ap_b:.3f})\", linewidth=lw)\n",
    "    ax.hlines(prev, 0, 1, linestyles=\"dotted\")\n",
    "    ax.set_xlim(0,1); ax.set_ylim(0,1); ax.set_title(lbl + (\" ★\" if is_min else \"\"), fontsize=9)\n",
    "    if j % ncols == 0: ax.set_ylabel(\"Precision\")\n",
    "    if j // ncols == nrows-1: ax.set_xlabel(\"Recall\")\n",
    "    if j == 0: ax.legend(fontsize=8, loc=\"lower left\")\n",
    "fig.suptitle(\"TEST — PR Curves: Specialist (calibrated) vs BLEND\\n★ minority assays; dotted line = prevalence baseline\", fontsize=12)\n",
    "plt.tight_layout(rect=[0,0.03,1,0.95])\n",
    "plt.savefig(DIR_F2b/\"F2b_test_pr_grid_spec_vs_blend.png\", dpi=200)\n",
    "plt.savefig(DIR_F2b/\"F2b_test_pr_grid_spec_vs_blend.pdf\")\n",
    "plt.close()\n",
    "print(f\"[T8] F2b saved → {DIR_F2b}\")\n",
    "\n",
    "# Δ(AP) bars (F2c)\n",
    "tbl = df_comp.sort_values(\"AP_delta\", ascending=True).reset_index(drop=True)\n",
    "vals = tbl[\"AP_delta\"].to_numpy()\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(np.arange(len(tbl)), vals)\n",
    "plt.axhline(0.0, linestyle=\"--\")\n",
    "plt.xticks(np.arange(len(tbl)), tbl[\"label\"].tolist(), rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Δ AP (Blend − Specialist)\")\n",
    "plt.title(\"TEST — Per-assay AP Gain/Loss: Blend vs Specialist\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(DIR_F2c/\"F2c_test_spec_vs_blend_delta_ap.png\", dpi=200)\n",
    "plt.savefig(DIR_F2c/\"F2c_test_spec_vs_blend_delta_ap.pdf\")\n",
    "plt.close()\n",
    "print(f\"[T8] F2c saved → {DIR_F2c}\")\n",
    "\n",
    "# =====================================================================\n",
    "# T9. Operating-point table on TEST using VAL-selected thresholds (blend)\n",
    "# =====================================================================\n",
    "# Load blend thresholds from calibration (VAL-fitted). Prefer th_fbeta15 (or th_f1 if desired).\n",
    "thr_blob = None\n",
    "thr_file_used = None\n",
    "for f in [\"thresholds_blend_v2.json\", \"thresholds_blend.json\"]:\n",
    "    p = CAL / f\n",
    "    if p.exists():\n",
    "        thr_blob = json.loads(p.read_text()); thr_file_used = p.name; break\n",
    "assert thr_blob is not None, \"No thresholds_blend*.json found.\"\n",
    "\n",
    "thr_mode = \"th_fbeta15\"  # or \"th_f1\"\n",
    "thr_vec = np.array([float(thr_blob[\"thresholds\"][lbl][thr_mode]) for lbl in LABELS], dtype=float)\n",
    "\n",
    "df_op = conf_mat_metrics_at_threshold(Y, P_blend, OBS, thr_vec)\n",
    "df_op.to_csv(DIR_OP/\"T1_op_test_blend.csv\", index=False)\n",
    "\n",
    "# Macro averages at operating point + micro F1\n",
    "macro_acc = float(df_op[\"accuracy\"].mean())\n",
    "macro_rec = float(df_op[\"recall\"].mean())\n",
    "macro_spe = float(df_op[\"specificity\"].mean())\n",
    "macro_pre = float(df_op[\"precision\"].mean())\n",
    "macro_f1  = float(df_op[\"F1\"].mean())\n",
    "\n",
    "# Micro (pool obs)\n",
    "m = OBS.astype(bool)\n",
    "yp = (P_blend >= thr_vec[None, :])\n",
    "yt = Y.astype(int)\n",
    "yt_micro = yt[m]; yp_micro = yp[m]\n",
    "micro_f1 = float(f1_score(yt_micro, yp_micro)) if _HAVE_SK else None\n",
    "\n",
    "# Bootstrap CIs for F1 (macro & micro) at operating point\n",
    "B2 = 1000; rng2 = np.random.default_rng(2027); idx2 = np.arange(N)\n",
    "macro_f1_all, micro_f1_all = np.zeros(B2), np.zeros(B2)\n",
    "for b in range(B2):\n",
    "    bs = rng2.choice(idx2, size=N, replace=True)\n",
    "    yb, pb, mb = Y[bs], P_blend[bs], OBS[bs]\n",
    "    dfb = conf_mat_metrics_at_threshold(yb, pb, mb, thr_vec)\n",
    "    macro_f1_all[b] = float(dfb[\"F1\"].mean())\n",
    "    m2 = mb.astype(bool)\n",
    "    yp2 = (pb >= thr_vec[None, :])\n",
    "    yt2 = yb.astype(int)\n",
    "    if _HAVE_SK:\n",
    "        micro_f1_all[b] = float(f1_score(yt2[m2], yp2[m2]))\n",
    "    else:\n",
    "        micro_f1_all[b] = np.nan\n",
    "\n",
    "def _ci3(x): return float(np.mean(x)), float(np.percentile(x,2.5)), float(np.percentile(x,97.5))\n",
    "\n",
    "macro_f1_mean, macro_f1_lo, macro_f1_hi = _ci3(macro_f1_all)\n",
    "micro_f1_mean, micro_f1_lo, micro_f1_hi = _ci3(micro_f1_all)\n",
    "\n",
    "op_agg = {\n",
    "    \"thresholds_file\": thr_file_used,\n",
    "    \"threshold_key\": thr_mode,\n",
    "    \"macro\": {\"accuracy\": macro_acc, \"recall\": macro_rec, \"specificity\": macro_spe, \"precision\": macro_pre, \"F1_mean\": macro_f1_mean, \"F1_CI_lo\": macro_f1_lo, \"F1_CI_hi\": macro_f1_hi},\n",
    "    \"micro\": {\"F1_mean\": micro_f1_mean, \"F1_CI_lo\": micro_f1_lo, \"F1_CI_hi\": micro_f1_hi},\n",
    "}\n",
    "(DIR_OP/\"T1_op_test_aggregates.json\").write_text(json.dumps(op_agg, indent=2))\n",
    "print(\"\\n[T9] Operating-point table saved:\")\n",
    "print(f\" - Table: {DIR_OP/'T1_op_test_blend.csv'}\")\n",
    "print(f\" - Aggregates (F1 CIs): {DIR_OP/'T1_op_test_aggregates.json'}\")\n",
    "\n",
    "# =====================================================================================\n",
    "# T10. (Nice-to-have) Paired bootstrap CIs for Δ(AP) (spec vs blend), macro/micro & per-assay\n",
    "# =====================================================================================\n",
    "B3 = 1000; rng3 = np.random.default_rng(99); idx3 = np.arange(N)\n",
    "delta_macro, delta_micro = np.zeros(B3), np.zeros(B3)\n",
    "delta_per = np.zeros((B3, L), dtype=float)\n",
    "for b in range(B3):\n",
    "    bs = rng3.choice(idx3, size=N, replace=True)\n",
    "    yb, ps, pb, mb = Y[bs], P_spec_cal[bs], P_blend[bs], OBS[bs]\n",
    "    ap_s = per_label_ap(yb, ps, mb)\n",
    "    ap_b = per_label_ap(yb, pb, mb)\n",
    "    delta_per[b] = ap_b - ap_s\n",
    "    delta_macro[b] = float(np.mean(ap_b) - np.mean(ap_s))\n",
    "    delta_micro[b] = micro_ap(yb, pb, mb) - micro_ap(yb, ps, mb)\n",
    "\n",
    "def _cis(x): return float(np.mean(x)), float(np.percentile(x,2.5)), float(np.percentile(x,97.5))\n",
    "mac_mean, mac_lo, mac_hi = _cis(delta_macro)\n",
    "mic_mean, mic_lo, mic_hi = _cis(delta_micro)\n",
    "rows = [{\"label\": lbl, \"delta_AP_mean\": float(np.mean(delta_per[:, j])), \"delta_AP_CI_lo\": float(np.percentile(delta_per[:, j],2.5)), \"delta_AP_CI_hi\": float(np.percentile(delta_per[:, j],97.5))} for j, lbl in enumerate(LABELS)]\n",
    "pd.DataFrame(rows).to_csv(DIR_BOOT_DEL/\"test_bootstrap_delta_ap_per_label.csv\", index=False)\n",
    "json.dump({\n",
    "    \"macro_delta_AP\": {\"mean\": mac_mean, \"ci_lo\": mac_lo, \"ci_hi\": mac_hi},\n",
    "    \"micro_delta_AP\": {\"mean\": mic_mean, \"ci_lo\": mic_lo, \"ci_hi\": mic_hi}\n",
    "}, open(DIR_BOOT_DEL/\"test_bootstrap_delta_ap_aggregates.json\",\"w\"), indent=2)\n",
    "print(\"\\n[T10] Paired Δ(AP) CIs saved →\", DIR_BOOT_DEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9391c29a",
   "metadata": {},
   "source": [
    "### Clean figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0032fbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving PNGs to: D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ1\\test\\figs\n",
      "Saved T1_test_per_assay_metrics_table.png\n",
      "Saved F1b_test_per_assay_ap_ci.png\n",
      "No 'prevalence' column detected. Skipping Prev.\n",
      "Saved F2_test_pr_grid_cal_vs_uncal.png\n",
      "Saved F2b_test_pr_grid_spec_vs_blend.png\n",
      "Saved F2c_test_spec_vs_blend_delta_ap.png\n",
      "Saved F3_test_roc_grid.png\n",
      "Saved T1_op_test_blend_table.png\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# RQ1 Figure & Table Generator (PNG-only, clean journal style)\n",
    "# Saves to: v7/v7_Eval/RQ1/test/figs\n",
    "# Requires: pandas, numpy, matplotlib\n",
    "# ==============================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import glob, json, re, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# ------------------------------- STYLE ----------------------------------------\n",
    "DPI = 300\n",
    "FONT_SIZE = 11\n",
    "LABEL_SIZE = 12\n",
    "TITLE_SIZE = 13\n",
    "LINE_WIDTH = 2.0\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    \"figure.dpi\": DPI,\n",
    "    \"savefig.dpi\": DPI,\n",
    "    \"font.size\": FONT_SIZE,\n",
    "    \"axes.labelsize\": LABEL_SIZE,\n",
    "    \"axes.titlesize\": TITLE_SIZE,\n",
    "    \"legend.fontsize\": FONT_SIZE,\n",
    "    \"xtick.labelsize\": FONT_SIZE,\n",
    "    \"ytick.labelsize\": FONT_SIZE,\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.alpha\": 0.25,\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.spines.right\": False,\n",
    "})\n",
    "\n",
    "# Sizes\n",
    "FIGSIZE_GRID = (12, 8.5)   # 3x4 small multiples\n",
    "FIGSIZE_BAR  = (10, 5.5)   # dot-whisker / delta bars\n",
    "FIGWIDTH_TAB = 11.0        # tables; height auto-scales by rows\n",
    "\n",
    "# Titles\n",
    "TITLE_T1   = \"T1 — Per-assay metrics (TEST)\"\n",
    "TITLE_F1B  = \"F1b — Per-assay Average Precision with 95% CIs (TEST)\"\n",
    "TITLE_F2   = \"F2 — Precision–Recall Curves (Calibrated vs Uncalibrated, Specialist; TEST)\"\n",
    "TITLE_F2B  = \"F2b — Precision–Recall (Specialist vs Blend; TEST)\"\n",
    "TITLE_F2C  = \"F2c — Δ(AP) = Blend − Specialist with 95% CIs (TEST)\"\n",
    "TITLE_F3   = \"F3 — ROC Curves (TEST)\"\n",
    "TITLE_T1OP = \"T1_op — Operating Points at VAL-selected Thresholds (Blend on TEST)\"\n",
    "\n",
    "# Outputs (PNG only)\n",
    "OUT = {\n",
    "    \"T1_table\":   \"T1_test_per_assay_metrics_table\",\n",
    "    \"F1b\":        \"F1b_test_per_assay_ap_ci\",\n",
    "    \"Prev\":       \"Prev_test_class_prevalence\",\n",
    "    \"F2_grid\":    \"F2_test_pr_grid_cal_vs_uncal\",\n",
    "    \"F2b_grid\":   \"F2b_test_pr_grid_spec_vs_blend\",\n",
    "    \"F2c_delta\":  \"F2c_test_spec_vs_blend_delta_ap\",\n",
    "    \"F3_grid\":    \"F3_test_roc_grid\",\n",
    "    \"T1op_table\": \"T1_op_test_blend_table\",\n",
    "}\n",
    "\n",
    "# Bold these in tables\n",
    "BOLD_ASSAYS = {\"NR-AR-LBD\", \"NR-PPAR-gamma\", \"SR-ATAD5\"}\n",
    "\n",
    "# ------------------------------- PATHS ----------------------------------------\n",
    "from pathlib import Path\n",
    "BASE_DIR = Path(\"v7/v7_Eval/RQ1/test\")\n",
    "FIGS_DIR = BASE_DIR / \"figs\"\n",
    "\n",
    "PATHS = {\n",
    "    \"T1_metrics_csv\":      BASE_DIR / \"C1_metrics\" / \"test_per_label_metrics_specialist.csv\",\n",
    "    \"AP_bootstrap_csv\":    BASE_DIR / \"C2_bootstrap\" / \"test_bootstrap_ap_per_label.csv\",\n",
    "    \"PR_curves_cal_dir\":   BASE_DIR / \"C1_metrics\" / \"pr_curves\",          # specialist calibrated\n",
    "    \"PR_curves_uncal_dir\": BASE_DIR / \"F2_cal_vs_uncal\" / \"pr_curves_uncal\",\n",
    "    \"PR_curves_blend_dir\": BASE_DIR / \"F2b_spec_vs_blend\" / \"pr_curves_blend\",\n",
    "    \"ROC_curves_dir\":      BASE_DIR / \"C1_metrics\" / \"roc_curves\",\n",
    "    \"Delta_bootstrap_csv\": BASE_DIR / \"C2b_bootstrap_delta\" / \"test_bootstrap_delta_ap_per_label.csv\",\n",
    "    \"T1_op_csv\":           BASE_DIR / \"T1_op\" / \"T1_op_test_blend.csv\",\n",
    "    \"T1_op_agg_json\":      BASE_DIR / \"T1_op\" / \"T1_op_test_aggregates.json\",\n",
    "}\n",
    "\n",
    "# ---------------------------- UTILITIES ---------------------------------------\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_png(fig, stem: str):\n",
    "    ensure_dir(FIGS_DIR)\n",
    "    fig.savefig(FIGS_DIR / f\"{stem}.png\", bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def load_csv(p: Path):\n",
    "    return pd.read_csv(p) if p and p.exists() else None\n",
    "\n",
    "def load_json(p: Path):\n",
    "    if p and p.exists():\n",
    "        with open(p, \"r\", encoding=\"utf-8\") as f: return json.load(f)\n",
    "    return None\n",
    "\n",
    "def nice_axes(ax, title=None, xlabel=None, ylabel=None, grid=True):\n",
    "    if title: ax.set_title(title, pad=8)\n",
    "    if xlabel: ax.set_xlabel(xlabel)\n",
    "    if ylabel: ax.set_ylabel(ylabel)\n",
    "    ax.grid(grid)\n",
    "\n",
    "def _norm(s):  # normalize for fuzzy matching\n",
    "    return re.sub(r'[^a-z0-9]+', '', str(s).lower())\n",
    "\n",
    "def fuzzy_pick(df, prefer=None, contains_any=None, contains_all=None, not_contains=None):\n",
    "    cols = list(df.columns)\n",
    "    if prefer:\n",
    "        for p in prefer:\n",
    "            if p in cols: return p\n",
    "    def ok(col):\n",
    "        n = _norm(col)\n",
    "        if contains_any and not any(k in n for k in contains_any): return False\n",
    "        if contains_all and not all(k in n for k in contains_all): return False\n",
    "        if not_contains and any(k in n for k in not_contains): return False\n",
    "        return True\n",
    "    cand = [c for c in cols if ok(c)]\n",
    "    if cand: \n",
    "        cand.sort(key=lambda c: len(_norm(c)))\n",
    "        return cand[0]\n",
    "    return None\n",
    "\n",
    "def extract_prevalence_map(per_label_metrics: pd.DataFrame) -> dict:\n",
    "    if per_label_metrics is None or per_label_metrics.empty: return {}\n",
    "    # try to find 'label' & 'prevalence'\n",
    "    lab = fuzzy_pick(per_label_metrics, prefer=[\"label\",\"Label\",\"assay\",\"name\"], contains_any=[\"label\",\"assay\",\"name\"])\n",
    "    prev = fuzzy_pick(per_label_metrics, prefer=[\"prevalence\",\"pos_rate\",\"positive_rate\",\"p_base\"],\n",
    "                      contains_any=[\"prev\",\"positive\",\"posrate\",\"pbase\",\"prevalence\"])\n",
    "    if not lab or not prev: return {}\n",
    "    df = per_label_metrics[[lab, prev]].copy()\n",
    "    df.columns = [\"label\",\"prevalence\"]\n",
    "    df = df[~df[\"label\"].astype(str).str.lower().isin({\"macro\",\"micro\"})]\n",
    "    return dict(zip(df[\"label\"], df[\"prevalence\"].astype(float)))\n",
    "\n",
    "def table_like_figure(table_df: pd.DataFrame, title: str, bold_rows=set()):\n",
    "    \"\"\"\n",
    "    Render a clean table similar to journal style:\n",
    "    - bold header\n",
    "    - horizontal rules (top, after header, bottom)\n",
    "    - left-aligned first column; others centered\n",
    "    \"\"\"\n",
    "    n_rows, n_cols = table_df.shape\n",
    "    fig_height = max(2.2, 0.38 * (n_rows + 2))  # compact, scales with rows\n",
    "    fig = plt.figure(figsize=(FIGWIDTH_TAB, fig_height))\n",
    "    ax = plt.gca()\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # Title\n",
    "    ax.text(0.0, 1.04, title, fontsize=TITLE_SIZE, fontweight=\"bold\", transform=ax.transAxes, ha=\"left\", va=\"bottom\")\n",
    "\n",
    "    # Build cell text manually with annotations\n",
    "    # Draw header rule, mid rule, bottom rule using axes coords\n",
    "    left, right = 0.02, 0.98\n",
    "    y_top = 0.96\n",
    "    line_w = 1.2 / 72  # points to inches-ish feel (thin)\n",
    "    ax.hlines(y_top, left, right, transform=ax.transAxes, linewidth=1.0, color=\"black\")\n",
    "\n",
    "    # Column widths: first wider\n",
    "    col_widths = [0.36] + [ (right-left-0.36)/(n_cols-1) ]*(n_cols-1)\n",
    "    x_positions = [left]\n",
    "    for w in col_widths[:-1]:\n",
    "        x_positions.append(x_positions[-1]+w)\n",
    "\n",
    "    # Header row\n",
    "    y = y_top - 0.08\n",
    "    for j, col in enumerate(table_df.columns):\n",
    "        ha = \"left\" if j==0 else \"center\"\n",
    "        ax.text(x_positions[j]+(0 if j==0 else col_widths[j]/2), y, str(col),\n",
    "                fontsize=FONT_SIZE, fontweight=\"bold\", ha=ha, va=\"center\", transform=ax.transAxes)\n",
    "    ax.hlines(y-0.035, left, right, transform=ax.transAxes, linewidth=0.8, color=\"black\")\n",
    "\n",
    "    # Body rows\n",
    "    y_step = 0.06\n",
    "    y -= 0.06\n",
    "    for i in range(n_rows):\n",
    "        row = table_df.iloc[i].tolist()\n",
    "        is_bold = str(row[0]) in bold_rows\n",
    "        for j, val in enumerate(row):\n",
    "            ha = \"left\" if j==0 else \"center\"\n",
    "            ax.text(x_positions[j]+(0 if j==0 else col_widths[j]/2), y, str(val),\n",
    "                    fontsize=FONT_SIZE, fontweight=\"bold\" if is_bold else \"normal\",\n",
    "                    ha=ha, va=\"center\", transform=ax.transAxes)\n",
    "        y -= y_step\n",
    "\n",
    "    # Bottom rule\n",
    "    ax.hlines(y+0.02, left, right, transform=ax.transAxes, linewidth=1.0, color=\"black\")\n",
    "    return fig\n",
    "\n",
    "# ------------------------------- T1 TABLE -------------------------------------\n",
    "def plot_T1_table():\n",
    "    df = load_csv(PATHS[\"T1_metrics_csv\"])\n",
    "    if df is None or df.empty:\n",
    "        print(\"T1 metrics CSV not found. Skipping T1.\")\n",
    "        return\n",
    "\n",
    "    # Fuzzy column picks\n",
    "    lab = fuzzy_pick(df, prefer=[\"label\",\"Label\",\"assay\",\"name\"], contains_any=[\"label\",\"assay\",\"name\"])\n",
    "    ap  = fuzzy_pick(df, prefer=[\"ap\",\"AP\",\"average_precision\",\"pr_auc\"], contains_any=[\"ap\",\"avgprecision\",\"prau\"])\n",
    "    roc = fuzzy_pick(df, prefer=[\"roc_auc\",\"ROC-AUC\",\"auc_roc\",\"roc\"], contains_any=[\"roc\",\"auc\"])\n",
    "    acc = fuzzy_pick(df, prefer=[\"acc\",\"accuracy\"], contains_any=[\"acc\"])\n",
    "    sen = fuzzy_pick(df, prefer=[\"sens\",\"sensitivity\",\"recall\"], contains_any=[\"sens\",\"recall\"])\n",
    "    spe = fuzzy_pick(df, prefer=[\"spec\",\"specificity\"], contains_any=[\"spec\"])\n",
    "    f1  = fuzzy_pick(df, prefer=[\"f1\",\"F1\"], contains_any=[\"f1\"])\n",
    "    fb  = fuzzy_pick(df, prefer=[\"fbeta\",\"Fβ\",\"Fbeta\",\"Fbeta1.5\",\"fbeta1_5\"], contains_any=[\"fbeta\",\"beta\",\"15\"])\n",
    "\n",
    "    cols = [c for c in [lab, ap, roc, acc, sen, spe, f1, fb] if c]\n",
    "    tdf = df[cols].copy()\n",
    "    tdf.columns = [\"Assay\"] + [x for x in [\"AP\",\"ROC-AUC\",\"Acc\",\"Sens\",\"Spec\",\"F1\",\"Fβ=1.5\"] if x in [\"AP\",\"ROC-AUC\",\"Acc\",\"Sens\",\"Spec\",\"F1\",\"Fβ=1.5\"]][:len(cols)-1]\n",
    "\n",
    "    # Separate Macro/Micro to bottom if present\n",
    "    mask_agg = tdf[\"Assay\"].astype(str).str.lower().isin({\"macro\",\"micro\"})\n",
    "    assays = tdf.loc[~mask_agg].sort_values(\"Assay\")\n",
    "    aggs   = tdf.loc[mask_agg]\n",
    "    tdf = pd.concat([assays, aggs], ignore_index=True)\n",
    "\n",
    "    # Round numeric\n",
    "    for c in tdf.columns[1:]:\n",
    "        tdf[c] = pd.to_numeric(tdf[c], errors=\"coerce\").map(lambda x: f\"{x:.3f}\" if pd.notna(x) else \"\")\n",
    "\n",
    "    fig = table_like_figure(tdf, TITLE_T1, bold_rows=BOLD_ASSAYS)\n",
    "    save_png(fig, OUT[\"T1_table\"])\n",
    "    print(f\"Saved {OUT['T1_table']}.png\")\n",
    "\n",
    "# ----------------------- F1b: AP dot-whisker with CIs -------------------------\n",
    "def plot_F1b_ap_ci():\n",
    "    df = load_csv(PATHS[\"AP_bootstrap_csv\"])\n",
    "    if df is None or df.empty:\n",
    "        print(\"AP bootstrap CSV not found. Skipping F1b.\")\n",
    "        return\n",
    "\n",
    "    lab = fuzzy_pick(df, prefer=[\"label\",\"Label\",\"assay\",\"name\"], contains_any=[\"label\",\"assay\",\"name\"])\n",
    "    ap   = fuzzy_pick(df, prefer=[\"ap\",\"AP\",\"average_precision\",\"pr_auc\",\"mean\",\"AP_mean\"], contains_any=[\"ap\",\"avg\",\"prau\",\"mean\"])\n",
    "    lo   = fuzzy_pick(df, prefer=[\"ap_low\",\"ci_low\",\"low\",\"lower\",\"lo\",\"2.5%\"], contains_any=[\"low\",\"2\",\"025\",\"ci\",\"lwr\"])\n",
    "    hi   = fuzzy_pick(df, prefer=[\"ap_high\",\"ci_high\",\"high\",\"upper\",\"hi\",\"97.5%\"], contains_any=[\"high\",\"97\",\"975\",\"ci\",\"upr\"])\n",
    "\n",
    "    need = {\"label\":lab, \"ap\":ap, \"ap_low\":lo, \"ap_high\":hi}\n",
    "    if any(v is None for v in need.values()):\n",
    "        print(\"F1b columns could not be inferred. Skipping.\")\n",
    "        return\n",
    "\n",
    "    df = df[[lab, ap, lo, hi]].copy()\n",
    "    df.columns = [\"label\",\"ap\",\"ap_low\",\"ap_high\"]\n",
    "    df = df[~df[\"label\"].astype(str).str.lower().isin({\"macro\",\"micro\"})]\n",
    "    df = df.sort_values(\"ap\", ascending=False)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE_BAR)\n",
    "    y = np.arange(len(df))[::-1]\n",
    "    ax.hlines(y, df[\"ap_low\"], df[\"ap_high\"], linewidth=LINE_WIDTH)\n",
    "    ax.plot(df[\"ap\"], y, \"o\", markersize=5)\n",
    "    ax.set_yticks(y); ax.set_yticklabels(df[\"label\"])\n",
    "    nice_axes(ax, title=TITLE_F1B, xlabel=\"Average Precision (AP)\", ylabel=\"\")\n",
    "    ax.set_xlim(0, 1)\n",
    "    save_png(fig, OUT[\"F1b\"])\n",
    "    print(f\"Saved {OUT['F1b']}.png\")\n",
    "\n",
    "# (Optional) Prevalence bars\n",
    "def maybe_plot_prevalence_bars():\n",
    "    per_label = load_csv(PATHS[\"T1_metrics_csv\"])\n",
    "    if per_label is None or per_label.empty:\n",
    "        print(\"No per-label metrics for prevalence. Skipping.\")\n",
    "        return\n",
    "    prev_map = extract_prevalence_map(per_label)\n",
    "    if not prev_map:\n",
    "        print(\"No 'prevalence' column detected. Skipping Prev.\")\n",
    "        return\n",
    "    labels, vals = zip(*sorted(prev_map.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE_BAR)\n",
    "    ax.barh(labels, vals)\n",
    "    nice_axes(ax, title=\"Prev — Class Prevalence (TEST)\", xlabel=\"Prevalence\", ylabel=\"\")\n",
    "    ax.set_xlim(0, 1)\n",
    "    save_png(fig, OUT[\"Prev\"])\n",
    "    print(f\"Saved {OUT['Prev']}.png\")\n",
    "\n",
    "# ---------------- PR/ROC curve file readers -----------------------------------\n",
    "def _read_curve_dir(curve_dir: Path, kind=\"pr\"):\n",
    "    curves = {}\n",
    "    if not (curve_dir and curve_dir.exists() and curve_dir.is_dir()):\n",
    "        return curves\n",
    "    for f in sorted(glob.glob(str(curve_dir / \"*.csv\"))):\n",
    "        df = pd.read_csv(f)\n",
    "        # try precision/recall OR tpr/fpr\n",
    "        if kind == \"pr\":\n",
    "            p = fuzzy_pick(df, prefer=[\"precision\"], contains_any=[\"prec\"])\n",
    "            r = fuzzy_pick(df, prefer=[\"recall\"], contains_any=[\"rec\"])\n",
    "            if p and r:\n",
    "                df = df[[r, p]].copy(); df.columns = [\"recall\",\"precision\"]\n",
    "                curves[Path(f).stem] = df\n",
    "        else:\n",
    "            fpr = fuzzy_pick(df, prefer=[\"fpr\",\"false_positive_rate\"], contains_any=[\"fpr\",\"falsepositiverate\"])\n",
    "            tpr = fuzzy_pick(df, prefer=[\"tpr\",\"true_positive_rate\"], contains_any=[\"tpr\",\"truepositiverate\"])\n",
    "            if fpr and tpr:\n",
    "                df = df[[fpr, tpr]].copy(); df.columns = [\"fpr\",\"tpr\"]\n",
    "                curves[Path(f).stem] = df\n",
    "    return curves\n",
    "\n",
    "# ---------------- F2: PR — cal vs uncal (3x4) ---------------------------------\n",
    "def plot_F2_pr_cal_vs_uncal():\n",
    "    cal = _read_curve_dir(PATHS[\"PR_curves_cal_dir\"], kind=\"pr\")\n",
    "    uncal = _read_curve_dir(PATHS[\"PR_curves_uncal_dir\"], kind=\"pr\")\n",
    "    if not cal:\n",
    "        print(\"No calibrated PR curves found. Skipping F2.\")\n",
    "        return\n",
    "    assays = sorted(cal.keys())\n",
    "    prev_map = extract_prevalence_map(load_csv(PATHS[\"T1_metrics_csv\"]))\n",
    "\n",
    "    rows, cols = 3, 4\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=FIGSIZE_GRID, sharex=True, sharey=True)\n",
    "    axes = axes.ravel()\n",
    "    for i, assay in enumerate(assays[:rows*cols]):\n",
    "        ax = axes[i]\n",
    "        dc = cal[assay]\n",
    "        ax.plot(dc[\"recall\"], dc[\"precision\"], linewidth=LINE_WIDTH, label=\"Specialist (cal)\")\n",
    "        if assay in uncal:\n",
    "            du = uncal[assay]\n",
    "            ax.plot(du[\"recall\"], du[\"precision\"], linewidth=LINE_WIDTH, linestyle=\"--\", label=\"Specialist (uncal)\")\n",
    "        if assay in prev_map:\n",
    "            ax.hlines(prev_map[assay], 0, 1, linestyles=\":\", linewidth=1.2, label=\"Prevalence\" if i==0 else None)\n",
    "        ax.set_title(assay)\n",
    "        ax.set_xlim(0,1); ax.set_ylim(0,1)\n",
    "        if i // cols == rows-1: ax.set_xlabel(\"Recall\")\n",
    "        if i % cols == 0: ax.set_ylabel(\"Precision\")\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc=\"lower center\", ncol=3, frameon=False)\n",
    "    fig.suptitle(TITLE_F2, y=0.98)\n",
    "    fig.tight_layout(rect=[0,0.04,1,0.95])\n",
    "    save_png(fig, OUT[\"F2_grid\"])\n",
    "    print(f\"Saved {OUT['F2_grid']}.png\")\n",
    "\n",
    "# --------------- F2b: PR — specialist vs blend (3x4) -------------------------\n",
    "def plot_F2b_pr_spec_vs_blend():\n",
    "    spec = _read_curve_dir(PATHS[\"PR_curves_cal_dir\"], kind=\"pr\")\n",
    "    blend = _read_curve_dir(PATHS[\"PR_curves_blend_dir\"], kind=\"pr\")\n",
    "    if not (spec and blend):\n",
    "        print(\"Missing spec or blend PR curves. Skipping F2b.\")\n",
    "        return\n",
    "    assays = sorted(set(spec.keys()) & set(blend.keys()))\n",
    "    prev_map = extract_prevalence_map(load_csv(PATHS[\"T1_metrics_csv\"]))\n",
    "\n",
    "    rows, cols = 3, 4\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=FIGSIZE_GRID, sharex=True, sharey=True)\n",
    "    axes = axes.ravel()\n",
    "    for i, assay in enumerate(assays[:rows*cols]):\n",
    "        ax = axes[i]\n",
    "        ds, db = spec[assay], blend[assay]\n",
    "        ax.plot(ds[\"recall\"], ds[\"precision\"], linewidth=LINE_WIDTH, label=\"Specialist (cal)\")\n",
    "        ax.plot(db[\"recall\"], db[\"precision\"], linewidth=LINE_WIDTH, linestyle=\"--\", label=\"Blend (cal)\")\n",
    "        if assay in prev_map:\n",
    "            ax.hlines(prev_map[assay], 0, 1, linestyles=\":\", linewidth=1.2, label=\"Prevalence\" if i==0 else None)\n",
    "        ax.set_title(assay); ax.set_xlim(0,1); ax.set_ylim(0,1)\n",
    "        if i // cols == rows-1: ax.set_xlabel(\"Recall\")\n",
    "        if i % cols == 0: ax.set_ylabel(\"Precision\")\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc=\"lower center\", ncol=3, frameon=False)\n",
    "    fig.suptitle(TITLE_F2B, y=0.98)\n",
    "    fig.tight_layout(rect=[0,0.04,1,0.95])\n",
    "    save_png(fig, OUT[\"F2b_grid\"])\n",
    "    print(f\"Saved {OUT['F2b_grid']}.png\")\n",
    "\n",
    "# ---------------- F2c: Δ(AP) bar with 95% CIs ---------------------------------\n",
    "def plot_F2c_delta_ap():\n",
    "    df = load_csv(PATHS[\"Delta_bootstrap_csv\"])\n",
    "    if df is None or df.empty:\n",
    "        print(\"Delta AP bootstrap CSV not found. Skipping F2c.\")\n",
    "        return\n",
    "    lab = fuzzy_pick(df, prefer=[\"label\",\"Label\",\"assay\",\"name\"], contains_any=[\"label\",\"assay\",\"name\"])\n",
    "    delta = fuzzy_pick(df, prefer=[\"delta\",\"delta_ap\",\"diff\",\"ap_diff\"], contains_any=[\"delta\",\"diff\",\"ap\"])\n",
    "    lo = fuzzy_pick(df, prefer=[\"delta_low\",\"ci_low\",\"low\",\"lower\",\"lo\",\"2.5%\"], contains_any=[\"low\",\"ci\",\"2\",\"025\"])\n",
    "    hi = fuzzy_pick(df, prefer=[\"delta_high\",\"ci_high\",\"high\",\"upper\",\"hi\",\"97.5%\"], contains_any=[\"high\",\"ci\",\"97\",\"975\"])\n",
    "    if any(x is None for x in [lab, delta, lo, hi]):\n",
    "        print(\"Could not infer delta columns. Skipping F2c.\")\n",
    "        return\n",
    "\n",
    "    df = df[[lab, delta, lo, hi]].copy()\n",
    "    df.columns = [\"label\",\"delta\",\"delta_low\",\"delta_high\"]\n",
    "    df = df[~df[\"label\"].astype(str).str.lower().isin({\"macro\",\"micro\"})]\n",
    "    df = df.sort_values(\"delta\", ascending=True)\n",
    "    crosses_zero = (df[\"delta_low\"] <= 0) & (df[\"delta_high\"] >= 0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE_BAR)\n",
    "    y = np.arange(len(df))\n",
    "    ax.hlines(y, df[\"delta_low\"], df[\"delta_high\"], linewidth=LINE_WIDTH)\n",
    "    ax.plot(df[\"delta\"], y, \"o\", markersize=5)\n",
    "    # emphasize CIs not crossing zero\n",
    "    for i, nz in enumerate(~crosses_zero):\n",
    "        if nz:\n",
    "            ax.hlines(i, df.iloc[i][\"delta_low\"], df.iloc[i][\"delta_high\"], linewidth=LINE_WIDTH+1.2, alpha=0.6)\n",
    "    ax.axvline(0, color=\"k\", linewidth=1)\n",
    "    ax.set_yticks(y); ax.set_yticklabels(df[\"label\"])\n",
    "    nice_axes(ax, title=TITLE_F2C, xlabel=\"Δ(AP) = Blend − Specialist\", ylabel=\"\")\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(8))\n",
    "    save_png(fig, OUT[\"F2c_delta\"])\n",
    "    print(f\"Saved {OUT['F2c_delta']}.png\")\n",
    "\n",
    "# -------------------- F3: ROC grid (optional) ---------------------------------\n",
    "def plot_F3_roc_grid():\n",
    "    curves = _read_curve_dir(PATHS[\"ROC_curves_dir\"], kind=\"roc\")\n",
    "    if not curves:\n",
    "        print(\"ROC curves not found. Skipping F3.\")\n",
    "        return\n",
    "    assays = sorted(curves.keys())\n",
    "    rows, cols = 3, 4\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=FIGSIZE_GRID, sharex=True, sharey=True)\n",
    "    axes = axes.ravel()\n",
    "    for i, assay in enumerate(assays[:rows*cols]):\n",
    "        ax = axes[i]; df = curves[assay]\n",
    "        ax.plot(df[\"fpr\"], df[\"tpr\"], linewidth=LINE_WIDTH, label=\"Model\")\n",
    "        ax.plot([0,1],[0,1], linestyle=\"--\", linewidth=1, label=\"Chance\" if i==0 else None)\n",
    "        ax.set_title(assay); ax.set_xlim(0,1); ax.set_ylim(0,1)\n",
    "        if i // cols == rows-1: ax.set_xlabel(\"False Positive Rate\")\n",
    "        if i % cols == 0: ax.set_ylabel(\"True Positive Rate\")\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc=\"lower center\", ncol=2, frameon=False)\n",
    "    fig.suptitle(TITLE_F3, y=0.98)\n",
    "    fig.tight_layout(rect=[0,0.04,1,0.95])\n",
    "    save_png(fig, OUT[\"F3_grid\"])\n",
    "    print(f\"Saved {OUT['F3_grid']}.png\")\n",
    "\n",
    "# -------------------- T1_op: operating point table ----------------------------\n",
    "def plot_T1_op_table():\n",
    "    df = load_csv(PATHS[\"T1_op_csv\"])\n",
    "    if df is None or df.empty:\n",
    "        print(\"T1_op CSV not found. Skipping T1_op table.\")\n",
    "        return\n",
    "    lab = fuzzy_pick(df, prefer=[\"label\",\"Label\",\"assay\",\"name\"], contains_any=[\"label\",\"assay\",\"name\"])\n",
    "    sen = fuzzy_pick(df, prefer=[\"sens\",\"sensitivity\",\"recall\"], contains_any=[\"sens\",\"recall\"])\n",
    "    spe = fuzzy_pick(df, prefer=[\"spec\",\"specificity\"], contains_any=[\"spec\"])\n",
    "    acc = fuzzy_pick(df, prefer=[\"acc\",\"accuracy\"], contains_any=[\"acc\"])\n",
    "    f1  = fuzzy_pick(df, prefer=[\"f1\",\"F1\"], contains_any=[\"f1\"])\n",
    "    fb  = fuzzy_pick(df, prefer=[\"fbeta\",\"Fβ\",\"Fbeta\",\"Fbeta1.5\",\"fbeta1_5\"], contains_any=[\"fbeta\",\"beta\",\"15\"])\n",
    "    cols = [c for c in [lab, sen, spe, acc, f1, fb] if c]\n",
    "    tdf = df[cols].copy()\n",
    "    new_cols = [\"Assay\",\"Sens\",\"Spec\",\"Acc\",\"F1\",\"Fβ=1.5\"][:len(cols)]\n",
    "    tdf.columns = new_cols\n",
    "\n",
    "    # Macro/Micro last\n",
    "    mask_agg = tdf[\"Assay\"].astype(str).str.lower().isin({\"macro\",\"micro\"})\n",
    "    assays = tdf.loc[~mask_agg].sort_values(\"Assay\")\n",
    "    aggs   = tdf.loc[mask_agg]\n",
    "    tdf = pd.concat([assays, aggs], ignore_index=True)\n",
    "\n",
    "    for c in tdf.columns[1:]:\n",
    "        tdf[c] = pd.to_numeric(tdf[c], errors=\"coerce\").map(lambda x: f\"{x:.3f}\" if pd.notna(x) else \"\")\n",
    "\n",
    "    fig = table_like_figure(tdf, TITLE_T1OP, bold_rows=BOLD_ASSAYS)\n",
    "    save_png(fig, OUT[\"T1op_table\"])\n",
    "    print(f\"Saved {OUT['T1op_table']}.png\")\n",
    "\n",
    "# -------------------------------- DRIVER --------------------------------------\n",
    "def main():\n",
    "    ensure_dir(FIGS_DIR)\n",
    "    print(f\"Saving PNGs to: {FIGS_DIR.resolve()}\")\n",
    "\n",
    "    plot_T1_table()\n",
    "    plot_F1b_ap_ci()\n",
    "    maybe_plot_prevalence_bars()\n",
    "\n",
    "    plot_F2_pr_cal_vs_uncal()\n",
    "    plot_F2b_pr_spec_vs_blend()\n",
    "    plot_F2c_delta_ap()\n",
    "\n",
    "    plot_F3_roc_grid()\n",
    "\n",
    "    plot_T1_op_table()\n",
    "    print(\"Done.\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a41c04",
   "metadata": {},
   "source": [
    "## RQ2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3022e155",
   "metadata": {},
   "source": [
    "### Data for graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ad4f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:55:59] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "# RQ2 — Reliability & Calibration (compute everything, export META for figures to v7/v7_Eval/RQ2/outs)\n",
    "# This script computes logits/probabilities, per-assay metrics, macro bootstrap\n",
    "#       (macro + micro), and writes all standardized META artifacts (CSV/JSON/NPY)\n",
    "#       needed to generate RQ2 figures. No figures are produced here.\n",
    "\n",
    "from __future__ import annotations\n",
    "import json, math\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# sklearn optional (for Platt)\n",
    "try:\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    _HAVE_SK = True\n",
    "except Exception:\n",
    "    _HAVE_SK = False\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers (UTF-8 writes)\n",
    "# ---------------------------\n",
    "def write_text_utf8(path: Path, text: str) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    path.write_text(text, encoding=\"utf-8\")\n",
    "\n",
    "def write_json_utf8(path: Path, obj: dict) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    write_text_utf8(path, json.dumps(obj, ensure_ascii=False, indent=2))\n",
    "\n",
    "# ---------------------------\n",
    "# Paths & output dirs\n",
    "# ---------------------------\n",
    "def detect_v7() -> Path:\n",
    "    cwd = Path(\".\").resolve()\n",
    "    if (cwd/\"data\").exists() and (cwd/\"model\").exists() and cwd.name == \"v7\":\n",
    "        return cwd\n",
    "    if (cwd/\"v7\"/\"data\").exists():\n",
    "        return (cwd/\"v7\").resolve()\n",
    "    return cwd\n",
    "\n",
    "V7    = detect_v7()\n",
    "PREP  = V7 / \"data\" / \"prepared\"\n",
    "SPL   = V7 / \"data\" / \"splits\"\n",
    "MOD   = V7 / \"model\"\n",
    "CAL   = MOD / \"calibration\"\n",
    "ENS   = MOD / \"ensembles\"\n",
    "CKPT  = MOD / \"checkpoints\" / \"shared\" / \"best.pt\"\n",
    "\n",
    "OUT   = V7 / \"v7_Eval\" / \"RQ2\"\n",
    "DIR_VAL     = OUT / \"val\";     DIR_VAL.mkdir(parents=True, exist_ok=True)\n",
    "DIR_TEST    = OUT / \"test\";    DIR_TEST.mkdir(parents=True, exist_ok=True)\n",
    "DIR_CALFIT  = OUT / \"val_calibration\"; DIR_CALFIT.mkdir(parents=True, exist_ok=True)\n",
    "DIR_T2      = OUT / \"T2\";      DIR_T2.mkdir(parents=True, exist_ok=True)\n",
    "DIR_BOOTDEL = OUT / \"test_bootstrap_deltas\"; DIR_BOOTDEL.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# NEW standardized META outbox (this is what plotting code will read)\n",
    "OUTS = OUT / \"outs\"\n",
    "(OUTS / \"reliability\").mkdir(parents=True, exist_ok=True)\n",
    "(OUTS / \"probs_temp_per_assay\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Manifest / labels\n",
    "# ---------------------------\n",
    "mani = json.loads((PREP/\"dataset_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "LABELS: List[str] = mani[\"labels\"]\n",
    "L = len(LABELS)\n",
    "DESC_IN_DIM = int(mani[\"n_features\"])\n",
    "\n",
    "# ---------------------------\n",
    "# Load & align splits\n",
    "# ---------------------------\n",
    "def load_split(split_path: Path, prefer=(\"val.npz\",\"test.npz\",\"train.npz\")) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, List[str]]:\n",
    "    idx = np.load(split_path)\n",
    "    choice = None\n",
    "    for name in prefer:\n",
    "        p = PREP / name\n",
    "        if not p.exists(): continue\n",
    "        z = np.load(p, allow_pickle=True)\n",
    "        if \"indices\" in z:\n",
    "            has = np.isin(idx, z[\"indices\"]).sum()\n",
    "            if has > 0:\n",
    "                choice = p; z.close(); break\n",
    "        z.close()\n",
    "    if choice is None:\n",
    "        for name in prefer:\n",
    "            p = PREP / name\n",
    "            if p.exists(): choice = p; break\n",
    "    Z = np.load(choice, allow_pickle=True)\n",
    "    Y_full = Z[\"Y\"].astype(float)\n",
    "    OBS_full = (~Z[\"y_missing_mask\"].astype(bool)) if \"y_missing_mask\" in Z else ~np.isnan(Y_full)\n",
    "    smiles_full = list(Z[\"smiles\"])\n",
    "    X_full = Z[\"X\"].astype(np.float32)\n",
    "    if \"indices\" in Z:\n",
    "        pos = pd.Series(np.arange(len(Z[\"indices\"])), index=Z[\"indices\"]).reindex(idx)\n",
    "        order = pos.astype(int).to_numpy()\n",
    "    else:\n",
    "        order = np.arange(len(idx))\n",
    "    Y = np.nan_to_num(Y_full[order], nan=0.0).astype(int)\n",
    "    OBS = OBS_full[order].astype(bool)\n",
    "    X = X_full[order]\n",
    "    SMI = np.array([smiles_full[i] for i in order], dtype=object)\n",
    "    return Y, OBS, X, SMI, LABELS\n",
    "\n",
    "VAL_SPLIT = SPL / \"val.npy\"\n",
    "TEST_SPLIT= SPL / \"train.npy\"   # used as TEST per your setup\n",
    "\n",
    "Yv, Mv, Xv, SMv, _ = load_split(VAL_SPLIT, (\"val.npz\",\"test.npz\",\"train.npz\"))\n",
    "Yt, Mt, Xt, SMt, _ = load_split(TEST_SPLIT, (\"test.npz\",\"train.npz\",\"val.npz\"))\n",
    "Nv, Nt = Yv.shape[0], Yt.shape[0]\n",
    "\n",
    "# ---------------------------\n",
    "# Phase-5 model rig (fusion + heads)\n",
    "# ---------------------------\n",
    "from rdkit import Chem\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ChemBERTaEncoder(nn.Module):\n",
    "    def __init__(self, ckpt_name=\"seyonec/ChemBERTa-zinc-base-v1\", fusion_dim=256, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(ckpt_name)\n",
    "        self.backbone  = AutoModel.from_pretrained(ckpt_name)\n",
    "        self.proj = nn.Sequential(nn.Dropout(dropout_p), nn.Linear(self.backbone.config.hidden_size, fusion_dim))\n",
    "        self.ln = nn.LayerNorm(fusion_dim)\n",
    "    def forward(self, smiles_list: List[str], max_length=256, add_special_tokens=True):\n",
    "        enc = self.tokenizer(list(smiles_list), padding=True, truncation=True,\n",
    "                             max_length=max_length, add_special_tokens=add_special_tokens, return_tensors=\"pt\")\n",
    "        input_ids, attention_mask = enc[\"input_ids\"].to(device), enc[\"attention_mask\"].to(device)\n",
    "        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "        toks = self.ln(self.proj(out))\n",
    "        return toks, attention_mask.to(dtype=torch.int32)\n",
    "\n",
    "ATOM_LIST = [\"H\",\"C\",\"N\",\"O\",\"F\",\"P\",\"S\",\"Cl\",\"Br\",\"I\"]\n",
    "def _one_hot(v, choices):\n",
    "    z = [0]*len(choices)\n",
    "    if v in choices: z[choices.index(v)] = 1\n",
    "    return z\n",
    "def _bucket_oh(v, lo, hi):\n",
    "    buckets = list(range(lo, hi+1))\n",
    "    o = [0]*(len(buckets)+1)\n",
    "    idx = v - lo\n",
    "    o[idx if 0 <= idx < len(buckets) else -1] = 1\n",
    "    return o\n",
    "def _atom_feat(atom):\n",
    "    hybs = [Chem.rdchem.HybridizationType.S, Chem.rdchem.HybridizationType.SP,\n",
    "            Chem.rdchem.HybridizationType.SP2, Chem.rdchem.HybridizationType.SP3,\n",
    "            Chem.rdchem.HybridizationType.SP3D, Chem.rdchem.HybridizationType.SP3D2]\n",
    "    chir = [Chem.rdchem.ChiralType.CHI_UNSPECIFIED,\n",
    "            Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CW,\n",
    "            Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CCW,\n",
    "            Chem.rdchem.ChiralType.CHI_OTHER]\n",
    "    sym = atom.GetSymbol()\n",
    "    feat = _one_hot(sym if sym in ATOM_LIST else \"other\", ATOM_LIST+[\"other\"])\n",
    "    feat += _bucket_oh(atom.GetDegree(), 0, 5)\n",
    "    feat += _bucket_oh(atom.GetFormalCharge(), -2, 2)\n",
    "    feat += (_one_hot(atom.GetHybridization(), hybs)+[0])\n",
    "    feat += [int(atom.GetIsAromatic())]\n",
    "    feat += [int(atom.IsInRing())]\n",
    "    feat += _one_hot(atom.GetChiralTag(), chir)\n",
    "    feat += _bucket_oh(atom.GetTotalNumHs(includeNeighbors=True), 0, 4)\n",
    "    feat += _bucket_oh(atom.GetTotalValence(), 0, 5)\n",
    "    feat += [atom.GetMass()/200.0]\n",
    "    return feat\n",
    "def _smiles_to_graph(smi, max_nodes=128):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None or mol.GetNumAtoms() == 0:\n",
    "        return np.zeros((0,0), dtype=np.float32), np.zeros((0,0), dtype=np.float32)\n",
    "    feats = [_atom_feat(mol.GetAtomWithIdx(i)) for i in range(mol.GetNumAtoms())]\n",
    "    x = np.asarray(feats, dtype=np.float32)\n",
    "    Nn = mol.GetNumAtoms()\n",
    "    adj = np.zeros((Nn, Nn), dtype=np.float32)\n",
    "    for b in mol.GetBonds():\n",
    "        i, j = b.GetBeginAtomIdx(), b.GetEndAtomIdx()\n",
    "        adj[i, j] = 1.0; adj[j, i] = 1.0\n",
    "    if Nn > max_nodes:\n",
    "        x = x[:max_nodes]; adj = adj[:max_nodes, :max_nodes]\n",
    "    return x, adj\n",
    "def _collate_graphs(smiles_batch, max_nodes=128):\n",
    "    graphs = [_smiles_to_graph(s) for s in smiles_batch]\n",
    "    Nmax = max([g[0].shape[0] for g in graphs] + [1])\n",
    "    Fnode = graphs[0][0].shape[1] if graphs[0][0].size>0 else 51\n",
    "    B = len(graphs)\n",
    "    X = np.zeros((B, Nmax, Fnode), dtype=np.float32)\n",
    "    A = np.zeros((B, Nmax, Nmax), dtype=np.float32)\n",
    "    M = np.zeros((B, Nmax), dtype=np.int64)\n",
    "    for i, (x, a) in enumerate(graphs):\n",
    "        n = x.shape[0]\n",
    "        if n == 0: continue\n",
    "        X[i, :n, :] = x\n",
    "        A[i, :n, :n] = a\n",
    "        M[i, :n] = 1\n",
    "    return torch.from_numpy(X).to(device), torch.from_numpy(A).to(device), torch.from_numpy(M).to(device)\n",
    "def masked_mean(x: torch.Tensor, mask: torch.Tensor, dim: int) -> torch.Tensor:\n",
    "    mask = mask.to(dtype=x.dtype, device=x.device)\n",
    "    denom = mask.sum(dim=dim, keepdim=True).clamp(min=1.0)\n",
    "    return (x * mask.unsqueeze(-1)).sum(dim=dim) / denom\n",
    "class GINLayer(nn.Module):\n",
    "    def __init__(self, h=256, p=0.1):\n",
    "        super().__init__()\n",
    "        self.eps = nn.Parameter(torch.tensor(0.0))\n",
    "        self.mlp = nn.Sequential(nn.Linear(h, h), nn.GELU(), nn.LayerNorm(h), nn.Dropout(p))\n",
    "    def forward(self, x, adj, mask):\n",
    "        out = (1.0 + self.eps) * x + torch.matmul(adj, x)\n",
    "        out = self.mlp(out)\n",
    "        return out * mask.unsqueeze(-1).to(out.dtype)\n",
    "class GraphGINEncoder(nn.Module):\n",
    "    def __init__(self, node_in_dim=51, hidden_dim=256, n_layers=4, p=0.1):\n",
    "        super().__init__()\n",
    "        self.inp = nn.Sequential(nn.Linear(node_in_dim, hidden_dim), nn.GELU(), nn.Dropout(p))\n",
    "        self.layers = nn.ModuleList([GINLayer(hidden_dim, p) for _ in range(n_layers)])\n",
    "        self.out_ln = nn.LayerNorm(hidden_dim)\n",
    "    def forward(self, smiles_list: List[str], max_nodes=128):\n",
    "        X, A, M = _collate_graphs(smiles_list, max_nodes=max_nodes)\n",
    "        h = self.inp(X)\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, A, M)\n",
    "        return self.out_ln(h), M.to(dtype=torch.int32)\n",
    "class CrossAttentionBlock(nn.Module):\n",
    "    def __init__(self, dim=256, n_heads=4, p=0.1):\n",
    "        super().__init__()\n",
    "        self.mha = nn.MultiheadAttention(dim, n_heads, dropout=p, batch_first=False)\n",
    "        self.ln  = nn.LayerNorm(dim)\n",
    "        self.do  = nn.Dropout(p)\n",
    "    def forward(self, text_tokens, text_mask, graph_nodes, graph_mask):\n",
    "        Q = text_tokens.transpose(0,1); K = graph_nodes.transpose(0,1); V = graph_nodes.transpose(0,1)\n",
    "        kpm = (graph_mask == 0)\n",
    "        attn, _ = self.mha(Q, K, V, key_padding_mask=kpm)\n",
    "        attn = attn.transpose(0,1)\n",
    "        return self.ln(text_tokens + self.do(attn))\n",
    "class DescriptorMLP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim=256, hidden=256, p=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden), nn.GELU(), nn.Dropout(p),\n",
    "            nn.Linear(hidden, out_dim), nn.GELU(), nn.Dropout(p)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "class FusionClassifier(nn.Module):\n",
    "    def __init__(self, dim=256, n_labels=12, p=0.1):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim*3, dim*2), nn.GELU(), nn.Dropout(p),\n",
    "            nn.Linear(dim*2, n_labels)\n",
    "        )\n",
    "    def forward(self, fused_vec): return self.mlp(fused_vec)\n",
    "class V7FusionModel(nn.Module):\n",
    "    def __init__(self, text_encoder, graph_encoder, desc_in_dim=208, dim=256, n_labels=12, n_heads=4, p=0.1):\n",
    "        super().__init__()\n",
    "        self.text_encoder=text_encoder\n",
    "        self.graph_encoder=graph_encoder\n",
    "        self.cross=CrossAttentionBlock(dim, n_heads, p)\n",
    "        self.desc_mlp=DescriptorMLP(desc_in_dim, out_dim=dim, hidden=256, p=p)\n",
    "        self.shared_head=FusionClassifier(dim, n_labels, p)\n",
    "    def forward(self, smiles_list, desc_feats):\n",
    "        tt, tm = self.text_encoder(smiles_list, max_length=256)\n",
    "        gn, gm = self.graph_encoder(smiles_list, max_nodes=128)\n",
    "        tta = self.cross(tt.to(device), tm.to(device), gn.to(device), gm.to(device))\n",
    "        de  = self.desc_mlp(desc_feats.to(device))\n",
    "        text_pool  = masked_mean(tta, tm.to(device), 1)\n",
    "        graph_pool = masked_mean(gn.to(device),  gm.to(device), 1)\n",
    "        fused = torch.cat([text_pool, graph_pool, de], dim=-1)\n",
    "        logits_shared = self.shared_head(fused)\n",
    "        return logits_shared, fused\n",
    "class LabelHead(nn.Module):\n",
    "    def __init__(self, in_dim=768, h1=512, h2=256, h3=128, p=0.30):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(nn.Linear(in_dim, h1), nn.GELU(), nn.LayerNorm(h1), nn.Dropout(p))\n",
    "        self.block2 = nn.Sequential(nn.Linear(h1, h2), nn.GELU(), nn.LayerNorm(h2), nn.Dropout(p))\n",
    "        self.block3 = nn.Sequential(nn.Linear(h2, h3), nn.GELU(), nn.LayerNorm(h3), nn.Dropout(p))\n",
    "        self.out    = nn.Linear(h3, 1)\n",
    "        self.short  = nn.Linear(in_dim, h3)\n",
    "    def forward(self, x):\n",
    "        z1 = self.block1(x); z2 = self.block2(z1); z3 = self.block3(z2)\n",
    "        z  = z3 + self.short(x)\n",
    "        return self.out(z).squeeze(-1)\n",
    "def load_best_head(label: str) -> nn.Module:\n",
    "    cands = []\n",
    "    for sd in sorted((ENS / label).glob(\"seed*/\")):\n",
    "        mfile = sd / \"metrics.json\"\n",
    "        if mfile.exists():\n",
    "            try:\n",
    "                ap = float(json.loads(mfile.read_text(encoding=\"utf-8\")).get(\"best_ap\", float(\"nan\")))\n",
    "                cands.append((ap, sd))\n",
    "            except Exception:\n",
    "                pass\n",
    "    if not cands: raise FileNotFoundError(f\"No trained heads for label {label}\")\n",
    "    cands.sort(key=lambda x: (-1.0 if math.isnan(x[0]) else x[0]), reverse=True)\n",
    "    best_dir = cands[0][1]\n",
    "    ck = torch.load(best_dir / \"best.pt\", map_location=\"cpu\")\n",
    "    cfg = ck.get(\"config\", {\"in_dim\":768,\"h1\":512,\"h2\":256,\"h3\":128,\"dropout\":0.30})\n",
    "    head = LabelHead(in_dim=cfg[\"in_dim\"], h1=cfg[\"h1\"], h2=cfg[\"h2\"], h3=cfg[\"h3\"], p=cfg.get(\"dropout\",0.30)).to(device)\n",
    "    head.load_state_dict(ck[\"model\"], strict=True)\n",
    "    head.eval()\n",
    "    return head\n",
    "\n",
    "text_enc = ChemBERTaEncoder().to(device)\n",
    "graph_enc= GraphGINEncoder().to(device)\n",
    "fusion = V7FusionModel(text_enc, graph_enc, desc_in_dim=DESC_IN_DIM, n_labels=L).to(device)\n",
    "ckpt = torch.load(CKPT, map_location=\"cpu\")\n",
    "fusion.load_state_dict(ckpt[\"model\"], strict=True)\n",
    "fusion.eval()\n",
    "HEADS: Dict[str, nn.Module] = {lbl: load_best_head(lbl) for lbl in LABELS}\n",
    "\n",
    "@torch.no_grad()\n",
    "def fused_features(smiles: List[str], desc: np.ndarray, batch: int = 32) -> np.ndarray:\n",
    "    out = np.zeros((len(smiles), 768), dtype=np.float32)\n",
    "    off=0\n",
    "    for i in range(0, len(smiles), batch):\n",
    "        b_smi = smiles[i:i+batch]; b_desc = torch.tensor(desc[i:i+batch], dtype=torch.float32, device=device)\n",
    "        _, fused = fusion(b_smi, b_desc)\n",
    "        out[off:off+len(b_smi)] = fused.detach().cpu().numpy(); off += len(b_smi)\n",
    "    return out\n",
    "@torch.no_grad()\n",
    "def specialist_logits(FUSED: np.ndarray, batch: int = 64) -> np.ndarray:\n",
    "    out = np.zeros((FUSED.shape[0], L), dtype=np.float32)\n",
    "    for i in range(0, FUSED.shape[0], batch):\n",
    "        x = torch.tensor(FUSED[i:i+batch], dtype=torch.float32, device=device)\n",
    "        cols=[]\n",
    "        for lbl in LABELS:\n",
    "            cols.append(HEADS[lbl](x).detach().cpu().numpy())\n",
    "        out[i:i+batch] = np.stack(cols, axis=1).astype(np.float32)\n",
    "    return out\n",
    "def sigmoid(z): return 1. / (1. + np.exp(-z))\n",
    "\n",
    "# ---------------------------\n",
    "# Temps (VAL-fitted) + Platt fit on VAL\n",
    "# ---------------------------\n",
    "temps_spec = json.loads((CAL/\"temps.json\").read_text(encoding=\"utf-8\"))\n",
    "\n",
    "Fv = fused_features(SMv.tolist(), Xv, batch=32)\n",
    "Zv = specialist_logits(Fv, batch=64)\n",
    "platt = {}\n",
    "if _HAVE_SK:\n",
    "    for j, lbl in enumerate(LABELS):\n",
    "        m = Mv[:, j]\n",
    "        yt = Yv[m, j].astype(int)\n",
    "        xs = Zv[m, j].reshape(-1, 1)\n",
    "        if yt.sum() == 0 or yt.sum() == yt.shape[0]:\n",
    "            a, b = 1.0, 0.0\n",
    "        else:\n",
    "            lr = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
    "            lr.fit(xs, yt)\n",
    "            a = float(lr.coef_[0][0]); b = float(lr.intercept_[0])\n",
    "        platt[lbl] = {\"a\": a, \"b\": b}\n",
    "else:\n",
    "    for lbl in LABELS:\n",
    "        platt[lbl] = {\"a\": 1.0, \"b\": 0.0}\n",
    "write_json_utf8(DIR_CALFIT/\"platt_params.json\", platt)\n",
    "np.save(DIR_VAL/\"val_logits_specialist.npy\", Zv)\n",
    "\n",
    "# ---------------------------\n",
    "# TEST logits + probs (None/Temp/Platt)\n",
    "# ---------------------------\n",
    "Ft = fused_features(SMt.tolist(), Xt, batch=32)\n",
    "Zt = specialist_logits(Ft, batch=64)\n",
    "np.save(DIR_TEST/\"test_logits_specialist.npy\", Zt)\n",
    "\n",
    "P_none  = sigmoid(Zt)\n",
    "Tvec    = np.array([max(float(temps_spec.get(lbl, 1.0)), 1e-3) for lbl in LABELS], dtype=np.float32)\n",
    "P_temp  = sigmoid(Zt / Tvec[None, :])\n",
    "P_platt = sigmoid(Zt * np.array([platt[l][\"a\"] for l in LABELS])[None,:] + np.array([platt[l][\"b\"] for l in LABELS])[None,:])\n",
    "\n",
    "np.save(DIR_TEST/\"test_probs_none.npy\",  P_none)\n",
    "np.save(DIR_TEST/\"test_probs_temp.npy\",  P_temp)\n",
    "np.save(DIR_TEST/\"test_probs_platt.npy\", P_platt)\n",
    "\n",
    "# ---------------------------\n",
    "# Metrics: ECE & Brier (TEST)\n",
    "# ---------------------------\n",
    "def ece_score(y_true: np.ndarray, y_prob: np.ndarray, mask: np.ndarray, n_bins: int = 15) -> Tuple[float, pd.DataFrame]:\n",
    "    m = mask.astype(bool)\n",
    "    yt, yp = y_true[m].astype(int), y_prob[m]\n",
    "    if yt.size == 0:\n",
    "        return 0.0, pd.DataFrame(columns=[\"bin\",\"count\",\"conf\",\"acc\"])\n",
    "    bins = np.linspace(0.0, 1.0, n_bins+1)\n",
    "    inds = np.clip(np.digitize(yp, bins) - 1, 0, n_bins-1)\n",
    "    rows = []\n",
    "    N = yt.shape[0]\n",
    "    ece = 0.0\n",
    "    for b in range(n_bins):\n",
    "        sel = (inds == b)\n",
    "        cb = sel.sum()\n",
    "        if cb == 0:\n",
    "            rows.append({\"bin\":b, \"count\":0, \"conf\":np.nan, \"acc\":np.nan}); continue\n",
    "        conf = float(np.mean(yp[sel])); acc  = float(np.mean(yt[sel]))\n",
    "        ece += (cb / N) * abs(acc - conf)\n",
    "        rows.append({\"bin\":b, \"count\":int(cb), \"conf\":conf, \"acc\":acc})\n",
    "    return float(ece), pd.DataFrame(rows)\n",
    "def brier_score(y_true: np.ndarray, y_prob: np.ndarray, mask: np.ndarray) -> float:\n",
    "    m = mask.astype(bool)\n",
    "    yt, yp = y_true[m].astype(float), y_prob[m].astype(float)\n",
    "    if yt.size == 0: return 0.0\n",
    "    return float(np.mean((yp - yt)**2))\n",
    "\n",
    "rows = []\n",
    "bins_none, bins_temp, bins_plat = {}, {}, {}\n",
    "for j, lbl in enumerate(LABELS):\n",
    "    eN, dfN = ece_score(Yt[:, j], P_none[:, j],  Mt[:, j], n_bins=15)\n",
    "    eT, dfT = ece_score(Yt[:, j], P_temp[:, j],  Mt[:, j], n_bins=15)\n",
    "    eP, dfP = ece_score(Yt[:, j], P_platt[:, j], Mt[:, j], n_bins=15)\n",
    "    bN = brier_score(Yt[:, j], P_none[:, j],  Mt[:, j])\n",
    "    bT = brier_score(Yt[:, j], P_temp[:, j],  Mt[:, j])\n",
    "    bP = brier_score(Yt[:, j], P_platt[:, j], Mt[:, j])\n",
    "    rows.append({\"label\": lbl,\n",
    "                 \"ECE_None\": eN, \"ECE_Temp\": eT, \"ECE_Platt\": eP,\n",
    "                 \"dECE_Temp\": eT - eN, \"dECE_Platt\": eP - eN,\n",
    "                 \"Brier_None\": bN, \"Brier_Temp\": bT, \"Brier_Platt\": bP})\n",
    "    bins_none[lbl]=dfN; bins_temp[lbl]=dfT; bins_plat[lbl]=dfP\n",
    "\n",
    "T2_base = pd.DataFrame(rows)\n",
    "T2_out_csv = DIR_T2/\"T2_test_ece_brier.csv\"\n",
    "T2 = T2_base.copy()\n",
    "for c in [c for c in T2.columns if c!=\"label\"]:\n",
    "    if c.startswith((\"ECE\",\"Brier\",\"dECE\")):\n",
    "        T2[c] = T2[c].astype(float).round(4)\n",
    "T2.to_csv(T2_out_csv, index=False)\n",
    "\n",
    "# ---------------------------\n",
    "# Bootstrap: macro & micro (molecule-level bootstrap), + deltas\n",
    "# ---------------------------\n",
    "B = 1000; SEED = 4242\n",
    "rng = np.random.default_rng(SEED)\n",
    "idx = np.arange(Nt)\n",
    "\n",
    "def ece_only(y, p, m, n_bins=15) -> float:\n",
    "    m = m.astype(bool)\n",
    "    yt, yp = y[m].astype(int), p[m]\n",
    "    if yt.size == 0: return 0.0\n",
    "    bins = np.linspace(0.0, 1.0, n_bins+1)\n",
    "    inds = np.clip(np.digitize(yp, bins) - 1, 0, n_bins-1)\n",
    "    N = yt.shape[0]; ece = 0.0\n",
    "    for b in range(n_bins):\n",
    "        sel = (inds == b); cb = sel.sum()\n",
    "        if cb == 0: continue\n",
    "        conf = float(np.mean(yp[sel])); acc = float(np.mean(yt[sel]))\n",
    "        ece += (cb / N) * abs(acc - conf)\n",
    "    return float(ece)\n",
    "\n",
    "def ci(a): return float(np.mean(a)), float(np.percentile(a,2.5)), float(np.percentile(a,97.5))\n",
    "\n",
    "mac_eN, mac_eT, mac_eP = np.zeros(B), np.zeros(B), np.zeros(B)\n",
    "mac_bN, mac_bT, mac_bP = np.zeros(B), np.zeros(B), np.zeros(B)\n",
    "mac_dET, mac_dEP = np.zeros(B), np.zeros(B)\n",
    "mac_dBT, mac_dBP = np.zeros(B), np.zeros(B)\n",
    "\n",
    "mic_eN, mic_eT, mic_eP = np.zeros(B), np.zeros(B), np.zeros(B)\n",
    "mic_bN, mic_bT, mic_bP = np.zeros(B), np.zeros(B), np.zeros(B)\n",
    "\n",
    "for b in range(B):\n",
    "    bs = rng.choice(idx, size=Nt, replace=True)\n",
    "    yb, mb = Yt[bs], Mt[bs]\n",
    "    pN, pT, pP = P_none[bs], P_temp[bs], P_platt[bs]\n",
    "\n",
    "    # macro over labels\n",
    "    eN = [ece_only(yb[:, j], pN[:, j], mb[:, j]) for j in range(L)]\n",
    "    eT = [ece_only(yb[:, j], pT[:, j], mb[:, j]) for j in range(L)]\n",
    "    eP = [ece_only(yb[:, j], pP[:, j], mb[:, j]) for j in range(L)]\n",
    "    bN = [brier_score(yb[:, j], pN[:, j], mb[:, j]) for j in range(L)]\n",
    "    bT = [brier_score(yb[:, j], pT[:, j], mb[:, j]) for j in range(L)]\n",
    "    bP = [brier_score(yb[:, j], pP[:, j], mb[:, j]) for j in range(L)]\n",
    "    mac_eN[b] = float(np.mean(eN)); mac_eT[b] = float(np.mean(eT)); mac_eP[b] = float(np.mean(eP))\n",
    "    mac_bN[b] = float(np.mean(bN)); mac_bT[b] = float(np.mean(bT)); mac_bP[b] = float(np.mean(bP))\n",
    "    mac_dET[b] = mac_eT[b] - mac_eN[b]; mac_dEP[b] = mac_eP[b] - mac_eN[b]\n",
    "    mac_dBT[b] = mac_bT[b] - mac_bN[b]; mac_dBP[b] = mac_bP[b] - mac_bN[b]\n",
    "\n",
    "    # micro: flatten all observed entries\n",
    "    m_flat = mb.reshape(-1)\n",
    "    y_flat = yb.reshape(-1)\n",
    "    n_flat = pN.reshape(-1); t_flat = pT.reshape(-1); p_flat = pP.reshape(-1)\n",
    "    mic_eN[b] = ece_only(y_flat, n_flat, m_flat, n_bins=15)\n",
    "    mic_eT[b] = ece_only(y_flat, t_flat, m_flat, n_bins=15)\n",
    "    mic_eP[b] = ece_only(y_flat, p_flat, m_flat, n_bins=15)\n",
    "    mic_bN[b] = brier_score(y_flat, n_flat, m_flat)\n",
    "    mic_bT[b] = brier_score(y_flat, t_flat, m_flat)\n",
    "    mic_bP[b] = brier_score(y_flat, p_flat, m_flat)\n",
    "\n",
    "agg_macro = {\n",
    "    \"B\": int(B), \"seed\": int(SEED),\n",
    "    \"ECE_None\":  {\"mean\": ci(mac_eN)[0], \"ci_lo\": ci(mac_eN)[1], \"ci_hi\": ci(mac_eN)[2]},\n",
    "    \"ECE_Temp\":  {\"mean\": ci(mac_eT)[0], \"ci_lo\": ci(mac_eT)[1], \"ci_hi\": ci(mac_eT)[2]},\n",
    "    \"ECE_Platt\": {\"mean\": ci(mac_eP)[0], \"ci_lo\": ci(mac_eP)[1], \"ci_hi\": ci(mac_eP)[2]},\n",
    "    \"Brier_None\":{\"mean\": ci(mac_bN)[0], \"ci_lo\": ci(mac_bN)[1], \"ci_hi\": ci(mac_bN)[2]},\n",
    "    \"Brier_Temp\":{\"mean\": ci(mac_bT)[0], \"ci_lo\": ci(mac_bT)[1], \"ci_hi\": ci(mac_bT)[2]},\n",
    "    \"Brier_Platt\":{\"mean\": ci(mac_bP)[0], \"ci_lo\": ci(mac_bP)[1], \"ci_hi\": ci(mac_bP)[2]},\n",
    "    \"Delta_ECE_Temp_vs_None\":  {\"mean\": ci(mac_dET)[0], \"ci_lo\": ci(mac_dET)[1], \"ci_hi\": ci(mac_dET)[2]},\n",
    "    \"Delta_ECE_Platt_vs_None\": {\"mean\": ci(mac_dEP)[0], \"ci_lo\": ci(mac_dEP)[1], \"ci_hi\": ci(mac_dEP)[2]},\n",
    "    \"Delta_Brier_Temp_vs_None\":{\"mean\": ci(mac_dBT)[0], \"ci_lo\": ci(mac_dBT)[1], \"ci_hi\": ci(mac_dBT)[2]},\n",
    "    \"Delta_Brier_Platt_vs_None\":{\"mean\": ci(mac_dBP)[0], \"ci_lo\": ci(mac_dBP)[1], \"ci_hi\": ci(mac_dBP)[2]},\n",
    "}\n",
    "write_json_utf8(DIR_BOOTDEL/\"test_macro_ece_brier_aggregates.json\", agg_macro)\n",
    "\n",
    "agg_micro = {\n",
    "    \"B\": int(B), \"seed\": int(SEED),\n",
    "    \"ECE_None\":  {\"mean\": ci(mic_eN)[0], \"low\": ci(mic_eN)[1], \"high\": ci(mic_eN)[2]},\n",
    "    \"ECE_Temp\":  {\"mean\": ci(mic_eT)[0], \"low\": ci(mic_eT)[1], \"high\": ci(mic_eT)[2]},\n",
    "    \"ECE_Platt\": {\"mean\": ci(mic_eP)[0], \"low\": ci(mic_eP)[1], \"high\": ci(mic_eP)[2]},\n",
    "    \"Brier_None\":{\"mean\": ci(mic_bN)[0], \"low\": ci(mic_bN)[1], \"high\": ci(mic_bN)[2]},\n",
    "    \"Brier_Temp\":{\"mean\": ci(mic_bT)[0], \"low\": ci(mic_bT)[1], \"high\": ci(mic_bT)[2]},\n",
    "    \"Brier_Platt\":{\"mean\": ci(mic_bP)[0], \"low\": ci(mic_bP)[1], \"high\": ci(mic_bP)[2]},\n",
    "}\n",
    "write_json_utf8(DIR_BOOTDEL/\"test_micro_ece_brier_aggregates.json\", agg_micro)\n",
    "\n",
    "# Per-assay Δ CI CSVs\n",
    "rng2 = np.random.default_rng(SEED)\n",
    "ece_delta_temp_all  = np.zeros((B, L), dtype=float)\n",
    "ece_delta_platt_all = np.zeros((B, L), dtype=float)\n",
    "br_delta_temp_all   = np.zeros((B, L), dtype=float)\n",
    "br_delta_platt_all  = np.zeros((B, L), dtype=float)\n",
    "for b in range(B):\n",
    "    bs = rng2.choice(idx, size=Nt, replace=True)\n",
    "    yb, mb = Yt[bs], Mt[bs]\n",
    "    pN, pT, pP = P_none[bs], P_temp[bs], P_platt[bs]\n",
    "    for j in range(L):\n",
    "        eN = ece_only(yb[:, j], pN[:, j], mb[:, j], n_bins=15)\n",
    "        eT = ece_only(yb[:, j], pT[:, j], mb[:, j], n_bins=15)\n",
    "        eP = ece_only(yb[:, j], pP[:, j], mb[:, j], n_bins=15)\n",
    "        ece_delta_temp_all[b, j]  = eT - eN\n",
    "        ece_delta_platt_all[b, j] = eP - eN\n",
    "        bN = brier_score(yb[:, j], pN[:, j], mb[:, j])\n",
    "        bT = brier_score(yb[:, j], pT[:, j], mb[:, j])\n",
    "        bP = brier_score(yb[:, j], pP[:, j], mb[:, j])\n",
    "        br_delta_temp_all[b, j]   = bT - bN\n",
    "        br_delta_platt_all[b, j]  = bP - bN\n",
    "\n",
    "def per_label_ci_frame(delta_mat: np.ndarray, col_mean: str, col_lo: str, col_hi: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for j, lbl in enumerate(LABELS):\n",
    "        mean = float(np.mean(delta_mat[:, j]))\n",
    "        lo   = float(np.percentile(delta_mat[:, j],2.5))\n",
    "        hi   = float(np.percentile(delta_mat[:, j],97.5))\n",
    "        rows.append({\"label\": lbl, col_mean: mean, col_lo: lo, col_hi: hi})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "per_ece_temp  = per_label_ci_frame(ece_delta_temp_all,  \"delta_ECE_Temp_mean\",\"delta_ECE_Temp_lo\",\"delta_ECE_Temp_hi\")\n",
    "per_ece_platt = per_label_ci_frame(ece_delta_platt_all, \"delta_ECE_Platt_mean\",\"delta_ECE_Platt_lo\",\"delta_ECE_Platt_hi\")\n",
    "per_br_temp   = per_label_ci_frame(br_delta_temp_all,   \"delta_Brier_Temp_mean\",\"delta_Brier_Temp_lo\",\"delta_Brier_Temp_hi\")\n",
    "per_br_platt  = per_label_ci_frame(br_delta_platt_all,  \"delta_Brier_Platt_mean\",\"delta_Brier_Platt_lo\",\"delta_Brier_Platt_hi\")\n",
    "\n",
    "per_ece_temp.to_csv(DIR_BOOTDEL/\"test_bootstrap_delta_ece_temp_per_label.csv\", index=False)\n",
    "per_ece_platt.to_csv(DIR_BOOTDEL/\"test_bootstrap_delta_ece_platt_per_label.csv\", index=False)\n",
    "per_br_temp.to_csv(DIR_BOOTDEL/\"test_bootstrap_delta_brier_temp_per_label.csv\", index=False)\n",
    "per_br_platt.to_csv(DIR_BOOTDEL/\"test_bootstrap_delta_brier_platt_per_label.csv\", index=False)\n",
    "\n",
    "# ---------------------------\n",
    "# === NEW: Standardized META to v7/v7_Eval/RQ2/outs ===\n",
    "# ---------------------------\n",
    "\n",
    "# 1) Macro+Micro aggregates CSVs (ECE/Brier; Uncal vs Temp) + JSON bundle\n",
    "def _ci_from(d):\n",
    "    return d.get(\"ci_lo\", d.get(\"low\")), d.get(\"ci_hi\", d.get(\"high\"))\n",
    "\n",
    "macro_norm = {\n",
    "    \"ECE_None\":   {\"mean\": agg_macro[\"ECE_None\"][\"mean\"],   \"ci_lo\": agg_macro[\"ECE_None\"][\"ci_lo\"],   \"ci_hi\": agg_macro[\"ECE_None\"][\"ci_hi\"]},\n",
    "    \"ECE_Temp\":   {\"mean\": agg_macro[\"ECE_Temp\"][\"mean\"],   \"ci_lo\": agg_macro[\"ECE_Temp\"][\"ci_lo\"],   \"ci_hi\": agg_macro[\"ECE_Temp\"][\"ci_hi\"]},\n",
    "    \"ECE_Platt\":  {\"mean\": agg_macro[\"ECE_Platt\"][\"mean\"],  \"ci_lo\": agg_macro[\"ECE_Platt\"][\"ci_lo\"],  \"ci_hi\": agg_macro[\"ECE_Platt\"][\"ci_hi\"]},\n",
    "    \"Brier_None\": {\"mean\": agg_macro[\"Brier_None\"][\"mean\"], \"ci_lo\": agg_macro[\"Brier_None\"][\"ci_lo\"], \"ci_hi\": agg_macro[\"Brier_None\"][\"ci_hi\"]},\n",
    "    \"Brier_Temp\": {\"mean\": agg_macro[\"Brier_Temp\"][\"mean\"], \"ci_lo\": agg_macro[\"Brier_Temp\"][\"ci_lo\"], \"ci_hi\": agg_macro[\"Brier_Temp\"][\"ci_hi\"]},\n",
    "    \"Brier_Platt\":{\"mean\": agg_macro[\"Brier_Platt\"][\"mean\"],\"ci_lo\": agg_macro[\"Brier_Platt\"][\"ci_lo\"],\"ci_hi\": agg_macro[\"Brier_Platt\"][\"ci_hi\"]},\n",
    "}\n",
    "\n",
    "def pack_rows(metric_key_prefix: str, agg_macro_dict: dict, agg_micro_dict: dict):\n",
    "    rows = []\n",
    "    for method_key, method_label in [(\"None\",\"Uncal.\"), (\"Temp\",\"Temp.\")]:\n",
    "        m = agg_macro_dict[f\"{metric_key_prefix}_{method_key}\"]\n",
    "        lo, hi = _ci_from(m)\n",
    "        rows.append({\"method\": method_label, \"group\": \"Macro\",\n",
    "                     \"mean\": m[\"mean\"], \"low\": lo, \"high\": hi})\n",
    "        mm = agg_micro_dict[f\"{metric_key_prefix}_{method_key}\"]\n",
    "        rows.append({\"method\": method_label, \"group\": \"Micro\",\n",
    "                     \"mean\": mm[\"mean\"], \"low\": mm[\"low\"], \"high\": mm[\"high\"]})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "ece_uncal_temp_df   = pack_rows(\"ECE\",   macro_norm, agg_micro)\n",
    "brier_uncal_temp_df = pack_rows(\"Brier\", macro_norm, agg_micro)\n",
    "ece_uncal_temp_df.to_csv(OUTS / \"T2_2_aggregates_ece_uncal_vs_temp.csv\", index=False)\n",
    "brier_uncal_temp_df.to_csv(OUTS / \"T2_2_aggregates_brier_uncal_vs_temp.csv\", index=False)\n",
    "\n",
    "with open(OUTS / \"T2_2_aggregates_macro_micro.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"macro\": macro_norm, \"micro\": agg_micro, \"n_bins\": 15}, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 2) T2.3: Per-assay ECE (Uncal vs Temp)\n",
    "t23 = T2_base[[\"label\",\"ECE_None\",\"ECE_Temp\"]].copy()\n",
    "t23 = t23[~t23[\"label\"].astype(str).str.lower().isin({\"macro\",\"micro\"})]\n",
    "t23 = t23.rename(columns={\"label\":\"Assay\", \"ECE_None\":\"ECE_Uncal\", \"ECE_Temp\":\"ECE_Temp\"})\n",
    "t23 = t23.assign(ECE_Uncal=lambda d: d[\"ECE_Uncal\"].astype(float).round(3),\n",
    "                 ECE_Temp=lambda d: d[\"ECE_Temp\"].astype(float).round(3))\n",
    "t23.to_csv(OUTS / \"T2_3_per_assay_ece_uncal_vs_temp.csv\", index=False)\n",
    "\n",
    "# 3) T2.5: Temp vs Platt (Macro/Micro table)\n",
    "def fmt_row(tup): \n",
    "    return \"\" if tup is None else f\"{tup['mean']:.3f} ({_ci_from(tup)[0]:.2f}, {_ci_from(tup)[1]:.2f})\"\n",
    "rows_t25 = []\n",
    "rows_t25.append({\n",
    "    \"Group\": \"Macro\",\n",
    "    \"ECE Uncal.\": fmt_row(macro_norm[\"ECE_None\"]),\n",
    "    \"ECE Temp.\":  fmt_row(macro_norm[\"ECE_Temp\"]),\n",
    "    \"ECE Platt\":  fmt_row(macro_norm[\"ECE_Platt\"]),\n",
    "    \"Brier Uncal.\": fmt_row(macro_norm[\"Brier_None\"]),\n",
    "    \"Brier Temp.\":  fmt_row(macro_norm[\"Brier_Temp\"]),\n",
    "    \"Brier Platt\":  fmt_row(macro_norm[\"Brier_Platt\"]),\n",
    "})\n",
    "rows_t25.append({\n",
    "    \"Group\": \"Micro\",\n",
    "    \"ECE Uncal.\": fmt_row(agg_micro[\"ECE_None\"]),\n",
    "    \"ECE Temp.\":  fmt_row(agg_micro[\"ECE_Temp\"]),\n",
    "    \"ECE Platt\":  fmt_row(agg_micro[\"ECE_Platt\"]),\n",
    "    \"Brier Uncal.\": fmt_row(agg_micro[\"Brier_None\"]),\n",
    "    \"Brier Temp.\":  fmt_row(agg_micro[\"Brier_Temp\"]),\n",
    "    \"Brier Platt\":  fmt_row(agg_micro[\"Brier_Platt\"]),\n",
    "})\n",
    "pd.DataFrame(rows_t25).to_csv(OUTS / \"T2_5_temp_vs_platt.csv\", index=False)\n",
    "\n",
    "# 4) Reliability CSVs per assay (Uncal vs Temp; same bins/axes)\n",
    "for lbl in LABELS:\n",
    "    dN = bins_none[lbl].copy()\n",
    "    dT = bins_temp[lbl].copy()\n",
    "    dN[\"method\"] = \"Uncal.\"\n",
    "    dT[\"method\"] = \"Temp.\"\n",
    "    rel = pd.concat([dN[[\"bin\",\"count\",\"conf\",\"acc\",\"method\"]],\n",
    "                     dT[[\"bin\",\"count\",\"conf\",\"acc\",\"method\"]]], ignore_index=True)\n",
    "    rel.to_csv(OUTS / \"reliability\" / f\"{lbl}.csv\", index=False)\n",
    "\n",
    "# 5) Temp probability CSVs per assay + prevalence map\n",
    "prev_rows = []\n",
    "for j, lbl in enumerate(LABELS):\n",
    "    m = Mt[:, j].astype(bool)\n",
    "    probs_j = P_temp[m, j].astype(float)\n",
    "    pd.DataFrame({\"prob\": probs_j}).to_csv(OUTS / \"probs_temp_per_assay\" / f\"{lbl}.csv\", index=False)\n",
    "    prev_rows.append({\"Assay\": lbl, \"Prevalence\": float((Yt[m, j].astype(int)).mean() if m.any() else np.nan)})\n",
    "pd.DataFrame(prev_rows).to_csv(OUTS / \"prevalence.csv\", index=False)\n",
    "\n",
    "# 6) Save bootstrap arrays (optional, helpful)\n",
    "np.save(OUTS / \"bootstrap_macro_ece_none.npy\",  mac_eN)\n",
    "np.save(OUTS / \"bootstrap_macro_ece_temp.npy\",  mac_eT)\n",
    "np.save(OUTS / \"bootstrap_macro_brier_none.npy\", mac_bN)\n",
    "np.save(OUTS / \"bootstrap_macro_brier_temp.npy\", mac_bT)\n",
    "np.save(OUTS / \"bootstrap_micro_ece_none.npy\",  mic_eN)\n",
    "np.save(OUTS / \"bootstrap_micro_ece_temp.npy\",  mic_eT)\n",
    "np.save(OUTS / \"bootstrap_micro_brier_none.npy\", mic_bN)\n",
    "np.save(OUTS / \"bootstrap_micro_brier_temp.npy\", mic_bT)\n",
    "\n",
    "# 7) Provenance manifest for outs\n",
    "manifest = {\n",
    "    \"n_labels\": int(L),\n",
    "    \"labels\": LABELS,\n",
    "    \"n_bins\": 15,\n",
    "    \"bootstrap\": {\"B\": int(B), \"seed\": int(SEED), \"level\": \"molecule\"},\n",
    "    \"sources\": {\n",
    "        \"macro_agg_json\": str((DIR_BOOTDEL / \"test_macro_ece_brier_aggregates.json\").resolve()),\n",
    "        \"micro_agg_json\": str((DIR_BOOTDEL / \"test_micro_ece_brier_aggregates.json\").resolve()),\n",
    "        \"t2_base_csv\": str((DIR_T2 / \"T2_test_ece_brier.csv\").resolve()),\n",
    "    },\n",
    "    \"generated\": {\n",
    "        \"T2_2_ece_csv\": \"T2_2_aggregates_ece_uncal_vs_temp.csv\",\n",
    "        \"T2_2_brier_csv\": \"T2_2_aggregates_brier_uncal_vs_temp.csv\",\n",
    "        \"macro_micro_json\": \"T2_2_aggregates_macro_micro.json\",\n",
    "        \"T2_3_ece_csv\": \"T2_3_per_assay_ece_uncal_vs_temp.csv\",\n",
    "        \"T2_5_table_csv\": \"T2_5_temp_vs_platt.csv\",\n",
    "        \"reliability_dir\": \"reliability/<ASSAY>.csv (bin,count,conf,acc,method)\",\n",
    "        \"temp_probs_dir\": \"probs_temp_per_assay/<ASSAY>.csv (prob)\",\n",
    "        \"prevalence_csv\": \"prevalence.csv\",\n",
    "        \"bootstrap_arrays\": [\n",
    "            \"bootstrap_macro_ece_none.npy\",\"bootstrap_macro_ece_temp.npy\",\n",
    "            \"bootstrap_macro_brier_none.npy\",\"bootstrap_macro_brier_temp.npy\",\n",
    "            \"bootstrap_micro_ece_none.npy\",\"bootstrap_micro_ece_temp.npy\",\n",
    "            \"bootstrap_micro_brier_none.npy\",\"bootstrap_micro_brier_temp.npy\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "with open(OUTS / \"manifest.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(manifest, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Done (no figures saved here). All META needed for RQ2 figures is under v7/v7_Eval/RQ2/outs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5aac69",
   "metadata": {},
   "source": [
    "### figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fced4a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving PNGs to: D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ2\\figs\n",
      "Saved: F2_2a_ece_macro_micro_uncal_vs_temp.png\n",
      "Saved: F2_2b_brier_macro_micro_uncal_vs_temp.png\n",
      "Saved: F2_3_reliability_grid_uncal_vs_temp.png\n",
      "Saved: F2_4_prob_histograms_after_temp.png\n",
      "Saved: T2_2_aggregates.png\n",
      "Saved: T2_3_per_assay_ece_uncal_vs_temp.png\n",
      "Saved: T2_5_temp_vs_platt.png\n",
      "Saved: F2_5_temp_vs_platt_macro_micro.png\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# RQ2 Figure & Table Generator (PNG-only, clean journal style — matches RQ1 style)\n",
    "# Reads META from: v7/v7_Eval/RQ2/outs\n",
    "# Saves PNGs to:    v7/v7_Eval/RQ2/figs\n",
    "# Requires: pandas, numpy, matplotlib\n",
    "# ==============================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import glob, json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# ------------------------------- STYLE ----------------------------------------\n",
    "DPI = 300\n",
    "FONT_SIZE = 11\n",
    "LABEL_SIZE = 12\n",
    "TITLE_SIZE = 13\n",
    "LINE_WIDTH = 2.0\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    \"figure.dpi\": DPI,\n",
    "    \"savefig.dpi\": DPI,\n",
    "    \"font.size\": FONT_SIZE,\n",
    "    \"axes.labelsize\": LABEL_SIZE,\n",
    "    \"axes.titlesize\": TITLE_SIZE,\n",
    "    \"legend.fontsize\": FONT_SIZE,\n",
    "    \"xtick.labelsize\": FONT_SIZE,\n",
    "    \"ytick.labelsize\": FONT_SIZE,\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.alpha\": 0.25,\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.spines.right\": False,\n",
    "})\n",
    "\n",
    "# Sizes (kept consistent with your RQ1 generator)\n",
    "FIGSIZE_GRID = (12, 8.5)   # 3x4 small multiples\n",
    "FIGSIZE_BAR  = (10, 5.5)   # grouped bars\n",
    "FIGWIDTH_TAB = 11.0        # tables; height auto-scales by rows\n",
    "\n",
    "# Titles\n",
    "TITLE_F22A = \"F2.2a — Macro/Micro ECE (Uncal. vs Temp.; TEST)\"\n",
    "TITLE_F22B = \"F2.2b — Macro/Micro Brier (Uncal. vs Temp.; TEST)\"\n",
    "TITLE_F23  = \"F2.3 — Reliability: Uncal. vs Temp. (TEST, same bins; B=15)\"\n",
    "TITLE_F24  = \"F2.4 — Probability histograms after Temp. (per assay; TEST)\"\n",
    "TITLE_T22  = \"T2.2 — Aggregate calibration (Macro/Micro; TEST)\"\n",
    "TITLE_T23  = \"T2.3 — Per-assay ECE (Uncal. vs Temp.; TEST)\"\n",
    "TITLE_T25  = \"T2.5 — Temp. vs Platt (Macro/Micro; TEST)\"\n",
    "TITLE_F25  = \"F2.5 — Macro/Micro: Temp. vs Platt (ECE & Brier; TEST)\"\n",
    "\n",
    "# Bold these assay names in tables (same set you used on RQ1)\n",
    "BOLD_ASSAYS = {\"NR-AR-LBD\", \"NR-PPAR-gamma\", \"SR-ATAD5\"}\n",
    "\n",
    "# ------------------------------- PATHS ----------------------------------------\n",
    "BASE = Path(\"v7/v7_Eval/RQ2\")\n",
    "OUTS = BASE / \"outs\"\n",
    "FIGS = BASE / \"figs\"\n",
    "FIGS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PATHS = {\n",
    "    \"ece_macro_micro_csv\": OUTS / \"T2_2_aggregates_ece_uncal_vs_temp.csv\",\n",
    "    \"brier_macro_micro_csv\": OUTS / \"T2_2_aggregates_brier_uncal_vs_temp.csv\",\n",
    "    \"macro_micro_json\": OUTS / \"T2_2_aggregates_macro_micro.json\",\n",
    "    \"t23_per_assay_ece_csv\": OUTS / \"T2_3_per_assay_ece_uncal_vs_temp.csv\",\n",
    "    \"t25_temp_vs_platt_csv\": OUTS / \"T2_5_temp_vs_platt.csv\",\n",
    "    \"reliability_dir\": OUTS / \"reliability\",\n",
    "    \"probs_temp_dir\": OUTS / \"probs_temp_per_assay\",\n",
    "    \"prevalence_csv\": OUTS / \"prevalence.csv\",\n",
    "}\n",
    "\n",
    "# Outputs (PNG file stems only)\n",
    "OUT = {\n",
    "    \"F22A\": \"F2_2a_ece_macro_micro_uncal_vs_temp\",\n",
    "    \"F22B\": \"F2_2b_brier_macro_micro_uncal_vs_temp\",\n",
    "    \"F23\":  \"F2_3_reliability_grid_uncal_vs_temp\",\n",
    "    \"F24\":  \"F2_4_prob_histograms_after_temp\",\n",
    "    \"T22\":  \"T2_2_aggregates\",\n",
    "    \"T23\":  \"T2_3_per_assay_ece_uncal_vs_temp\",\n",
    "    \"T25\":  \"T2_5_temp_vs_platt\",\n",
    "    \"F25\":  \"F2_5_temp_vs_platt_macro_micro\",\n",
    "}\n",
    "\n",
    "# ---------------------------- UTILITIES ---------------------------------------\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_png(fig, stem: str):\n",
    "    ensure_dir(FIGS)\n",
    "    fig.savefig(FIGS / f\"{stem}.png\", bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(\"Saved:\", f\"{stem}.png\")\n",
    "\n",
    "def load_csv(p: Path):\n",
    "    return pd.read_csv(p) if p and p.exists() else None\n",
    "\n",
    "def _norm(s):  # normalize for fuzzy matching\n",
    "    return re.sub(r'[^a-z0-9]+', '', str(s).lower())\n",
    "\n",
    "def table_like_figure(table_df: pd.DataFrame, title: str, bold_rows=set()):\n",
    "    \"\"\"\n",
    "    Render a clean table similar to RQ1 journal style:\n",
    "    - bold title & header\n",
    "    - horizontal rules (top, after header, bottom)\n",
    "    - left-aligned first column; others centered\n",
    "    \"\"\"\n",
    "    n_rows, n_cols = table_df.shape\n",
    "    fig_height = max(2.2, 0.38 * (n_rows + 2))  # compact, scales with rows\n",
    "    fig = plt.figure(figsize=(FIGWIDTH_TAB, fig_height))\n",
    "    ax = plt.gca()\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # Title\n",
    "    ax.text(0.0, 1.04, title, fontsize=TITLE_SIZE, fontweight=\"bold\",\n",
    "            transform=ax.transAxes, ha=\"left\", va=\"bottom\")\n",
    "\n",
    "    left, right = 0.02, 0.98\n",
    "    y_top = 0.96\n",
    "\n",
    "    # Top rule\n",
    "    ax.hlines(y_top, left, right, transform=ax.transAxes, linewidth=1.0, color=\"black\")\n",
    "\n",
    "    # Column widths (first wider)\n",
    "    col_widths = [0.36] + [ (right-left-0.36)/(n_cols-1) ]*(n_cols-1)\n",
    "    x_positions = [left]\n",
    "    for w in col_widths[:-1]:\n",
    "        x_positions.append(x_positions[-1]+w)\n",
    "\n",
    "    # Header row\n",
    "    y = y_top - 0.08\n",
    "    for j, col in enumerate(table_df.columns):\n",
    "        ha = \"left\" if j==0 else \"center\"\n",
    "        ax.text(x_positions[j]+(0 if j==0 else col_widths[j]/2), y, str(col),\n",
    "                fontsize=FONT_SIZE, fontweight=\"bold\", ha=ha, va=\"center\", transform=ax.transAxes)\n",
    "\n",
    "    # Mid rule\n",
    "    ax.hlines(y-0.035, left, right, transform=ax.transAxes, linewidth=0.8, color=\"black\")\n",
    "\n",
    "    # Body rows\n",
    "    y_step = 0.06\n",
    "    y -= 0.06\n",
    "    for i in range(n_rows):\n",
    "        row = table_df.iloc[i].tolist()\n",
    "        is_bold = str(row[0]) in bold_rows\n",
    "        for j, val in enumerate(row):\n",
    "            ha = \"left\" if j==0 else \"center\"\n",
    "            ax.text(x_positions[j]+(0 if j==0 else col_widths[j]/2), y, str(val),\n",
    "                    fontsize=FONT_SIZE, fontweight=\"bold\" if is_bold else \"normal\",\n",
    "                    ha=ha, va=\"center\", transform=ax.transAxes)\n",
    "        y -= y_step\n",
    "\n",
    "    # Bottom rule\n",
    "    ax.hlines(y+0.02, left, right, transform=ax.transAxes, linewidth=1.0, color=\"black\")\n",
    "    return fig\n",
    "\n",
    "# ----------------------- F2.2a / F2.2b: Grouped bars --------------------------\n",
    "def grouped_bars_from_csv(csv_path: Path, metric_label: str, title: str, out_stem: str):\n",
    "    df = load_csv(csv_path)\n",
    "    if df is None or df.empty:\n",
    "        print(\"Missing:\", csv_path)\n",
    "        return\n",
    "\n",
    "    # Expect columns: method (Uncal., Temp.), group (Macro/Micro), mean, low, high\n",
    "    groups  = [\"Macro\", \"Micro\"]\n",
    "    methods = df[\"method\"].drop_duplicates().tolist()\n",
    "    x = np.arange(len(groups))\n",
    "    width = 0.36 if len(methods) == 2 else 0.26\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE_BAR)\n",
    "    for i, method in enumerate(methods):\n",
    "        sub = df[df[\"method\"] == method].set_index(\"group\").reindex(groups)\n",
    "        means = sub[\"mean\"].values.astype(float)\n",
    "        lows  = sub[\"low\"].values.astype(float)\n",
    "        highs = sub[\"high\"].values.astype(float)\n",
    "        errs  = np.vstack([means - lows, highs - means])\n",
    "        ax.bar(x + (i - (len(methods)-1)/2)*width, means, width, label=method)\n",
    "        ax.errorbar(x + (i - (len(methods)-1)/2)*width, means, yerr=errs,\n",
    "                    fmt=\"none\", capsize=3, linewidth=1)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(groups)\n",
    "    ax.set_ylabel(metric_label)\n",
    "    ax.set_title(title)\n",
    "    ax.legend(frameon=False, ncol=3, loc=\"upper right\")\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(nbins=6, prune=\"upper\"))\n",
    "    save_png(fig, out_stem)\n",
    "\n",
    "# ----------------------- F2.3: Reliability grid -------------------------------\n",
    "def reliability_grid(reliability_dir: Path, title: str, out_stem: str, max_panels=12):\n",
    "    files = sorted(glob.glob(str(reliability_dir / \"*.csv\")))[:max_panels]\n",
    "    if not files:\n",
    "        print(\"No reliability CSVs in\", reliability_dir)\n",
    "        return\n",
    "    names = [Path(f).stem for f in files]\n",
    "\n",
    "    rows, cols = 3, 4\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=FIGSIZE_GRID, sharex=True, sharey=True)\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i, (assay, f) in enumerate(zip(names, files)):\n",
    "        ax = axes[i]\n",
    "        df = pd.read_csv(f)\n",
    "        for method, style, label in [(\"Uncal.\", \"--\", \"Uncal.\"), (\"Temp.\", \"-\", \"Temp.\")]:\n",
    "            sub = df[df[\"method\"].astype(str) == method]\n",
    "            if not sub.empty:\n",
    "                ax.plot(sub[\"conf\"], sub[\"acc\"], linestyle=style, linewidth=LINE_WIDTH, label=label)\n",
    "        ax.plot([0, 1], [0, 1], linestyle=\":\", linewidth=1, label=\"Perfect\" if i == 0 else None)\n",
    "        ax.set_title(assay)\n",
    "        ax.set_xlim(0, 1); ax.set_ylim(0, 1)\n",
    "        if i // cols == rows - 1: ax.set_xlabel(\"Mean confidence (bin)\")\n",
    "        if i % cols == 0: ax.set_ylabel(\"Accuracy (bin)\")\n",
    "\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc=\"lower center\", ncol=3, frameon=False)\n",
    "    fig.suptitle(title, y=0.98)\n",
    "    fig.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    save_png(fig, out_stem)\n",
    "\n",
    "# ----------------------- F2.4: Probability histograms -------------------------\n",
    "def prob_histograms_after_temp(probs_dir: Path, prevalence_csv: Path, title: str, out_stem: str):\n",
    "    prev = load_csv(prevalence_csv)\n",
    "    if prev is None or prev.empty:\n",
    "        print(\"Missing prevalence:\", prevalence_csv)\n",
    "        return\n",
    "    prev_map = dict(zip(prev[\"Assay\"], prev[\"Prevalence\"]))\n",
    "\n",
    "    files = sorted(glob.glob(str(probs_dir / \"*.csv\")))[:12]\n",
    "    if not files:\n",
    "        print(\"No probability CSVs in\", probs_dir)\n",
    "        return\n",
    "    names = [Path(f).stem for f in files]\n",
    "\n",
    "    rows, cols = 3, 4\n",
    "    bins = np.linspace(0, 1, 21)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=FIGSIZE_GRID, sharex=True, sharey=True)\n",
    "    axes = axes.ravel()\n",
    "    for i, (assay, f) in enumerate(zip(names, files)):\n",
    "        ax = axes[i]\n",
    "        p = pd.read_csv(f)[\"prob\"].astype(float).values\n",
    "        ax.hist(p, bins=bins, alpha=0.9)\n",
    "        if assay in prev_map and np.isfinite(prev_map[assay]):\n",
    "            ax.axvline(prev_map[assay], linestyle=\"--\", linewidth=1.2, label=\"Prevalence\" if i == 0 else None)\n",
    "        ax.set_title(assay)\n",
    "        ax.set_xlim(0, 1)\n",
    "        if i // cols == rows - 1: ax.set_xlabel(\"Predicted probability (Temp.)\")\n",
    "        if i % cols == 0: ax.set_ylabel(\"Count\")\n",
    "\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    if handles:\n",
    "        fig.legend(handles, labels, loc=\"lower center\", ncol=3, frameon=False)\n",
    "    fig.suptitle(title, y=0.98)\n",
    "    fig.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    save_png(fig, out_stem)\n",
    "\n",
    "# ----------------------- T2.2: Aggregate table (PNG) --------------------------\n",
    "def make_T22_aggregate_table(ece_csv: Path, brier_csv: Path):\n",
    "    def load_tidy(p):\n",
    "        d = pd.read_csv(p)\n",
    "        d = d.copy()\n",
    "        d[\"val\"] = d.apply(lambda r: f\"{r['mean']:.3f} ({r['low']:.2f}, {r['high']:.2f})\", axis=1)\n",
    "        piv = d.pivot(index=\"group\", columns=\"method\", values=\"val\").reindex([\"Macro\",\"Micro\"])\n",
    "        return piv.reset_index().rename(columns={\"group\":\"Group\"})\n",
    "\n",
    "    e = load_tidy(ece_csv)\n",
    "    b = load_tidy(brier_csv)\n",
    "\n",
    "    table = pd.DataFrame({\n",
    "        \"Group\": e[\"Group\"],\n",
    "        \"ECE (Uncal.)\": e.get(\"Uncal.\", \"\"),\n",
    "        \"ECE (Temp.)\":  e.get(\"Temp.\", \"\"),\n",
    "        \"Brier (Uncal.)\": b.get(\"Uncal.\", \"\"),\n",
    "        \"Brier (Temp.)\":  b.get(\"Temp.\", \"\")\n",
    "    })\n",
    "    fig = table_like_figure(table, TITLE_T22, bold_rows=set())\n",
    "    save_png(fig, OUT[\"T22\"])\n",
    "\n",
    "# ----------------------- T2.3: Per-assay ECE table (PNG) ----------------------\n",
    "def make_T23_per_assay_table(t23_csv: Path):\n",
    "    df = load_csv(t23_csv)\n",
    "    if df is None or df.empty:\n",
    "        print(\"Missing:\", t23_csv)\n",
    "        return\n",
    "    tidy = df.copy()\n",
    "    tidy[\"ΔECE (Temp − Uncal)\"] = (tidy[\"ECE_Temp\"].astype(float) - tidy[\"ECE_Uncal\"].astype(float)).round(3)\n",
    "    tidy = tidy.rename(columns={\"Assay\":\"Assay\",\"ECE_Uncal\":\"ECE (Uncal.)\",\"ECE_Temp\":\"ECE (Temp.)\"})\n",
    "    # pretty rounding\n",
    "    for c in [\"ECE (Uncal.)\",\"ECE (Temp.)\"]:\n",
    "        tidy[c] = tidy[c].astype(float).map(lambda x: f\"{x:.3f}\")\n",
    "    fig = table_like_figure(tidy, TITLE_T23, bold_rows=BOLD_ASSAYS)\n",
    "    save_png(fig, OUT[\"T23\"])\n",
    "\n",
    "# ----------------------- T2.5: Temp vs Platt table (PNG) ----------------------\n",
    "def make_T25_table(t25_csv: Path):\n",
    "    df = load_csv(t25_csv)\n",
    "    if df is None or df.empty:\n",
    "        print(\"Missing:\", t25_csv)\n",
    "        return\n",
    "    # Ensure column order if present\n",
    "    cols = [\"Group\",\"ECE Uncal.\",\"ECE Temp.\",\"ECE Platt\",\"Brier Uncal.\",\"Brier Temp.\",\"Brier Platt\"]\n",
    "    df = df[[c for c in cols if c in df.columns]]\n",
    "    fig = table_like_figure(df, TITLE_T25, bold_rows=set())\n",
    "    save_png(fig, OUT[\"T25\"])\n",
    "\n",
    "# ----------------------- F2.5: Temp vs Platt grouped bars ---------------------\n",
    "def plot_F25_temp_vs_platt(macro_micro_json: Path):\n",
    "    if not macro_micro_json.exists():\n",
    "        print(\"Missing:\", macro_micro_json)\n",
    "        return\n",
    "    jj = json.loads(macro_micro_json.read_text(encoding=\"utf-8\"))\n",
    "    macro, micro = jj[\"macro\"], jj[\"micro\"]\n",
    "\n",
    "    def grab(scope, met, meth):\n",
    "        k = f\"{met}_{meth}\"\n",
    "        v = scope[k]\n",
    "        lo = v.get(\"ci_lo\", v.get(\"low\"))\n",
    "        hi = v.get(\"ci_hi\", v.get(\"high\"))\n",
    "        return v[\"mean\"], lo, hi\n",
    "\n",
    "    groups  = [\"Macro\",\"Micro\"]\n",
    "    methods = [\"Uncal.\",\"Temp.\",\"Platt\"]\n",
    "    metrics = [\"ECE\",\"Brier\"]\n",
    "\n",
    "    frames = {}\n",
    "    for met in metrics:\n",
    "        rows = []\n",
    "        for grp, scope in [(\"Macro\", macro), (\"Micro\", micro)]:\n",
    "            for meth_key, label in [(\"None\",\"Uncal.\"), (\"Temp\",\"Temp.\"), (\"Platt\",\"Platt\")]:\n",
    "                m, lo, hi = grab(scope, met, meth_key)\n",
    "                rows.append({\"Group\": grp, \"Method\": label, \"Mean\": m, \"Low\": lo, \"High\": hi})\n",
    "        frames[met] = pd.DataFrame(rows)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(13, 5.5), sharey=False)\n",
    "    for ax, met in zip(axes, metrics):\n",
    "        df = frames[met]\n",
    "        x = np.arange(len(groups))\n",
    "        width = 0.23\n",
    "        for i, method in enumerate(methods):\n",
    "            sub = df[df[\"Method\"] == method].set_index(\"Group\").reindex(groups)\n",
    "            means = sub[\"Mean\"].values.astype(float)\n",
    "            lows  = sub[\"Low\"].values.astype(float)\n",
    "            highs = sub[\"High\"].values.astype(float)\n",
    "            errs = np.vstack([means - lows, highs - means])\n",
    "            ax.bar(x + (i-1)*width, means, width, label=method)\n",
    "            ax.errorbar(x + (i-1)*width, means, yerr=errs, fmt=\"none\", capsize=3, linewidth=1)\n",
    "        ax.set_xticks(x); ax.set_xticklabels(groups)\n",
    "        ax.set_ylabel(met)\n",
    "        ax.set_title(met)\n",
    "\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc=\"upper center\", ncol=3, frameon=False, bbox_to_anchor=(0.5, 1.03))\n",
    "    fig.suptitle(TITLE_F25, y=0.98)\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "    save_png(fig, OUT[\"F25\"])\n",
    "\n",
    "# -------------------------------- DRIVER --------------------------------------\n",
    "def main():\n",
    "    print(f\"Saving PNGs to: {FIGS.resolve()}\")\n",
    "\n",
    "    # F2.2a / F2.2b bars\n",
    "    grouped_bars_from_csv(PATHS[\"ece_macro_micro_csv\"],   metric_label=\"ECE\",\n",
    "                          title=TITLE_F22A + \"\\n95% bootstrap CI\", out_stem=OUT[\"F22A\"])\n",
    "    grouped_bars_from_csv(PATHS[\"brier_macro_micro_csv\"], metric_label=\"Brier\",\n",
    "                          title=TITLE_F22B + \"\\n95% bootstrap CI\", out_stem=OUT[\"F22B\"])\n",
    "\n",
    "    # F2.3 reliability grid\n",
    "    reliability_grid(PATHS[\"reliability_dir\"], title=TITLE_F23, out_stem=OUT[\"F23\"])\n",
    "\n",
    "    # F2.4 prob histograms (Temp) w/ prevalence\n",
    "    prob_histograms_after_temp(PATHS[\"probs_temp_dir\"], PATHS[\"prevalence_csv\"],\n",
    "                               title=TITLE_F24, out_stem=OUT[\"F24\"])\n",
    "\n",
    "    # T2.2 / T2.3 / T2.5 table PNGs\n",
    "    make_T22_aggregate_table(PATHS[\"ece_macro_micro_csv\"], PATHS[\"brier_macro_micro_csv\"])\n",
    "    make_T23_per_assay_table(PATHS[\"t23_per_assay_ece_csv\"])\n",
    "    make_T25_table(PATHS[\"t25_temp_vs_platt_csv\"])\n",
    "\n",
    "    # F2.5 bars (Temp vs Platt, ECE & Brier)\n",
    "    plot_F25_temp_vs_platt(PATHS[\"macro_micro_json\"])\n",
    "\n",
    "    print(\"Done.\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc359055",
   "metadata": {},
   "source": [
    "## RQ3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b9ded",
   "metadata": {},
   "source": [
    "### All the requirements including the Tables and the Graphs and saved under RQ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ba29a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] N=6265 L=12  observed=62450  positives=4888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:33:22] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Seeds] common: ['seed13', 'seed29', 'seed47', 'seed61', 'seed83']\n",
      "\n",
      "[T3] Saved → D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ3\\T3\\T3_macro_pr_auc.csv\n",
      "[T3] Variance reduction: {'specialist_var': 0.00026, 'blend_var': 9.8e-05, 'variance_reduction_pct': 62.51, 'note': 'Variance is computed across seeds (ddof=1).'}\n",
      "[F6] Saved boxplots → D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ3\\F6_boxplots\n",
      "\n",
      "✅ RQ3 complete.\n",
      "• Seeds: ['seed13', 'seed29', 'seed47', 'seed61', 'seed83']\n",
      "• T3: D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ3\\T3\\T3_macro_pr_auc.csv\n",
      "• Variance summary: D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ3\\T3\\variance_summary.json\n",
      "• F6: D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ3\\F6_boxplots\n",
      "• Empty rates: D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ3\\empty_predictions\\empty_rate_by_seed.csv\n",
      "• Per-assay OFF: D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ3\\empty_predictions\\label_off_rate_before_after.csv\n"
     ]
    }
   ],
   "source": [
    "# RQ3 — Robustness across seeds & empty-prediction analysis (variance reduction + optional stress test)\n",
    "from __future__ import annotations\n",
    "import json, math\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ===== config =====\n",
    "RUN_STRESS_TEST = False       # optional MC-dropout/TTA\n",
    "TTA_PASSES      = 8           # number of stochastic passes if enabled\n",
    "\n",
    "# ===== helpers =====\n",
    "def wtxt(p: Path, s: str): p.parent.mkdir(parents=True, exist_ok=True); p.write_text(s, encoding=\"utf-8\")\n",
    "def wjson(p: Path, o: dict): p.parent.mkdir(parents=True, exist_ok=True); p.write_text(json.dumps(o, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "def detect_v7() -> Path:\n",
    "    cwd = Path(\".\").resolve()\n",
    "    if (cwd/\"data\").exists() and (cwd/\"model\").exists() and cwd.name == \"v7\": return cwd\n",
    "    if (cwd/\"v7\"/\"data\").exists(): return (cwd/\"v7\").resolve()\n",
    "    return cwd\n",
    "\n",
    "V7 = detect_v7()\n",
    "PREP = V7/\"data\"/\"prepared\"\n",
    "SPL  = V7/\"data\"/\"splits\"\n",
    "MOD  = V7/\"model\"\n",
    "ENS  = MOD/\"ensembles\"\n",
    "CAL  = MOD/\"calibration\"\n",
    "CKPT = MOD/\"checkpoints\"/\"shared\"/\"best.pt\"\n",
    "\n",
    "OUT  = V7/\"v7_Eval\"/\"RQ3\"\n",
    "DIR_SEEDS   = OUT/\"seeds\";              DIR_SEEDS.mkdir(parents=True, exist_ok=True)\n",
    "DIR_T3      = OUT/\"T3\";                 DIR_T3.mkdir(parents=True, exist_ok=True)\n",
    "DIR_F6      = OUT/\"F6_boxplots\";        DIR_F6.mkdir(parents=True, exist_ok=True)\n",
    "DIR_EMPTY   = OUT/\"empty_predictions\";  DIR_EMPTY.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ===== data =====\n",
    "def load_split(split_path: Path, prefer=(\"test.npz\",\"train.npz\",\"val.npz\")) -> Tuple[np.ndarray,np.ndarray,np.ndarray,np.ndarray]:\n",
    "    idx = np.load(split_path)\n",
    "    choice = None\n",
    "    for name in prefer:\n",
    "        p = PREP/name\n",
    "        if not p.exists(): continue\n",
    "        z = np.load(p, allow_pickle=True)\n",
    "        if \"indices\" in z and np.isin(idx, z[\"indices\"]).any():\n",
    "            choice = p; z.close(); break\n",
    "        z.close()\n",
    "    if choice is None:\n",
    "        for name in prefer:\n",
    "            p = PREP/name\n",
    "            if p.exists(): choice=p; break\n",
    "    Z = np.load(choice, allow_pickle=True)\n",
    "    Y_full = Z[\"Y\"].astype(float)\n",
    "    OBS_full = (~Z[\"y_missing_mask\"].astype(bool)) if \"y_missing_mask\" in Z else ~np.isnan(Y_full)\n",
    "    smiles_full = list(Z[\"smiles\"]); X_full = Z[\"X\"].astype(np.float32)\n",
    "    if \"indices\" in Z:\n",
    "        pos = pd.Series(np.arange(len(Z[\"indices\"])), index=Z[\"indices\"]).reindex(idx)\n",
    "        order = pos.astype(int).to_numpy()\n",
    "    else:\n",
    "        order = np.arange(len(idx))\n",
    "    Y = np.nan_to_num(Y_full[order], nan=0.0).astype(int)\n",
    "    OBS = OBS_full[order].astype(bool)\n",
    "    X = X_full[order]\n",
    "    SMI = np.array([smiles_full[i] for i in order], dtype=object)\n",
    "    return Y, OBS, X, SMI\n",
    "\n",
    "TEST_SPLIT = SPL/\"train.npy\"\n",
    "assert TEST_SPLIT.exists(), \"Missing split: v7/data/splits/train.npy\"\n",
    "Yt, Mt, Xt, SMt = load_split(TEST_SPLIT)\n",
    "\n",
    "mani = json.loads((PREP/\"dataset_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "LABELS: List[str] = mani[\"labels\"]; L = len(LABELS)\n",
    "DESC_IN_DIM = int(mani[\"n_features\"])\n",
    "\n",
    "N = Yt.shape[0]\n",
    "print(f\"[TEST] N={N} L={L}  observed={int(Mt.sum())}  positives={int((Yt*Mt).sum())}\")\n",
    "\n",
    "# ===== model rig (Phase-5, 51D graph feats) =====\n",
    "from rdkit import Chem\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ChemBERTaEncoder(nn.Module):\n",
    "    def __init__(self, ckpt_name=\"seyonec/ChemBERTa-zinc-base-v1\", fusion_dim=256, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(ckpt_name)\n",
    "        self.backbone  = AutoModel.from_pretrained(ckpt_name)\n",
    "        self.proj = nn.Sequential(nn.Dropout(dropout_p), nn.Linear(self.backbone.config.hidden_size, fusion_dim))\n",
    "        self.ln = nn.LayerNorm(fusion_dim)\n",
    "    def forward(self, smiles_list: List[str], max_length=256, add_special_tokens=True):\n",
    "        enc = self.tokenizer(list(smiles_list), padding=True, truncation=True,\n",
    "                             max_length=max_length, add_special_tokens=add_special_tokens, return_tensors=\"pt\")\n",
    "        input_ids, attention_mask = enc[\"input_ids\"].to(device), enc[\"attention_mask\"].to(device)\n",
    "        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "        toks = self.ln(self.proj(out))\n",
    "        return toks, attention_mask.to(dtype=torch.int32)\n",
    "\n",
    "ATOM_LIST = [\"H\",\"C\",\"N\",\"O\",\"F\",\"P\",\"S\",\"Cl\",\"Br\",\"I\"]\n",
    "def _one_hot(v, choices):\n",
    "    z=[0]*len(choices)\n",
    "    if v in choices: z[choices.index(v)] = 1\n",
    "    return z\n",
    "def _bucket_oh(v, lo, hi):\n",
    "    buckets=list(range(lo,hi+1)); o=[0]*(len(buckets)+1); idx=v-lo\n",
    "    o[idx if 0 <= idx < len(buckets) else -1] = 1; return o\n",
    "def _atom_feat(atom):\n",
    "    hybs=[Chem.rdchem.HybridizationType.S, Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
    "          Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.SP3D, Chem.rdchem.HybridizationType.SP3D2]\n",
    "    chir=[Chem.rdchem.ChiralType.CHI_UNSPECIFIED, Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CW,\n",
    "          Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CCW, Chem.rdchem.ChiralType.CHI_OTHER]\n",
    "    sym=atom.GetSymbol()\n",
    "    feat=_one_hot(sym if sym in ATOM_LIST else \"other\", ATOM_LIST+[\"other\"])   # 11\n",
    "    feat+=_bucket_oh(atom.GetDegree(),0,5)                                     # +7 => 18\n",
    "    feat+=_bucket_oh(atom.GetFormalCharge(),-2,2)                              # +6 => 24\n",
    "    feat+=(_one_hot(atom.GetHybridization(), hybs)+[0])                        # +7 => 31\n",
    "    feat+=[int(atom.GetIsAromatic())]                                          # +1 => 32\n",
    "    feat+=[int(atom.IsInRing())]                                               # +1 => 33\n",
    "    feat+=_one_hot(atom.GetChiralTag(), chir)                                  # +4 => 37\n",
    "    feat+=_bucket_oh(atom.GetTotalNumHs(includeNeighbors=True),0,4)            # +6 => 43\n",
    "    feat+=_bucket_oh(atom.GetTotalValence(),0,5)                               # +7 => 50\n",
    "    feat+=[atom.GetMass()/200.0]                                               # +1 => 51\n",
    "    return feat\n",
    "def _smiles_to_graph(smi, max_nodes=128):\n",
    "    mol=Chem.MolFromSmiles(smi)\n",
    "    if mol is None or mol.GetNumAtoms()==0:\n",
    "        return np.zeros((0,0),np.float32), np.zeros((0,0),np.float32)\n",
    "    feats=[_atom_feat(mol.GetAtomWithIdx(i)) for i in range(mol.GetNumAtoms())]\n",
    "    if len(feats) and len(feats[0]) != 51:\n",
    "        raise RuntimeError(f\"Node feature dim drifted: got {len(feats[0])}, expected 51.\")\n",
    "    x=np.asarray(feats,dtype=np.float32)\n",
    "    Nn=mol.GetNumAtoms(); A=np.zeros((Nn,Nn),np.float32)\n",
    "    for b in mol.GetBonds():\n",
    "        i,j=b.GetBeginAtomIdx(), b.GetEndAtomIdx(); A[i,j]=1.0; A[j,i]=1.0\n",
    "    if Nn>max_nodes: x=x[:max_nodes]; A=A[:max_nodes,:max_nodes]\n",
    "    return x,A\n",
    "def _collate_graphs(smiles_batch, max_nodes=128):\n",
    "    gs=[_smiles_to_graph(s) for s in smiles_batch]\n",
    "    Nmax=max([g[0].shape[0] for g in gs]+[1])\n",
    "    F=gs[0][0].shape[1] if gs[0][0].size>0 else 51\n",
    "    B=len(gs)\n",
    "    X=np.zeros((B,Nmax,F),np.float32); A=np.zeros((B,Nmax,Nmax),np.float32); M=np.zeros((B,Nmax),np.int64)\n",
    "    for i,(x,a) in enumerate(gs):\n",
    "        n=x.shape[0]\n",
    "        if n==0: continue\n",
    "        X[i,:n,:]=x; A[i,:n,:n]=a; M[i,:n]=1\n",
    "    import torch\n",
    "    return torch.from_numpy(X).to(device), torch.from_numpy(A).to(device), torch.from_numpy(M).to(device)\n",
    "def masked_mean(x,m,dim):\n",
    "    m=m.to(dtype=x.dtype,device=x.device); d=m.sum(dim=dim,keepdim=True).clamp(min=1.0)\n",
    "    return (x*m.unsqueeze(-1)).sum(dim=dim)/d\n",
    "\n",
    "class GINLayer(nn.Module):\n",
    "    def __init__(self,h=256,p=0.1): super().__init__(); self.eps=nn.Parameter(torch.tensor(0.0)); self.mlp=nn.Sequential(nn.Linear(h,h),nn.GELU(),nn.LayerNorm(h),nn.Dropout(p))\n",
    "    def forward(self,x,a,m): out=(1.0+self.eps)*x+torch.matmul(a,x); out=self.mlp(out); return out*m.unsqueeze(-1).to(out.dtype)\n",
    "\n",
    "class GraphGINEncoder(nn.Module):\n",
    "    def __init__(self,node_in_dim=51,hidden_dim=256,n_layers=4,p=0.1):\n",
    "        super().__init__(); self.inp=nn.Sequential(nn.Linear(node_in_dim,hidden_dim),nn.GELU(),nn.Dropout(p))\n",
    "        self.layers=nn.ModuleList([GINLayer(hidden_dim,p) for _ in range(n_layers)]); self.out_ln=nn.LayerNorm(hidden_dim)\n",
    "    def forward(self,smiles_list: List[str], max_nodes=128):\n",
    "        X,A,M=_collate_graphs(smiles_list,max_nodes=max_nodes); h=self.inp(X)\n",
    "        for lyr in self.layers: h=lyr(h,A,M)\n",
    "        return self.out_ln(h), M.to(dtype=torch.int32)\n",
    "\n",
    "class CrossAttentionBlock(nn.Module):\n",
    "    def __init__(self,dim=256,n_heads=4,p=0.1): super().__init__(); self.mha=nn.MultiheadAttention(dim,n_heads,dropout=p,batch_first=False); self.ln=nn.LayerNorm(dim); self.do=nn.Dropout(p)\n",
    "    def forward(self,tt,tm,gn,gm):\n",
    "        Q=tt.transpose(0,1); K=gn.transpose(0,1); V=gn.transpose(0,1); kpm=(gm==0)\n",
    "        attn,_=self.mha(Q,K,V,key_padding_mask=kpm); attn=attn.transpose(0,1)\n",
    "        return self.ln(tt+self.do(attn))\n",
    "\n",
    "class DescriptorMLP(nn.Module):\n",
    "    def __init__(self,in_dim,out_dim=256,hidden=256,p=0.1): super().__init__(); self.net=nn.Sequential(nn.Linear(in_dim,hidden),nn.GELU(),nn.Dropout(p),nn.Linear(hidden,out_dim),nn.GELU(),nn.Dropout(p))\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "class FusionClassifier(nn.Module):\n",
    "    def __init__(self,dim=256,n_labels=12,p=0.1): super().__init__(); self.mlp=nn.Sequential(nn.Linear(dim*3,dim*2),nn.GELU(),nn.Dropout(p),nn.Linear(dim*2,n_labels))\n",
    "    def forward(self,z): return self.mlp(z)\n",
    "\n",
    "class V7FusionModel(nn.Module):\n",
    "    def __init__(self, te, ge, desc_in_dim=208, dim=256, n_labels=12, n_heads=4, p=0.1):\n",
    "        super().__init__(); self.text_encoder=te; self.graph_encoder=ge; self.cross=CrossAttentionBlock(dim,n_heads,p); self.desc_mlp=DescriptorMLP(desc_in_dim,dim,256,p); self.shared_head=FusionClassifier(dim,n_labels,p)\n",
    "    def forward(self,smiles,desc):\n",
    "        tt,tm=self.text_encoder(smiles,256); gn,gm=self.graph_encoder(smiles,128)\n",
    "        tta=self.cross(tt.to(device),tm.to(device),gn.to(device),gm.to(device)); de=self.desc_mlp(desc.to(device))\n",
    "        text_pool=masked_mean(tta,tm.to(device),1); graph_pool=masked_mean(gn.to(device),gm.to(device),1)\n",
    "        fused=torch.cat([text_pool,graph_pool,de],dim=-1); logits=self.shared_head(fused); return logits,fused\n",
    "\n",
    "class LabelHead(nn.Module):\n",
    "    # names aligned with training checkpoints: block1/2/3\n",
    "    def __init__(self,in_dim=768,h1=512,h2=256,h3=128,p=0.30):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(nn.Linear(in_dim,h1), nn.GELU(), nn.LayerNorm(h1), nn.Dropout(p))\n",
    "        self.block2 = nn.Sequential(nn.Linear(h1,h2),    nn.GELU(), nn.LayerNorm(h2), nn.Dropout(p))\n",
    "        self.block3 = nn.Sequential(nn.Linear(h2,h3),    nn.GELU(), nn.LayerNorm(h3), nn.Dropout(p))\n",
    "        self.out    = nn.Linear(h3,1)\n",
    "        self.short  = nn.Linear(in_dim,h3)\n",
    "    def forward(self,x):\n",
    "        z1=self.block1(x); z2=self.block2(z1); z3=self.block3(z2); z=z3+self.short(x); return self.out(z).squeeze(-1)\n",
    "\n",
    "def _remap_block_keys(state_dict: dict) -> dict:\n",
    "    sd={}\n",
    "    for k,v in state_dict.items():\n",
    "        kk=k.replace(\"b1.\",\"block1.\").replace(\"b2.\",\"block2.\").replace(\"b3.\",\"block3.\")\n",
    "        kk=kk.replace(\"block_1.\",\"block1.\").replace(\"block_2.\",\"block2.\").replace(\"block_3.\",\"block3.\")\n",
    "        sd[kk]=v\n",
    "    return sd\n",
    "\n",
    "def load_head_for_label_seed(label: str, seed_dir: Path, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")) -> nn.Module:\n",
    "    ck = torch.load(seed_dir/\"best.pt\", map_location=\"cpu\")\n",
    "    cfg = ck.get(\"config\", {\"in_dim\":768,\"h1\":512,\"h2\":256,\"h3\":128,\"dropout\":0.30})\n",
    "    head = LabelHead(in_dim=cfg.get(\"in_dim\",768), h1=cfg.get(\"h1\",512), h2=cfg.get(\"h2\",256), h3=cfg.get(\"h3\",128), p=cfg.get(\"dropout\",0.30)).to(device)\n",
    "    try:\n",
    "        head.load_state_dict(ck[\"model\"], strict=True)\n",
    "    except RuntimeError:\n",
    "        head.load_state_dict(_remap_block_keys(ck[\"model\"]), strict=True)\n",
    "    head.eval(); return head\n",
    "\n",
    "# build shared model\n",
    "text_enc = ChemBERTaEncoder().to(device)\n",
    "graph_enc= GraphGINEncoder().to(device)\n",
    "fusion = V7FusionModel(text_enc, graph_enc, desc_in_dim=DESC_IN_DIM, n_labels=L).to(device)\n",
    "ckpt = torch.load(CKPT, map_location=\"cpu\")\n",
    "fusion.load_state_dict(ckpt[\"model\"], strict=True)\n",
    "fusion.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def fused_features(smiles: List[str], desc: np.ndarray, batch: int = 32) -> np.ndarray:\n",
    "    out=np.zeros((len(smiles),768),np.float32); off=0\n",
    "    for i in range(0,len(smiles),batch):\n",
    "        b_smi=smiles[i:i+batch]; b_desc=torch.tensor(desc[i:i+batch],dtype=torch.float32,device=device)\n",
    "        _, fused = fusion(b_smi, b_desc)\n",
    "        out[off:off+len(b_smi)] = fused.detach().cpu().numpy(); off += len(b_smi)\n",
    "    return out\n",
    "\n",
    "def sigmoid(z): return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "@torch.no_grad()\n",
    "def shared_probs(FUSED: np.ndarray) -> np.ndarray:\n",
    "    out=np.zeros((FUSED.shape[0],L),np.float32)\n",
    "    for i in range(0,FUSED.shape[0],64):\n",
    "        x=torch.tensor(FUSED[i:i+64],dtype=torch.float32,device=device)\n",
    "        out[i:i+64]=fusion.shared_head(x).detach().cpu().numpy()\n",
    "    return sigmoid(out)\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "def per_label_ap(Y, P, M) -> np.ndarray:\n",
    "    aps = np.zeros((L,), np.float32)\n",
    "    for j in range(L):\n",
    "        m = M[:, j]\n",
    "        yt, yp = Y[m, j].astype(int), P[m, j].astype(float)\n",
    "        aps[j] = average_precision_score(yt, yp) if (yt.sum()>0 and yt.sum()<yt.size) else np.nan\n",
    "    return aps\n",
    "\n",
    "# ===== calib/thresholds & alpha =====\n",
    "temps_spec = json.loads((CAL/\"temps.json\").read_text(encoding=\"utf-8\"))\n",
    "thr_blob = None\n",
    "for f in [\"thresholds_blend_v2.json\",\"thresholds_blend.json\"]:\n",
    "    p=CAL/f\n",
    "    if p.exists(): thr_blob=json.loads(p.read_text(encoding=\"utf-8\")); break\n",
    "assert thr_blob is not None, \"Missing thresholds_blend(_v2).json\"\n",
    "ALPHA = float(thr_blob.get(\"alpha\", 0.8))\n",
    "thr_map = thr_blob.get(\"thresholds\", {})\n",
    "th_f1      = np.array([float(thr_map[lbl].get(\"th_f1\", np.nan))       if isinstance(thr_map.get(lbl),dict) else np.nan for lbl in LABELS], dtype=float)\n",
    "th_fbeta15 = np.array([float(thr_map[lbl].get(\"th_fbeta15\", np.nan))  if isinstance(thr_map.get(lbl),dict) else np.nan for lbl in LABELS], dtype=float)\n",
    "\n",
    "# ===== fused/shared once =====\n",
    "FUSED = fused_features(SMt.tolist(), Xt, batch=32)\n",
    "shared_P = shared_probs(FUSED)\n",
    "\n",
    "# ===== seeds =====\n",
    "seed_map: Dict[str, List[Path]] = {}\n",
    "for lbl in LABELS:\n",
    "    paths = sorted((ENS/lbl).glob(\"seed*/\"))\n",
    "    seed_map[lbl] = [p for p in paths if (p/\"best.pt\").exists()]\n",
    "seed_names = None\n",
    "for lbl, paths in seed_map.items():\n",
    "    names = set(p.name for p in paths)\n",
    "    seed_names = names if seed_names is None else (seed_names & names)\n",
    "seed_names = sorted(list(seed_names))\n",
    "assert len(seed_names)>0, \"No common seeds across labels.\"\n",
    "print(\"[Seeds] common:\", seed_names)\n",
    "\n",
    "# ===== per-seed APs =====\n",
    "seed_rows = []\n",
    "spec_AP_matrix = np.zeros((len(seed_names), L), dtype=np.float32)\n",
    "blend_AP_matrix= np.zeros((len(seed_names), L), dtype=np.float32)\n",
    "\n",
    "@torch.no_grad()\n",
    "def head_logits(FUSED: np.ndarray, head: nn.Module, batch: int = 64) -> np.ndarray:\n",
    "    out=np.zeros((FUSED.shape[0],),np.float32)\n",
    "    for i in range(0,FUSED.shape[0],batch):\n",
    "        x=torch.tensor(FUSED[i:i+batch],dtype=torch.float32,device=device)\n",
    "        out[i:i+batch]=head(x).detach().cpu().numpy()\n",
    "    return out\n",
    "\n",
    "for si, sname in enumerate(seed_names):\n",
    "    spec_logits = np.zeros((N, L), np.float32)\n",
    "    for j, lbl in enumerate(LABELS):\n",
    "        sdir = (ENS/lbl/sname)\n",
    "        head = load_head_for_label_seed(lbl, sdir, device=device)\n",
    "        spec_logits[:, j] = head_logits(FUSED, head, batch=64)\n",
    "    T = np.array([max(float(temps_spec.get(lbl,1.0)),1e-3) for lbl in LABELS], dtype=np.float32)\n",
    "    spec_P = sigmoid(spec_logits / T[None,:])\n",
    "    blend_P = ALPHA*spec_P + (1.0-ALPHA)*shared_P\n",
    "\n",
    "    np.save(DIR_SEEDS/f\"test_probs_specialist_{sname}.npy\", spec_P)\n",
    "    np.save(DIR_SEEDS/f\"test_probs_blend_{sname}.npy\",      blend_P)\n",
    "\n",
    "    ap_spec  = per_label_ap(Yt, spec_P, Mt)\n",
    "    ap_blend = per_label_ap(Yt, blend_P, Mt)\n",
    "    spec_AP_matrix[si,:]  = ap_spec\n",
    "    blend_AP_matrix[si,:] = ap_blend\n",
    "\n",
    "    mac_spec  = float(np.nanmean(ap_spec))\n",
    "    mac_blend = float(np.nanmean(ap_blend))\n",
    "    seed_rows.append({\"seed\": sname, \"macro_AP_specialist\": mac_spec, \"macro_AP_blend\": mac_blend})\n",
    "\n",
    "# shared APs (single)\n",
    "ap_shared = per_label_ap(Yt, shared_P, Mt)\n",
    "mac_shared = float(np.nanmean(ap_shared))\n",
    "np.save(DIR_SEEDS/\"test_probs_shared.npy\", shared_P)\n",
    "\n",
    "df_seed = pd.DataFrame(seed_rows)\n",
    "df_seed[\"macro_AP_shared\"] = mac_shared\n",
    "df_seed.to_csv(DIR_SEEDS/\"macro_ap_by_seed.csv\", index=False)\n",
    "\n",
    "# ===== T3: macro AP mean±SD±95%CI + variance & % reduction =====\n",
    "def mean_sd_ci(x: np.ndarray) -> Tuple[float,float,Tuple[float,float]]:\n",
    "    x = np.asarray(x, dtype=float); x = x[np.isfinite(x)]\n",
    "    if x.size==0: return float(\"nan\"), float(\"nan\"), (float(\"nan\"), float(\"nan\"))\n",
    "    m = float(np.mean(x)); sd=float(np.std(x, ddof=1)) if x.size>1 else 0.0\n",
    "    half = 1.96*(sd/np.sqrt(max(1,x.size))) if x.size>1 else 0.0\n",
    "    return m, sd, (m-half, m+half)\n",
    "\n",
    "def variance(x: np.ndarray) -> float:\n",
    "    x = np.asarray(x, dtype=float); x = x[np.isfinite(x)]\n",
    "    if x.size<=1: return 0.0\n",
    "    return float(np.var(x, ddof=1))\n",
    "\n",
    "m_spec, sd_spec, ci_spec   = mean_sd_ci(df_seed[\"macro_AP_specialist\"].to_numpy())\n",
    "m_blnd, sd_blnd, ci_blnd   = mean_sd_ci(df_seed[\"macro_AP_blend\"].to_numpy())\n",
    "var_spec = variance(df_seed[\"macro_AP_specialist\"].to_numpy())\n",
    "var_blnd = variance(df_seed[\"macro_AP_blend\"].to_numpy())\n",
    "var_red_pct = (100.0*(var_spec - var_blnd)/var_spec) if var_spec>0 else float(\"nan\")\n",
    "\n",
    "m_shr,  sd_shr,  ci_shr    = mac_shared, 0.0, (mac_shared, mac_shared)\n",
    "\n",
    "t3 = pd.DataFrame([\n",
    "    {\"model\":\"shared\",     \"macro_AP_mean\":m_shr,  \"macro_AP_sd\":sd_shr,  \"macro_AP_var\":0.0,      \"macro_AP_95CI_lo\":ci_shr[0],  \"macro_AP_95CI_hi\":ci_shr[1]},\n",
    "    {\"model\":\"specialist\", \"macro_AP_mean\":m_spec, \"macro_AP_sd\":sd_spec, \"macro_AP_var\":var_spec, \"macro_AP_95CI_lo\":ci_spec[0], \"macro_AP_95CI_hi\":ci_spec[1]},\n",
    "    {\"model\":\"blend\",      \"macro_AP_mean\":m_blnd, \"macro_AP_sd\":sd_blnd, \"macro_AP_var\":var_blnd, \"macro_AP_95CI_lo\":ci_blnd[0], \"macro_AP_95CI_hi\":ci_blnd[1]},\n",
    "])\n",
    "t3_rounded = t3.copy()\n",
    "for c in [\"macro_AP_mean\",\"macro_AP_sd\",\"macro_AP_var\",\"macro_AP_95CI_lo\",\"macro_AP_95CI_hi\"]:\n",
    "    t3_rounded[c] = t3_rounded[c].astype(float).round(4)\n",
    "t3_rounded.to_csv(DIR_T3/\"T3_macro_pr_auc.csv\", index=False)\n",
    "\n",
    "variance_summary = {\n",
    "    \"specialist_var\": round(var_spec, 6),\n",
    "    \"blend_var\": round(var_blnd, 6),\n",
    "    \"variance_reduction_pct\": None if not np.isfinite(var_red_pct) else round(float(var_red_pct), 2),\n",
    "    \"note\": \"Variance is computed across seeds (ddof=1).\"\n",
    "}\n",
    "wjson(DIR_T3/\"variance_summary.json\", variance_summary)\n",
    "\n",
    "caption = (\n",
    "    t3_rounded.to_markdown(index=False)\n",
    "    + \"\\n\\n_Caption: Macro PR-AUC on TEST. Specialist rows aggregate across seeds; shared is fixed; \"\n",
    "      \"blend = α·specialist + (1−α)·shared. VAL-fit temps/thresholds and α applied unchanged to TEST._\\n\\n\"\n",
    "      f\"Δ variance summary: Blend reduced macro PR-AUC variance across seeds from \"\n",
    "      f\"{var_spec:.3f} to {var_blnd:.3f} \"\n",
    "      f\"({('-' if np.isfinite(var_red_pct) and var_red_pct>=0 else '')}{'' if not np.isfinite(var_red_pct) else abs(var_red_pct):.0f}%).\"\n",
    ")\n",
    "wtxt(DIR_T3/\"T3_macro_pr_auc.md\", caption)\n",
    "print(\"\\n[T3] Saved →\", DIR_T3/\"T3_macro_pr_auc.csv\")\n",
    "print(\"[T3] Variance reduction:\", variance_summary)\n",
    "\n",
    "# ===== F6: boxplots =====\n",
    "pd.DataFrame(spec_AP_matrix, columns=LABELS, index=seed_names).to_csv(DIR_F6/\"per_assay_ap_specialist_by_seed.csv\")\n",
    "pd.DataFrame(blend_AP_matrix, columns=LABELS, index=seed_names).to_csv(DIR_F6/\"per_assay_ap_blend_by_seed.csv\")\n",
    "pd.DataFrame([ap_shared], columns=LABELS, index=[\"shared\"]).to_csv(DIR_F6/\"per_assay_ap_shared.csv\")\n",
    "\n",
    "def boxplot_matrix(ap_mat: np.ndarray, title: str, out_png: Path, out_pdf: Path):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(16,5))\n",
    "    # Matplotlib >=3.9 uses tick_labels\n",
    "    ax.boxplot([ap_mat[:, j][np.isfinite(ap_mat[:, j])] for j in range(L)], tick_labels=LABELS, showfliers=False)\n",
    "    ax.set_ylabel(\"PR-AUC (AP)\"); ax.set_title(title); plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout(); plt.savefig(out_png, dpi=200); plt.savefig(out_pdf); plt.close()\n",
    "\n",
    "boxplot_matrix(spec_AP_matrix, \"F6 — Specialist per-assay AP across seeds\", DIR_F6/\"F6_specialist_boxplots.png\", DIR_F6/\"F6_specialist_boxplots.pdf\")\n",
    "boxplot_matrix(blend_AP_matrix, \"F6 — Blend per-assay AP across seeds\",      DIR_F6/\"F6_blend_boxplots.png\",      DIR_F6/\"F6_blend_boxplots.pdf\")\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.boxplot([df_seed[\"macro_AP_specialist\"].to_numpy(), df_seed[\"macro_AP_blend\"].to_numpy()], tick_labels=[\"specialist\",\"blend\"], showfliers=False)\n",
    "ax.axhline(mac_shared, linestyle=\":\")  # shared macro reference\n",
    "ax.set_ylabel(\"Macro PR-AUC\"); ax.set_title(\"F6 — Macro AP across seeds (shared line)\")\n",
    "plt.tight_layout(); plt.savefig(DIR_F6/\"F6_macro_box.png\", dpi=200); plt.savefig(DIR_F6/\"F6_macro_box.pdf\"); plt.close()\n",
    "print(\"[F6] Saved boxplots →\", DIR_F6)\n",
    "\n",
    "# ===== F7: empty-prediction rates (overall bar) =====\n",
    "empty_rows = []\n",
    "for sname in seed_names:\n",
    "    spec_P = np.load(DIR_SEEDS/f\"test_probs_specialist_{sname}.npy\")\n",
    "    blend_P = ALPHA*spec_P + (1.0-ALPHA)*shared_P\n",
    "    Yb = (blend_P >= th_fbeta15[None, :]).astype(int)\n",
    "    Ya = Yb.copy()\n",
    "    em = (Yb.sum(axis=1) == 0)\n",
    "    if em.any():\n",
    "        Ya[em] = (blend_P[em] >= th_f1[None, :]).astype(int)\n",
    "    empty_rows.append({\n",
    "        \"seed\": sname,\n",
    "        \"empty_rate_before\": float((Yb.sum(axis=1) == 0).mean()),\n",
    "        \"empty_rate_after\":  float((Ya.sum(axis=1)  == 0).mean())\n",
    "    })\n",
    "df_empty = pd.DataFrame(empty_rows)\n",
    "df_empty.to_csv(DIR_EMPTY/\"empty_rate_by_seed.csv\", index=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "ax.bar([0,1],[df_empty[\"empty_rate_before\"].mean(), df_empty[\"empty_rate_after\"].mean()])\n",
    "ax.set_xticks([0,1]); ax.set_xticklabels([\"Before\",\"After\"])\n",
    "ax.set_ylabel(\"Empty prediction rate\")\n",
    "ax.set_title(\"F7 — Empty predictions (strict th_fβ=1.5 vs guardrail fallback to th_f1)\")\n",
    "plt.tight_layout(); plt.savefig(DIR_EMPTY/\"F7_empty_rate_overall.png\", dpi=200); plt.savefig(DIR_EMPTY/\"F7_empty_rate_overall.pdf\"); plt.close()\n",
    "\n",
    "# Supplement: per-assay OFF rate (proxy for “ON coverage” change)\n",
    "label_rows=[]\n",
    "for j, lbl in enumerate(LABELS):\n",
    "    offs_before=[]; offs_after=[]\n",
    "    for sname in seed_names:\n",
    "        spec_P = np.load(DIR_SEEDS/f\"test_probs_specialist_{sname}.npy\")\n",
    "        blend_P = ALPHA*spec_P + (1.0-ALPHA)*shared_P\n",
    "        Yb = (blend_P >= th_fbeta15[None,:]).astype(int)\n",
    "        Ya = Yb.copy()\n",
    "        em = (Yb.sum(axis=1)==0)\n",
    "        if em.any():\n",
    "            Ya[em] = (blend_P[em] >= th_f1[None,:]).astype(int)\n",
    "        offs_before.append(1.0 - Yb[:, j].mean())\n",
    "        offs_after.append(1.0 - Ya[:, j].mean())\n",
    "    label_rows.append({\"label\": lbl, \"off_rate_before\": float(np.mean(offs_before)), \"off_rate_after\": float(np.mean(offs_after))})\n",
    "df_off = pd.DataFrame(label_rows)\n",
    "df_off.to_csv(DIR_EMPTY/\"label_off_rate_before_after.csv\", index=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,5))\n",
    "w = 0.4; idx = np.arange(L)\n",
    "ax.bar(idx-w/2, df_off[\"off_rate_before\"].to_numpy(), width=w, label=\"Before\")\n",
    "ax.bar(idx+w/2, df_off[\"off_rate_after\"].to_numpy(),  width=w, label=\"After\")\n",
    "ax.set_xticks(idx); ax.set_xticklabels(LABELS, rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"Per-assay OFF rate\")\n",
    "ax.set_title(\"Supplement — Per-assay OFF rate (strict th_fβ=1.5 vs guardrail fallback)\")\n",
    "ax.legend()\n",
    "plt.tight_layout(); plt.savefig(DIR_EMPTY/\"F7b_off_rate_per_label.png\", dpi=200); plt.savefig(DIR_EMPTY/\"F7b_off_rate_per_label.pdf\"); plt.close()\n",
    "\n",
    "# ===== (Optional) Stress test — MC Dropout/TTA agreement =====\n",
    "stress_summary = None\n",
    "if RUN_STRESS_TEST:\n",
    "    # enable dropout in shared head only (cheap check)\n",
    "    def enable_dropout(m):\n",
    "        if isinstance(m, nn.Dropout): m.train()\n",
    "    fusion.apply(enable_dropout)\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(TTA_PASSES):\n",
    "            # logits -> probs\n",
    "            out = []\n",
    "            for i in range(0, FUSED.shape[0], 64):\n",
    "                x = torch.tensor(FUSED[i:i+64], dtype=torch.float32, device=device)\n",
    "                out.append(fusion.shared_head(x).detach().cpu().numpy())\n",
    "            out = sigmoid(np.concatenate(out, axis=0))\n",
    "            preds.append(out)\n",
    "    preds = np.stack(preds, axis=0)  # (T,N,L)\n",
    "    agree = (np.mean((preds >= 0.5).astype(int), axis=0) >= 0.75).mean()  # fraction of (N,L) with ≥75% agreement\n",
    "    stress_summary = {\"tta_passes\": TTA_PASSES, \"agreement_frac_ge_0p75\": float(agree)}\n",
    "    wjson(OUT/\"stress_test_summary.json\", stress_summary)\n",
    "\n",
    "summary = {\n",
    "    \"seeds\": seed_names,\n",
    "    \"macro_AP_shared\": float(mac_shared),\n",
    "    \"macro_AP_specialist_mean\": float(m_spec), \"macro_AP_specialist_sd\": float(sd_spec),\n",
    "    \"macro_AP_blend_mean\": float(m_blnd),     \"macro_AP_blend_sd\": float(sd_blnd),\n",
    "    \"macro_AP_specialist_var\": float(var_spec), \"macro_AP_blend_var\": float(var_blnd),\n",
    "    \"variance_reduction_pct\": None if not np.isfinite(var_red_pct) else float(round(var_red_pct,2)),\n",
    "    \"empty_rate_overall_before_mean\": float(df_empty[\"empty_rate_before\"].mean()),\n",
    "    \"empty_rate_overall_after_mean\":  float(df_empty[\"empty_rate_after\"].mean()),\n",
    "    \"stress_test\": stress_summary,\n",
    "}\n",
    "wjson(OUT/\"summary.json\", summary)\n",
    "\n",
    "print(\"\\n✅ RQ3 complete.\")\n",
    "print(\"• Seeds:\", seed_names)\n",
    "print(\"• T3:\", DIR_T3/\"T3_macro_pr_auc.csv\")\n",
    "print(\"• Variance summary:\", DIR_T3/\"variance_summary.json\")\n",
    "print(\"• F6:\", DIR_F6)\n",
    "print(\"• Empty rates:\", DIR_EMPTY/\"empty_rate_by_seed.csv\")\n",
    "print(\"• Per-assay OFF:\", DIR_EMPTY/\"label_off_rate_before_after.csv\")\n",
    "if RUN_STRESS_TEST:\n",
    "    print(\"• Stress test:\", OUT/\"stress_test_summary.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade2afe7",
   "metadata": {},
   "source": [
    "### figs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "342bb7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving PNGs to: D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ3\\figs\n",
      "Saved: T3_macro_pr_auc_table.png\n",
      "Saved: F6_macro_box.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_13292\\3256573651.py:279: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot(data, labels=[\"Specialist\",\"Blend\"], patch_artist=True, widths=0.5,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: F6_specialist_boxplots.png\n",
      "Saved: F6_blend_boxplots.png\n",
      "Saved: F7_empty_rate_overall.png\n",
      "Saved: F7b_off_rate_per_label.png\n",
      "Saved: T3_summary.png\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# RQ3 Figure & Table Generator (PNG-only, improved table visuals — matches RQ1/RQ2)\n",
    "# Saves PNGs to: v7/v7_Eval/RQ3/figs\n",
    "# ==============================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import json, re, textwrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------- STYLE ----------------------------------------\n",
    "DPI = 300\n",
    "FONT_SIZE = 11\n",
    "LABEL_SIZE = 12\n",
    "TITLE_SIZE = 13\n",
    "LINE_WIDTH = 2.0\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    \"figure.dpi\": DPI,\n",
    "    \"savefig.dpi\": DPI,\n",
    "    \"font.size\": FONT_SIZE,\n",
    "    \"axes.labelsize\": LABEL_SIZE,\n",
    "    \"axes.titlesize\": TITLE_SIZE,\n",
    "    \"legend.fontsize\": FONT_SIZE,\n",
    "    \"xtick.labelsize\": FONT_SIZE,\n",
    "    \"ytick.labelsize\": FONT_SIZE,\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.alpha\": 0.25,\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.spines.right\": False,\n",
    "})\n",
    "\n",
    "FIGSIZE_GRID = (12, 8.5)\n",
    "FIGSIZE_BAR  = (10, 5.5)\n",
    "FIGWIDTH_TAB = 11.0\n",
    "\n",
    "TITLE_T3TAB = \"T3 — Macro PR-AUC robustness across seeds (TEST)\"\n",
    "TITLE_F6MAC = \"F6 (macro) — Macro AP across seeds (Specialist vs Blend; TEST)\"\n",
    "TITLE_F6S   = \"F6 (spec) — Per-assay AP boxplots across seeds (Specialist; TEST)\"\n",
    "TITLE_F6B   = \"F6 (blend) — Per-assay AP boxplots across seeds (Blend; TEST)\"\n",
    "TITLE_F7    = \"F7 — Empty Prediction Rate (Before vs After guardrails; TEST)\"\n",
    "TITLE_F7B   = \"F7b — OFF-rate per assay (Before vs After; TEST)\"\n",
    "TITLE_T3SUM = \"T3 — Summary (seeds, robustness, empty-rate; TEST)\"\n",
    "\n",
    "BOLD_ASSAYS = {\"NR-AR-LBD\", \"NR-PPAR-gamma\", \"SR-ATAD5\"}\n",
    "\n",
    "BASE = Path(\"v7/v7_Eval/RQ3\")\n",
    "FIGS = BASE / \"figs\"\n",
    "FIGS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PATHS = {\n",
    "    \"t3_csv\":      BASE / \"T3\" / \"T3_macro_pr_auc.csv\",\n",
    "    \"var_json\":    BASE / \"T3\" / \"variance_summary.json\",\n",
    "    \"macro_by_seed_csv\": BASE / \"seeds\" / \"macro_ap_by_seed.csv\",\n",
    "    \"macro_by_seed_alt\": BASE / \"F6_boxplots\" / \"macro_ap_by_seed.csv\",\n",
    "    \"per_assay_spec_csv\": BASE / \"F6_boxplots\" / \"per_assay_ap_specialist_by_seed.csv\",\n",
    "    \"per_assay_blend_csv\": BASE / \"F6_boxplots\" / \"per_assay_ap_blend_by_seed.csv\",\n",
    "    \"shared_macro_csv\": BASE / \"F6_boxplots\" / \"per_assay_ap_shared.csv\",\n",
    "    \"shared_macro_alt\": BASE / \"seeds\" / \"shared_macro_ap.csv\",\n",
    "    \"empty_rate_csv\": BASE / \"empty_predictions\" / \"empty_rate_by_seed.csv\",\n",
    "    \"off_rate_csv\":   BASE / \"empty_predictions\" / \"label_off_rate_before_after.csv\",\n",
    "}\n",
    "\n",
    "OUT = {\n",
    "    \"T3_table\": \"T3_macro_pr_auc_table\",\n",
    "    \"F6_macro\": \"F6_macro_box\",\n",
    "    \"F6_spec\":  \"F6_specialist_boxplots\",\n",
    "    \"F6_blend\": \"F6_blend_boxplots\",\n",
    "    \"F7_over\":  \"F7_empty_rate_overall\",\n",
    "    \"F7b_lab\":  \"F7b_off_rate_per_label\",\n",
    "    \"T3_sum\":   \"T3_summary\",\n",
    "}\n",
    "\n",
    "# ---------------------------- UTILITIES ---------------------------------------\n",
    "def ensure_dir(p: Path): p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_png(fig, stem: str):\n",
    "    ensure_dir(FIGS)\n",
    "    fig.savefig(FIGS / f\"{stem}.png\", bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(\"Saved:\", f\"{stem}.png\")\n",
    "\n",
    "def load_csv(path: Path):\n",
    "    return pd.read_csv(path) if path.exists() else None\n",
    "\n",
    "def first_existing(*candidates: Path) -> Path | None:\n",
    "    for p in candidates:\n",
    "        if p and p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "# ---------- prettier table renderer (zebra rows, better spacing, soft-wrapping)\n",
    "def table_like_figure(\n",
    "    table_df: pd.DataFrame,\n",
    "    title: str,\n",
    "    bold_rows=set(),\n",
    "    wrap_cols=None,\n",
    "    wrap_width=70,\n",
    "):\n",
    "    wrap_cols = set(wrap_cols or [])\n",
    "    df = table_df.copy()\n",
    "\n",
    "    # soft-wrap long text columns\n",
    "    for col in df.columns:\n",
    "        if col in wrap_cols:\n",
    "            df[col] = df[col].astype(str).map(lambda s: \"\\n\".join(textwrap.wrap(s, width=wrap_width)) if isinstance(s, str) else s)\n",
    "\n",
    "    n_rows, n_cols = df.shape\n",
    "    # more vertical space per row to avoid clutter\n",
    "    fig_height = max(2.75, 0.55 * (n_rows + 2))\n",
    "    fig = plt.figure(figsize=(FIGWIDTH_TAB, fig_height))\n",
    "    ax = plt.gca()\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # Title\n",
    "    ax.text(0.02, 0.98, title, fontsize=TITLE_SIZE, fontweight=\"bold\",\n",
    "            transform=ax.transAxes, ha=\"left\", va=\"top\")\n",
    "\n",
    "    # Layout constants\n",
    "    left, right = 0.03, 0.98\n",
    "    y_top = 0.90\n",
    "    header_h = 0.065\n",
    "    row_h = 0.07  # taller rows\n",
    "    # column widths: first wider for labels\n",
    "    first_w = 0.38\n",
    "    rem = (right-left-first_w)\n",
    "    col_widths = [first_w] + [rem/(n_cols-1)]*(n_cols-1)\n",
    "    xs = [left]\n",
    "    for w in col_widths[:-1]:\n",
    "        xs.append(xs[-1]+w)\n",
    "\n",
    "    # Header band\n",
    "    ax.hlines(y_top+0.01, left, right, transform=ax.transAxes, linewidth=1.2, color=\"black\")\n",
    "    y = y_top - header_h/2\n",
    "    for j, col in enumerate(df.columns):\n",
    "        ha = \"left\" if j==0 else \"center\"\n",
    "        xtext = xs[j] + (0 if j==0 else col_widths[j]/2)\n",
    "        ax.text(xtext, y, str(col), fontsize=FONT_SIZE, fontweight=\"bold\",\n",
    "                ha=ha, va=\"center\", transform=ax.transAxes)\n",
    "    ax.hlines(y_top-header_h, left, right, transform=ax.transAxes, linewidth=0.9, color=\"black\")\n",
    "\n",
    "    # Body with zebra shading\n",
    "    y = y_top - header_h - row_h/2\n",
    "    for i in range(n_rows):\n",
    "        # zebra\n",
    "        if i % 2 == 0:\n",
    "            ax.add_patch(plt.Rectangle((left, y-row_h/2), right-left, row_h, transform=ax.transAxes,\n",
    "                                       facecolor=\"0.96\", edgecolor=\"none\", zorder=0))\n",
    "        row = df.iloc[i].tolist()\n",
    "        is_bold = str(row[0]) in bold_rows\n",
    "        for j, val in enumerate(row):\n",
    "            ha = \"left\" if j==0 else \"center\"\n",
    "            xtext = xs[j] + (0 if j==0 else col_widths[j]/2)\n",
    "            ax.text(xtext, y, str(val),\n",
    "                    fontsize=FONT_SIZE, fontweight=\"bold\" if is_bold else \"normal\",\n",
    "                    ha=ha, va=\"center\", transform=ax.transAxes)\n",
    "        y -= row_h\n",
    "\n",
    "    # Bottom rule\n",
    "    ax.hlines(y+row_h/2, left, right, transform=ax.transAxes, linewidth=1.0, color=\"black\")\n",
    "    return fig\n",
    "\n",
    "def bootstrap_ci_mean(values: np.ndarray, B: int = 1000, seed: int = 13) -> tuple[float,float,float]:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    vals = values.astype(float)\n",
    "    boots = np.array([np.mean(rng.choice(vals, size=len(vals), replace=True)) for _ in range(B)], dtype=float)\n",
    "    return float(np.mean(vals)), float(np.percentile(boots, 2.5)), float(np.percentile(boots, 97.5))\n",
    "\n",
    "# -------------------------- A) T3 — Macro PR-AUC table ------------------------\n",
    "def make_T3_table():\n",
    "    df = load_csv(PATHS[\"t3_csv\"])\n",
    "    if df is None or df.empty:\n",
    "        print(\"T3 CSV not found; skipping T3 table.\")\n",
    "        return\n",
    "\n",
    "    def find_col(cands):\n",
    "        lc = {c.lower(): c for c in df.columns}\n",
    "        for key, orig in lc.items():\n",
    "            nk = re.sub(r'[^a-z0-9]+', '', key)\n",
    "            for cand in cands:\n",
    "                if cand in nk:\n",
    "                    return orig\n",
    "        return None\n",
    "\n",
    "    col_model = find_col([\"model\",\"method\",\"system\",\"approach\",\"type\"])\n",
    "    col_n     = find_col([\"nseeds\",\"numseeds\",\"seeds\",\"n\"])\n",
    "    col_mean  = find_col([\"mean\",\"avg\",\"average\",\"macroapmean\",\"macropraucmean\"])\n",
    "    col_sd    = find_col([\"sd\",\"std\",\"stdev\",\"sigma\"])\n",
    "    col_lo    = find_col([\"cilow\",\"cilwr\",\"lwr\",\"lower\",\"ci_lo\"])\n",
    "    col_hi    = find_col([\"cihigh\",\"ciupr\",\"upr\",\"upper\",\"ci_hi\"])\n",
    "    col_var   = find_col([\"variance\",\"var\"])\n",
    "\n",
    "    tidy = df.copy()\n",
    "\n",
    "    if col_model is None:\n",
    "        if len(df) == 3:\n",
    "            tidy.insert(0, \"Model\", [\"Shared\",\"Specialist\",\"Blend\"])\n",
    "            col_model = \"Model\"\n",
    "\n",
    "    if col_n is None:\n",
    "        p = first_existing(PATHS[\"macro_by_seed_csv\"], PATHS[\"macro_by_seed_alt\"])\n",
    "        n_guess = None\n",
    "        if p:\n",
    "            mbs = pd.read_csv(p)\n",
    "            n_guess = int(mbs[\"seed\"].nunique()) if \"seed\" in [c.lower() for c in mbs.columns] else int(len(mbs))\n",
    "        col_n = \"_n_\"; tidy[col_n] = n_guess if n_guess is not None else 0\n",
    "\n",
    "    if col_var is None and col_sd is not None:\n",
    "        col_var = \"_var_\"; tidy[col_var] = pd.to_numeric(tidy[col_sd], errors=\"coerce\")**2\n",
    "\n",
    "    if (col_lo is None or col_hi is None) and (col_mean and col_sd and col_n):\n",
    "        m = pd.to_numeric(tidy[col_mean], errors=\"coerce\")\n",
    "        s = pd.to_numeric(tidy[col_sd], errors=\"coerce\")\n",
    "        n = pd.to_numeric(tidy[col_n], errors=\"coerce\").replace(0, np.nan)\n",
    "        lo = m - 1.96 * s / np.sqrt(n)\n",
    "        hi = m + 1.96 * s / np.sqrt(n)\n",
    "        if col_lo is None: col_lo = \"_ci_lo_\"; tidy[col_lo] = lo\n",
    "        if col_hi is None: col_hi = \"_ci_hi_\"; tidy[col_hi] = hi\n",
    "\n",
    "    needed = [col_model, col_n, col_mean, col_sd, col_lo, col_hi, col_var]\n",
    "    if any(c is None for c in needed):\n",
    "        print(\"T3 CSV missing essential columns; skipping T3 table.\")\n",
    "        return\n",
    "\n",
    "    tidy = tidy[[col_model, col_n, col_mean, col_sd, col_lo, col_hi, col_var]].copy()\n",
    "    tidy.columns = [\"Model\",\"#seeds\",\"Mean\",\"SD\",\"CI_low\",\"CI_high\",\"Variance\"]\n",
    "\n",
    "    tidy[\"Mean\"]     = pd.to_numeric(tidy[\"Mean\"], errors=\"coerce\").map(lambda x: f\"{x:.3f}\")\n",
    "    tidy[\"SD\"]       = pd.to_numeric(tidy[\"SD\"],   errors=\"coerce\").map(lambda x: f\"{x:.3f}\")\n",
    "    tidy[\"95% CI\"]   = tidy.apply(lambda r: f\"[{float(r['CI_low']):.3f}, {float(r['CI_high']):.3f}]\", axis=1)\n",
    "    tidy[\"Variance\"] = pd.to_numeric(tidy[\"Variance\"], errors=\"coerce\").map(lambda x: f\"{x:.6f}\")\n",
    "    tidy = tidy[[\"Model\",\"#seeds\",\"Mean\",\"SD\",\"95% CI\",\"Variance\"]]\n",
    "\n",
    "    var_line = \"\"\n",
    "    if PATHS[\"var_json\"].exists():\n",
    "        vv = json.loads(PATHS[\"var_json\"].read_text(encoding=\"utf-8\"))\n",
    "        vs = vv.get(\"var_specialist\", vv.get(\"Specialist\", vv.get(\"specialist\")))\n",
    "        vb = vv.get(\"var_blend\", vv.get(\"Blend\", vv.get(\"blend\")))\n",
    "        if vs is not None and vb is not None and float(vs) > 0:\n",
    "            red = 100.0 * (1.0 - float(vb)/float(vs))\n",
    "            var_line = f\"Variance reduction (Blend vs Specialist): {red:.1f}%\"\n",
    "\n",
    "    fig = table_like_figure(tidy, TITLE_T3TAB, bold_rows=set())\n",
    "    ax = fig.gca()\n",
    "    note = \"95% CI via bootstrap (B=1000)\"\n",
    "    ax.text(0.02, 0.06, (var_line + \"  •  \" + note) if var_line else note,\n",
    "            transform=ax.transAxes, fontsize=FONT_SIZE, ha=\"left\", va=\"bottom\")\n",
    "    save_png(fig, OUT[\"T3_table\"])\n",
    "\n",
    "# -------------------------- B) F6 — Macro AP boxplot --------------------------\n",
    "def plot_F6_macro():\n",
    "    p = first_existing(PATHS[\"macro_by_seed_csv\"], PATHS[\"macro_by_seed_alt\"])\n",
    "    df = load_csv(p) if p else None\n",
    "    if df is None or df.empty:\n",
    "        print(\"Macro AP by seed CSV not found; skipping F6 (macro).\")\n",
    "        return\n",
    "\n",
    "    lc = {c.lower(): c for c in df.columns}\n",
    "    c_spec = lc.get(\"specialist\") or next((c for c in df.columns if \"spec\" in c.lower()), None)\n",
    "    c_blnd = lc.get(\"blend\") or next((c for c in df.columns if \"blend\" in c.lower()), None)\n",
    "    if c_spec is None or c_blnd is None:\n",
    "        print(\"Could not infer Specialist/Blend columns for macro boxplot; skipping.\")\n",
    "        return\n",
    "\n",
    "    shared_scalar = None\n",
    "    for cand in [PATHS[\"shared_macro_csv\"], PATHS[\"shared_macro_alt\"]]:\n",
    "        if cand and cand.exists():\n",
    "            try:\n",
    "                s = pd.read_csv(cand)\n",
    "                maybe = [c for c in s.columns if \"shared\" in c.lower()]\n",
    "                if maybe: shared_scalar = float(s[maybe[0]].iloc[0]); break\n",
    "            except Exception: pass\n",
    "\n",
    "    data = [df[c_spec].astype(float).values, df[c_blnd].astype(float).values]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE_BAR)\n",
    "    ax.boxplot(data, labels=[\"Specialist\",\"Blend\"], patch_artist=True, widths=0.5,\n",
    "               showfliers=False, medianprops=dict(linewidth=2))\n",
    "    for i, ys in enumerate(data, start=1):\n",
    "        med = float(np.median(ys))\n",
    "        ax.text(i, med, f\"{med:.3f}\", ha=\"center\", va=\"bottom\", fontsize=FONT_SIZE)\n",
    "    if shared_scalar is not None:\n",
    "        ax.axhline(shared_scalar, linestyle=\"--\", linewidth=1.2, label=\"Shared (macro)\")\n",
    "        ax.legend(frameon=False, loc=\"lower right\")\n",
    "    ax.set_title(TITLE_F6MAC)\n",
    "    ax.set_ylabel(\"Macro AP\"); ax.set_ylim(0, 1)\n",
    "    save_png(fig, OUT[\"F6_macro\"])\n",
    "\n",
    "# -------- C/D) F6 — Per-assay AP boxplots (Specialist / Blend; 3×4 grid) -----\n",
    "def _per_assay_box_grid(csv_path: Path, title: str, out_stem: str):\n",
    "    df = load_csv(csv_path)\n",
    "    if df is None or df.empty:\n",
    "        print(\"Missing per-assay CSV:\", csv_path)\n",
    "        return\n",
    "\n",
    "    lc = {c.lower(): c for c in df.columns}\n",
    "    if {\"assay\",\"ap\"}.issubset(lc.keys()):\n",
    "        long = df[[lc[\"assay\"], lc[\"ap\"]]].rename(columns={lc[\"assay\"]:\"Assay\", lc[\"ap\"]:\"AP\"})\n",
    "    else:\n",
    "        cols = df.columns.tolist()\n",
    "        wide_assays = [c for c in cols if c.lower() not in {\"seed\",\"seeds\"}]\n",
    "        long = df[wide_assays].melt(var_name=\"Assay\", value_name=\"AP\")\n",
    "\n",
    "    assays = sorted(long[\"Assay\"].unique().tolist())[:12]\n",
    "    rows, cols = 3, 4\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=FIGSIZE_GRID, sharex=True, sharey=True)\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i, assay in enumerate(assays):\n",
    "        ax = axes[i]\n",
    "        vals = long[long[\"Assay\"]==assay][\"AP\"].astype(float).values\n",
    "        ax.boxplot([vals], showfliers=False, widths=0.5, patch_artist=True, medianprops=dict(linewidth=2))\n",
    "        ax.set_title(assay, fontweight=\"bold\" if assay in BOLD_ASSAYS else \"normal\")\n",
    "        ax.set_ylim(0, 1)\n",
    "        if i // cols == rows - 1: ax.set_xlabel(\"Seeds\")\n",
    "        if i % cols == 0: ax.set_ylabel(\"AP\")\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    save_png(fig, out_stem)\n",
    "\n",
    "def plot_F6_spec_blend():\n",
    "    _per_assay_box_grid(PATHS[\"per_assay_spec_csv\"],  TITLE_F6S, OUT[\"F6_spec\"])\n",
    "    _per_assay_box_grid(PATHS[\"per_assay_blend_csv\"], TITLE_F6B, OUT[\"F6_blend\"])\n",
    "\n",
    "# --------------------------- E) F7 — Empty rate bars --------------------------\n",
    "def plot_F7_empty_overall():\n",
    "    df = load_csv(PATHS[\"empty_rate_csv\"])\n",
    "    if df is None or df.empty:\n",
    "        print(\"Missing empty_rate_by_seed.csv; skipping F7.\")\n",
    "        return\n",
    "\n",
    "    lc = {c.lower(): c for c in df.columns}\n",
    "    c_before = lc.get(\"before\") or lc.get(\"empty_before\") or list(df.columns)[1]\n",
    "    c_after  = lc.get(\"after\")  or lc.get(\"empty_after\")  or list(df.columns)[2]\n",
    "\n",
    "    before = df[c_before].astype(float).values\n",
    "    after  = df[c_after].astype(float).values\n",
    "    if before.max() <= 1.01 and after.max() <= 1.01:\n",
    "        before *= 100.0; after *= 100.0\n",
    "\n",
    "    def ci(v):\n",
    "        m, l, h = bootstrap_ci_mean(v)\n",
    "        return m, m-l, h-m\n",
    "\n",
    "    mb, lob, hib = ci(before)\n",
    "    ma, loa, hia = ci(after)\n",
    "\n",
    "    x = np.arange(2)\n",
    "    means = [mb, ma]\n",
    "    errs = np.array([[lob, loa],[hib, hia]])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE_BAR)\n",
    "    ax.bar(x, means, width=0.55, tick_label=[\"Before\",\"After\"])\n",
    "    ax.errorbar(x, means, yerr=errs, fmt=\"none\", capsize=3, linewidth=1)\n",
    "    for xi, m in zip(x, means):\n",
    "        ax.text(xi, m, f\"{m:.1f}%\", ha=\"center\", va=\"bottom\", fontsize=FONT_SIZE)\n",
    "    ax.set_ylim(0, max(100, (np.array(means)+errs[1]).max()*1.10))\n",
    "    ax.set_ylabel(\"Empty prediction rate (%)\")\n",
    "    ax.set_title(TITLE_F7 + \"\\nGuardrail: Fβ→F1 fallback\")\n",
    "    save_png(fig, OUT[\"F7_over\"])\n",
    "\n",
    "# ---------- F) F7b — OFF-rate per assay (paired bars; Before vs After) -------\n",
    "def plot_F7b_off_per_label():\n",
    "    df = load_csv(PATHS[\"off_rate_csv\"])\n",
    "    if df is None or df.empty:\n",
    "        print(\"Missing label_off_rate_before_after.csv; skipping F7b.\")\n",
    "        return\n",
    "\n",
    "    lc = {c.lower(): c for c in df.columns}\n",
    "    col_lab = lc.get(\"assay\") or lc.get(\"label\") or df.columns[0]\n",
    "    col_bef = lc.get(\"before\") or df.columns[1]\n",
    "    col_aft = lc.get(\"after\")  or df.columns[2]\n",
    "    tidy = df[[col_lab, col_bef, col_aft]].copy()\n",
    "    tidy.columns = [\"Assay\",\"Before\",\"After\"]\n",
    "\n",
    "    if tidy[[\"Before\",\"After\"]].max().max() <= 1.01:\n",
    "        tidy[[\"Before\",\"After\"]] *= 100.0\n",
    "\n",
    "    tidy = tidy.sort_values(\"Before\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    fig_height = max(4.0, 0.35 * len(tidy) + 1.5)\n",
    "    fig, ax = plt.subplots(figsize=(10, fig_height))\n",
    "    y = np.arange(len(tidy))\n",
    "    ax.barh(y - 0.2, tidy[\"Before\"], height=0.38, label=\"Before\")\n",
    "    ax.barh(y + 0.2, tidy[\"After\"],  height=0.38, label=\"After\")\n",
    "\n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels(tidy[\"Assay\"].tolist())\n",
    "    for i, tick in enumerate(ax.get_yticklabels()):\n",
    "        if tick.get_text() in BOLD_ASSAYS:\n",
    "            tick.set_fontweight(\"bold\")\n",
    "\n",
    "    ax.set_xlabel(\"OFF-rate (%)\")\n",
    "    ax.set_xlim(0, max(100, tidy[[\"Before\",\"After\"]].max().max()*1.10))\n",
    "    ax.set_title(TITLE_F7B)\n",
    "    ax.legend(frameon=False, loc=\"lower right\")\n",
    "    save_png(fig, OUT[\"F7b_lab\"])\n",
    "\n",
    "# -------------------------- G) T3-summary (PNG table) -------------------------\n",
    "def make_T3_summary():\n",
    "    summ_path = BASE / \"summary.json\"\n",
    "    if not summ_path.exists():\n",
    "        print(\"summary.json not found; skipping T3 summary.\")\n",
    "        return\n",
    "    jj = json.loads(summ_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    seeds = jj.get(\"seeds\", [])\n",
    "    def fmt_stat(obj):\n",
    "        if obj is None: return \"\"\n",
    "        mean = obj.get(\"mean\", np.nan)\n",
    "        sd   = obj.get(\"sd\", obj.get(\"std\", np.nan))\n",
    "        lo   = obj.get(\"ci_lo\", obj.get(\"low\", np.nan))\n",
    "        hi   = obj.get(\"ci_hi\", obj.get(\"high\", np.nan))\n",
    "        return f\"{mean:.3f} ± {sd:.3f}  [{lo:.3f}, {hi:.3f}]\"\n",
    "\n",
    "    rows = [\n",
    "        [\"Seeds\", \", \".join(map(str, seeds)) if seeds else \"\"],\n",
    "        [\"Shared — Macro AP (mean±SD, 95% CI)\",     fmt_stat(jj.get(\"macro_shared\"))],\n",
    "        [\"Specialist — Macro AP (mean±SD, 95% CI)\", fmt_stat(jj.get(\"macro_specialist\"))],\n",
    "        [\"Blend — Macro AP (mean±SD, 95% CI)\",      fmt_stat(jj.get(\"macro_blend\"))],\n",
    "        [\"Variance reduction (Blend vs Specialist)\", f\"{jj.get('variance_reduction_pct', np.nan):.1f}%\"],\n",
    "        [\"EPR Before (mean, 95% CI)\",               fmt_stat(jj.get(\"empty_rate_before\"))],\n",
    "        [\"EPR After (mean, 95% CI)\",                fmt_stat(jj.get(\"empty_rate_after\"))],\n",
    "    ]\n",
    "    table = pd.DataFrame(rows, columns=[\"Metric\",\"Value\"])\n",
    "    # wrap the Value column to avoid long single-line strings (e.g., seeds list)\n",
    "    fig = table_like_figure(table, TITLE_T3SUM, bold_rows=set(), wrap_cols={\"Value\"}, wrap_width=90)\n",
    "    save_png(fig, OUT[\"T3_sum\"])\n",
    "\n",
    "# -------------------------------- DRIVER --------------------------------------\n",
    "def main():\n",
    "    print(f\"Saving PNGs to: {FIGS.resolve()}\")\n",
    "    make_T3_table()\n",
    "    # The boxplots / empty-rate plots are unchanged from your last run:\n",
    "    plot_F6_macro()\n",
    "    plot_F6_spec_blend()\n",
    "    plot_F7_empty_overall()\n",
    "    plot_F7b_off_per_label()\n",
    "    make_T3_summary()\n",
    "    print(\"Done.\")\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3fa84aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - v7\\v7_Eval\\RQ3\\figs\\T3_summary.png\n",
      " - v7\\v7_Eval\\RQ3\\figs\\T3_summary.pdf\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# T3 — Summary (seeds, robustness, empty-rate; TEST) — clean 2-column table\n",
    "# Standalone Jupyter cell. Saves: v7/v7_Eval/RQ3/figs/T3_summary.png (+ .pdf)\n",
    "# ==============================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import json, math, numpy as np, pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------- STYLE ----------------------------------------\n",
    "DPI = 300\n",
    "FONT_SIZE = 11\n",
    "LABEL_SIZE = 12\n",
    "TITLE_SIZE = 16\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    \"figure.dpi\": DPI,\n",
    "    \"savefig.dpi\": DPI,\n",
    "    \"font.size\": FONT_SIZE,\n",
    "    \"axes.labelsize\": LABEL_SIZE,\n",
    "    \"axes.titlesize\": TITLE_SIZE,\n",
    "    \"legend.fontsize\": FONT_SIZE,\n",
    "    \"xtick.labelsize\": FONT_SIZE,\n",
    "    \"ytick.labelsize\": FONT_SIZE,\n",
    "    \"axes.grid\": False,\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.spines.right\": False,\n",
    "})\n",
    "\n",
    "# ------------------------------ PATHS -----------------------------------------\n",
    "BASE = Path(\"v7/v7_Eval/RQ3\")\n",
    "SEEDS_CSV = BASE / \"seeds\" / \"macro_ap_by_seed.csv\"\n",
    "EMPTY_CSV = BASE / \"empty_predictions\" / \"empty_rate_by_seed.csv\"\n",
    "OUT_DIR   = BASE / \"figs\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ------------------------------ HELPERS ---------------------------------------\n",
    "def _pick(df, contains):\n",
    "    \"\"\"pick first column whose lowercase name contains `contains`.\"\"\"\n",
    "    for c in df.columns:\n",
    "        if contains in c.lower():\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _bootstrap_ci_mean(x, B=1000, seed=1337, pct=(2.5,97.5)):\n",
    "    \"\"\"non-parametric bootstrap CI for the mean.\"\"\"\n",
    "    x = np.asarray(x, float)\n",
    "    x = x[np.isfinite(x)]\n",
    "    if x.size == 0:\n",
    "        return (np.nan, np.nan)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = rng.integers(0, x.size, size=(B, x.size))\n",
    "    means = x[idx].mean(axis=1)\n",
    "    lo, hi = np.percentile(means, pct)\n",
    "    return float(lo), float(hi)\n",
    "\n",
    "def _table_figure_two_cols(table_df: pd.DataFrame, title: str, footnote: str = \"\"):\n",
    "    \"\"\"\n",
    "    Render a clean two-column table with proper alignment.\n",
    "    \"\"\"\n",
    "    n_rows = table_df.shape[0]\n",
    "    fig_w = 13.0\n",
    "    fig_h = max(3.5, 0.65*(n_rows+2))\n",
    "    fig = plt.figure(figsize=(fig_w, fig_h))\n",
    "    ax = plt.gca()\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # Title\n",
    "    ax.text(0.02, 1.03, title, fontsize=TITLE_SIZE, fontweight=\"bold\",\n",
    "            transform=ax.transAxes, ha=\"left\", va=\"bottom\")\n",
    "\n",
    "    left, right = 0.02, 0.98\n",
    "    y = 0.975\n",
    "    ax.hlines(y, left, right, transform=ax.transAxes, linewidth=1.2, color=\"black\")\n",
    "\n",
    "    # Column headers\n",
    "    col_w = [0.40, 0.56]\n",
    "    x0 = [left, left + col_w[0]]\n",
    "    y -= 0.07\n",
    "    ax.text(x0[0], y, \"Metric\", fontsize=FONT_SIZE, fontweight=\"bold\",\n",
    "            ha=\"left\", va=\"center\", transform=ax.transAxes)\n",
    "    ax.text(x0[1] + col_w[1]/2, y, \"Value\", fontsize=FONT_SIZE, fontweight=\"bold\",\n",
    "            ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "    ax.hlines(y-0.03, left, right, transform=ax.transAxes, linewidth=0.9, color=\"black\")\n",
    "\n",
    "    # Body rows (striped)\n",
    "    y -= 0.06\n",
    "    ystep = 0.085\n",
    "    for i, (metric, value) in enumerate(table_df.itertuples(index=False)):\n",
    "        if i % 2 == 1:\n",
    "            # light gray stripe\n",
    "            ax.add_patch(plt.Rectangle((left, y-ystep/2), right-left, ystep,\n",
    "                                       transform=ax.transAxes, color=\"#f4f4f4\", zorder=-1))\n",
    "        # metric left, value centered in value column\n",
    "        ax.text(x0[0], y, str(metric), fontsize=FONT_SIZE, ha=\"left\", va=\"center\", transform=ax.transAxes)\n",
    "        ax.text(x0[1] + col_w[1]/2, y, str(value), fontsize=FONT_SIZE, ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "        y -= ystep\n",
    "\n",
    "    ax.hlines(y+0.025, left, right, transform=ax.transAxes, linewidth=1.0, color=\"black\")\n",
    "\n",
    "    if footnote:\n",
    "        ax.text(0.02, 0.03, footnote, fontsize=FONT_SIZE, style=\"italic\",\n",
    "                transform=ax.transAxes, ha=\"left\", va=\"bottom\", color=\"dimgray\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "# ------------------------------ LOAD & COMPUTE --------------------------------\n",
    "seeds_df = pd.read_csv(SEEDS_CSV)\n",
    "col_spec = _pick(seeds_df, \"specialist\")\n",
    "col_blnd = _pick(seeds_df, \"blend\")\n",
    "col_shrd = _pick(seeds_df, \"shared\") or \"macro_AP_shared\"\n",
    "\n",
    "seeds = list(seeds_df[\"seed\"]) if \"seed\" in seeds_df.columns else [f\"seed{i}\" for i in range(len(seeds_df))]\n",
    "\n",
    "spec_vals = seeds_df[col_spec].to_numpy(float)\n",
    "blnd_vals = seeds_df[col_blnd].to_numpy(float)\n",
    "shared_val = float(seeds_df[col_shrd].iloc[0]) if col_shrd in seeds_df.columns else float(\"nan\")\n",
    "\n",
    "m_spec, sd_spec = float(np.mean(spec_vals)), float(np.std(spec_vals, ddof=1))\n",
    "m_blnd, sd_blnd = float(np.mean(blnd_vals)), float(np.std(blnd_vals, ddof=1))\n",
    "ci_spec = _bootstrap_ci_mean(spec_vals)\n",
    "ci_blnd = _bootstrap_ci_mean(blnd_vals)\n",
    "\n",
    "# Empty prediction rate (overall), as percentages\n",
    "empty_df = pd.read_csv(EMPTY_CSV)\n",
    "before = empty_df[_pick(empty_df, \"before\")].to_numpy(float) * 100.0\n",
    "after  = empty_df[_pick(empty_df, \"after\") ].to_numpy(float) * 100.0\n",
    "mean_b, mean_a = float(np.mean(before)), float(np.mean(after))\n",
    "lo_b, hi_b = _bootstrap_ci_mean(before)\n",
    "lo_a, hi_a = _bootstrap_ci_mean(after)\n",
    "\n",
    "# Variance reduction\n",
    "var_spec = float(np.var(spec_vals, ddof=1))\n",
    "var_blnd = float(np.var(blnd_vals, ddof=1))\n",
    "var_red_pct = None if var_spec <= 0 else round(100.0*(1.0 - var_blnd/var_spec), 1)\n",
    "\n",
    "# ------------------------------ BUILD TABLE -----------------------------------\n",
    "rows = [\n",
    "    (\"Seeds\", \", \".join(map(str, seeds))),\n",
    "    (\"Shared — Macro AP (mean)\", f\"{shared_val:.3f}\"),\n",
    "    (\"Specialist — Macro AP (mean±SD, 95% CI)\", f\"{m_spec:.3f} ± {sd_spec:.3f} [{ci_spec[0]:.3f}, {ci_spec[1]:.3f}]\"),\n",
    "    (\"Blend — Macro AP (mean±SD, 95% CI)\",      f\"{m_blnd:.3f} ± {sd_blnd:.3f} [{ci_blnd[0]:.3f}, {ci_blnd[1]:.3f}]\"),\n",
    "    (\"Variance reduction (Blend vs Specialist)\", f\"{var_red_pct:.1f}%\"),\n",
    "    (\"EPR Before (mean, 95% CI)\",               f\"{mean_b:.1f}% [{lo_b:.1f}, {hi_b:.1f}]\"),\n",
    "    (\"EPR After  (mean, 95% CI)\",               f\"{mean_a:.1f}% [{lo_a:.1f}, {hi_a:.1f}]\"),\n",
    "]\n",
    "table_df = pd.DataFrame(rows, columns=[\"Metric\", \"Value\"])\n",
    "\n",
    "foot = \"CIs for macro AP via bootstrap over seeds (B=1000). EPR CIs via bootstrap over seeds.\"\n",
    "\n",
    "fig = _table_figure_two_cols(table_df, \"T3 — Summary (seeds, robustness, empty-rate; TEST)\", footnote=foot)\n",
    "\n",
    "# ------------------------------- SAVE -----------------------------------------\n",
    "png_path = OUT_DIR / \"T3_summary.png\"\n",
    "pdf_path = OUT_DIR / \"T3_summary.pdf\"  # optional; comment if PNG-only\n",
    "fig.savefig(png_path, bbox_inches=\"tight\")\n",
    "fig.savefig(pdf_path, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"Saved:\\n - {png_path}\\n - {pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae80a2c",
   "metadata": {},
   "source": [
    "## RQ4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a01afebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Split] train.npy  N=6265  L=12  observed=62450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:44:38] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F8] Label=NR-ER  TP_idx=6262  FP_idx=2594  thr=0.480\n",
      "\n",
      "✅ RQ4 complete.\n",
      "• Attention NPZs → D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ4\\attention\n",
      "• F8 figures → D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ4\\F8\n",
      "• T4 tables → D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\v7\\v7_Eval\\RQ4\\T4\n"
     ]
    }
   ],
   "source": [
    "# RQ4 — Token→Atom Cross-Attention Extraction, F8 Heatmaps, T4 Error Analysis (final, safe API)\n",
    "from __future__ import annotations\n",
    "import json, math, io\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ========= config =========\n",
    "SPLIT_NAME = \"train.npy\"  # TEST split per your setup\n",
    "TOP_K_ERRORS = 50         # per assay, top FP/FN to mine motifs\n",
    "EXAMPLE_ASSAYS = [\"NR-ER\", \"SR-p53\", \"SR-HSE\", \"NR-PPAR-gamma\"]  # try these first for F8 TP/FP\n",
    "HEAD_REDUCTION = \"mean\"   # aggregate heads for rendering: \"mean\" or \"max\"\n",
    "\n",
    "# ========= IO helpers =========\n",
    "def wtxt(p: Path, s: str): p.parent.mkdir(parents=True, exist_ok=True); p.write_text(s, encoding=\"utf-8\")\n",
    "def wjson(p: Path, o: dict): p.parent.mkdir(parents=True, exist_ok=True); p.write_text(json.dumps(o, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "def wnpz(p: Path, **kw): p.parent.mkdir(parents=True, exist_ok=True); np.savez_compressed(p, **kw)\n",
    "\n",
    "def detect_v7() -> Path:\n",
    "    cwd = Path(\".\").resolve()\n",
    "    if (cwd/\"data\").exists() and (cwd/\"model\").exists() and cwd.name == \"v7\": return cwd\n",
    "    if (cwd/\"v7\"/\"data\").exists(): return (cwd/\"v7\").resolve()\n",
    "    return cwd\n",
    "\n",
    "V7 = detect_v7()\n",
    "PREP = V7/\"data\"/\"prepared\"\n",
    "SPL  = V7/\"data\"/\"splits\"\n",
    "MOD  = V7/\"model\"\n",
    "ENS  = MOD/\"ensembles\"\n",
    "CAL  = MOD/\"calibration\"\n",
    "CKPT = MOD/\"checkpoints\"/\"shared\"/\"best.pt\"\n",
    "\n",
    "OUT  = V7/\"v7_Eval\"/\"RQ4\"\n",
    "DIR_ATT  = OUT/\"attention\";   DIR_ATT.mkdir(parents=True, exist_ok=True)\n",
    "DIR_F8   = OUT/\"F8\";          DIR_F8.mkdir(parents=True, exist_ok=True)\n",
    "DIR_T4   = OUT/\"T4\";          DIR_T4.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ========= dataset & labels =========\n",
    "mani = json.loads((PREP/\"dataset_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "LABELS: List[str] = mani[\"labels\"]; L = len(LABELS)\n",
    "DESC_IN_DIM = int(mani[\"n_features\"])\n",
    "label_to_idx = {lbl:i for i,lbl in enumerate(LABELS)}\n",
    "\n",
    "def load_split(split_name: str, prefer=(\"test.npz\",\"train.npz\",\"val.npz\")):\n",
    "    split_path = SPL/split_name\n",
    "    assert split_path.exists(), f\"Missing split: {split_path}\"\n",
    "    idx = np.load(split_path)\n",
    "    choice = None\n",
    "    for name in prefer:\n",
    "        p = PREP/name\n",
    "        if not p.exists(): continue\n",
    "        z = np.load(p, allow_pickle=True)\n",
    "        if \"indices\" in z and np.isin(idx, z[\"indices\"]).any():\n",
    "            choice = p; z.close(); break\n",
    "        z.close()\n",
    "    if choice is None:\n",
    "        for name in prefer:\n",
    "            p = PREP/name\n",
    "            if p.exists(): choice=p; break\n",
    "    Z = np.load(choice, allow_pickle=True)\n",
    "    Y_full = Z[\"Y\"].astype(float)\n",
    "    OBS_full = (~Z[\"y_missing_mask\"].astype(bool)) if \"y_missing_mask\" in Z else ~np.isnan(Y_full)\n",
    "    smiles_full = list(Z[\"smiles\"]); X_full = Z[\"X\"].astype(np.float32)\n",
    "    if \"indices\" in Z:\n",
    "        pos = pd.Series(np.arange(len(Z[\"indices\"])), index=Z[\"indices\"]).reindex(idx)\n",
    "        order = pos.astype(int).to_numpy()\n",
    "    else:\n",
    "        order = np.arange(len(idx))\n",
    "    Y = np.nan_to_num(Y_full[order], nan=0.0).astype(int)\n",
    "    OBS = OBS_full[order].astype(bool)\n",
    "    X = X_full[order]\n",
    "    SMI = np.array([smiles_full[i] for i in order], dtype=object)\n",
    "    return Y, OBS, X, SMI\n",
    "\n",
    "Yt, Mt, Xt, SMt = load_split(SPLIT_NAME)\n",
    "N = Yt.shape[0]\n",
    "print(f\"[Split] {SPLIT_NAME}  N={N}  L={L}  observed={int(Mt.sum())}\")\n",
    "\n",
    "# ========= model (Phase-5), with attention export (ALWAYS returns (fused_tokens, attn_w)) =========\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ChemBERTaEncoder(nn.Module):\n",
    "    def __init__(self, ckpt_name=\"seyonec/ChemBERTa-zinc-base-v1\", fusion_dim=256, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(ckpt_name)\n",
    "        self.backbone  = AutoModel.from_pretrained(ckpt_name)\n",
    "        self.proj = nn.Sequential(nn.Dropout(dropout_p), nn.Linear(self.backbone.config.hidden_size, fusion_dim))\n",
    "        self.ln = nn.LayerNorm(fusion_dim)\n",
    "    def forward_tokens(self, smiles_list: List[str], max_length=256, add_special_tokens=True):\n",
    "        enc = self.tokenizer(list(smiles_list), padding=True, truncation=True,\n",
    "                             max_length=max_length, add_special_tokens=add_special_tokens, return_tensors=\"pt\")\n",
    "        input_ids, attention_mask = enc[\"input_ids\"].to(device), enc[\"attention_mask\"].to(device)\n",
    "        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state  # (B,L,H)\n",
    "        toks = self.ln(self.proj(out))  # (B,L,256)\n",
    "        return toks, attention_mask.to(dtype=torch.int32), enc\n",
    "    def decode_tokens(self, enc_dict, i: int) -> List[str]:\n",
    "        ids = enc_dict[\"input_ids\"][i].tolist()\n",
    "        return self.tokenizer.convert_ids_to_tokens(ids)\n",
    "\n",
    "# 51-dim node features (exactly as trained)\n",
    "ATOM_LIST = [\"H\",\"C\",\"N\",\"O\",\"F\",\"P\",\"S\",\"Cl\",\"Br\",\"I\"]\n",
    "def _one_hot(v, choices):\n",
    "    z=[0]*len(choices)\n",
    "    if v in choices: z[choices.index(v)] = 1\n",
    "    return z\n",
    "def _bucket_oh(v, lo, hi):\n",
    "    buckets=list(range(lo,hi+1)); o=[0]*(len(buckets)+1); idx=v-lo\n",
    "    o[idx if 0 <= idx < len(buckets) else -1] = 1; return o\n",
    "def _atom_feat(atom):\n",
    "    hybs=[Chem.rdchem.HybridizationType.S, Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
    "          Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.SP3D, Chem.rdchem.HybridizationType.SP3D2]\n",
    "    chir=[Chem.rdchem.ChiralType.CHI_UNSPECIFIED, Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CW,\n",
    "          Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CCW, Chem.rdchem.ChiralType.CHI_OTHER]\n",
    "    sym=atom.GetSymbol()\n",
    "    feat=_one_hot(sym if sym in ATOM_LIST else \"other\", ATOM_LIST+[\"other\"])   # 11\n",
    "    feat+=_bucket_oh(atom.GetDegree(),0,5)                                     # +7 => 18\n",
    "    feat+=_bucket_oh(atom.GetFormalCharge(),-2,2)                              # +6 => 24\n",
    "    feat+=(_one_hot(atom.GetHybridization(), hybs)+[0])                        # +7 => 31\n",
    "    feat+=[int(atom.GetIsAromatic())]                                          # +1 => 32\n",
    "    feat+=[int(atom.IsInRing())]                                               # +1 => 33\n",
    "    feat+=_one_hot(atom.GetChiralTag(), chir)                                  # +4 => 37\n",
    "    feat+=_bucket_oh(atom.GetTotalNumHs(includeNeighbors=True),0,4)            # +6 => 43\n",
    "    feat+=_bucket_oh(atom.GetTotalValence(),0,5)                               # +7 => 50\n",
    "    feat+=[atom.GetMass()/200.0]                                               # +1 => 51\n",
    "    return feat\n",
    "def _smiles_to_graph(smi, max_nodes=128):\n",
    "    mol=Chem.MolFromSmiles(smi)\n",
    "    if mol is None or mol.GetNumAtoms()==0:\n",
    "        return np.zeros((0,0),np.float32), np.zeros((0,0),np.float32)\n",
    "    feats=[_atom_feat(mol.GetAtomWithIdx(i)) for i in range(mol.GetNumAtoms())]\n",
    "    if len(feats) and len(feats[0]) != 51:\n",
    "        raise RuntimeError(f\"Node feature dim drifted: got {len(feats[0])}, expected 51.\")\n",
    "    x=np.asarray(feats,dtype=np.float32)\n",
    "    Nn=mol.GetNumAtoms(); A=np.zeros((Nn,Nn),np.float32)\n",
    "    for b in mol.GetBonds():\n",
    "        i,j=b.GetBeginAtomIdx(), b.GetEndAtomIdx(); A[i,j]=1.0; A[j,i]=1.0\n",
    "    if Nn>max_nodes: x=x[:max_nodes]; A=A[:max_nodes,:max_nodes]\n",
    "    return x,A\n",
    "def _collate_graphs(smiles_batch, max_nodes=128):\n",
    "    gs=[_smiles_to_graph(s) for s in smiles_batch]\n",
    "    Nmax=max([g[0].shape[0] for g in gs]+[1])\n",
    "    F=gs[0][0].shape[1] if gs[0][0].size>0 else 51\n",
    "    B=len(gs)\n",
    "    X=np.zeros((B,Nmax,F),np.float32); A=np.zeros((B,Nmax,Nmax),np.float32); M=np.zeros((B,Nmax),np.int64)\n",
    "    for i,(x,a) in enumerate(gs):\n",
    "        n=x.shape[0]\n",
    "        if n==0: continue\n",
    "        X[i,:n,:]=x; A[i,:n,:n]=a; M[i,:n]=1\n",
    "    return torch.from_numpy(X).to(device), torch.from_numpy(A).to(device), torch.from_numpy(M).to(device)\n",
    "\n",
    "def masked_mean(x,m,dim):\n",
    "    m=m.to(dtype=x.dtype,device=x.device); d=m.sum(dim=dim,keepdim=True).clamp(min=1.0)\n",
    "    return (x*m.unsqueeze(-1)).sum(dim=dim)/d\n",
    "\n",
    "class CrossAttentionBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    SAFE API: ALWAYS returns (fused_tokens, attn_w)\n",
    "      - if return_attn=False => attn_w is None\n",
    "      - if return_attn=True  => attn_w shape = (B, H, L, N)\n",
    "    \"\"\"\n",
    "    def __init__(self, dim=256, n_heads=4, p=0.1):\n",
    "        super().__init__()\n",
    "        self.mha = nn.MultiheadAttention(dim, n_heads, dropout=p, batch_first=False)\n",
    "        self.ln  = nn.LayerNorm(dim)\n",
    "        self.do  = nn.Dropout(p)\n",
    "    def forward(self, text_tokens, text_mask, graph_nodes, graph_mask, return_attn=False):\n",
    "        Q = text_tokens.transpose(0,1)   # (L,B,D)\n",
    "        K = graph_nodes.transpose(0,1)   # (N,B,D)\n",
    "        V = graph_nodes.transpose(0,1)\n",
    "        kpm = (graph_mask == 0)          # (B,N)\n",
    "        if return_attn:\n",
    "            attn_out, attn_w = self.mha(Q, K, V, key_padding_mask=kpm, need_weights=True, average_attn_weights=False)  # attn_w: (B,H,L,N)\n",
    "        else:\n",
    "            attn_out = self.mha(Q, K, V, key_padding_mask=kpm, need_weights=False)[0]\n",
    "            attn_w = None\n",
    "        attn_out = attn_out.transpose(0,1)   # (B,L,D)\n",
    "        fused = self.ln(text_tokens + self.do(attn_out))\n",
    "        return fused, attn_w  # ALWAYS tuple\n",
    "\n",
    "class GINLayer(nn.Module):\n",
    "    def __init__(self,h=256,p=0.1): super().__init__(); self.eps=nn.Parameter(torch.tensor(0.0)); self.mlp=nn.Sequential(nn.Linear(h,h),nn.GELU(),nn.LayerNorm(h),nn.Dropout(p))\n",
    "    def forward(self,x,a,m): out=(1.0+self.eps)*x+torch.matmul(a,x); out=self.mlp(out); return out*m.unsqueeze(-1).to(out.dtype)\n",
    "\n",
    "class GraphGINEncoder(nn.Module):\n",
    "    def __init__(self,node_in_dim=51,hidden_dim=256,n_layers=4,p=0.1):\n",
    "        super().__init__(); self.inp=nn.Sequential(nn.Linear(node_in_dim,hidden_dim),nn.GELU(),nn.Dropout(p))\n",
    "        self.layers=nn.ModuleList([GINLayer(hidden_dim,p) for _ in range(n_layers)]); self.out_ln=nn.LayerNorm(hidden_dim)\n",
    "    def forward(self,smiles_list: List[str], max_nodes=128):\n",
    "        X,A,M=_collate_graphs(smiles_list,max_nodes=max_nodes); h=self.inp(X)\n",
    "        for lyr in self.layers: h=lyr(h,A,M)\n",
    "        return self.out_ln(h), M.to(dtype=torch.int32)\n",
    "\n",
    "class DescriptorMLP(nn.Module):\n",
    "    def __init__(self,in_dim,out_dim=256,hidden=256,p=0.1): super().__init__(); self.net=nn.Sequential(nn.Linear(in_dim,hidden),nn.GELU(),nn.Dropout(p),nn.Linear(hidden,out_dim),nn.GELU(),nn.Dropout(p))\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "class FusionClassifier(nn.Module):\n",
    "    def __init__(self,dim=256,n_labels=12,p=0.1): super().__init__(); self.mlp=nn.Sequential(nn.Linear(dim*3,dim*2),nn.GELU(),nn.Dropout(p),nn.Linear(dim*2,n_labels))\n",
    "    def forward(self,z): return self.mlp(z)\n",
    "\n",
    "class V7FusionModel(nn.Module):\n",
    "    def __init__(self, te, ge, desc_in_dim=208, dim=256, n_labels=12, n_heads=4, p=0.1):\n",
    "        super().__init__()\n",
    "        self.text_encoder=te; self.graph_encoder=ge\n",
    "        self.cross=CrossAttentionBlock(dim, n_heads, p)\n",
    "        self.desc_mlp=DescriptorMLP(desc_in_dim, dim, 256, p)\n",
    "        self.shared_head=FusionClassifier(dim, n_labels, p)\n",
    "    def forward(self, smiles_list, desc_feats, return_attn=False):\n",
    "        tt, tm, _enc = self.text_encoder.forward_tokens(smiles_list, max_length=256)\n",
    "        gn, gm = self.graph_encoder(smiles_list, max_nodes=128)\n",
    "        fused_tokens, attn_w = self.cross(tt.to(device), tm.to(device), gn.to(device), gm.to(device), return_attn=return_attn)\n",
    "        de  = self.desc_mlp(desc_feats.to(device))\n",
    "        text_pool  = masked_mean(fused_tokens, tm.to(device), 1)\n",
    "        graph_pool = masked_mean(gn.to(device),  gm.to(device), 1)\n",
    "        fused = torch.cat([text_pool, graph_pool, de], dim=-1)\n",
    "        logits = self.shared_head(fused)\n",
    "        return (logits, fused, tm, gm, _enc, attn_w) if return_attn else (logits, fused)\n",
    "\n",
    "# (Re)build & (re)load shared model — IMPORTANT: re-instantiate to use safe API\n",
    "text_enc = ChemBERTaEncoder().to(device)\n",
    "graph_enc= GraphGINEncoder().to(device)\n",
    "fusion = V7FusionModel(text_enc, graph_enc, desc_in_dim=DESC_IN_DIM, n_labels=L).to(device)\n",
    "ckpt = torch.load(CKPT, map_location=\"cpu\")\n",
    "fusion.load_state_dict(ckpt[\"model\"], strict=True)\n",
    "fusion.eval()\n",
    "\n",
    "def sigmoid(z): return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "@torch.no_grad()\n",
    "def fused_features(smiles: List[str], desc: np.ndarray, batch: int = 32) -> np.ndarray:\n",
    "    out=np.zeros((len(smiles),768),np.float32); off=0\n",
    "    for i in range(0,len(smiles),batch):\n",
    "        b_smi=smiles[i:i+batch]; b_desc=torch.tensor(desc[i:i+batch],dtype=torch.float32,device=device)\n",
    "        _, fused = fusion(b_smi, b_desc, return_attn=False)  # SAFE: returns (logits, fused)\n",
    "        out[off:off+len(b_smi)] = fused.detach().cpu().numpy(); off += len(b_smi)\n",
    "    return out\n",
    "\n",
    "@torch.no_grad()\n",
    "def shared_probs(FUSED: np.ndarray) -> np.ndarray:\n",
    "    out=np.zeros((FUSED.shape[0],L),np.float32)\n",
    "    for i in range(0,FUSED.shape[0],64):\n",
    "        x=torch.tensor(FUSED[i:i+64],dtype=torch.float32,device=device)\n",
    "        out[i:i+64]=fusion.shared_head(x).detach().cpu().numpy()\n",
    "    return sigmoid(out)\n",
    "\n",
    "# specialist heads (block* naming robust)\n",
    "class LabelHead(nn.Module):\n",
    "    def __init__(self, in_dim=768, h1=512, h2=256, h3=128, p=0.30):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(nn.Linear(in_dim,h1), nn.GELU(), nn.LayerNorm(h1), nn.Dropout(p))\n",
    "        self.block2 = nn.Sequential(nn.Linear(h1,h2),    nn.GELU(), nn.LayerNorm(h2), nn.Dropout(p))\n",
    "        self.block3 = nn.Sequential(nn.Linear(h2,h3),    nn.GELU(), nn.LayerNorm(h3), nn.Dropout(p))\n",
    "        self.out    = nn.Linear(h3,1)\n",
    "        self.short  = nn.Linear(in_dim,h3)\n",
    "    def forward(self, x):\n",
    "        z1=self.block1(x); z2=self.block2(z1); z3=self.block3(z2); z=z3+self.short(x); return self.out(z).squeeze(-1)\n",
    "\n",
    "def _remap_block_keys(sd: dict) -> dict:\n",
    "    out={}\n",
    "    for k,v in sd.items():\n",
    "        kk=k.replace(\"b1.\",\"block1.\").replace(\"b2.\",\"block2.\").replace(\"b3.\",\"block3.\")\n",
    "        kk=kk.replace(\"block_1.\",\"block1.\").replace(\"block_2.\",\"block2.\").replace(\"block_3.\",\"block3.\")\n",
    "        out[kk]=v\n",
    "    return out\n",
    "\n",
    "def load_best_head(label: str) -> nn.Module:\n",
    "    cands=[]\n",
    "    for sd in sorted((ENS/label).glob(\"seed*/\")):\n",
    "        mfile = sd/\"metrics.json\"\n",
    "        if mfile.exists():\n",
    "            try:\n",
    "                ap = float(json.loads(mfile.read_text()).get(\"best_ap\", float(\"nan\")))\n",
    "                cands.append((ap, sd))\n",
    "            except Exception:\n",
    "                pass\n",
    "    if not cands: raise FileNotFoundError(f\"No trained heads for label {label}\")\n",
    "    cands.sort(key=lambda x: (-1.0 if math.isnan(x[0]) else x[0]), reverse=True)\n",
    "    best_dir = cands[0][1]\n",
    "    ck = torch.load(best_dir/\"best.pt\", map_location=\"cpu\")\n",
    "    cfg = ck.get(\"config\", {\"in_dim\":768,\"h1\":512,\"h2\":256,\"h3\":128,\"dropout\":0.30})\n",
    "    head = LabelHead(cfg.get(\"in_dim\",768), cfg.get(\"h1\",512), cfg.get(\"h2\",256), cfg.get(\"h3\",128), cfg.get(\"dropout\",0.30)).to(device)\n",
    "    try:\n",
    "        head.load_state_dict(ck[\"model\"], strict=True)\n",
    "    except RuntimeError:\n",
    "        head.load_state_dict(_remap_block_keys(ck[\"model\"]), strict=True)\n",
    "    head.eval(); return head\n",
    "\n",
    "# temps & thresholds & alpha\n",
    "temps_spec   = json.loads((CAL/\"temps.json\").read_text(encoding=\"utf-8\"))\n",
    "temps_shared = json.loads((CAL/\"temps_shared.json\").read_text(encoding=\"utf-8\"))\n",
    "thr_blob = None\n",
    "for f in [\"thresholds_blend_v2.json\",\"thresholds_blend.json\"]:\n",
    "    p=CAL/f\n",
    "    if p.exists(): thr_blob=json.loads(p.read_text(encoding=\"utf-8\")); break\n",
    "assert thr_blob is not None, \"Missing thresholds_blend(_v2).json\"\n",
    "ALPHA = float(thr_blob.get(\"alpha\", 0.8))\n",
    "thr_map = thr_blob.get(\"thresholds\", {})\n",
    "\n",
    "# ===== predictions (specialist, shared, blend) =====\n",
    "FUSED = fused_features(SMt.tolist(), Xt, batch=32)\n",
    "P_shared = shared_probs(FUSED)  # NOTE: PR ranking invariant to temperature; use for blend term\n",
    "\n",
    "@torch.no_grad()\n",
    "def specialist_probs(FUSED: np.ndarray) -> np.ndarray:\n",
    "    out=np.zeros((N,L),np.float32)\n",
    "    for j,lbl in enumerate(LABELS):\n",
    "        head=load_best_head(lbl)\n",
    "        logits=[]\n",
    "        for i in range(0,N,64):\n",
    "            x=torch.tensor(FUSED[i:i+64],dtype=torch.float32,device=device)\n",
    "            logits.append(head(x).detach().cpu().numpy())\n",
    "        logits = np.concatenate(logits, axis=0)\n",
    "        T = max(float(temps_spec.get(lbl,1.0)),1e-3)\n",
    "        out[:,j] = 1.0/(1.0+np.exp(-logits/T))\n",
    "    return out\n",
    "\n",
    "P_spec  = specialist_probs(FUSED)\n",
    "P_blend = ALPHA*P_spec + (1.0-ALPHA)*P_shared\n",
    "\n",
    "# ===== attention extraction per molecule =====\n",
    "@torch.no_grad()\n",
    "def extract_token_atom_attention(smiles_list: List[str]):\n",
    "    desc = torch.zeros((len(smiles_list), DESC_IN_DIM), dtype=torch.float32, device=device)\n",
    "    logits, fused, tm, gm, enc, attn_w = fusion(smiles_list, desc, return_attn=True)\n",
    "    # attn_w: (B, H, L, N) or None\n",
    "    return attn_w, tm, gm, enc\n",
    "\n",
    "def head_reduce(attn: np.ndarray, mode: str = \"mean\"):\n",
    "    if mode == \"max\": return np.nanmax(attn, axis=0)\n",
    "    return np.nanmean(attn, axis=0)\n",
    "\n",
    "def render_heatmap_token_atom(attn_ln: np.ndarray, token_labels: List[str], atom_labels: List[str], out_png: Path, title: str):\n",
    "    plt.figure(figsize=(max(8, len(token_labels)*0.35), max(4, len(atom_labels)*0.35)))\n",
    "    plt.imshow(attn_ln, aspect='auto', interpolation='nearest')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Tokens\")\n",
    "    plt.ylabel(\"Atoms\")\n",
    "    plt.xticks(range(len(token_labels)), token_labels, rotation=90)\n",
    "    plt.yticks(range(len(atom_labels)), atom_labels)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png.with_suffix(\".png\"), dpi=200)\n",
    "    plt.savefig(out_png.with_suffix(\".pdf\"))\n",
    "    plt.close()\n",
    "\n",
    "def render_rdkit_atom_weights(smiles: str, atom_weights: np.ndarray, out_png: Path, title: str):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None: return\n",
    "    # normalize 0..1\n",
    "    w = np.array(atom_weights, dtype=float)\n",
    "    if np.nanmax(w) > 0:\n",
    "        w = (w - np.nanmin(w)) / (np.nanmax(w) - np.nanmin(w) + 1e-12)\n",
    "    else:\n",
    "        w = np.zeros_like(w)\n",
    "    # RDKit highlight radii proportional to attention\n",
    "    aw_radii = {i: float(0.3 + 0.7*w[i]) for i in range(min(mol.GetNumAtoms(), len(w)))}\n",
    "    img = Draw.MolToImage(mol, size=(600, 400),\n",
    "                          highlightAtoms=list(aw_radii.keys()),\n",
    "                          highlightAtomRadii=aw_radii)\n",
    "    img.save(str(out_png.with_suffix(\".png\")))\n",
    "    plt.figure(figsize=(6,4)); plt.imshow(img); plt.axis('off'); plt.title(title); plt.tight_layout()\n",
    "    plt.savefig(out_png.with_suffix(\".pdf\")); plt.close()\n",
    "\n",
    "# ===== pick TP / FP examples for F8 =====\n",
    "def pick_tp_fp_indices(label: str):\n",
    "    j = label_to_idx[label]\n",
    "    th = float(thr_map.get(label, {}).get(\"th_fbeta15\", 0.5))\n",
    "    y = Yt[:, j]; m = Mt[:, j]\n",
    "    p = P_blend[:, j]\n",
    "    valid = m\n",
    "    tps = np.where(valid & (y==1) & (p>=th))[0]\n",
    "    fps = np.where(valid & (y==0) & (p>=th))[0]\n",
    "    tp_idx = int(tps[np.argmax(p[tps])]) if tps.size>0 else None\n",
    "    fp_idx = int(fps[np.argmax(p[fps])]) if fps.size>0 else None\n",
    "    return tp_idx, fp_idx, th\n",
    "\n",
    "def first_available_tp_fp():\n",
    "    for lbl in EXAMPLE_ASSAYS + LABELS:\n",
    "        tp, fp, th = pick_tp_fp_indices(lbl)\n",
    "        if tp is not None and fp is not None:\n",
    "            return lbl, tp, fp, th\n",
    "    for lbl in EXAMPLE_ASSAYS + LABELS:\n",
    "        tp, fp, th = pick_tp_fp_indices(lbl)\n",
    "        if tp is not None or fp is not None:\n",
    "            return lbl, tp, fp, th\n",
    "    return LABELS[0], None, None, 0.5\n",
    "\n",
    "# ========= F8 generation =========\n",
    "label_F8, idx_tp, idx_fp, thr_used = first_available_tp_fp()\n",
    "print(f\"[F8] Label={label_F8}  TP_idx={idx_tp}  FP_idx={idx_fp}  thr={thr_used:.3f}\")\n",
    "\n",
    "def make_F8_for_index(i: int, label: str, tag: str):\n",
    "    smi = SMt[i]\n",
    "    attn_w, tm, gm, enc = extract_token_atom_attention([smi])\n",
    "    if attn_w is None:\n",
    "        raise RuntimeError(\"Attention weights are None — check CrossAttentionBlock need_weights=True path.\")\n",
    "    attn = attn_w[0].detach().cpu().numpy()  # [H,L,N]\n",
    "    tmask = tm[0].detach().cpu().numpy().astype(bool)\n",
    "    gmask = gm[0].detach().cpu().numpy().astype(bool)\n",
    "    attn_ln = head_reduce(attn, HEAD_REDUCTION)  # [L,N]\n",
    "    attn_ln = attn_ln * tmask[:,None] * gmask[None,:]\n",
    "    toks = text_enc.decode_tokens(enc, 0)\n",
    "    token_labels = [t for t,mz in zip(toks, tmask) if mz]\n",
    "    atom_labels  = [f\"a{i}\" for i in np.where(gmask)[0].tolist()]\n",
    "    attn_compact = attn_ln[tmask][:, gmask]\n",
    "    wnpz(DIR_ATT/f\"attn_{label}_{tag}_{i}.npz\",\n",
    "         smiles=smi, label=label, tokens=np.array(token_labels, dtype=object),\n",
    "         atom_idx=np.where(gmask)[0], attn=attn_compact.astype(np.float32))\n",
    "    render_heatmap_token_atom(attn_compact, token_labels, atom_labels, DIR_F8/f\"F8_{label}_{tag}_{i}_heatmap\", f\"F8 {label} {tag} — token→atom attention\")\n",
    "    atom_w = np.nan_to_num(attn_compact.sum(axis=0))\n",
    "    render_rdkit_atom_weights(smi, atom_w, DIR_F8/f\"F8_{label}_{tag}_{i}_rdkit\", f\"F8 {label} {tag} — atom attention overlay\")\n",
    "    meta = {\"smiles\": smi, \"label\": label, \"index\": int(i), \"threshold\": float(thr_used), \"prob\": float(P_blend[i, label_to_idx[label]]),\n",
    "            \"true_y\": int(Yt[i, label_to_idx[label]]), \"heads\": int(attn.shape[0]), \"tokens\": token_labels}\n",
    "    wjson(DIR_F8/f\"F8_{label}_{tag}_{i}.json\", meta)\n",
    "\n",
    "if idx_tp is not None:\n",
    "    make_F8_for_index(idx_tp, label_F8, \"TP\")\n",
    "if idx_fp is not None:\n",
    "    make_F8_for_index(idx_fp, label_F8, \"FP\")\n",
    "\n",
    "# ========= T4 — Error analysis: top FP/FN per assay with motif mining =========\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "def per_label_errors(label: str, topk=TOP_K_ERRORS):\n",
    "    j = label_to_idx[label]\n",
    "    y = Yt[:, j]; m = Mt[:, j]; p = P_blend[:, j]\n",
    "    th_f = float(thr_map.get(label, {}).get(\"th_fbeta15\", 0.5))\n",
    "    valid = m\n",
    "    fp_idx = np.where(valid & (y==0) & (p>=th_f))[0]\n",
    "    fps_ord = fp_idx[np.argsort(p[fp_idx])[::-1]][:topk]\n",
    "    fn_idx = np.where(valid & (y==1) & (p<th_f))[0]\n",
    "    fns_ord = fn_idx[np.argsort(p[fn_idx])[::-1]][:topk]\n",
    "    df_fp = pd.DataFrame({\"idx\": fps_ord, \"smiles\": SMt[fps_ord], \"prob\": p[fps_ord], \"true\": y[fps_ord]})\n",
    "    df_fn = pd.DataFrame({\"idx\": fns_ord, \"smiles\": SMt[fns_ord], \"prob\": p[fns_ord], \"true\": y[fns_ord]})\n",
    "    return df_fp, df_fn\n",
    "\n",
    "# illustrative SMARTS library\n",
    "TOX_SMARTS = {\n",
    "    \"nitro_aromatic\": \"[NX3](=O)=O\",\n",
    "    \"aniline\": \"Nc1ccccc1\",\n",
    "    \"epoxide\": \"C1OC1\",\n",
    "    \"aldehyde\": \"[CX3H1](=O)[#6]\",\n",
    "    \"michael_acceptor\": \"C=CC=O\",\n",
    "    \"hydrazine\": \"NN\",\n",
    "    \"isothiocyanate\": \"N=C=S\",\n",
    "    \"halogenated_alkane\": \"[F,Cl,Br,I]C([F,Cl,Br,I])([F,Cl,Br,I])[F,Cl,Br,I]\",\n",
    "}\n",
    "SMARTS_MOLS = {name: Chem.MolFromSmarts(s) for name,s in TOX_SMARTS.items()}\n",
    "\n",
    "def match_motifs(smiles: str) -> List[str]:\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None: return []\n",
    "    hits=[]\n",
    "    for name, q in SMARTS_MOLS.items():\n",
    "        if q is None: continue\n",
    "        if mol.HasSubstructMatch(q): hits.append(name)\n",
    "    return hits\n",
    "\n",
    "fp_rows=[]; fn_rows=[]\n",
    "for lbl in LABELS:\n",
    "    df_fp, df_fn = per_label_errors(lbl, TOP_K_ERRORS)\n",
    "    df_fp[\"label\"]=lbl; df_fn[\"label\"]=lbl\n",
    "    df_fp[\"motifs\"] = df_fp[\"smiles\"].apply(lambda s: \",\".join(match_motifs(s)))\n",
    "    df_fn[\"motifs\"] = df_fn[\"smiles\"].apply(lambda s: \",\".join(match_motifs(s)))\n",
    "    fp_rows.append(df_fp); fn_rows.append(df_fn)\n",
    "\n",
    "FP_ALL = pd.concat(fp_rows, ignore_index=True) if fp_rows else pd.DataFrame()\n",
    "FN_ALL = pd.concat(fn_rows, ignore_index=True) if fn_rows else pd.DataFrame()\n",
    "\n",
    "FP_ALL.to_csv(DIR_T4/\"T4_false_positives.csv\", index=False)\n",
    "FN_ALL.to_csv(DIR_T4/\"T4_false_negatives.csv\", index=False)\n",
    "\n",
    "def motif_summary(df: pd.DataFrame, kind: str):\n",
    "    if df.empty: return pd.DataFrame()\n",
    "    recs=[]\n",
    "    for lbl in LABELS:\n",
    "        sub = df[df[\"label\"]==lbl]\n",
    "        if sub.empty: continue\n",
    "        expl = sub.assign(m=sub[\"motifs\"].str.split(\",\")).explode(\"m\")\n",
    "        expl = expl[expl[\"m\"].fillna(\"\").ne(\"\")]\n",
    "        counts = expl[\"m\"].value_counts().to_dict()\n",
    "        total = int(sub.shape[0])\n",
    "        for m, c in counts.items():\n",
    "            recs.append({\"label\": lbl, \"type\": kind, \"motif\": m, \"count\": int(c), \"rate\": (c/total if total>0 else 0.0)})\n",
    "    return pd.DataFrame(recs)\n",
    "\n",
    "SUM_FP = motif_summary(FP_ALL, \"FP\")\n",
    "SUM_FN = motif_summary(FN_ALL, \"FN\")\n",
    "SUM = pd.concat([SUM_FP, SUM_FN], ignore_index=True) if not SUM_FP.empty or not SUM_FN.empty else pd.DataFrame()\n",
    "if not SUM.empty:\n",
    "    SUM.sort_values([\"label\",\"type\",\"count\"], ascending=[True, True, False], inplace=True)\n",
    "SUM.to_csv(DIR_T4/\"motifs_summary.csv\", index=False)\n",
    "\n",
    "md = []\n",
    "md.append(\"# RQ4 — Cross-Attention & Error Analysis\")\n",
    "md.append(f\"- Split: `{SPLIT_NAME}`; Inference: **blend** (α={ALPHA:.2f}); thresholds from VAL (`th_fβ=1.5`).\")\n",
    "md.append(\"- F8: token→atom heatmaps + RDKit overlays for 1 TP and 1 FP (if available).\")\n",
    "if idx_tp is not None: md.append(f\"  - TP example: label={label_F8}, idx={idx_tp}\")\n",
    "if idx_fp is not None: md.append(f\"  - FP example: label={label_F8}, idx={idx_fp}\")\n",
    "md.append(\"- T4: `T4_false_positives.csv`, `T4_false_negatives.csv`, `motifs_summary.csv` (simple SMARTS library).\")\n",
    "wtxt(OUT/\"README.md\", \"\\n\".join(md))\n",
    "\n",
    "print(\"\\n✅ RQ4 complete.\")\n",
    "print(\"• Attention NPZs →\", DIR_ATT)\n",
    "print(\"• F8 figures →\", DIR_F8)\n",
    "print(\"• T4 tables →\", DIR_T4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lord",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
