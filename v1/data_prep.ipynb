{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98719ccb",
   "metadata": {},
   "source": [
    "# objective is to prepare our data from step 0 to step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e09ea38",
   "metadata": {},
   "source": [
    "## step 0 \n",
    "\n",
    "**AIM:** \n",
    "* Multilabel classification with 3 specific ADE targets.\n",
    "* Input = SMILES; Output = 3 binary labels.\n",
    "\n",
    "**Specifying our label columns:**\n",
    "* label_Gastrointestinal disorders\n",
    "* label_Infections and infestations\n",
    "* label_Nervous system disorders\n",
    "\n",
    "**we need to Ensure input column (smiles) exists and is clean, thus:**\n",
    "\n",
    "* Remove rows with missing or malformed SMILES.\n",
    "\n",
    "\n",
    "**Inspect label distributions (class balance preview):**\n",
    "* helps later with class weighting and threshold tuning.\n",
    "\n",
    "\n",
    "**NOTE:** we are dropping everything else from the DataFrame, as they are not needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f2e2d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Processing TRAIN set...\n",
      "‚úÖ Rows after cleaning: 12419\n",
      "Label distribution:\n",
      " label_Gastrointestinal disorders     4683\n",
      "label_Infections and infestations    3303\n",
      "label_Nervous system disorders       4206\n",
      "dtype: uint64\n",
      "üìÅ Saved to: Data\\clean\\clean_train.csv\n",
      "\n",
      "üîπ Processing VAL set...\n",
      "‚úÖ Rows after cleaning: 1518\n",
      "Label distribution:\n",
      " label_Gastrointestinal disorders     629\n",
      "label_Infections and infestations    410\n",
      "label_Nervous system disorders       514\n",
      "dtype: uint64\n",
      "üìÅ Saved to: Data\\clean\\clean_val.csv\n",
      "\n",
      "üîπ Processing TEST set...\n",
      "‚úÖ Rows after cleaning: 1260\n",
      "Label distribution:\n",
      " label_Gastrointestinal disorders     513\n",
      "label_Infections and infestations    367\n",
      "label_Nervous system disorders       522\n",
      "dtype: uint64\n",
      "üìÅ Saved to: Data\\clean\\clean_test.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define input/output paths\n",
    "input_dir = Path(\"Data/CT-ADE-SOC\")\n",
    "output_dir = Path(\"Data/clean\")\n",
    "\n",
    "# Target label columns to keep\n",
    "target_cols = [\n",
    "    \"label_Gastrointestinal disorders\",\n",
    "    \"label_Infections and infestations\",\n",
    "    \"label_Nervous system disorders\"\n",
    "]\n",
    "\n",
    "# Input and output mapping\n",
    "file_map = {\n",
    "    \"train\": (\"train.csv\", \"clean_train.csv\"),\n",
    "    \"val\": (\"val.csv\", \"clean_val.csv\"),\n",
    "    \"test\": (\"test.csv\", \"clean_test.csv\")\n",
    "}\n",
    "\n",
    "# Process each file\n",
    "for split_name, (in_file, out_file) in file_map.items():\n",
    "    print(f\"\\nüîπ Processing {split_name.upper()} set...\")\n",
    "    \n",
    "    # Load and filter\n",
    "    df = pd.read_csv(input_dir / in_file)\n",
    "    df = df[['smiles'] + target_cols]\n",
    "    df = df.dropna(subset=['smiles']).reset_index(drop=True)\n",
    "    df[target_cols] = df[target_cols].astype('uint8')\n",
    "\n",
    "    # Basic stats\n",
    "    print(f\"‚úÖ Rows after cleaning: {len(df)}\")\n",
    "    print(\"Label distribution:\\n\", df[target_cols].sum())\n",
    "\n",
    "    # Save cleaned file\n",
    "    df.to_csv(output_dir / out_file, index=False)\n",
    "    print(f\"üìÅ Saved to: {output_dir / out_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e3fe1",
   "metadata": {},
   "source": [
    "## Step 1:\n",
    "\n",
    "* Load every cleaned split from Data/clean/.\n",
    "\n",
    "* Drop ‚Äúall-zero‚Äù rows:, why? \n",
    "If a compound has none of the three labels, it doesn't help the classifier unless you need extra negatives. We‚Äôll drop them now for a more balanced training set.\n",
    "\n",
    "\n",
    "* Compute label counts per split ‚Äî needed later for pos_weight in the loss.\n",
    "\n",
    "* Persist curated files to Data/interim/ for downstream tokenisation.\n",
    "\n",
    "* Save a YAML or JSON summary of the label statistics so you never lose track.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f0ef74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TRAIN saved to Data\\interim\\ade_3lbl_train.csv  (6542 rows)\n",
      "‚úÖ VAL saved to Data\\interim\\ade_3lbl_val.csv  (803 rows)\n",
      "‚úÖ TEST saved to Data\\interim\\ade_3lbl_test.csv  (710 rows)\n",
      "\n",
      "üìä Label stats written to Data\\interim\\label_stats.yaml\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# Paths\n",
    "clean_dir = Path(\"Data/clean\")          # input from Step 0\n",
    "interim_dir = Path(\"Data/interim\")\n",
    "interim_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "splits = {\n",
    "    \"train\": \"clean_train.csv\",\n",
    "    \"val\":   \"clean_val.csv\",\n",
    "    \"test\":  \"clean_test.csv\"\n",
    "}\n",
    "\n",
    "target_cols = [\n",
    "    \"label_Gastrointestinal disorders\",\n",
    "    \"label_Infections and infestations\",\n",
    "    \"label_Nervous system disorders\"\n",
    "]\n",
    "\n",
    "stats = {}  # hold label counts for YAML summary\n",
    "\n",
    "for split, fname in splits.items():\n",
    "    df = pd.read_csv(clean_dir / fname)\n",
    "\n",
    "    # 1Ô∏è‚É£  Remove rows where all three labels are zero\n",
    "    mask_nonzero = df[target_cols].sum(axis=1) > 0\n",
    "    dropped = len(df) - mask_nonzero.sum()\n",
    "    df = df[mask_nonzero].reset_index(drop=True)\n",
    "\n",
    "    # 2Ô∏è‚É£  Capture label counts\n",
    "    label_counts = df[target_cols].sum().to_dict()\n",
    "    stats[split] = {\n",
    "        \"rows_after_drop\": len(df),\n",
    "        \"rows_dropped_all_zero\": int(dropped),\n",
    "        \"label_counts\": {k: int(v) for k, v in label_counts.items()}\n",
    "    }\n",
    "\n",
    "    # 3Ô∏è‚É£  Save curated split\n",
    "    out_path = interim_dir / f\"ade_3lbl_{split}.csv\"\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"‚úÖ {split.upper()} saved to {out_path}  ({len(df)} rows)\")\n",
    "\n",
    "# 4Ô∏è‚É£  Persist stats for future reference\n",
    "with open(interim_dir / \"label_stats.yaml\", \"w\") as fp:\n",
    "    yaml.dump(stats, fp, default_flow_style=False)\n",
    "\n",
    "print(\"\\nüìä Label stats written to\", interim_dir / \"label_stats.yaml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c93040",
   "metadata": {},
   "source": [
    "## Step 2: \n",
    "\n",
    "* Load curated CSVs from Data/interim/ade_3lbl_{train,val,test}.csv.\n",
    "\n",
    "* Initialise ChemBERTa tokenizer\n",
    "\n",
    "* Model: seyonec/ChemBERTa-zinc-250k-pubchem-1m.\n",
    "\n",
    "* Parameters: max_length = 128, padding='max_length', truncation=True.\n",
    "\n",
    "* Convert SMILES to token IDs (input_ids, optional attention_mask if desired).\n",
    "\n",
    "* Extract label matrix (y = N √ó 3, dtype uint8).\n",
    "\n",
    "* Save arrays to Data/processed/\n",
    "\n",
    "* X_train.npy, y_train.npy, X_val.npy, y_val.npy, X_test.npy, y_test.npy.\n",
    "\n",
    "* Optionally save attn_train.npy, etc. for attention masks.\n",
    "\n",
    "* Log shapes so you can sanity-check later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a58e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\god\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Amir\\.cache\\huggingface\\hub\\models--seyonec--ChemBERTa_zinc250k_v2_40k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Tokenising TRAIN set ‚Ä¶\n",
      "‚úÖ Saved: X_train.npy   (6542, 128)\n",
      "‚úÖ Saved: y_train.npy   (6542, 3)\n",
      "‚úÖ Saved: attn_train.npy (6542, 128)\n",
      "\n",
      "üîπ Tokenising VAL set ‚Ä¶\n",
      "‚úÖ Saved: X_val.npy   (803, 128)\n",
      "‚úÖ Saved: y_val.npy   (803, 3)\n",
      "‚úÖ Saved: attn_val.npy (803, 128)\n",
      "\n",
      "üîπ Tokenising TEST set ‚Ä¶\n",
      "‚úÖ Saved: X_test.npy   (710, 128)\n",
      "‚úÖ Saved: y_test.npy   (710, 3)\n",
      "‚úÖ Saved: attn_test.npy (710, 128)\n",
      "\n",
      "üìÅ All processed tensors now reside in D:\\Coding Projects\\Predicting-Drug-Response-Using-Multi-Omics-Data-with-XAI\\Data\\processed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# --- Config ---\n",
    "interim_dir   = Path(\"Data/interim\")\n",
    "processed_dir = Path(\"Data/processed\")\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "target_cols = [\n",
    "    \"label_Gastrointestinal disorders\",\n",
    "    \"label_Infections and infestations\",\n",
    "    \"label_Nervous system disorders\"\n",
    "]\n",
    "\n",
    "# üîÑ  Using the open-access checkpoint\n",
    "model_name = \"seyonec/ChemBERTa_zinc250k_v2_40k\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name, trust_remote_code=False)\n",
    "\n",
    "max_len = 128  # keep sequences short for speed\n",
    "\n",
    "for split in splits:\n",
    "    print(f\"\\nüîπ Tokenising {split.upper()} set ‚Ä¶\")\n",
    "\n",
    "    # 1) Load curated CSV\n",
    "    df = pd.read_csv(interim_dir / f\"ade_3lbl_{split}.csv\")\n",
    "\n",
    "    # 2) Tokenise SMILES strings\n",
    "    toks = tokenizer(\n",
    "        df[\"smiles\"].tolist(),\n",
    "        max_length=max_len,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"np\"\n",
    "    )\n",
    "\n",
    "    X     = toks[\"input_ids\"].astype(np.int32)     # (N, 128)\n",
    "    attn  = toks[\"attention_mask\"].astype(np.int8) # (N, 128) OPTIONAL\n",
    "    y     = df[target_cols].values.astype(np.uint8)# (N, 3)\n",
    "\n",
    "    # 3) Save arrays\n",
    "    np.save(processed_dir / f\"X_{split}.npy\",     X)\n",
    "    np.save(processed_dir / f\"y_{split}.npy\",     y)\n",
    "    np.save(processed_dir / f\"attn_{split}.npy\",  attn)  # drop if not used\n",
    "\n",
    "    print(f\"‚úÖ Saved: X_{split}.npy   {X.shape}\")\n",
    "    print(f\"‚úÖ Saved: y_{split}.npy   {y.shape}\")\n",
    "    print(f\"‚úÖ Saved: attn_{split}.npy {attn.shape}\")\n",
    "\n",
    "print(\"\\nüìÅ All processed tensors now reside in\", processed_dir.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd449283",
   "metadata": {},
   "source": [
    "## step 3: \n",
    "\n",
    "**Load tensors**\n",
    "\n",
    "* X_train.npy, y_train.npy, attn_train.npy (and corresponding val).\n",
    "* Shapes: X = (N, 128) token IDs, attn = (N, 128) masks, y = (N, 3). (it's in the code above)\n",
    "\n",
    "**Compute class weights (to fight imbalance)**\n",
    "\n",
    "* For each label: pos_weight = (N ‚àí pos) / pos.\n",
    "* Feed into BCEWithLogitsLoss.\n",
    "\n",
    "**Build model**\n",
    "\n",
    "* Base: seyonec/ChemBERTa_zinc250k_v2_40k. it's our base line, could use other ones too\n",
    "* Replace head with nn.Linear(hidden_size, 3), followed by sigmoid at inference.\n",
    "\n",
    "**Training hyper-params**\n",
    "\n",
    "* LR = 3 e-5, batch = 32, epochs = 5‚Äì8, weight-decay = 0.01.\n",
    "* Scheduler: cosine with 10 % warm-up steps.\n",
    "* Metric: per-label F1 + ‚Äúnone-positive‚Äù accuracy (all logits < thr).\n",
    "\n",
    "**Validation each epoch**\n",
    "\n",
    "* Track loss + macro F1; early-stop if no improvement ‚â• 2 epochs.\n",
    "\n",
    "**Save artefacts**\n",
    "\n",
    "* Best checkpoint ‚Üí models/chemberta_3lbl/.\n",
    "* Store config.json, pytorch_model.bin, tokenizer files.\n",
    "\n",
    "**(Optional) Threshold sweep on validation set (Step 4 later).**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e531d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce RTX 4070 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "317a8216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è  Using device: cuda\n",
      "Epoch 1 | val macro-F1=0.5534\n",
      "  ‚úÖ  New best, model saved.\n",
      "Epoch 2 | val macro-F1=0.6410\n",
      "  ‚úÖ  New best, model saved.\n",
      "Epoch 3 | val macro-F1=0.5882\n",
      "Epoch 4 | val macro-F1=0.6233\n",
      "  ‚èπÔ∏è  Early stop.\n",
      "\n",
      "üéØ  Best val macro-F1: 0.6410\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# ---------- Device ----------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"üñ•Ô∏è  Using device:\", device)\n",
    "\n",
    "# ---------- Data ----------\n",
    "proc_dir = Path(\"Data/processed\")\n",
    "X_train = np.load(proc_dir / \"X_train.npy\")\n",
    "y_train = np.load(proc_dir / \"y_train.npy\")\n",
    "attn_train = np.load(proc_dir / \"attn_train.npy\")\n",
    "\n",
    "X_val = np.load(proc_dir / \"X_val.npy\")\n",
    "y_val = np.load(proc_dir / \"y_val.npy\")\n",
    "attn_val = np.load(proc_dir / \"attn_val.npy\")\n",
    "\n",
    "to_t = lambda arr, dtype: torch.tensor(arr, dtype=dtype)\n",
    "\n",
    "train_ds = TensorDataset(\n",
    "    to_t(X_train, torch.long),  to_t(attn_train, torch.long),  to_t(y_train, torch.float32)\n",
    ")\n",
    "val_ds = TensorDataset(\n",
    "    to_t(X_val, torch.long),    to_t(attn_val, torch.long),    to_t(y_val, torch.float32)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False)\n",
    "\n",
    "# ---------- Model ----------\n",
    "model_name = \"seyonec/ChemBERTa_zinc250k_v2_40k\"\n",
    "base = AutoModel.from_pretrained(model_name)\n",
    "hidden = base.config.hidden_size\n",
    "classifier = nn.Linear(hidden, 3)\n",
    "\n",
    "class ChemClassifier(nn.Module):\n",
    "    def __init__(self, base, head):\n",
    "        super().__init__()\n",
    "        self.base = base\n",
    "        self.head = head\n",
    "    def forward(self, ids, attn):\n",
    "        out = self.base(input_ids=ids, attention_mask=attn)\n",
    "        cls = out.last_hidden_state[:, 0, :]          # CLS token\n",
    "        return self.head(cls)\n",
    "\n",
    "model = ChemClassifier(base, classifier).to(device)\n",
    "\n",
    "# ---------- Loss (with class weights) ----------\n",
    "pos = y_train.sum(axis=0)\n",
    "neg = len(y_train) - pos\n",
    "pos_weight = torch.tensor(neg / pos, dtype=torch.float32, device=device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# ---------- Optimizer & scheduler ----------\n",
    "optim = AdamW(model.parameters(), lr=3e-5, weight_decay=0.01)\n",
    "total_steps = len(train_loader) * 6\n",
    "sched = get_cosine_schedule_with_warmup(\n",
    "    optim, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# ---------- Training ----------\n",
    "best_f1, patience = 0, 0\n",
    "for epoch in range(1, 10):\n",
    "    model.train()\n",
    "    for ids, attn, labels in train_loader:\n",
    "        ids, attn, labels = ids.to(device), attn.to(device), labels.to(device)\n",
    "        loss = criterion(model(ids, attn), labels)\n",
    "        loss.backward()\n",
    "        optim.step(); sched.step(); optim.zero_grad()\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval(); p_all, y_all = [], []\n",
    "    with torch.no_grad():\n",
    "        for ids, attn, labels in val_loader:\n",
    "            ids, attn = ids.to(device), attn.to(device)\n",
    "            p_all.append(torch.sigmoid(model(ids, attn)).cpu())\n",
    "            y_all.append(labels)\n",
    "    preds = torch.cat(p_all).numpy()\n",
    "    gts   = torch.cat(y_all).numpy()\n",
    "    f1 = f1_score(gts, preds > 0.5, average=\"macro\")\n",
    "    print(f\"Epoch {epoch} | val macro-F1={f1:.4f}\")\n",
    "\n",
    "    # ---- Early-stopping ----\n",
    "    if f1 > best_f1:\n",
    "        best_f1, patience = f1, 0\n",
    "        torch.save(model.state_dict(), \"models/chemberta_3lbl/pytorch_model.bin\")\n",
    "        print(\"  ‚úÖ  New best, model saved.\")\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience == 2:\n",
    "            print(\"  ‚èπÔ∏è  Early stop.\")\n",
    "            break\n",
    "\n",
    "print(f\"\\nüéØ  Best val macro-F1: {best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717f26e0",
   "metadata": {},
   "source": [
    "## Step 4:\n",
    "\n",
    "* Reload the best checkpoint (weights + tokenizer).\n",
    "\n",
    "* Run inference on the validation tensors to collect raw logits (before sigmoid).\n",
    "\n",
    "* Convert logits ‚Üí probabilities with sigmoid.\n",
    "\n",
    "* Sweep thresholds from 0.05 to 0.50 (step 0.01) for each label independently.\n",
    "    * Compute balanced accuracy = ¬Ω ( TPR + TNR ).\n",
    "    * Keep the threshold giving the highest balanced accuracy.\n",
    "\n",
    "* Persist thresholds to models/chemberta_3lbl/thresholds.json.\n",
    "\n",
    "* Quick report: print the chosen threshold and val metrics (F1, bal-acc) for each label.\n",
    "\n",
    "* These thresholds will be used at inference; if all three probs < their thresholds we return ‚Äúnone-of-three‚Äù."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fda41e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gastrointestinal  thr=0.48 | bal-acc=0.584 | F1=0.775\n",
      "Infections       thr=0.33 | bal-acc=0.593 | F1=0.673\n",
      "NervousSystem    thr=0.50 | bal-acc=0.523 | F1=0.685\n",
      "\n",
      "üíæ Thresholds saved to models\\chemberta_3lbl\\thresholds.json\n"
     ]
    }
   ],
   "source": [
    "import torch, json, numpy as np, torch.nn as nn\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
    "from transformers import AutoModel\n",
    "from pathlib import Path\n",
    "\n",
    "# --- paths ---\n",
    "proc_dir  = Path(\"Data/processed\")\n",
    "model_dir = Path(\"models/chemberta_3lbl\")\n",
    "ckpt_path = model_dir / \"pytorch_model.bin\"\n",
    "thresh_out = model_dir / \"thresholds.json\"\n",
    "\n",
    "# --- data ---\n",
    "X_val   = np.load(proc_dir / \"X_val.npy\")\n",
    "attn_val = np.load(proc_dir / \"attn_val.npy\")\n",
    "y_val   = np.load(proc_dir / \"y_val.npy\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- rebuild architecture exactly as during training ---\n",
    "base_name = \"seyonec/ChemBERTa_zinc250k_v2_40k\"\n",
    "base = AutoModel.from_pretrained(base_name)\n",
    "hidden = base.config.hidden_size\n",
    "classifier = nn.Linear(hidden, 3)\n",
    "class ChemClassifier(nn.Module):\n",
    "    def __init__(self, base, classifier):\n",
    "        super().__init__()\n",
    "        self.base = base\n",
    "        self.classifier = classifier\n",
    "    def forward(self, ids, attn):\n",
    "        cls = self.base(input_ids=ids, attention_mask=attn).last_hidden_state[:,0,:]\n",
    "        return self.classifier(cls)\n",
    "\n",
    "model = ChemClassifier(base, classifier).to(device)\n",
    "\n",
    "# --- load state dict, renaming head.* -> classifier.* ---\n",
    "state = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "if \"head.weight\" in state:\n",
    "    state[\"classifier.weight\"] = state.pop(\"head.weight\")\n",
    "    state[\"classifier.bias\"]   = state.pop(\"head.bias\")\n",
    "model.load_state_dict(state, strict=True)\n",
    "model.eval()\n",
    "\n",
    "# --- collect logits on val ---\n",
    "batch = 256\n",
    "logits = []\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(X_val), batch):\n",
    "        ids  = torch.tensor(X_val[i:i+batch], dtype=torch.long, device=device)\n",
    "        att  = torch.tensor(attn_val[i:i+batch], dtype=torch.long, device=device)\n",
    "        logits.append(model(ids, att).cpu())\n",
    "logits = torch.cat(logits).numpy()\n",
    "probs  = 1/(1+np.exp(-logits))\n",
    "\n",
    "# --- sweep thresholds ---\n",
    "thr_range = np.arange(0.05,0.51,0.01)\n",
    "best_thr, best_bal, best_f1 = [], [], []\n",
    "for c in range(3):\n",
    "    bal = [balanced_accuracy_score(y_val[:,c], probs[:,c]>=t) for t in thr_range]\n",
    "    f1  = [f1_score(y_val[:,c], probs[:,c]>=t)               for t in thr_range]\n",
    "    idx = int(np.argmax(bal))\n",
    "    best_thr.append(float(thr_range[idx])); best_bal.append(float(bal[idx])); best_f1.append(float(f1[idx]))\n",
    "\n",
    "labels = [\"Gastrointestinal\",\"Infections\",\"NervousSystem\"]\n",
    "json.dump({k:v for k,v in zip(labels,best_thr)}, open(thresh_out,\"w\"), indent=2)\n",
    "\n",
    "for l,t,ba,f in zip(labels,best_thr,best_bal,best_f1):\n",
    "    print(f\"{l:15s}  thr={t:.2f} | bal-acc={ba:.3f} | F1={f:.3f}\")\n",
    "print(\"\\nüíæ Thresholds saved to\", thresh_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a29825",
   "metadata": {},
   "source": [
    "## Step 5: \n",
    "\n",
    "* Reload the frozen ChemBERTa classifier (weights + classifier renaming trick).\n",
    "\n",
    "* Pick a compact background set for SHAP DeepExplainer\n",
    "    * Randomly select 100 diverse SMILES from train (stratified by label).\n",
    "\n",
    "* Build the SHAP explainer\n",
    "    * shap.DeepExplainer(model, background_embeddings) where\n",
    "      background_embeddings = base(**tokenised_bg).last_hidden_state[:,0,:].\n",
    "    * We pass embeddings instead of token IDs to cut compute time.\n",
    "\n",
    "* Batch-compute SHAP values for each split\n",
    "    * Loop over X_* tensors (batch 128).\n",
    "    * For each batch:\n",
    "        * Feed token IDs & masks ‚Üí logits.\n",
    "        * explainer.shap_values((ids, attn)) returns 3 √ó B √ó 128 arrays.\n",
    "    * Store alongside y_* and token IDs into .npz files: data/shap/shap_train.npz, shap_val.npz, shap_test.npz.\n",
    "\n",
    "**Memory tips** \n",
    "* Process on GPU but move finished SHAP arrays to CPU before saving.\n",
    "* Save in float16 (astype(np.float16)) to shrink disk usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf337302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ saved train: (3, 6542, 768)\n",
      "‚úÖ saved val: (3, 803, 768)\n",
      "‚úÖ saved test: (3, 710, 768)\n"
     ]
    }
   ],
   "source": [
    "import shap, torch, numpy as np\n",
    "from transformers import AutoModel\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# ---------------- paths ----------------\n",
    "proc_dir = Path(\"Data/processed\")\n",
    "shap_dir = Path(\"Data/shap_clean\"); shap_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ---------------- rebuild model ----------------\n",
    "base_name = \"seyonec/ChemBERTa_zinc250k_v2_40k\"\n",
    "base = AutoModel.from_pretrained(base_name)\n",
    "head = torch.nn.Linear(base.config.hidden_size, 3)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, b, h): super().__init__(); self.base, self.head = b, h\n",
    "    def forward(self, ids, att): return self.head(\n",
    "        self.base(input_ids=ids, attention_mask=att).last_hidden_state[:,0,:])\n",
    "\n",
    "model = Net(base, head)\n",
    "ckpt = torch.load(\"models/chemberta_3lbl/pytorch_model.bin\", map_location=\"cpu\")\n",
    "model.load_state_dict(ckpt, strict=False)\n",
    "model.eval().cuda()\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed(ids, att):\n",
    "    return base(input_ids=ids, attention_mask=att).last_hidden_state[:,0,:]\n",
    "\n",
    "# ---------------- background ----------------\n",
    "Xtr = np.load(proc_dir/\"X_train.npy\"); Att = np.load(proc_dir/\"attn_train.npy\")\n",
    "bg = embed(torch.tensor(Xtr[random.sample(range(len(Xtr)),100)],\n",
    "                        device=\"cuda\"),\n",
    "           torch.tensor(Att[random.sample(range(len(Xtr)),100)],\n",
    "                        device=\"cuda\"))\n",
    "explainer = shap.GradientExplainer(model.head, [bg])\n",
    "\n",
    "# ---------------- cache exactly (3,N,768) ----------------\n",
    "def cache(name):\n",
    "    ids = np.load(proc_dir/f\"X_{name}.npy\")\n",
    "    att = np.load(proc_dir/f\"attn_{name}.npy\")\n",
    "    y   = np.load(proc_dir/f\"y_{name}.npy\")\n",
    "\n",
    "    shap_full = np.empty((3, len(ids), 768), dtype=np.float16)  # pre-alloc\n",
    "    batch = 128; idx = 0\n",
    "    for start in range(0, len(ids), batch):\n",
    "        end = start + batch\n",
    "        emb = embed(torch.tensor(ids[start:end], device=\"cuda\"),\n",
    "                    torch.tensor(att[start:end], device=\"cuda\"))\n",
    "        sv  = explainer.shap_values([emb])          # list len=3, each (B,768)\n",
    "        for lbl in range(3):\n",
    "            shap_full[lbl, idx:idx+emb.size(0)] = sv[lbl].astype(np.float16)\n",
    "        idx += emb.size(0)\n",
    "\n",
    "    np.savez(shap_dir/f\"shap_{name}.npz\", shap=shap_full, y=y)\n",
    "    print(f\"‚úÖ saved {name}: {shap_full.shape}\")\n",
    "\n",
    "for split in [\"train\",\"val\",\"test\"]:\n",
    "    cache(split)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0143a836",
   "metadata": {},
   "source": [
    "## Step 6: \n",
    "\n",
    "* Normalise SHAP per sample\n",
    "    * For each label ‚Ñì, divide the |SHAP| vector by its L1 sum ‚Üí relative importance.\n",
    "\n",
    "* Select top-k CLS dimensions (k = 5)\n",
    "    * For every label pick the k indices with highest mean |SHAP| across train.\n",
    "    * Fix this index list so train/val/test line up.\n",
    "\n",
    "* Build feature matrix\n",
    "    * For every sample: concatenate the 3 labels √ó k values ‚Üí 15-dim vector.\n",
    "    * Shape after stack: Xmeta_train = (Ntrain, 15).\n",
    "\n",
    "**Save artefacts**\n",
    "* Data/meta/Xmeta_{split}.npy ‚Äì float32\n",
    "* Data/meta/ymeta_{split}.npy ‚Äì same y matrix (uint8)\n",
    "* Data/meta/topk_indices.json ‚Äì the 3 √ó k CLS dimension IDs.\n",
    "\n",
    "Why this works\n",
    "\n",
    "* CLS dims capture global chemical context; top-k dims act like high-level ‚Äútopics‚Äù.\n",
    "* The Meta-MLP learns consistent patterns across splits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31756cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ fixed train: (6542, 15)\n",
      "üîÑ fixed val: (803, 15)\n",
      "üîÑ fixed test: (710, 15)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "meta = Path(\"Data/meta\")\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    X = np.load(meta / f\"Xmeta_{split}.npy\")          # (5,  N√ó3)\n",
    "    y = np.load(meta / f\"ymeta_{split}.npy\")          # (N, 3)\n",
    "\n",
    "    if X.shape[0] == 5:                               # the ‚Äúwrong‚Äù layout\n",
    "        N = y.shape[0]                                # true sample count\n",
    "        X_fixed = X.T.reshape(N, 3, 5).reshape(N, 15) # (N,15)\n",
    "        np.save(meta / f\"Xmeta_{split}.npy\", X_fixed.astype(np.float32))\n",
    "        print(f\"üîÑ fixed {split}: {X_fixed.shape}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ {split} already OK: {X.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c575594b",
   "metadata": {},
   "source": [
    "## Step 7: \n",
    "\n",
    "* Standardise the 15-dim features (z-score) and persist the scaler (scaler.pkl).\n",
    "\n",
    "* Define a compact MLP: 15 ‚Üí 512 ‚Üí Dropout(0.2) ‚Üí 3 (sigmoid).\n",
    "\n",
    "* Use class-weighted BCEWithLogitsLoss to balance positives vs negatives.\n",
    "\n",
    "* Train for up to 100 epochs with early-stopping (patience = 10) on val macro-F1.\n",
    "\n",
    "* Save best weights to models/meta_mlp.pt plus the scaler for inference.\n",
    "\n",
    "* Report final val F1 and a quick test F1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d11726bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | val F1 = 0.499\n",
      "  ‚úÖ new best saved\n",
      "Epoch 002 | val F1 = 0.540\n",
      "  ‚úÖ new best saved\n",
      "Epoch 003 | val F1 = 0.586\n",
      "  ‚úÖ new best saved\n",
      "Epoch 004 | val F1 = 0.455\n",
      "Epoch 005 | val F1 = 0.578\n",
      "Epoch 006 | val F1 = 0.584\n",
      "Epoch 007 | val F1 = 0.539\n",
      "Epoch 008 | val F1 = 0.516\n",
      "Epoch 009 | val F1 = 0.508\n",
      "Epoch 010 | val F1 = 0.534\n",
      "Epoch 011 | val F1 = 0.549\n",
      "Epoch 012 | val F1 = 0.558\n",
      "Epoch 013 | val F1 = 0.545\n",
      "  ‚èπÔ∏è early stop\n",
      "\n",
      "üéØ best val F1: 0.586 | test F1: 0.604\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, torch, torch.nn as nn, pickle, os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- paths ----------\n",
    "meta_dir  = Path(\"Data/meta\")\n",
    "model_dir = Path(\"models\"); model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# ---------- load data ----------\n",
    "X_tr = np.load(meta_dir/\"Xmeta_train.npy\")\n",
    "y_tr = np.load(meta_dir/\"ymeta_train.npy\")\n",
    "X_va = np.load(meta_dir/\"Xmeta_val.npy\")\n",
    "y_va = np.load(meta_dir/\"ymeta_val.npy\")\n",
    "X_te = np.load(meta_dir/\"Xmeta_test.npy\")\n",
    "y_te = np.load(meta_dir/\"ymeta_test.npy\")\n",
    "\n",
    "# ---------- standardise ----------\n",
    "scaler = StandardScaler().fit(X_tr)\n",
    "X_tr = scaler.transform(X_tr).astype(np.float32)\n",
    "X_va = scaler.transform(X_va).astype(np.float32)\n",
    "X_te = scaler.transform(X_te).astype(np.float32)\n",
    "pickle.dump(scaler, open(model_dir/\"scaler.pkl\", \"wb\"))\n",
    "\n",
    "# ---------- tensors ----------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "to_t  = lambda x: torch.tensor(x, device=device)\n",
    "Xtr_t, ytr_t = to_t(X_tr), to_t(y_tr).float()\n",
    "Xva_t, yva_t = to_t(X_va), to_t(y_va).float()\n",
    "Xte_t, yte_t = to_t(X_te), to_t(y_te).float()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(Xtr_t, ytr_t),\n",
    "    batch_size=128, shuffle=True\n",
    ")\n",
    "\n",
    "# ---------- model ----------\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(15, 512),\n",
    "    nn.GELU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, 3)           # 3 explanation classes (one per ADE label for now)\n",
    ").to(device)\n",
    "\n",
    "# ---------- loss ----------\n",
    "pos = y_tr.sum(axis=0); neg = len(y_tr) - pos\n",
    "pos_weight = torch.tensor(neg/pos, dtype=torch.float32, device=device)\n",
    "criterion  = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "opt = torch.optim.AdamW(mlp.parameters(), lr=1e-3)\n",
    "\n",
    "# ---------- training ----------\n",
    "best_f1, patience = 0, 0\n",
    "for epoch in range(1, 101):\n",
    "    mlp.train()\n",
    "    for xb, yb in train_loader:\n",
    "        loss = criterion(mlp(xb), yb)\n",
    "        loss.backward(); opt.step(); opt.zero_grad()\n",
    "\n",
    "    mlp.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_va = torch.sigmoid(mlp(Xva_t)).cpu().numpy()\n",
    "    f1_va = f1_score(y_va, pred_va > 0.5, average=\"macro\")\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | val F1 = {f1_va:.3f}\")\n",
    "\n",
    "    if f1_va > best_f1:\n",
    "        best_f1, patience = f1_va, 0\n",
    "        torch.save(mlp.state_dict(), model_dir/\"meta_mlp.pt\")\n",
    "        print(\"  ‚úÖ new best saved\")\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience == 10:\n",
    "            print(\"  ‚èπÔ∏è early stop\")\n",
    "            break\n",
    "\n",
    "# ---------- quick test score ----------\n",
    "mlp.load_state_dict(torch.load(model_dir/\"meta_mlp.pt\"))\n",
    "mlp.eval()\n",
    "with torch.no_grad():\n",
    "    pred_te = torch.sigmoid(mlp(Xte_t)).detach().cpu().numpy()\n",
    "\n",
    "f1_te = f1_score(y_te, pred_te > 0.5, average=\"macro\")\n",
    "print(f\"\\nüéØ best val F1: {best_f1:.3f} | test F1: {f1_te:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a63fb6",
   "metadata": {},
   "source": [
    "## Step 8: Testing!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4743f4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction:\n",
      "  Gastrointestinal prob=0.543 ‚Üí POS (thr 0.48)\n",
      "  Infections      prob=0.350 ‚Üí POS (thr 0.33)\n",
      "  NervousSystem   prob=0.389 ‚Üí NEG (thr 0.50)\n",
      "\n",
      "Meta-explanations:\n",
      "  Gastrointestinal Moderate support (score 0.53)\n",
      "    ‚Ü≥ Moderate evidence. 'acidic_group' (ChEBI: ChEBI:30879) synergises with 'arylacetic_core' (MeSH: MeSH:D000894) in COX-1 inhibition √¢‚Ä†‚Äô √¢‚Ä†‚Äú prostaglandin √¢‚Ä†‚Äô GI mucosa irritation (Diclofenac; PMID 10542302).\n",
      "  Infections      Moderate support (score 0.50)\n",
      "    ‚Ü≥ Moderate evidence. 'glucocorticoid_core' (MeSH: MeSH:D005938) synergises with '11beta_OH' (: ) in Immunosuppression √¢‚Ä†‚Äô √¢‚Ä†‚Äò infection susceptibility (Prednisolone; PMID 31162841).\n",
      "  NervousSystem   Weak support    (score 0.40)\n",
      "    ‚Ü≥ Weak evidence. 'aromatic_amine' (MeSH: MeSH:D000608) synergises with 'trifluoromethyl' (ChEBI: ChEBI:51112) in Selective serotonin reuptake inhibition (Fluoxetine; PMID 33164745).\n"
     ]
    }
   ],
   "source": [
    "# ===== Interactive ADE Predictor with Ontology-Driven Explanations =====\n",
    "import torch, pickle, json, yaml, numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MolToSmiles\n",
    "import shap, warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 1.  Load artefacts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "base_name = \"seyonec/ChemBERTa_zinc250k_v2_40k\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_name)\n",
    "\n",
    "base  = AutoModel.from_pretrained(base_name)\n",
    "head  = torch.nn.Linear(base.config.hidden_size, 3)\n",
    "\n",
    "class ADEModel(torch.nn.Module):\n",
    "    def __init__(self, backbone, classifier):\n",
    "        super().__init__(); self.backbone, self.classifier = backbone, classifier\n",
    "    def forward(self, ids, attn):\n",
    "        cls = self.backbone(input_ids=ids,\n",
    "                            attention_mask=attn).last_hidden_state[:,0,:]\n",
    "        return self.classifier(cls)\n",
    "\n",
    "net = ADEModel(base, head)\n",
    "net.load_state_dict(torch.load(\"models/chemberta_3lbl/pytorch_model.bin\",\n",
    "                               map_location=\"cpu\"), strict=False)\n",
    "net.eval()\n",
    "\n",
    "thr_json = json.load(open(\"models/chemberta_3lbl/thresholds.json\"))\n",
    "thr_vec  = np.array([thr_json[\"Gastrointestinal\"],\n",
    "                     thr_json[\"Infections\"],\n",
    "                     thr_json[\"NervousSystem\"]], dtype=np.float32)\n",
    "\n",
    "scaler = pickle.load(open(\"models/scaler.pkl\",\"rb\"))\n",
    "topk   = json.load(open(\"Data/meta/topk_indices.json\"))\n",
    "\n",
    "meta_mlp = torch.nn.Sequential(\n",
    "    torch.nn.Linear(15,512), torch.nn.GELU(), torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(512,3)\n",
    ")\n",
    "meta_mlp.load_state_dict(torch.load(\"models/meta_mlp.pt\", map_location=\"cpu\"))\n",
    "meta_mlp.eval()\n",
    "\n",
    "# SHAP explainer (head wrt CLS embedding)\n",
    "proc = Path(\"Data/processed\")\n",
    "bg_ids  = np.load(proc/\"X_train.npy\")[:100]\n",
    "bg_attn = np.load(proc/\"attn_train.npy\")[:100]\n",
    "with torch.no_grad():\n",
    "    bg_emb = base(input_ids=torch.tensor(bg_ids),\n",
    "                  attention_mask=torch.tensor(bg_attn)).last_hidden_state[:,0,:]\n",
    "explainer = shap.GradientExplainer(head, [bg_emb])\n",
    "\n",
    "labels = [\"Gastrointestinal\",\"Infections\",\"NervousSystem\"]\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ NEW: load feature-ontology map ‚îÄ‚îÄ‚îÄ\n",
    "ont_map = yaml.safe_load(open(\"ontology_map.yaml\"))\n",
    "\n",
    "# helper to build contextual sentence\n",
    "def contextual_why(label:str, score:float)->str:\n",
    "    drug, info = next(iter(yaml.safe_load(open(\"explanatory_map.yaml\"))[label].items()))\n",
    "    f1, f2 = info[\"synergy\"]\n",
    "    pathway = info[\"pathway\"]; ref = info[\"reference\"]\n",
    "\n",
    "    # ontology look-ups for each feature\n",
    "    o1 = ont_map.get(f1, {})\n",
    "    o2 = ont_map.get(f2, {})\n",
    "    tag1 = f\"{o1.get('source','')}: {o1.get('id','')}\"\n",
    "    tag2 = f\"{o2.get('source','')}: {o2.get('id','')}\"\n",
    "\n",
    "    strength = (\"Strong evidence\" if score>0.7 else\n",
    "                \"Moderate evidence\" if score>0.5 else\n",
    "                \"Weak evidence\")\n",
    "\n",
    "    return (f\"{strength}. '{f1}' ({tag1}) synergises with '{f2}' ({tag2}) \"\n",
    "            f\"in {pathway} ({drug}; {ref}).\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 2.  feature vector ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def feature_vector(smiles:str):\n",
    "    tok = tokenizer(smiles, return_tensors=\"pt\", max_length=128,\n",
    "                    truncation=True, padding=\"max_length\")\n",
    "    with torch.no_grad():\n",
    "        emb = base(**tok).last_hidden_state[:,0,:]\n",
    "    sv = np.abs(np.stack(explainer.shap_values([emb]), axis=0))[:,0,:]\n",
    "    sv /= sv.sum(-1, keepdims=True)+1e-8\n",
    "    feat = np.concatenate([sv[l, topk[l]] for l in range(3)])\n",
    "    return scaler.transform(feat.reshape(1,-1)).astype(np.float32)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 3.  Main loop (unchanged) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "while True:\n",
    "    smi_input = input(\"\\nEnter SMILES (or 'q' to quit): \").strip()\n",
    "    if smi_input.lower()==\"q\": break\n",
    "    mol = Chem.MolFromSmiles(smi_input)\n",
    "    if mol is None:\n",
    "        print(\"‚ö†Ô∏è  Invalid SMILES.\"); continue\n",
    "    smi = MolToSmiles(mol)\n",
    "\n",
    "    tok = tokenizer(smi, return_tensors=\"pt\", max_length=128,\n",
    "                    truncation=True, padding=\"max_length\")\n",
    "    with torch.no_grad():\n",
    "        logits = net(tok[\"input_ids\"], tok[\"attention_mask\"]).numpy().squeeze()\n",
    "    probs = 1/(1+np.exp(-logits))\n",
    "    preds = (probs>=thr_vec).astype(int)\n",
    "\n",
    "    print(\"\\nPrediction:\")\n",
    "    for lab,p,pr,thr in zip(labels,preds,probs,thr_vec):\n",
    "        print(f\"  {lab:<15} prob={pr:.3f} ‚Üí {'POS' if p else 'NEG'} (thr {thr:.2f})\")\n",
    "\n",
    "    feats = feature_vector(smi)\n",
    "    with torch.no_grad():\n",
    "        scores = torch.sigmoid(meta_mlp(torch.tensor(feats))).numpy().squeeze()\n",
    "\n",
    "    print(\"\\nMeta-explanations:\")\n",
    "    shown=False\n",
    "    for lab,sc in zip(labels,scores):\n",
    "        if sc>0.3:\n",
    "            verdict=(\"Strong support\" if sc>0.7 else\n",
    "                     \"Moderate support\" if sc>0.5 else\n",
    "                     \"Weak support\")\n",
    "            print(f\"  {lab:<15} {verdict:15} (score {sc:.2f})\")\n",
    "            print(f\"    ‚Ü≥ {contextual_why(lab,sc)}\")\n",
    "            shown=True\n",
    "    if not shown:\n",
    "        print(\"  (none above 0.3)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "god",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
